(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{423:function(e,v,a){"use strict";a.r(v);var n=a(2),_=Object(n.a)({},(function(){var e=this,v=e._self._c;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("h2",{attrs:{id:"第一章-简历制作"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第一章-简历制作"}},[e._v("#")]),e._v(" 第一章：简历制作")]),e._v(" "),v("p",[v("strong",[e._v("1.1、如何写出一份牛X的简历")])]),e._v(" "),v("p",[e._v("对于互联网行业来说，一份优秀的简历，需要具备两个特点：")]),e._v(" "),v("p",[e._v("让招聘者看了很舒服，不会看了就想丢垃圾桶里。")]),e._v(" "),v("p",[e._v("让招聘者能很快看到自己想要看到的东⻄。")]),e._v(" "),v("p",[e._v("招聘者可能每天都需要看上百份，一份简历的查看时间可能是按秒计算，没那么多时间去从一堆垃圾信息中寻找亮")]),e._v(" "),v("p",[e._v("点，总结下来就两个词：简洁工整、突出重点。")]),e._v(" "),v("p",[e._v("1.1.1、简洁工整")]),e._v(" "),v("p",[e._v("简历整体排版上要工整、结构清晰，字体尽量保持一致。")]),e._v(" "),v("p",[e._v("⻚数不超过 2 ⻚，经验较少的 1 ⻚，较多的 2 ⻚，超过了，说明你肯定说废话了。")]),e._v(" "),v("p",[e._v("写完检查几遍，不要有错别字，这个会让招聘者觉得这个人不细心或者不重视。")]),e._v(" "),v("p",[e._v("白底黑字，不要有太多花里胡哨的颜色，在标题部分可以有一些色彩，但是不要太多，不要太刺眼。")]),e._v(" "),v("p",[e._v("保存时使用 PDF，这个细节很多人不知道，WORD 文档在不同设备上的格式排版可能会乱掉，导致根本没法")]),e._v(" "),v("p",[e._v("看，所以记得一定要用PDF。")]),e._v(" "),v("p",[e._v("1.1.2、突出重点")]),e._v(" "),v("p",[e._v("关键的信息可以放在显眼的位置、加粗、用较大的字号来突出体现等等，让招聘者能更容易看到。")]),e._v(" "),v("p",[e._v("无关紧要的内容不用写，简历不是比谁字数更多。一个比较简单的判断标准是：这个内容会让你看起来变得")]),e._v(" "),v("p",[e._v("牛吗，如果一点也不会，那就删了吧。")]),e._v(" "),v("p",[e._v("尽量使用总结性的话语概括而不是冗⻓的描述，可以参考 STAR 法则。简单来说就是：遇到了什么问题、怎")]),e._v(" "),v("p",[e._v("么解决的、带来了多少价值。")]),e._v(" "),v("p",[v("strong",[e._v("1.2、简历应该包含哪些模块")])]),e._v(" "),v("p",[e._v("一份标准的简历通常应该有以下几个模块：基本信息、教育背景、专业技能、工作和项目经历、自我评价。如果以")]),e._v(" "),v("p",[e._v("前有获得过一些荣誉，还有可以有个曾获荣誉。")]),e._v(" "),v("p",[e._v("1.2.1、基本信息")]),e._v(" "),v("p",[e._v("这一栏没啥好说的，放在简历第一栏，然后整⻬、完整的写好必要的信息就行了。")]),e._v(" "),v("p",[e._v("必要的几项：姓名、性别、出生年月、电话、邮箱、现居住地、期望工作地、工作年限。")]),e._v(" "),v("p",[e._v("BTW：")]),e._v(" "),v("p",[e._v("写上籍贯：说不定碰到老乡就放水了；")]),e._v(" "),v("p",[e._v("这一模块有一个容易有分歧的问题是：要不要放个人照片。")]),e._v(" "),v("p",[e._v("因为这一项并不是必须的，当一个选项不是必须的时候，你不放就不会给别人扣分的机会，如果你放了就给机会")]),e._v(" "),v("p",[e._v("了。当然，如果有老弟对自己的相貌非常自信的话，hr又通常是妹子，可以尝试放一下，说不定就加分了。")]),e._v(" "),v("p",[e._v("1 、熟练掌握计算机原理、操作系统、计算机网络、数据结构等基础知识。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("2 、具有扎实的 Java 基础，熟练掌握IO、集合、多线程、反射等基础框架，对集合、JUC有深入的研究。熟\n练掌握 JVM相关知识，对垃圾收集原理、常⻅的垃圾收集器有深入的研究，熟悉常用的JVM 参数、能进行\nJVM 问题处理与调优。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("3 、熟练掌握 Spring MVC、Spring、MyBatis、Spring Boot 等开源框架，对 Spring 源码和核心原理有深\n入的研究。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("4 、熟练掌握 SQL 和 MySQL 的核心原理，能进行 SQL 的优化与问题处理。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("5 、熟悉分布式系统的设计与应用，熟练掌握 Redis、Kafka、Zookeeper、Dubbo、TDDL、\nElasticsearch 的使用与核心原理。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("6 、熟悉设计模式原则，熟练掌握常用的设计模式 ∶∶ 模板、单例、代理、适配器、责任链等。\n")])])]),v("p",[e._v("1.2.2、教育背景")]),e._v(" "),v("p",[e._v("通常放在基本信息下面，每一段经历一行，也是整⻬、完整的写好必要的信息就行了。")]),e._v(" "),v("p",[e._v("从大学的经历写起，通常包含：时间、学校、专业即可。如果成绩优秀的可以将平均学分绩点啥的加上。")]),e._v(" "),v("p",[e._v("有些人会罗列自己学过的学科，什么高等数学、离散数学，这些其实就不用了，基本不会有人关心这个。")]),e._v(" "),v("p",[e._v("1.2.3、专业技能")]),e._v(" "),v("p",[e._v("专业技能是简历里比较关键的一项，这一栏的几个关键点：")]),e._v(" "),v("p",[e._v("1 ）罗列出你会的技能 ，例如HashMap、MySQL、JVM、Redis 等等。")]),e._v(" "),v("p",[e._v("2 ）你对该技能的掌握程度：了解、熟悉、熟练（掌握）、精通。这边精通最好慎用，否则面试官会很友好的像你\n“请教”一下你所精通的技能。")]),e._v(" "),v("p",[e._v("3 ）技能不是随便罗列，要分组，例如：IO、集合、多线程、反射这些可以放一行，都是属于 Java 基础。常⻅的\n分组有：计算机基础、Java基础、SSM框架、JVM、SQL、分布式和中间件、设计模式等。")]),e._v(" "),v("p",[e._v("4 ）全部内容最好控制在十行或者以内，太⻓了就容易没有重点。")]),e._v(" "),v("p",[e._v("5 ）突出亮点。对于亮点不多的同学来说，可以写的更细一点，看过哪些源码，可以直接写上去，例如：深入学习\n过 HashMap、ArrayList、LinkedList 等常用集合的源码。对于经验丰富亮点较多的同学来说，可以写的总结一\n点，例如：对常用的 JDK 源码有深入的研究。")]),e._v(" "),v("p",[e._v("6 ）非本岗位的相关技能，例如很常⻅的前端相关知识：Html、js、ajax 等。我觉得如果内容实在不多的话，可以\n写一下，但是如果内容已经很多了，那就可以不写了。")]),e._v(" "),v("p",[v("strong",[e._v("以下是 Java 常用的技术栈简单列了一个模板，如下：")])]),e._v(" "),v("p",[e._v("1.2.4、工作（项目）经历")]),e._v(" "),v("p",[e._v("简历里另外一个比较关键的一项，工作经历和项目经历可以写一起，按时间倒序，按公司分组。主要包含几个信")]),e._v(" "),v("p",[e._v("息：工作时间、公司名称、项目名称、担任的⻆色、项目背景、主要职责。")]),e._v(" "),v("p",[e._v("1 ）工作时间：正常写即可。")]),e._v(" "),v("p",[e._v("2 ）公司名称：这边有个重点，有的同学比较老实，会写合同上的公司名称，例如：上海拉扎斯信息科技有限公")]),e._v(" "),v("p",[e._v("司、北京三快在线科技有限公司、上海寻梦科技有限公司。这边其实没有必要，直接写公司更广为人知的名字即")]),e._v(" "),v("p",[e._v("可，例如：饿了么、美团、拼多多，不然万一有招聘者不知道被刷就亏大了。")]),e._v(" "),v("p",[e._v("3 ）项目名称：也是正常写就ok。")]),e._v(" "),v("p",[e._v("4 ）担任的⻆色：如果只是普通的开发者，可以写核心开发，如果是主要负责，则可以写XX模块负责人、XX域负责\n人、项目负责人。")]),e._v(" "),v("p",[e._v("5 ）项目背景：比较关键的一项信息，项目背景要尽量简短，最好不超过 2 行，并且又要能让招聘者看出你究竟做\n了个什么东⻄，同时还要尽量看起来牛X点。这个比较考验总结能力，可以多花点时间想想，然后可以让其他没有\n参与过该项目的同学模拟看一看是否能看得懂。")]),e._v(" "),v("p",[e._v("6 ） "),v("strong",[e._v("主要职责：本栏最重要的内容，内容可以是：做过的牛X需求、解决过的复杂问题等等。关键词还是：尽量简\n短、突出重点、STAR 法则。")])]),e._v(" "),v("p",[e._v("几个常⻅的样例如下，招聘者喜欢看到的点：")]),e._v(" "),v("p",[e._v("样例 1 ：参与XX项目从 0 到 1 的搭建，负责项目的架构设计、技术选型和整体环境搭建。")]),e._v(" "),v("p",[e._v("样例 2 ：引入了XX技术/框架，解决了XX问题，提升了XX指标50%。")]),e._v(" "),v("p",[e._v("样例 3 ：搭建XX工具，实现了XX功能的可视化、配置化、自动化（智能化）。")]),e._v(" "),v("p",[e._v("样例 4 ：沉淀了XX技术，复用到XX个部⻔/小组，提升了开发效率50%。")]),e._v(" "),v("p",[e._v("样例 5 ：负责系统整体的稳定性保障，使用隔离、熔断、降级、限流等，保障了系统可用性99.99%以上、XX指标\n99.99%以上。")]),e._v(" "),v("p",[e._v("样例 6 ：负责X个人的小团队，团队同学在部⻔表现突出，XX指标排名第 1 ，获得XX荣誉。")]),e._v(" "),v("p",[v("strong",[e._v("这一栏整体的排版如下：")])]),e._v(" "),v("p",[e._v("1.2.5、自我评价")]),e._v(" "),v("p",[e._v("自我评价主要要让招聘者更多的了解你这个人的优点，所以尽量写一些优秀的习惯、特质。跟工作不是很相关的、")]),e._v(" "),v("p",[e._v("比较日常的东⻄就不用写了，例如有同学写：喜欢打羽毛球、喜欢打篮球等等....就算了~。")]),e._v(" "),v("p",[e._v("可以展现自己的工作态度，例如：工作积极主动、工作效率高、责任心强、注重细节、追求完美。")]),e._v(" "),v("p",[e._v("可以展现自己的学习能力，例如：学习能力强、解决问题能力强，喜欢钻研技术，喜欢学习源码，经常利用业余时")]),e._v(" "),v("p",[e._v("间进行学习。")]),e._v(" "),v("p",[e._v("可以展现自己的思考和总结能力：能及时进行思考与总结，对相关知识进行沉淀与分享。")]),e._v(" "),v("p",[e._v("可以展现自己的团队精神：为人乐观大方，有很强的团队意识，乐于分享，乐于帮助别人，乐于与人沟通交流。")]),e._v(" "),v("h2",{attrs:{id:"第二章-java基础"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第二章-java基础"}},[e._v("#")]),e._v(" 第二章：Java基础")]),e._v(" "),v("p",[v("strong",[e._v("2.1、面向对象的三个基本特征？")])]),e._v(" "),v("p",[e._v("面向对象的三个基本特征是：封装、继承和多态。")]),e._v(" "),v("p",[e._v("继承：让某个类型的对象获得另一个类型的对象的属性和方法。继承就是子类继承父类的特征和行为，使得子类对")]),e._v(" "),v("p",[e._v("象（实例）具有父类的实例域和方法，或子类从父类继承方法，使得子类具有父类相同的行为。")]),e._v(" "),v("p",[e._v("封装：隐藏部分对象的属性和实现细节，对数据的访问只能通过外公开的接口。通过这种方式，对象对内部数据提")]),e._v(" "),v("p",[e._v("供了不同级别的保护，以防止程序中无关的部分意外的改变或错误的使用了对象的私有部分。")]),e._v(" "),v("p",[e._v("多态：对于同一个行为，不同的子类对象具有不同的表现形式。多态存在的 3 个条件： 1 ）继承； 2 ）重写； 3 ）父")]),e._v(" "),v("p",[e._v("类引用指向子类对象。")]),e._v(" "),v("p",[e._v("举个简单的例子：英雄联盟里面我们按下 Q 键这个动作：")]),e._v(" "),v("p",[e._v("对于亚索，就是斩钢闪")]),e._v(" "),v("p",[e._v("对于提莫，就是致盲吹箭")]),e._v(" "),v("p",[e._v("对于剑圣，就是阿尔法突袭")]),e._v(" "),v("p",[e._v("同一个事件发生在不同的对象上会产生不同的结果。")]),e._v(" "),v("p",[e._v("下面再举个简单的例子帮助大家理解，这个例子可能不是完全准确，但是依然是可以帮助我们理解的。")]),e._v(" "),v("p",[e._v("在这个例子中：")]),e._v(" "),v("p",[e._v("House 和 Cat 都是 Animal，所以他们都继承了 Animal，同时也从 Animal 继承了 sleep 这个行为。")]),e._v(" "),v("p",[e._v("但是针对 sleep 这个行为，House 和 Cat 进行了重写，有了不同的表现形式（实现），这个我们称为多态。")]),e._v(" "),v("p",[e._v("在 Cat 里，将 age 属性定义为 private，外界无法直接访问，要获取 Cat 的 age 信息只能通过 getAge 方法，从而\n对外隐藏了 age 属性，这个就叫做封装。当然，这边 age 只是个例子，实际使用中可能是一个复杂很多的对象。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class Animal { // 动物\npublic void sleep() {\nSystem.out.println("躺着睡");\n}\n}\nclass Horse extends Animal { // ⻢ 是一种动物\npublic void sleep() {\nSystem.out.println("站着睡");\n}\n}\nclass Cat extends Animal { // 猫 是一种动物\nprivate int age;\npublic int getAge() {\nreturn age + 1 ;\n}\n@Override\npublic void sleep() {\nSystem.out.println("四脚朝天的睡");\n}\n}\n')])])]),v("p",[v("strong",[e._v("2.2、访问修饰符public，private，protected，以及不写（default）时的区别？")])]),e._v(" "),v("p",[e._v("类的成员不写访问修饰符默认为default，默认对于同一个包的其他类相当于公开（public），对于不是同一个包\n的其他类相当于私有（private）。")]),e._v(" "),v("p",[e._v("受保护（protected）对子类相当于公开，对于不是同一个包没有父子关系的类相当于私有。")]),e._v(" "),v("p",[e._v("Java中，外部类的修饰符只能是public或默认，类的成员（包括内部类）的修饰符可以是以上四种。")]),e._v(" "),v("p",[v("strong",[e._v("2.3、下面两个代码块能正常编译和执行吗？")])]),e._v(" "),v("p",[e._v("代码块 1 编译报错，错误原因是：不兼容的类型: 从int转换到short可能会有损失”。")]),e._v(" "),v("p",[e._v("代码块 2 正常编译和执行。")]),e._v(" "),v("p",[e._v("我们将代码块 2 进行编译，字节码如下：")]),e._v(" "),v("p",[e._v("// 代码块 1")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("short s1 = 1 ; s1 = s1 + 1 ;\n// 代码块 2\nshort s1 = 1 ; s1 += 1 ;\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class com.joonwhee.open.demo.Convert {\npublic com.joonwhee.open.demo.Convert();\nCode:\n0 : aload_\n1 : invokespecial #1 // Method java/lang/Object."\\<init\\>":()V\n4 : return\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static void main(java.lang.String[]);\nCode:\n0 : iconst_1 // 将int类型值 1 入（操作数）栈\n1 : istore_1 // 将栈顶int类型值保存到局部变量 1 中\n2 : iload_1 // 从局部变量 1 中装载int类型值入栈\n3 : iconst_1 // 将int类型值 1 入栈\n4 : iadd // 将栈顶两int类型数相加，结果入栈\n5 : i2s // 将栈顶int类型值截断成short类型值，后带符号扩展成int类型值入栈。\n6 : istore_1 // 将栈顶int类型值保存到局部变量 1 中\n")])])]),v("p",[e._v("可以看到字节码中包含了 i2s 指令，该指令用于将 int 转成 short。i2s 是 int to short 的缩写。")]),e._v(" "),v("p",[e._v("其实，s1 += 1 相当于 s1 = (short)(s1 + 1)，有兴趣的可以自己编译下这两行代码的字节码，你会发现是一摸一样\n的。")]),e._v(" "),v("p",[e._v("说好的 Java 基础题，怎么又开始变态起来了？？？")]),e._v(" "),v("p",[e._v("2.4、基础考察，指出下题的输出结果")]),e._v(" "),v("p",[e._v("答案是：false，true。")]),e._v(" "),v("p",[e._v("执行 Integer a = 128，相当于执行：Integer a = Integer.valueOf(128)，基本类型自动转换为包装类的过程称为自\n动装箱（autoboxing）。")]),e._v(" "),v("p",[e._v("在 Integer 中引入了 IntegerCache 来缓存一定范围的值，IntegerCache 默认情况下范围为：-128~127。")]),e._v(" "),v("p",[e._v("本题中的 127 命中了 IntegerCache，所以 c 和 d 是相同对象，而 128 则没有命中，所以 a 和 b 是不同对象。")]),e._v(" "),v("p",[e._v("但是这个缓存范围时可以修改的，可能有些人不知道。可以通过JVM启动参数：-XX:AutoBoxCacheMax= 来修改\n上限值，如下图所示：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("7 : return\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static void main(String[] args) {\nInteger a = 128 , b = 128 , c = 127 , d = 127 ;\nSystem.out.println(a == b);\nSystem.out.println(c == d);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static Integer valueOf(int i) {\nif (i >= IntegerCache.low && i <= IntegerCache.high)\nreturn IntegerCache.cache[i + (-IntegerCache.low)];\nreturn new Integer(i);\n}\n")])])]),v("p",[e._v("2.5、用最有效率的方法计算 2 乘以 8 ？")]),e._v(" "),v("p",[e._v("2 << 3。(左移 相当于乘以 2 的几次幂 n << m 相当于n乘 2 的m次幂)")]),e._v(" "),v("p",[e._v("进阶：通常情况下，可以认为位运算是性能最高的。但是，其实编译器现在已经“非常聪明了”，很多指令编译器都\n能自己做优化。所以在实际实用中，我们无需特意去追求实用位运算，这样不仅会导致代码可读性很差，而且某些\n自作聪明的优化反而会误导编译器，使得编译器无法进行更好的优化。")]),e._v(" "),v("p",[v("strong",[e._v("2.6、&和&&的区别？")])]),e._v(" "),v("p",[e._v("&&：逻辑与运算符。当运算符左右两边的表达式都为 true，才返回 true。同时具有短路性，如果第一个表达式为\nfalse，则直接返回 false。")]),e._v(" "),v("p",[e._v("&：逻辑与运算符、按位与运算符。")]),e._v(" "),v("p",[e._v("以开关开灯论：")]),e._v(" "),v("p",[e._v("有这样两个开关， 0 为开关关闭， 1 为开关打开。")]),e._v(" "),v("p",[e._v("与运算进行的是这样的算法：")]),e._v(" "),v("p",[e._v("在与运算中两个开关是串联的，如果我们要开灯，需要两个开关都打开灯才会打开。 理解为A与B都打开，则开")]),e._v(" "),v("p",[e._v("灯，所以是1&1=1 任意一个开关没打开，都不开灯，所以其他运算都是 0 。")]),e._v(" "),v("p",[e._v("按位与运算符：用于二进制的计算，只有对应的两个二进位均为 1 时，结果位才为 1 ，否则为 0 。")]),e._v(" "),v("p",[e._v("逻辑与运算符：& 在用于逻辑与时，和 && 的区别是不具有短路性。所在通常使用逻辑与运算符都会使用 &&，而")]),e._v(" "),v("p",[e._v("& 更多的适用于位运算。")]),e._v(" "),v("p",[v("strong",[e._v("2.7、String 是 Java 基本数据类型吗？")])]),e._v(" "),v("p",[e._v("答：不是。Java 中的基本数据类型只有 8 个：byte、short、int、long、float、double、char、boolean；除了基\n本类型（primitive type），剩下的都是引用类型（reference type）。")]),e._v(" "),v("p",[e._v("基本数据类型：数据直接存储在栈上")]),e._v(" "),v("p",[e._v("引用数据类型区别：数据存储在堆上，栈上只存储引用地址。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('static boolean f1() { System.out.println( "function f1 called." ); return true; }\nstatic boolean f2() { System.out.println( "function f2 called." ); return false; }\nif ( false && f1() ) {} // f1不会被调用\nif ( true || f2() ){} // f2不会被调用\n')])])]),v("p",[e._v("0&0=0,0&1=0,1&0=0,1&1=")]),e._v(" "),v("p",[v("strong",[e._v("2.8、String 类可以继承吗？")])]),e._v(" "),v("p",[e._v("不行。String 类使用 final 修饰，无法被继承。")]),e._v(" "),v("p",[v("strong",[e._v("2.9、String和StringBuilder、StringBuffer的区别？")])]),e._v(" "),v("p",[e._v("String：String 的值被创建后不能修改，任何对 String 的修改都会引发新的 String 对象的生成。")]),e._v(" "),v("p",[e._v("StringBuffer：跟 String 类似，但是值可以被修改，使用 synchronized 来保证线程安全。")]),e._v(" "),v("p",[e._v("StringBuilder：StringBuffer 的非线程安全版本，没有使用 synchronized，具有更高的性能，推荐优先使用。")]),e._v(" "),v("p",[v("strong",[e._v('2.10、String s = new String("xyz") 创建了几个字符串对象？')])]),e._v(" "),v("p",[e._v("一个或两个。如果字符串常量池已经有“xyz”，则是一个；否则，两个。")]),e._v(" "),v("p",[e._v("当字符串常量池没有 “xyz”，此时会创建如下两个对象：")]),e._v(" "),v("p",[e._v('一个是字符串字面量 "xyz" 所对应的、驻留（intern）在一个全局共享的字符串常量池中的实例，此时该实例也是\n在堆中，字符串常量池只放引用。')]),e._v(" "),v("p",[e._v('另一个是通过 new String() 创建并初始化的，内容与"xyz"相同的实例，也是在堆中。')]),e._v(" "),v("p",[v("strong",[e._v('2.11、String s = "xyz" 和 String s = new String("xyz") 区别？')])]),e._v(" "),v("p",[e._v("两个语句都会先去字符串常量池中检查是否已经存在 “xyz”，如果有则直接使用，如果没有则会在常量池中创建\n“xyz” 对象。")]),e._v(" "),v("p",[e._v('另外，String s = new String("xyz") 还会通过 new String() 在堆里创建一个内容与 "xyz" 相同的对象实例。')]),e._v(" "),v("p",[e._v("所以前者其实理解为被后者的所包含。")]),e._v(" "),v("p",[v("strong",[e._v("2.12、== 和 equals 的区别是什么？")])]),e._v(" "),v("p",[e._v("==：运算符，用于比较基础类型变量和引用类型变量。")]),e._v(" "),v("p",[e._v("对于基础类型变量，比较的变量保存的值是否相同，类型不一定要相同。")]),e._v(" "),v("p",[e._v("对于引用类型变量，比较的是两个对象的地址是否相同。")]),e._v(" "),v("p",[e._v("equals：Object 类中定义的方法，通常用于比较两个对象的值是否相等。")]),e._v(" "),v("p",[e._v("equals 在 Object 方法中其实等同于 ==，但是在实际的使用中，equals 通常被重写用于比较两个对象的值是否相\n同。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("short s1 = 1 ; long l1 = 1 ;\n// 结果：true。类型不同，但是值相同\nSystem.out.println(s1 == l1);\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Integer i1 = new Integer( 1 );\nInteger i2 = new Integer( 1 );\n// 结果：false。通过new创建，在内存中指向两个不同的对象\nSystem.out.println(i1 == i2);\n")])])]),v("p",[v("strong",[e._v("2.13、两个对象的 hashCode() 相同，则 equals() 也一定为 true，对吗？")])]),e._v(" "),v("p",[e._v("不对。hashCode() 和 equals() 之间的关系如下：")]),e._v(" "),v("p",[e._v("当有 a.equals(b) == true 时，则 a.hashCode() == b.hashCode() 必然成立，反过来，当 a.hashCode() ==\nb.hashCode() 时，a.equals(b) 不一定为 true。")]),e._v(" "),v("p",[v("strong",[e._v("2.14、什么是反射？")])]),e._v(" "),v("p",[e._v("反射是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调\n用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能称为反射机制。")]),e._v(" "),v("p",[e._v("反射涉及到四个核心类：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.lang. Class.java ：类对象；\njava.lang.reflect. Constructor.java ：类的构造器对象；\njava.lang.reflect. Method.java ：类的方法对象；\njava.lang.reflect. Field.java ：类的属性对象；\n")])])]),v("p",[e._v("反射有什么用？")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("操作因访问权限限制的属性和方法；\n实现自定义注解；\n动态加载第三方jar包；\n按需加载类，节省编译和初始化APK的时间；\n")])])]),v("p",[e._v("反射工作原理")]),e._v(" "),v("p",[e._v("当我们编写完一个Java项目之后，每个java文件都会被编译成一个.class文件，这些Class对象承载了这个类的所有\n信息，包括父类、接口、构造函数、方法、属性等，这些class文件在程序运行时会被ClassLoader加载到虚拟机\n中。当一个类被加载以后，Java虚拟机就会在内存中自动产生一个Class对象。我们通过new的形式创建对象实际\n上就是通过这些Class来创建，只是这个过程对于我们是不透明的而已。")]),e._v(" "),v("p",[e._v("反射的工作原理就是借助Class.java、Constructor.java、Method.java、Field.java这四个类在程序运行时动态访\n问和修改任何类的行为及状态。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Integer i1 = new Integer( 1 );\nInteger i2 = new Integer( 1 );\n// 结果：true。两个不同的对象，但是具有相同的值\nSystem.out.println(i1.equals(i2));\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// Integer的equals重写方法\npublic boolean equals(Object obj) {\nif (obj instanceof Integer) {\n// 比较对象中保存的值是否相同\nreturn value == ((Integer)obj).intValue();\n}\nreturn false;\n}\n")])])]),v("p",[e._v("2.15、深拷⻉和浅拷⻉区别是什么？")]),e._v(" "),v("p",[e._v("数据分为基本数据类型和引用数据类型。基本数据类型：数据直接存储在栈中；引用数据类型：存储在栈中的是对")]),e._v(" "),v("p",[e._v("象的引用地址，真实的对象数据存放在堆内存里。")]),e._v(" "),v("p",[e._v("浅拷⻉：对于基础数据类型：直接复制数据值；对于引用数据类型：只是复制了对象的引用地址，新旧对象指向同")]),e._v(" "),v("p",[e._v("一个内存地址，修改其中一个对象的值，另一个对象的值随之改变。")]),e._v(" "),v("p",[e._v("深拷⻉：对于基础数据类型：直接复制数据值；对于引用数据类型：开辟新的内存空间，在新的内存空间里复制一")]),e._v(" "),v("p",[e._v("个一模一样的对象，新老对象不共享内存，修改其中一个对象的值，不会影响另一个对象。")]),e._v(" "),v("p",[e._v("深拷⻉相比于浅拷⻉速度较慢并且花销较大。")]),e._v(" "),v("p",[e._v("举个例子这就好比两兄弟大家买衣服可以一人一套，然后房子大家住在一套房子里（浅拷⻉），当两个人成家立业")]),e._v(" "),v("p",[e._v("了，房子分开了一人一套互不影响（深拷⻉）")]),e._v(" "),v("p",[e._v("2.16、并发和并行有什么区别？")]),e._v(" "),v("p",[e._v("并发：两个或多个事件在同一时间间隔发生。")]),e._v(" "),v("p",[e._v("并行：两个或者多个事件在同一时刻发生。")]),e._v(" "),v("p",[e._v("并行是真正意义上，同一时刻做多件事情，而并发在同一时刻只会做一件事件，只是可以将时间切碎，交替做多件")]),e._v(" "),v("p",[e._v("事情。")]),e._v(" "),v("p",[e._v("并行在多处理器系统中存在，而并发可以在单处理器和多处理器系统中都存在，并发能够在单处理器系统中存在是")]),e._v(" "),v("p",[e._v("因为并发是并行的假象，并行要求程序能够同时执行多个操作，而并发只是要求程序假装同时执行多个操作（每个")]),e._v(" "),v("p",[e._v("小时间片执行一个操作，多个操作快速切换执行）。")]),e._v(" "),v("p",[e._v("当系统有一个以上 CPU 时，则线程的操作有可能非并发。当一个 CPU 执行一个线程时，另一个 CPU 可以执行另")]),e._v(" "),v("p",[e._v("一个线程，两个线程互不抢占 CPU 资源，可以同时进行，这种方式我们称之为并行（Parallel）。")]),e._v(" "),v("p",[e._v("并发编程的目标是充分的利用处理器的每一个核，以达到最高的处理性能。")]),e._v(" "),v("p",[e._v("2.17、当一个对象被当作参数传递到一个方法后，此方法可改变这个对象的属性，并可返回变化后的结果，那么这")]),e._v(" "),v("p",[e._v("里到底是值传递还是引用传递？")]),e._v(" "),v("p",[e._v("值传递。Java 中只有值传递，对于对象参数，值的内容是对象的引用。")]),e._v(" "),v("p",[v("strong",[e._v("2.18、重载（Overload）和重写（Override）的区别？")])]),e._v(" "),v("p",[e._v("方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态\n性。")]),e._v(" "),v("p",[e._v("重载：一个类中有多个同名的方法，但是具有有不同的参数列表（参数类型不同、参数个数不同或者二者都不\n同）。")]),e._v(" "),v("p",[e._v("重写：发生在子类与父类之间，子类对父类的方法进行重写，参数都不能改变，返回值类型可以不相同，但是必须\n是父类返回值的派生类。即外壳不变，核心重写！重写的好处在于子类可以根据需要，定义特定于自己的行为。")]),e._v(" "),v("p",[v("strong",[e._v("2.19、构造器是否可被重写？")])]),e._v(" "),v("p",[e._v("Constructor 不能被 override（重写），但是可以 overload（重载），所以你可以看到一个类中有多个构造函数\n的情况。")]),e._v(" "),v("p",[v("strong",[e._v("2.20、为什么不能根据返回类型来区分重载？")])]),e._v(" "),v("p",[e._v("如果我们有两个方法如下，当我们调用：test(1) 时，编译器无法确认要调用的是哪个。")]),e._v(" "),v("p",[e._v("// 方法 1")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("int test(int a);\n// 方法 2\nlong test(int a);\n")])])]),v("p",[e._v("方法的返回值只是作为方法运行之后的一个“状态”，但是并不是所有调用都关注返回值，所以不能将返回值作为重")]),e._v(" "),v("p",[e._v("载的唯一区分条件。")]),e._v(" "),v("p",[v("strong",[e._v("2.21、Java 静态变量和成员变量的区别。")])]),e._v(" "),v("p",[e._v("成员变量存在于堆内存中。静态变量存在于方法区中。")]),e._v(" "),v("p",[e._v("成员变量与对象共存亡，随着对象创建而存在，随着对象被回收而释放。静态变量与类共存亡，随着类的加载而存")]),e._v(" "),v("p",[e._v("在，随着类的消失而消失。")]),e._v(" "),v("p",[e._v("成员变量所属于对象，所以也称为实例变量。静态变量所属于类，所以也称为类变量。")]),e._v(" "),v("p",[e._v("成员变量只能被对象所调用 。静态变量可以被对象调用，也可以被类名调用。")]),e._v(" "),v("p",[v("strong",[e._v("2.22、是否可以从一个静态（static）方法内部发出对非静态（non-static）方法的调用？")])]),e._v(" "),v("p",[e._v("区分两种情况，发出调用时是否显示创建了对象实例。")]),e._v(" "),v("p",[e._v("1 ）没有显示创建对象实例：不可以发起调用，非静态方法只能被对象所调用，静态方法可以通过对象调用，也可\n以通过类名调用，所以静态方法被调用时，可能还没有创建任何实例对象。因此通过静态方法内部发出对非静态方\n法的调用，此时可能无法知道非静态方法属于哪个对象。")]),e._v(" "),v("p",[e._v("2 ）显示创建对象实例：可以发起调用，在静态方法中显示的创建对象实例，则可以正常的调用。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class Demo {\n/**\n* 静态变量：又称类变量，static修饰\n*/\npublic static String STATIC_VARIABLE = "静态变量";\n/**\n* 实例变量：又称成员变量，没有static修饰\n*/\npublic String INSTANCE_VARIABLE = "实例变量";\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class Demo {\npublic static void staticMethod() {\n// 直接调用非静态方法：编译报错\ninstanceMethod();\n}\npublic void instanceMethod() {\nSystem.out.println("非静态方法");\n}\n}\n')])])]),v("p",[e._v("2.23、初始化考察，请指出下面程序的运行结果。")]),e._v(" "),v("p",[e._v("执行结果：ABabab，两个考察点：")]),e._v(" "),v("p",[e._v("1 ）静态变量只会初始化（执行）一次。")]),e._v(" "),v("p",[e._v("2 ）当有父类时，完整的初始化顺序为：父类静态变量（静态代码块）->子类静态变量（静态代码块）->父类非静\n态变量（非静态代码块）->父类构造器 ->子类非静态变量（非静态代码块）->子类构造器 。")]),e._v(" "),v("p",[v("strong",[e._v("2.24、抽象类（abstract class）和接口（interface）有什么区别？")])]),e._v(" "),v("p",[e._v("1 ）抽象类只能单继承，接口可以多实现。")]),e._v(" "),v("p",[e._v("2 ）抽象类可以有构造方法，接口中不能有构造方法。")]),e._v(" "),v("p",[e._v("3 ）抽象类中可以有成员变量，接口中没有成员变量，只能有常量（默认就是 public static final）")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class Demo {\npublic static void staticMethod() {\n// 先创建实例对象，再调用非静态方法：成功执行\nDemo demo = new Demo();\ndemo.instanceMethod();\n}\npublic void instanceMethod() {\nSystem.out.println("非静态方法");\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class InitialTest {\npublic static void main(String[] args) {\nA ab = new B();\nab = new B();\n}\n}\nclass A {\nstatic { // 父类静态代码块\nSystem.out.print("A");\n}\npublic A() { // 父类构造器\nSystem.out.print("a");\n}\n}\nclass B extends A {\nstatic { // 子类静态代码块\nSystem.out.print("B");\n}\npublic B() { // 子类构造器\nSystem.out.print("b");\n}\n}\n')])])]),v("p",[e._v("4 ）抽象类中可以包含非抽象的方法，在 Java 7 之前接口中的所有方法都是抽象的，在 Java 8 之后，接口支持非\n抽象方法：default 方法、静态方法等。Java 9 支持私有方法、私有静态方法。")]),e._v(" "),v("p",[e._v("5 ）抽象类中的抽象方法类型可以是任意修饰符，Java 8 之前接口中的方法只能是 public 类型，Java 9 支持\nprivate 类型。")]),e._v(" "),v("p",[v("strong",[e._v("设计思想的区别：")])]),e._v(" "),v("p",[e._v("接口是自上而下的抽象过程，接口规范了某些行为，是对某一行为的抽象。我需要这个行为，我就去实现某个接\n口，但是具体这个行为怎么实现，完全由自己决定。")]),e._v(" "),v("p",[e._v("抽象类是自下而上的抽象过程，抽象类提供了通用实现，是对某一类事物的抽象。我们在写实现类的时候，发现某\n些实现类具有几乎相同的实现，因此我们将这些相同的实现抽取出来成为抽象类，然后如果有一些差异点，则可以\n提供抽象方法来支持自定义实现。")]),e._v(" "),v("p",[e._v("网上看到有个说法，挺形象的：")]),e._v(" "),v("p",[e._v("普通类像亲爹 ，他有啥都是你的。")]),e._v(" "),v("p",[e._v("抽象类像叔伯，有一部分会给你，还能指导你做事的方法。")]),e._v(" "),v("p",[e._v("接口像干爹，可以给你指引方法，但是做成啥样得你自己努力实现。")]),e._v(" "),v("p",[v("strong",[e._v("2.25、Java 中的 final 关键字有哪些用法？")])]),e._v(" "),v("p",[e._v("修饰类：该类不能再派生出新的子类，不能作为父类被继承。因此，一个类不能同时被声明为abstract 和 final。")]),e._v(" "),v("p",[e._v("修饰方法：该方法不能被子类重写。")]),e._v(" "),v("p",[e._v("修饰变量：该变量必须在声明时给定初值，而在以后只能读取，不可修改。 如果变量是对象，则指的是引用不可\n修改，但是对象的属性还是可以修改的。")]),e._v(" "),v("p",[v("strong",[e._v("2.26、阐述 final、finally、finalize 的区别。")])]),e._v(" "),v("p",[e._v("其实是三个完全不相关的东⻄，只是⻓的有点像。")]),e._v(" "),v("p",[e._v("final 如上所示。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class FinalDemo {\n// 不可再修改该变量的值\npublic static final int FINAL_VARIABLE = 0 ;\n// 不可再修改该变量的引用，但是可以直接修改属性值\npublic static final User USER = new User();\npublic static void main(String[] args) {\n// 输出：User(id=0, name=null, age=0)\nSystem.out.println(USER);\n// 直接修改属性值\nUSER.setName("test");\n// 输出：User(id=0, name=test, age=0)\nSystem.out.println(USER);\n}\n}\n')])])]),v("p",[e._v("finally：finally 是对 Java 异常处理机制的最佳补充，通常配合 try、catch 使用，用于存放那些无论是否出现异常\n都一定会执行的代码。在实际使用中，通常用于释放锁、数据库连接等资源，把资源释放方法放到 finally 中，可\n以大大降低程序出错的几率。")]),e._v(" "),v("p",[e._v("finalize：Object 中的方法，在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。finalize()方法仅作为\n了解即可，在 Java 9 中该方法已经被标记为废弃，并添加新的 java.lang.ref.Cleaner，提供了更灵活和有效的方\n法来释放资源。这也侧面说明了，这个方法的设计是失败的，因此更加不能去使用它。")]),e._v(" "),v("p",[v("strong",[e._v("2.27、try、catch、finally 考察，请指出下面程序的运行结果（ 1 ）。")])]),e._v(" "),v("p",[e._v("执行结果： 31 。")]),e._v(" "),v("p",[e._v("相信很多同学应该都做对了，try、catch。finally 的基础用法，在 return 前会先执行 finally 语句块，所以是先输\n出 finally 里的 3 ，再输出 return 的 1 。")]),e._v(" "),v("p",[v("strong",[e._v("2.28、try、catch、finally 考察，请指出下面程序的运行结果（ 2 ）。")])]),e._v(" "),v("p",[e._v("执行结果： 3 。")]),e._v(" "),v("p",[e._v("这题有点意思，但也不难，try 返回前先执行 finally，结果 finally 里不按套路出牌，直接 return 了，自然也就走\n不到 try 里面的 return 了。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public class TryDemo {\npublic static void main(String[] args) {\nSystem.out.println(test());\n}\npublic static int test() {\ntry {\nreturn 1 ;\n} catch (Exception e) {\nreturn 2 ;\n} finally {\nSystem.out.print("3");\n}\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class TryDemo {\npublic static void main(String[] args) {\nSystem.out.println(test1());\n}\npublic static int test1() {\ntry {\nreturn 2 ;\n} finally {\nreturn 3 ;\n}\n}\n}\n")])])]),v("p",[e._v("finally 里面使用 return 仅存在于面试题中，实际开发中千万不要这么用。")]),e._v(" "),v("p",[v("strong",[e._v("2.29、try、catch、finally 考察 3 ，请指出下面程序的运行结果（ 3 ）。")])]),e._v(" "),v("p",[e._v("执行结果： 2 。")]),e._v(" "),v("p",[e._v("这边估计有不少同学会以为结果应该是 3 ，因为我们知道在 return 前会执行 finally，而 i 在 finally 中被修改为 3\n了，那最终返回 i 不是应该为 3 吗？")]),e._v(" "),v("p",[e._v("这边的根本原因是，在执行 finally 之前，JVM 会先将 i 的结果暂存起来，然后 finally 执行完毕后，会返回之前暂\n存的结果，而不是返回 i，所以即使这边 i 已经被修改为 3 ，最终返回的还是之前暂存起来的结果 2 。")]),e._v(" "),v("p",[e._v("这边其实根据字节码可以很容易看出来，在进入 finally 之前，JVM 会使用 iload、istore 两个指令，将结果暂存，\n在最终返回时在通过 iload、ireturn 指令返回暂存的结果。")]),e._v(" "),v("p",[v("strong",[e._v("2.30、Error 和 Exception 有什么区别？")])]),e._v(" "),v("p",[e._v("Error 和 Exception 都是 Throwable 的子类，用于表示程序出现了不正常的情况。区别在于：")]),e._v(" "),v("p",[e._v("Error 表示系统级的错误和程序不必处理的异常，是恢复不是不可能但很困难的情况下的一种严重问题，比如内存\n溢出，不可能指望程序能处理这样的情况。")]),e._v(" "),v("p",[e._v("Exception 表示需要捕捉或者需要程序进行处理的异常，是一种设计或实现问题，也就是说，它表示如果程序运行\n正常，从不会发生的情况。")]),e._v(" "),v("p",[v("strong",[e._v("2.31、JDK1.8之后有哪些新特性？")])]),e._v(" "),v("p",[v("strong",[e._v("1 ）接口默认方法")]),e._v(" ：Java 8 允许我们给接口添加一个非抽象的方法实现，只需要使用 default 关键字即可。")]),e._v(" "),v("p",[e._v("从Java 8开始，引入了接口默认方法，这样的好处也是很明显的，首先解决了 Java8 以前版本接口兼容性问题，同\n时对于我们以后的程序开发，也可以在接口子类中直接使用接口默认方法，而不再需要在各个子类中各自实现响应\n接口方法。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class TryDemo {\npublic static void main(String[] args) {\nSystem.out.println(test1());\n}\npublic static int test1() {\nint i = 0 ;\ntry {\ni = 2 ;\nreturn i;\n} finally {\ni = 3 ;\n}\n}\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public interface IMathOperation {\n/**\n* 定义接口默认方法 支持方法形参\n*/\n")])])]),v("p",[v("strong",[e._v("2 ）Lambda 表达式和函数式接口")]),e._v(" ：Lambda 表达式本质上是一段匿名内部类，也可以是一段可以传递的代码。\nLambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中），使用 Lambda 表达式使代码更加简\n洁，但是也不要滥用，否则会有可读性等问题，《Effective Java》作者 Josh Bloch 建议使用 Lambda 表达式最好\n不要超过 3 行。")]),e._v(" "),v("p",[v("strong",[e._v("匿名内部类")])]),e._v(" "),v("p",[v("strong",[e._v("Lambda 表达式")])]),e._v(" "),v("p",[e._v("函数式接口")]),e._v(" "),v("p",[e._v("Lambda表达式需要函数式接口的支持，所以，我们有必要来说说什么是函数式接口。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('default void print(){\nSystem.out.println("这是数值运算基本接口。。。");\n}\n/**\n* 定义静态默认方法\n*/\nstatic void version(){\nSystem.out.println("这是1.0版简易计算器");\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class MathOperationImpl implements IMathOperation {\n@Override\npublic int add(int a, int b) {\n// 子类中可以直接调用父类接口默认方法\nIMathOperation.super.print();\n// 调用父类静态默认方法\nIMathOperation.version();\nreturn a+b;\n}\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Test\npublic void test1(){\nComparator<Integer> com = new Comparator<Integer>() {\n@Override\npublic int compare(Integer o1, Integer o2) {\nreturn Integer.compare(o1, o2);\n}\n};\nTreeSet<Integer> treeSet = new TreeSet<>(com);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Comparator<Integer> com = (x, y) -> Integer.compare(x, y);\n")])])]),v("p",[e._v("只包含一个抽象方法的接口，称为函数式接口。 可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda表\n达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。可以在任意函数式接口上使用\n@FunctionalInterface 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明\n这个接口是一个函数式接口。")]),e._v(" "),v("p",[v("strong",[e._v("3 ）Stream API")]),e._v(" ：用函数式编程方式在集合类上进行复杂操作的工具，配合Lambda表达式可以方便的对集合进行\n处理。Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤\n和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用\nStream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@FunctionalInterface\npublic interface MyFunc <T> {\npublic T getValue(T t);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public String handlerString(MyFunc<String> myFunc, String str){\nreturn myFunc.getValue(str);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('@Test\npublic void test6(){\nString str = handlerString((s) -> s.toUpperCase(), "binghe");\nSystem.out.println(str);//输出结果BINGHE\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("List<Teacher> teacherList = new ArrayList<>();\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('teacherList.add(new Teacher("张磊", 22 ,"zl"));\nteacherList.add(new Teacher("李鹏", 36 ,"lp"));\nteacherList.add(new Teacher("刘敏", 50 ,"lm"));\nteacherList.add(new Teacher("宋亚楠", 62 ,"syn"));\nteacherList.add(new Teacher("彩彬", 18 ,"cb"));\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('//filter 过滤\nList<Teacher> list = teacherList.stream().filter(x -> x.getAge() >\n30 ).collect(Collectors.toList());\n//joining拼接 所有老师姓名拼接成字符串\nString nameJoin =\nteacherList.stream().map(Teacher::getName).collect(Collectors.joining(","));\n//排序\nList sortList =\nteacherList.stream().sorted(Comparator.comparing(Teacher::getAge).reversed()).collect(C\nollectors.toList());\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('System.out.println(nameJoin);\nSystem.out.println(list);\nSystem.out.println("按年龄降序: "+sortList);\n')])])]),v("p",[v("strong",[e._v("4 ）方法引用")]),e._v(" ：方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与\nlambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。")]),e._v(" "),v("p",[e._v("方法引用就是操作符“::”将方法名和对象或类的名字分隔开来。")]),e._v(" "),v("p",[e._v("如下三种使用情况：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("对象::实例方法\n类::静态方法\n类::实例方法\n")])])]),v("p",[v("strong",[e._v("5 ）日期时间API")]),e._v(" ：Java 8 引入了新的日期时间API改进了日期时间的管理。")]),e._v(" "),v("p",[e._v("在Java 8之前，所有关于时间和日期的API都存在各种使用方面的缺陷，主要有：")]),e._v(" "),v("p",[e._v("由于以上这些问题，出现了一些三方的日期处理框架，例如Joda-Time，date4j等开源项目。但是，Java需要一套\n标准的用于处理时间和日期的框架，于是Java 8中引入了新的日期API。新的日期API是JSR-310规范的实现，Joda-\nTime框架的作者正是JSR-310的规范的倡导者，所以能从Java 8的日期API中看到很多Joda-Time的特性。")]),e._v(" "),v("p",[e._v("Java 8的日期和时间类包含LocalDate、LocalTime、Instant、Duration以及Period，这些类都包含\n在java.time包中，下面我们看看这些类的用法。")]),e._v(" "),v("p",[v("strong",[e._v("6 ）Optional 类")]),e._v(" ：著名的 NullPointerException 是引起系统失败最常⻅的原因。很久以前 Google Guava 项目引\n入了 Optional 作为解决空指针异常的一种方式，不赞成代码被 null 检查的代码污染，期望程序员写整洁的代码。\n受Google Guava的鼓励，Optional 现在是Java 8库的一部分。")]),e._v(" "),v("p",[v("strong",[e._v("7 ）新工具")]),e._v(" ：新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器 jdeps。")]),e._v(" "),v("p",[e._v("/*输出结果")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("*[Teacher(name=李鹏, age=36, nikeName=lp), Teacher(name=刘敏, age=50, nikeName=lm),\nTeacher(name=宋亚楠, *age=62, nikeName=syn)]\n*张磊,李鹏,刘敏,宋亚楠,彩彬\n*按年龄降序: [Teacher(name=宋亚楠, age=62, nikeName=syn), Teacher(name=刘敏, age=50,\nnikeName=lm), *Teacher(name=李鹏, age=36, nikeName=lp), Teacher(name=张磊, age=22,\nnikeName=zl), Teacher(name=彩彬, age=18, nikeName=cb)]\n*/\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("(x) -> System.out.println(x);//等同于 System.out::println\nBinaryOperator<Double> bo = (x, y) -> Math.pow(x, y);//等同于 BinaryOperator<Double> bo\n= Math::pow;\n")])])]),v("ol",[v("li",[e._v("Java的java.util.Date和java.util.Calendar类易用性差，不支持时区，而且他们都不是线程安全的；")]),e._v(" "),v("li",[e._v("用于格式化日期的类DateFormat被放在java.text包中，它是一个抽象类，所以我们需要实例化一个\nSimpleDateFormat对象来处理日期格式化，并且DateFormat也是非线程安全，这意味着如果你在多线程程序中调\n用同一个DateFormat对象，会得到意想不到的结果。")]),e._v(" "),v("li",[e._v("对日期的计算方式繁琐，而且容易出错，因为月份是从 0 开始的，从Calendar中获取的月份需要加一才能表示\n当前月份。")])]),e._v(" "),v("h2",{attrs:{id:"第三章-jvm"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第三章-jvm"}},[e._v("#")]),e._v(" 第三章：JVM")]),e._v(" "),v("p",[v("strong",[e._v("3.1、介绍下Java内存区域（运行时数据区）。")])]),e._v(" "),v("p",[e._v("Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为以下 6 个运行时数据区域。")]),e._v(" "),v("p",[e._v("1 ） "),v("strong",[e._v("程序计数器（Program Counter Register）")])]),e._v(" "),v("p",[e._v("一块较小的内存空间，可以看作当前线程所执行的字节码的行号指示器。如果线程正在执行的是一个Java方法，这\n个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空。")]),e._v(" "),v("p",[e._v("2 ） "),v("strong",[e._v("Java虚拟机栈（Java Virtual Machine Stacks）")])]),e._v(" "),v("p",[e._v("与程序计数器一样，Java虚拟机栈也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的\n内存模型：每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信\n息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。")]),e._v(" "),v("p",[e._v("3 ） "),v("strong",[e._v("本地方法栈（Native Method Stack）")])]),e._v(" "),v("p",[e._v("本地方法栈与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（也就\n是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。")]),e._v(" "),v("p",[e._v("4 ） "),v("strong",[e._v("Java堆（Java Heap）")])]),e._v(" "),v("p",[e._v("对大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，\n在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。")]),e._v(" "),v("p",[e._v("5 ） "),v("strong",[e._v("元数据区（Method Area）")])]),e._v(" "),v("p",[e._v("在JDK1.7的时候，有一个JVM内存区域中有一块 "),v("strong",[e._v("方法区")]),e._v(" ，主要存放虚拟机加载的类信息，静态变量，常量等。\nJDK1.8时，移除了方法区的概念，用一个元数据区代替。与Java堆一样，是各个线程共享的内存区域，它用于存储\n已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。方法区是JVM规范中定义的一个概\n念，具体放在哪里，不同的实现可以放在不同的地方。")]),e._v(" "),v("p",[e._v("6 ） "),v("strong",[e._v("运行时常量池（Runtime Constant Pool）")])]),e._v(" "),v("p",[e._v("运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息\n是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中\n存放。")]),e._v(" "),v("p",[v("strong",[e._v("3.2、怎么判定对象已经“死去”？")])]),e._v(" "),v("p",[e._v("常⻅的判定方法有两种：引用计数法和可达性分析算法，HotSpot中采用的是可达性分析算法。")]),e._v(" "),v("p",[v("strong",[e._v("引用计数法")])]),e._v(" "),v("p",[e._v("给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加 1 ；当引用失效时，计数器值就减 1 ；任\n何时刻计数器为 0 的对象就是不可能再被使用的。")]),e._v(" "),v("p",[e._v("客观地说，引用计数算法的实现简单，判定效率也很高，在大部分情况下它都是一个不错的算法，但是主流的Java\n虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互循环引用的问题。")]),e._v(" "),v("p",[v("strong",[e._v("可达性分析算法")])]),e._v(" "),v("p",[e._v("这个算法的基本思路就是通过一系列的称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过\n的路径称为引用链，当一个对象到GC Roots没有任何引用链相连（用图论的话来说，就是从GC Roots到这个对象\n不可达）时，则证明此对象是不可用的。如下图所示，对象object 5、object 6、object 7虽然互相有关联，但是\n它们到GC Roots是不可达的，所以它们将会被判定为是可回收的对象。")]),e._v(" "),v("p",[e._v("3.3、介绍下四种引用（强引用、软引用、弱引用、虚引用）？")]),e._v(" "),v("p",[v("strong",[e._v("强引用：")]),e._v(" 在程序代码之中普遍存在的，类似“Object obj=new Object()”这类的引用，只要强引用还存在，垃圾收集\n器永远不会回收掉被引用的对象。")]),e._v(" "),v("p",[v("strong",[e._v("软引用：")]),e._v(" 用来描述一些还有用但并非必需的对象，使用SoftReference类来实现软引用，在系统将要发生内存溢出\n异常之前，将会把这些对象列进回收范围之中进行第二次回收。")]),e._v(" "),v("p",[v("strong",[e._v("弱引用")]),e._v(" ：用来描述非必需对象的，使用WeakReference类来实现弱引用，被弱引用关联的对象只能生存到下一次\n垃圾收集发生之前。")]),e._v(" "),v("p",[v("strong",[e._v("虚引用")]),e._v(" ：是最弱的一种引用关系，使用PhantomReference类来实现虚引用，一个对象是否有虚引用的存在，完全\n不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是\n能在这个对象被收集器回收时收到一个系统通知。")]),e._v(" "),v("p",[v("strong",[e._v("3.4、垃圾收集有哪些算法，各自的特点？")])]),e._v(" "),v("p",[v("strong",[e._v("标记 - 清除算法")])]),e._v(" "),v("p",[e._v("首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。它的主要不足有两个：一个是效率问\n题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片，空间碎\n片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次\n垃圾收集动作。")]),e._v(" "),v("p",[v("strong",[e._v("复制算法")])]),e._v(" "),v("p",[e._v("为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用内存按容量划分为大小相等的两\n块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用\n过的内存空间一次清理掉。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂\n情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。只是这种算法的代价是将内存缩小为了原\n来的一半，未免太高了一点。")]),e._v(" "),v("p",[v("strong",[e._v("标记 - 整理算法")])]),e._v(" "),v("p",[e._v("根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一\n样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以\n外的内存。")]),e._v(" "),v("p",[v("strong",[e._v("分代收集算法")])]),e._v(" "),v("p",[e._v("当前商业虚拟机的垃圾收集都采用“分代收集”算法，这种算法并无新的方法，只是根据对象的存活周期的不同将内\n存划分为几块，一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在\n新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象\n的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用“标记-\n清理”或“标记-整理”算法来进行回收。")]),e._v(" "),v("p",[v("strong",[e._v("3.5、HotSpot为什么要分为新生代和老年代？")])]),e._v(" "),v("p",[e._v("HotSpot根据对象存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代，这样就可以根据各个\n年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选\n用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间\n对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。")]),e._v(" "),v("p",[e._v("其中新生代又分为 1 个Eden区和 2 个Survivor区，通常称为From Survivor和To Survivor区。")]),e._v(" "),v("p",[v("strong",[e._v("3.6、新生代中Eden区和Survivor区的默认比例？")])]),e._v(" "),v("p",[e._v("在HotSpot虚拟机中，Eden区和Survivor区的默认比例为8:1:1，即-XX:SurvivorRatio=8，其中Survivor分为From\nSurvivor和ToSurvivor，因此Eden此时占新生代空间的80%。")]),e._v(" "),v("p",[v("strong",[e._v("3.7、HotSpot GC的分类？")])]),e._v(" "),v("p",[v("strong",[e._v("针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种：")])]),e._v(" "),v("p",[e._v("1 ） "),v("strong",[e._v("Partial GC：")]),e._v(" 并不收集整个GC堆的模式，具体如下：")]),e._v(" "),v("ol",[v("li",[e._v("Young GC/Minor GC：只收集新生代的GC。")]),e._v(" "),v("li",[e._v("Old GC：只收集老年代的GC。只有CMS的concurrent collection是这个模式。")]),e._v(" "),v("li",[e._v("Mixed GC：收集整个新生代以及部分老年代的GC，只有G1有这个模式。")])]),e._v(" "),v("p",[e._v("2 ） "),v("strong",[e._v("Full GC/Major GC：")]),e._v(" 收集整个GC堆的模式，包括新生代、老年代、永久代（如果存在的话）等所有部分的模\n式。")]),e._v(" "),v("p",[e._v("FullGC是对整个堆来说的，出现Full GC的时候经常伴随至少一次的Minor GC，但非绝对的。Major GC的速度一般\n会比Minor GC慢 10 倍以上。")]),e._v(" "),v("p",[v("strong",[e._v("3.8、HotSpot GC的触发条件？")])]),e._v(" "),v("p",[v("strong",[e._v("这里只说常⻅的Young GC和Full GC。")])]),e._v(" "),v("p",[v("strong",[e._v("Young GC：")]),e._v(" 当新生代中的Eden区没有足够空间进行分配时会触发Young GC。")]),e._v(" "),v("p",[v("strong",[e._v("Full GC：")])]),e._v(" "),v("ol",[v("li",[e._v("当准备要触发一次Young GC时，如果发现统计数据说之前Young GC的平均晋升大小比目前老年代剩余的空\n间大，则不会触发Young GC而是转为触发Full GC。（通常情况）")]),e._v(" "),v("li",[e._v("如果有永久代的话，在永久代需要分配空间但已经没有足够空间时，也要触发一次Full GC。")]),e._v(" "),v("li",[e._v("System.gc()默认也是触发Full GC。")]),e._v(" "),v("li",[e._v("heap dump带GC默认也是触发Full GC。")]),e._v(" "),v("li",[e._v("CMS GC时出现Concurrent Mode Failure会导致一次Full GC的产生。")])]),e._v(" "),v("p",[v("strong",[e._v("3.9、Full GC后老年代的空间反而变小？")])]),e._v(" "),v("p",[e._v("HotSpot的Full GC实现中，默认新生代里所有活的对象都要晋升到老年代，实在晋升不了才会留在新生代。假如\n做Full GC的时候，老年代里的对象几乎没有死掉的，而新生代又要晋升活对象上来，那么Full GC结束后老年代的\n使用量自然就上升了。")]),e._v(" "),v("p",[v("strong",[e._v("3.10、什么情况下新生代对象会晋升到老年代？")])]),e._v(" "),v("ol",[v("li",[e._v("如果新生代的垃圾收集器为Serial和ParNew，并且设置了-XX:PretenureSizeThreshold参数，当对象大于这\n个参数值时，会被认为是大对象，直接进入老年代。")]),e._v(" "),v("li",[e._v("Young GC后，如果对象太大无法进入Survivor区，则会通过分配担保机制进入老年代。")]),e._v(" "),v("li",[e._v("对象每在Survivor区中“熬过”一次Young GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁，\n可以通过-XX:MaxTenuringThreshold设置），就将会被晋升到老年代中。")]),e._v(" "),v("li",[e._v("如果在Survivor区中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就\n可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。")])]),e._v(" "),v("p",[v("strong",[e._v("3.11、新生代垃圾回收器和老年代垃圾回收器都有哪些？有什么区别？")])]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("新生代回收器：Serial、ParNew、Parallel Scavenge\n老年代回收器：Serial Old、Parallel Old、CMS\n整堆回收器：G1\n")])])]),v("p",[e._v("新生代垃圾回收器一般采用的是复制算法，复制算法的优点是效率高，缺点是内存利用率低；老年代回收器一般采\n用的是标记-整理的算法进行垃圾回收。")]),e._v(" "),v("p",[e._v("1 ）Serial收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效；")]),e._v(" "),v("p",[e._v("2 ）ParNew收集器 (复制算法): 新生代收并行集器，实际上是Serial收集器的多线程版本，在多核CPU环境下有着\n比Serial更好的表现；")]),e._v(" "),v("p",[e._v("3 ）Parallel Scavenge收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程\n时间/(用户线程时间+GC线程时间)，高吞吐量可以高效率的利用CPU时间，尽快完成程序的运算任务，适合后台应\n用等对交互相应要求不高的场景；")]),e._v(" "),v("p",[e._v("4 ）Serial Old收集器 (标记-整理算法): 老年代单线程收集器，Serial收集器的老年代版本；")]),e._v(" "),v("p",[e._v("5 ）Parallel Old收集器 (标记-整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版\n本；")]),e._v(" "),v("p",[e._v("6 ）CMS(Concurrent Mark Sweep)收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿时间为\n目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间。对于要求服务器响应速度的应用上，这\n种垃圾回收器非常适合。在启动 JVM 的参数加上“-XX:+UseConcMarkSweepGC”来指定使用 CMS 垃圾回收器。\nCMS 使用的是标记-清除的算法实现的，所以在 gc 的时候回产生大量的内存碎片，当剩余内存不能满足程序运行\n要求时，系统将会出现 Concurrent Mode Failure，临时 CMS 会采用 Serial Old 回收器进行垃圾清除，此时的性\n能将会被降低。")]),e._v(" "),v("p",[e._v("7 ）G1(Garbage First)收集器 (标记-整理算法)： Java堆并行收集器，G1收集器是JDK1.7开始提供的一个新收集\n器，G1收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G1收集器不同于之前的收集器的一\n个重要特点是：G1回收的范围是整个Java堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老\n年代。")]),e._v(" "),v("p",[e._v("隔离级别 脏读 不可重复度 幻读")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("读未提交（Read Uncommitted） 有 有 有\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("读已提交（Read Committed） 无 有 有\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("可重复读（Repeatable Read） 无 无 有\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("串行读（Serializable） 无 无 无\n")])])]),v("h2",{attrs:{id:"第四章-mysql"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第四章-mysql"}},[e._v("#")]),e._v(" 第四章：MySQL")]),e._v(" "),v("p",[v("strong",[e._v("4.1、MySQL 的事务隔离级别有哪些？分别用于解决什么问题？")])]),e._v(" "),v("p",[e._v("主要用于解决脏读、不可重复读、幻读。")]),e._v(" "),v("p",[v("strong",[e._v("脏读：")]),e._v(" 一个事务读取到另一个事务还未提交的数据。")]),e._v(" "),v("p",[v("strong",[e._v("不可重复读：")]),e._v(" 在一个事务中多次读取同一个数据时，结果出现不一致。")]),e._v(" "),v("p",[v("strong",[e._v("幻读：")]),e._v(" 在一个事务中使用相同的 SQL 两次读取，第二次读取到了其他事务新插入的行。")]),e._v(" "),v("p",[v("strong",[e._v("不可重复读注重于数据的修改，而幻读注重于数据的插入。")])]),e._v(" "),v("p",[v("strong",[e._v("4.2、MySQL 的可重复读怎么实现的？")])]),e._v(" "),v("p",[e._v("使用 MVCC 实现的，即 Mutil-Version Concurrency Control，多版本并发控制。关于 MVCC，比较常⻅的说法如\n下，包括《高性能 MySQL》也是这么介绍的。")]),e._v(" "),v("p",[e._v("InnoDB 在每行记录后面保存两个隐藏的列，分别保存了数据行的 "),v("strong",[e._v("创建版本号")]),e._v(" 和 "),v("strong",[e._v("删除版本号")]),e._v(" 。每开始一个新的事\n务，系统版本号都会递增。事务开始时刻的版本号会作为事务的版本号，用来和查询到的每行记录的版本号对比。\n在可重复读级别下，MVCC是如何操作的：")]),e._v(" "),v("p",[e._v("SELECT：必须同时满足以下两个条件，才能查询到。")]),e._v(" "),v("p",[e._v("1 ）只查版本号早于当前版本的数据行；")]),e._v(" "),v("p",[e._v("2 ）行的删除版本要么未定义，要么大于当前事务版本号。")]),e._v(" "),v("p",[e._v("INSERT：为插入的每一行保存当前系统版本号作为创建版本号。")]),e._v(" "),v("p",[e._v("DELETE：为删除的每一行保存当前系统版本号作为删除版本号。")]),e._v(" "),v("p",[e._v("UPDATE：插入一条新数据，保存当前系统版本号作为创建版本号。同时保存当前系统版本号作为原来的数据行删\n除版本号。")]),e._v(" "),v("p",[e._v("MVCC 只作用于 RC（Read Committed）和 RR（Repeatable Read）级别，因为 RU（Read Uncommitted）总\n是读取最新的数据版本，而不是符合当前事务版本的数据行。而 Serializable 则会对所有读取的行都加锁。这两种\n级别都不需要 MVCC 的帮助。")]),e._v(" "),v("p",[e._v("4.3、MVCC 解决了幻读了没有？")]),e._v(" "),v("p",[e._v("幻读：在一个事务中使用相同的 SQL 两次读取，第二次读取到了其他事务新插入的行，则称为发生了幻读。")]),e._v(" "),v("p",[e._v("例如：")]),e._v(" "),v("p",[e._v("1 ）事务 1 第一次查询：select * from user where id < 10 时查到了 id = 1 的数据")]),e._v(" "),v("p",[e._v("2 ）事务 2 插入了 id = 2 的数据")]),e._v(" "),v("p",[e._v("3 ）事务 1 使用同样的语句第二次查询时，查到了 id = 1、id = 2 的数据，出现了幻读。")]),e._v(" "),v("p",[e._v("谈到幻读，首先我们要引入“快照读”和“当前读”的概念：")]),e._v(" "),v("p",[e._v("快照读：生成一个事务快照（ReadView），之后都从这个快照获取数据。普通 select 语句就是快照读。")]),e._v(" "),v("p",[e._v("当前读：读取数据的最新版本。常⻅的 update/insert/delete、还有 select ... for update、select ... lock in share\nmode 都是当前读。")]),e._v(" "),v("p",[e._v("对于快照读，MVCC 因为因为从 ReadView 读取，所以必然不会看到新插入的行，所以天然就解决了幻读的问\n题。")]),e._v(" "),v("p",[e._v("而对于当前读的幻读，MVCC 是无法解决的。需要使用 Gap Lock 或 Next-Key Lock（Gap Lock + Record Lock）\n来解决。")]),e._v(" "),v("p",[e._v("其实原理也很简单，用上面的例子稍微修改下以触发当前读：select * from user where id < 10 for update，当\n使用了 Gap Lock 时，Gap 锁会锁住 id < 10 的整个范围，因此其他事务无法插入 id < 10 的数据，从而防止了幻\n读。")]),e._v(" "),v("p",[v("strong",[e._v("4.4、经常有人说 Repeatable Read 解决了幻读是什么情况？")])]),e._v(" "),v("p",[e._v("SQL 标准中规定的 RR 并不能消除幻读，但是 MySQL 的 RR 可以，靠的就是 Gap 锁。在 RR 级别下，Gap 锁是默\n认开启的，而在 RC 级别下，Gap 锁是关闭的。")]),e._v(" "),v("p",[v("strong",[e._v("4.5、什么是索引？")])]),e._v(" "),v("p",[e._v("MySQL 官方对索引的定义为：索引（Index）是帮助 MySQL 高效获取数据的数据结构。简单的理解，索引类似于\n字典里面的目录。")]),e._v(" "),v("p",[v("strong",[e._v("4.6、常⻅的索引类型有哪些？")])]),e._v(" "),v("p",[e._v("常⻅的索引类型有：hash、b树、b+树。")]),e._v(" "),v("p",[e._v("hash：底层就是 hash 表。进行查找时，根据 key 调用hash 函数获得对应的 hashcode，根据 hashcode 找到对\n应的数据行地址，根据地址拿到对应的数据。")]),e._v(" "),v("p",[e._v("B树：B树是一种多路搜索树，n 路搜索树代表每个节点最多有 n 个子节点。每个节点存储 key + 指向下一层节点\n的指针+ 指向 key 数据记录的地址。查找时，从根结点向下进行查找，直到找到对应的key。")]),e._v(" "),v("p",[e._v("B+树：B+树是b树的变种，主要区别在于：B+树的非叶子节点只存储 key + 指向下一层节点的指针。另外，B+树\n的叶子节点之间通过指针来连接，构成一个有序链表，因此对整棵树的遍历只需要一次线性遍历叶子结点即可。")]),e._v(" "),v("p",[v("strong",[e._v("4.7、为什么MySQL数据库要用B+树存储索引？而不用红黑树、B树、Hash？")])]),e._v(" "),v("p",[e._v("红黑树：如果在内存中，红黑树的查找效率比B树更高，但是涉及到磁盘操作，B树就更优了。因为红黑树是二叉\n树，数据量大时树的层数很高，从树的根结点向下寻找的过程，每读 1 个节点，都相当于一次IO操作，因此红黑树\n的I/O操作会比B树多的多。")]),e._v(" "),v("p",[e._v("hash 索引：如果只查询单个值的话，hash 索引的效率非常高。但是 hash 索引有几个问题： 1 ）不支持范围查\n询； 2 ）不支持索引值的排序操作； 3 ）不支持联合索引的最左匹配规则。")]),e._v(" "),v("p",[e._v("B树索引：B树索相比于B+树，在进行范围查询时，需要做局部的中序遍历，可能要跨层访问，跨层访问代表着要\n进行额外的磁盘I/O操作；另外，B树的非叶子节点存放了数据记录的地址，会导致存放的节点更少，树的层数变\n高。")]),e._v(" "),v("p",[v("strong",[e._v("4.8、MySQL 中的索引叶子节点存放的是什么？")])]),e._v(" "),v("p",[e._v("MyISAM和InnoDB都是采用的B+树作为索引结构，但是叶子节点的存储上有些不同。")]),e._v(" "),v("p",[e._v("MyISAM：主键索引和辅助索引（普通索引）的叶子节点都是存放 key 和 key 对应数据行的地址。在MyISAM\n中，主键索引和辅助索引没有任何区别。")]),e._v(" "),v("p",[e._v("InnoDB：主键索引存放的是 key 和 key 对应的数据行。辅助索引存放的是 key 和 key 对应的主键值。因此在使用\n辅助索引时，通常需要检索两次索引，首先检索辅助索引获得主键值，然后用主键值到主键索引中检索获得记录。")]),e._v(" "),v("p",[v("strong",[e._v("4.9、什么是聚簇索引（聚集索引）？")])]),e._v(" "),v("p",[e._v("聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。聚簇索引将索引和数据行放到了一块，找到索引也\n就找到了数据。因为无需进行回表操作，所以效率很高。")]),e._v(" "),v("p",[e._v("InnoDB 中必然会有，且只会有一个聚簇索引。通常是主键，如果没有主键，则优先选择非空的唯一索引，如果唯\n一索引也没有，则会创建一个隐藏的row_id 作为聚簇索引。至于为啥会只有一个聚簇索引，其实很简单，因为我\n们的数据只会存储一份。")]),e._v(" "),v("p",[e._v("而非聚簇索引则将数据存储和索引分开，找到索引后，需要通过对应的地址找到对应的数据行。MyISAM 的索引\n方式就是非聚簇索引。")]),e._v(" "),v("p",[e._v("4.10、什么是回表查询？")]),e._v(" "),v("p",[e._v("InnoDB 中，对于主键索引，只需要走一遍主键索引的查询就能在叶子节点拿到数据。")]),e._v(" "),v("p",[e._v("而对于普通索引，叶子节点存储的是 key + 主键值，因此需要再走一次主键索引，通过主键索引找到行记录，这就\n是所谓的回表查询，先定位主键值，再定位行记录。")]),e._v(" "),v("p",[v("strong",[e._v("4.11、走普通索引，一定会出现回表查询吗？")])]),e._v(" "),v("p",[e._v("不一定，如果查询语句所要求的字段全部命中了索引，那么就不必再进行回表查询。")]),e._v(" "),v("p",[e._v("很容易理解，有一个 user 表，主键为 id，name 为普通索引，则再执行：select id, name from user where\nname = 'joonwhee' 时，通过name 的索引就能拿到 id 和 name了，因此无需再回表去查数据行了。")]),e._v(" "),v("p",[v("strong",[e._v("4.12、那你知道什么是覆盖索引（索引覆盖）吗？")])]),e._v(" "),v("p",[e._v("覆盖索引是 SQL-Server 中的一种说法，上面讲的例子其实就实现了覆盖索引。具体的：当索引上包含了查询语句\n中的所有列时，我们无需进行回表查询就能拿到所有的请求数据，因此速度会很快。")]),e._v(" "),v("p",[e._v("假设你定义一个联合索引：")]),e._v(" "),v("p",[e._v("查询名称为 joon 的年龄：")]),e._v(" "),v("p",[e._v("上述语句中，查找的字段 name 和 age 都包含在联合索引 idx_name_age 的索引树中，这样的查询就是覆盖索引\n查询。")]),e._v(" "),v("p",[v("strong",[e._v("4.13、联合索引（复合索引）的底层实现？最佳左前缀原则？")])]),e._v(" "),v("p",[e._v("联合索引底层还是使用B+树索引，并且还是只有一棵树，只是此时的排序会：首先按照第一个索引排序，在第一\n个索引相同的情况下，再按第二个索引排序，依次类推。")]),e._v(" "),v("p",[e._v("这也是为什么有“最佳左前缀原则”的原因，因为右边（后面）的索引都是在左边（前面）的索引排序的基础上进行\n排序的，如果没有左边的索引，单独看右边的索引，其实是无序的。")]),e._v(" "),v("p",[e._v("还是以字典为例，我们如果要查第 2 个字母为 k 的，通过目录是无法快速找的，因为首字母 A - Z 里面都可能包含\n第 2 个字母为 k 的。")]),e._v(" "),v("p",[v("strong",[e._v("4.14、union 和 union all 的区别")])]),e._v(" "),v("p",[e._v("union all：对两个结果集直接进行并集操作，记录可能有重复，不会进行排序。")]),e._v(" "),v("p",[e._v("union：对两个结果集进行并集操作，会进行去重，记录不会重复，按字段的默认规则排序。")]),e._v(" "),v("p",[e._v("因此，从效率上说，UNION ALL 要比 UNION 更快。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("CREATE INDEX idx_name_age ON user(name,age);\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select name,age from user where name = 'joon';\n")])])]),v("p",[e._v("4.15、B+树中一个节点到底多大合适？")]),e._v(" "),v("p",[e._v("1 ⻚或⻚的倍数最为合适。因为如果一个节点的大小小于 1 ⻚，那么读取这个节点的时候其实也会读出 1 ⻚，造成资")]),e._v(" "),v("p",[e._v("源的浪费。所以为了不造成浪费，所以把一个节点的大小控制在 1 ⻚、 2 ⻚、 3 ⻚等倍数⻚大小最为合适。")]),e._v(" "),v("p",[e._v("这里说的“⻚”是 MySQL 自定义的单位（和操作系统类似），MySQL 的 Innodb 引擎中 1 ⻚的默认大小是16k，可\n以使用命令SHOW GLOBAL STATUS LIKE 'Innodb_page_size' 查看。")]),e._v(" "),v("p",[v("strong",[e._v("4.16、那 MySQL 中B+树的一个节点大小为多大呢？")])]),e._v(" "),v("p",[e._v("在 MySQL 中 B+ 树的一个节点大小为“1⻚”，也就是16k。")]),e._v(" "),v("p",[v("strong",[e._v("4.17、什么一个节点为 1 ⻚就够了？")])]),e._v(" "),v("p",[e._v("Innodb中，B+树中的一个节点存储的内容是：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("非叶子节点：key + 指针\n叶子节点：数据行（key 通常是数据的主键）\n")])])]),v("p",[e._v("对于叶子节点：我们假设 1 行数据大小为1k（对于普通业务绝对够了），那么 1 ⻚能存 16 条数据。")]),e._v(" "),v("p",[e._v("对于非叶子节点：key 使用 bigint 则为 8 字节，指针在 MySQL 中为 6 字节，一共是 14 字节，则16k能存放 16 *\n1024 / 14 = 1170个。那么一颗高度为 3 的B+树能存储的数据为：1170 * 1170 * 16 = 21902400（千万级）。")]),e._v(" "),v("p",[e._v("所以在 InnoDB 中B+树高度一般为 3 层时，就能满足千万级的数据存储。在查找数据时一次⻚的查找代表一次IO，\n所以通过主键索引查询通常只需要1-3次 IO 操作即可查找到数据。千万级别对于一般的业务来说已经足够了，所\n以一个节点为 1 ⻚，也就是16k是比较合理的。")]),e._v(" "),v("p",[v("strong",[e._v("4.18、什么是 Buffer Pool？")])]),e._v(" "),v("p",[e._v("Buffer Pool 是 InnoDB 维护的一个缓存区域，用来缓存数据和索引在内存中，主要用来加速数据的读写，如果\nBuffer Pool 越大，那么 MySQL 就越像一个内存数据库，默认大小为 128M。")]),e._v(" "),v("p",[e._v("InnoDB 会将那些热点数据和一些 InnoDB 认为即将访问到的数据存在 Buffer Pool 中，以提升数据的读取性能。")]),e._v(" "),v("p",[e._v("InnoDB 在修改数据时，如果数据的⻚在 Buffer Pool 中，则会直接修改 Buffer Pool，此时我们称这个⻚为脏⻚，\nInnoDB 会以一定的频率将脏⻚刷新到磁盘，这样可以尽量减少磁盘I/O，提升性能。")]),e._v(" "),v("p",[v("strong",[e._v("4.19、InnoDB 四大特性知道吗？")])]),e._v(" "),v("p",[v("strong",[e._v("插入缓冲（insert buffer）：")])]),e._v(" "),v("p",[e._v("索引是存储在磁盘上的，所以对于索引的操作需要涉及磁盘操作。如果我们使用自增主键，那么在插入主键索引")]),e._v(" "),v("p",[e._v("（聚簇索引）时，只需不断追加即可，不需要磁盘的随机 I/O。但是如果我们使用的是普通索引，大概率是无序")]),e._v(" "),v("p",[e._v("的，此时就涉及到磁盘的随机 I/O，而随机I/O的性能是比较差的（Kafka 官方数据：磁盘顺序I/O的性能是磁盘随\n机I/O的4000~5000倍）。")]),e._v(" "),v("p",[e._v("因此，InnoDB 存储引擎设计了 Insert Buffer ，对于非聚集索引的插入或更新操作，不是每一次直接插入到索引\n⻚中，而是先判断插入的非聚集索引⻚是否在缓冲池（Buffer pool）中，若在，则直接插入；若不在，则先放入\n到一个 Insert Buffer 对象中，然后再以一定的频率和情况进行 Insert Buffer 和辅助索引⻚子节点的 merge（合\n并）操作，这时通常能将多个插入合并到一个操作中（因为在一个索引⻚中），这就大大提高了对于非聚集索引插\n入的性能。")]),e._v(" "),v("p",[e._v("插入缓冲的使用需要满足以下两个条件： "),v("strong",[e._v("1 ）索引是辅助索引； 2 ）索引不是唯一的。")])]),e._v(" "),v("p",[e._v("因为在插入缓冲时，数据库不会去查找索引⻚来判断插入的记录的唯一性。如果去查找肯定又会有随机读取的情况\n发生，从而导致 Insert Buffer 失去了意义。")]),e._v(" "),v("p",[v("strong",[e._v("二次写（double write）：")])]),e._v(" "),v("p",[e._v("脏⻚刷盘⻛险：InnoDB 的 page size一般是16KB，操作系统写文件是以4KB作为单位，那么每写一个 InnoDB 的\npage 到磁盘上，操作系统需要写 4 个块。于是可能出现16K的数据，写入4K 时，发生了系统断电或系统崩溃，只\n有一部分写是成功的，这就是 partial page write（部分⻚写入）问题。这时会出现数据不完整的问题。")]),e._v(" "),v("p",[e._v("这时是无法通过 redo log 恢复的，因为 redo log 记录的是对⻚的物理修改，如果⻚本身已经损坏，重做日志也无\n能为力。")]),e._v(" "),v("p",[e._v("doublewrite 就是用来解决该问题的。doublewrite 由两部分组成，一部分为内存中的 doublewrite buffer，其大\n小为2MB，另一部分是磁盘上共享表空间中连续的 128 个⻚，即 2 个区(extent)，大小也是2M。")]),e._v(" "),v("p",[e._v("为了解决 partial page write 问题，当 MySQL 将脏数据刷新到磁盘的时候，会进行以下操作：")]),e._v(" "),v("p",[e._v("1 ）先将脏数据复制到内存中的 doublewrite buffer")]),e._v(" "),v("p",[e._v("2 ）之后通过 doublewrite buffer 再分 2 次，每次1MB写入到共享表空间的磁盘上（顺序写，性能很高）")]),e._v(" "),v("p",[e._v("3 ）完成第二步之后，⻢上调用 fsync 函数，将doublewrite buffer中的脏⻚数据写入实际的各个表空间文件（离\n散写）。")]),e._v(" "),v("p",[e._v("如果操作系统在将⻚写入磁盘的过程中发生崩溃，InnoDB 再次启动后，发现了一个 page 数据已经损坏，\nInnoDB 存储引擎可以从共享表空间的 doublewrite 中找到该⻚的一个最近的副本，用于进行数据恢复了。")]),e._v(" "),v("p",[v("strong",[e._v("自适应哈希索引(adaptive hash index）：")])]),e._v(" "),v("p",[e._v("哈希（hash）是一种非常快的查找方法，一般情况下查找的时间复杂度为 O(1)。但是由于不支持范围查询等条件\n的限制，InnoDB 并没有采用 hash 索引，但是如果能在一些特殊场景下使用 hash 索引，则可能是一个不错的补\n充，而 InnoDB 正是这么做的。")]),e._v(" "),v("p",[e._v("具体的，InnoDB 会监控对表上索引的查找，如果观察到某些索引被频繁访问，索引成为热数据，建立哈希索引可\n以带来速度的提升，则建立哈希索引，所以称之为自适应（adaptive）的。自适应哈希索引通过缓冲池的 B+ 树构\n造而来，因此建立的速度很快。而且不需要将整个表都建哈希索引，InnoDB 会自动根据访问的频率和模式来为某\n些⻚建立哈希索引。")]),e._v(" "),v("p",[v("strong",[e._v("预读（read ahead）：")])]),e._v(" "),v("p",[e._v("InnoDB 在 I/O 的优化上有个比较重要的特性为预读，当 InnoDB 预计某些 page 可能很快就会需要用到时，它会\n异步地将这些 page 提前读取到缓冲池（buffer pool）中，这其实有点像空间局部性的概念。")]),e._v(" "),v("p",[e._v("空间局部性（spatial locality）：如果一个数据项被访问，那么与它地址相邻的数据项也可能很快被访问。")]),e._v(" "),v("p",[e._v("InnoDB使用两种预读算法来提高I/O性能： "),v("strong",[e._v("线性预读（linear read-ahead）和随机预读（randomread-\nahead）")]),e._v(" 。")]),e._v(" "),v("p",[e._v("其中，线性预读以 extent（块， 1 个 extent 等于 64 个 page）为单位，而随机预读放到以 extent 中的 page 为单\n位。线性预读着眼于将下一个extent 提前读取到 buffer pool 中，而随机预读着眼于将当前 extent 中的剩余的\npage 提前读取到 buffer pool 中。")]),e._v(" "),v("p",[e._v("线性预读（Linear read-ahead）：线性预读方式有一个很重要的变量 innodb_read_ahead_threshold，可以控制\nInnodb 执行预读操作的触发阈值。如果一个 extent 中的被顺序读取的 page 超过或者等于该参数变量时，\nInnodb将会异步的将下一个 extent 读取到 buffer pool中，innodb_read_ahead_threshold 可以设置为0-64（一\n个 extend 上限就是 64 ⻚）的任何值，默认值为 56 ，值越高，访问模式检查越严格。")]),e._v(" "),v("p",[e._v("随机预读（Random read-ahead）: 随机预读方式则是表示当同一个 extent 中的一些 page 在 buffer pool 中发\n现时，Innodb 会将该 extent 中的剩余 page 一并读到 buffer pool中，由于随机预读方式给 Innodb code 带来了\n一些不必要的复杂性，同时在性能也存在不稳定性，在5.5中已经将这种预读方式废弃。要启用此功能，请将配置\n变量设置 innodb_random_read_ahead 为ON。")]),e._v(" "),v("p",[v("strong",[e._v("4.20、请说一下共享锁和排他锁？")])]),e._v(" "),v("p",[e._v("共享锁又称为读锁，简称S锁，顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，\n但是只能读不能修改。")]),e._v(" "),v("p",[e._v("排他锁又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他\n锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务可以对数据就行读取和修\n改。")]),e._v(" "),v("p",[e._v("常⻅的几种 SQL 语句的加锁情况如下：")]),e._v(" "),v("p",[e._v("4.21、请说一下数据库的行锁和表锁？")]),e._v(" "),v("p",[e._v("行锁：操作时只锁某一（些）行，不对其它行有影响。开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的")]),e._v(" "),v("p",[e._v("概率低，并发度高。")]),e._v(" "),v("p",[e._v("表锁：即使操作一条记录也会锁住整个表。开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突概率高，并")]),e._v(" "),v("p",[e._v("发度最低。")]),e._v(" "),v("p",[e._v("⻚锁：操作时锁住一⻚数据（16kb）。开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和\n行锁之间，并发度一般。")]),e._v(" "),v("p",[e._v("InnoDB 有行锁和表锁，MyIsam 只有表锁。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from table; #不加锁\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("update/insert/delete #排他锁\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from table where id = 1 for update; #id为索引，加排他锁\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("select * from table where id = 1 lock in share mode; #id为索引，加共享锁\n")])])]),v("p",[v("strong",[e._v("4.22、InnoDB 的行锁是怎么实现的？")])]),e._v(" "),v("p",[e._v("InnoDB 行锁是通过索引上的索引项来实现的。意味者：只有通过索引条件检索数据，InnoDB 才会使用行级锁，\n否则，InnoDB将使用表锁！")]),e._v(" "),v("p",[e._v("对于主键索引：直接锁住锁住主键索引即可。")]),e._v(" "),v("p",[e._v("对于普通索引：先锁住普通索引，接着锁住主键索引，这是因为一张表的索引可能存在多个，通过主键索引才能确\n保锁是唯一的，不然如果同时有 2 个事务对同 1 条数据的不同索引分别加锁，那就可能存在 2 个事务同时操作一条数\n据了。")]),e._v(" "),v("p",[v("strong",[e._v("4.23、InnoDB 锁的算法有哪几种？")])]),e._v(" "),v("p",[e._v("Record lock：记录锁，单条索引记录上加锁，锁住的永远是索引，而非记录本身。")]),e._v(" "),v("p",[e._v("Gap lock：间隙锁，在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索\n引记录本身。")]),e._v(" "),v("p",[e._v("Next-key lock：Record lock 和 Gap lock 的结合，即除了锁住记录本身，也锁住索引之间的间隙。")]),e._v(" "),v("p",[v("strong",[e._v("4.24、MySQL 如何实现悲观锁和乐观锁？")])]),e._v(" "),v("p",[e._v("乐观锁：更新时带上版本号（cas更新）")]),e._v(" "),v("p",[e._v("悲观锁：使用共享锁和排它锁，select...lock in share mode，select...for update。")]),e._v(" "),v("p",[v("strong",[e._v("4.25、InnoDB 和 MyISAM 的区别？")])]),e._v(" "),v("p",[e._v("4.26、存储引擎的选择？")]),e._v(" "),v("p",[e._v("没有特殊情况，使用 InnoDB 即可。如果表中绝大多数都只是读查询，可以考虑 MyISAM。")]),e._v(" "),v("p",[v("strong",[e._v("4.27、explain 用过吗，有哪些字段分别是啥意思？")])]),e._v(" "),v("p",[e._v("explain 字段有：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("id：标识符\nselect_type：查询的类型\ntable：输出结果集的表\npartitions：匹配的分区\ntype：表的连接类型\npossible_keys：查询时，可能使用的索引\nkey：实际使用的索引\nkey_len：使用的索引字段的⻓度\nref：列与索引的比较\nrows：估计要检查的行数\nfiltered：按表条件过滤的行百分比\nExtra：附加信息\n")])])]),v("p",[v("strong",[e._v("4.28、explain 主要关注哪些字段？")])]),e._v(" "),v("p",[e._v("主要关注 type、key、row、extra 等字段。主要是看是否使用了索引，是否扫描了过多的行数，是否出现 Using\ntemporary、Using filesort 等一些影响性能的主要指标。")]),e._v(" "),v("p",[v("strong",[e._v("4.29、type 中有哪些常⻅的值？")])]),e._v(" "),v("p",[e._v("按类型排序，从好到坏，常⻅的有：const > eq_ref > ref > range > index > ALL。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("const：通过主键或唯一键查询，并且结果只有 1 行（也就是用等号查询）。因为仅有一行，所以优化器的其\n余部分可以将这一行中的列值视为常量。\neq_ref：通常出现于两表关联查询时，使用主键或者非空唯一键关联，并且查询条件不是主键或唯一键的等\n号查询。\nref：通过普通索引查询，并且使用的等号查询。\nrange：索引的范围查找（>=、<、in 等）。\nindex：全索引扫描。\nAll：全表扫描\n")])])]),v("p",[v("strong",[e._v("4.30、如何做慢 SQL 优化？")])]),e._v(" "),v("p",[e._v("首先要搞明白慢的原因是什么：是查询条件没有命中索引？还是 load 了不需要的数据列？还是数据量太大？所以\n优化也是针对这三个方向来的。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("首先用 explain 分析语句的执行计划，查看使用索引的情况，是不是查询没走索引，如果可以加索引解决，\n优先采用加索引解决。\n分析语句，看看是否存在一些导致索引失效的用法，是否 load 了额外的数据，是否加载了许多结果中并不需\n要的列，对语句进行分析以及重写。\n如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行垂直拆分或者水平\n拆分。\n")])])]),v("p",[v("strong",[e._v("4.31、说说 MySQL 的主从复制？")])]),e._v(" "),v("p",[e._v("MySQL主从复制涉及到三个线程，一个运行在主节点（Log Dump Thread），其余两个（I/O Thread，SQL\nThread）运行在从节点，如下图所示")]),e._v(" "),v("p",[e._v("主从复制默认是异步的模式，具体过程如下。")]),e._v(" "),v("p",[e._v("1 ）从节点上的I/O 线程连接主节点，并请求从指定日志文件（bin log file）的指定位置（bin log position，或者\n从最开始的日志）之后的日志内容；")]),e._v(" "),v("p",[e._v("2 ）主节点接收到来自从节点的 I/O请求后，读取指定文件的指定位置之后的日志信息，返回给从节点。返回信息\n中除了日志所包含的信息之外，还包括本次返回的信息的 bin-log file 以及 bin-log position；从节点的 I/O 进程接\n收到内容后，将接收到的日志内容更新到 relay log 中，并将读取到的 bin log file（文件名）和position（位置）\n保存到 master-info 文件中，以便在下一次读取的时候能够清楚的告诉 Master “我需要从某个bin-log 的个位置开\n始往后的日志内容”；")]),e._v(" "),v("p",[e._v("3 ）从节点的 SQL 线程检测到 relay-log 中新增加了内容后，会解析 relay-log 的内容，并在本数据库中执行。")]),e._v(" "),v("p",[v("strong",[e._v("4.32、异步复制，主库宕机后，数据可能丢失？")])]),e._v(" "),v("p",[e._v("可以使用半同步复制或全同步复制。")]),e._v(" "),v("p",[e._v("半同步复制：")]),e._v(" "),v("p",[e._v("修改语句写入bin log后，不会立即给客户端返回结果。而是首先通过log dump 线程将 binlog 发送给从节点，从\n节点的 I/O 线程收到 binlog 后，写入到 relay log，然后返回 ACK 给主节点，主节点收到 ACK 后，再返回给客户\n端成功。")]),e._v(" "),v("p",[e._v("半同步复制的特点：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("确保事务提交后 binlog 至少传输到一个从库\n不保证从库应用完这个事务的 binlog\n性能有一定的降低，响应时间会更⻓\n网络异常或从库宕机，卡主主库，直到超时或从库恢复\n全同步复制：主节点和所有从节点全部执行了该事务并确认才会向客户端返回成功。因为需要等待所有从库\n执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。\n")])])]),v("p",[v("strong",[e._v("4.33、主库写压力大，从库复制很可能出现延迟？")])]),e._v(" "),v("p",[e._v("可以使用并行复制（并行是指从库多个SQL线程并行执行 relay log），解决从库复制延迟的问题。")]),e._v(" "),v("p",[e._v("MySQL 5.7 中引入基于组提交的并行复制，其核心思想：一个组提交的事务都是可以并行回放，因为这些事务都\n已进入到事务的 prepare 阶段，则说明事务之间没有任何冲突（否则就不可能提交）。")]),e._v(" "),v("p",[e._v("判断事务是否处于一个组是通过 last_committed 变量，last_committed 表示事务提交的时候，上次事务提交的\n编号，如果事务具有相同的 last_committed，则表示这些事务都在一组内，可以进行并行的回放。")]),e._v(" "),v("h2",{attrs:{id:"第五章-spring"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第五章-spring"}},[e._v("#")]),e._v(" 第五章：Spring")]),e._v(" "),v("p",[v("strong",[e._v("5.1、Spring IoC 的容器构建流程？")])]),e._v(" "),v("p",[e._v("核心的构建流程如下，也就是 refresh 方法的核心内容：")]),e._v(" "),v("p",[v("strong",[e._v("5.2、Spring Bean 的生命周期")])]),e._v(" "),v("p",[e._v("bean 的生命周期主要有以下几个阶段，深色底的 5 个是比较重要的阶段。")]),e._v(" "),v("p",[v("strong",[e._v("5.3、BeanFactory 和 FactoryBean 的区别？")])]),e._v(" "),v("p",[e._v("BeanFactory：Spring 容器最核心也是最基础的接口，本质是个工厂类，用于管理 bean 的工厂，最核心的功能是\n加载 bean，也就是 getBean 方法，通常我们不会直接使用该接口，而是使用其子接口。")]),e._v(" "),v("p",[e._v("FactoryBean：该接口以 bean 样式定义，但是它不是一种普通的 bean，它是个工厂 bean，实现该接口的类可以\n自己定义要创建的 bean 实例，只需要实现它的 getObject 方法即可。")]),e._v(" "),v("p",[e._v("FactoryBean 被广泛应用于 Java 相关的中间件中，如果你看过一些中间件的源码，一定会看到 FactoryBean 的身\n影。")]),e._v(" "),v("p",[e._v("一般来说，都是通过 FactoryBean#getObject 来返回一个代理类，当我们触发调用时，会走到代理类中，从而可\n以在代理类中实现中间件的自定义逻辑，比如：RPC 最核心的几个功能，选址、建立连接、远程调用，还有一些\n自定义的监控、限流等等。")]),e._v(" "),v("p",[v("strong",[e._v("5.4、BeanFactory 和 ApplicationContext 的区别？")])]),e._v(" "),v("p",[e._v("BeanFactory：基础 IoC 容器，提供完整的 IoC 服务支持。")]),e._v(" "),v("p",[e._v("ApplicationContext：高级 IoC 容器，BeanFactory 的子接口，在 BeanFactory 的基础上进行扩展。包含\nBeanFactory 的所有功能，还提供了其他高级的特性，比如：事件发布、国际化信息支持、统一资源加载策略\n等。正常情况下，我们都是使用的 ApplicationContext。")]),e._v(" "),v("p",[e._v("这边以电话来举个简单的例子：")]),e._v(" "),v("p",[e._v("我们家里使用的 “座机” 就类似于 BeanFactory，可以进行电话通讯，满足了最基本的需求。")]),e._v(" "),v("p",[e._v("而现在非常普及的智能手机，iPhone、小米等，就类似于 ApplicationContext，除了能进行电话通讯，还有其他\n很多功能：拍照、地图导航、听歌等。")]),e._v(" "),v("p",[v("strong",[e._v("5.5、Spring 的 AOP 是怎么实现的？")])]),e._v(" "),v("p",[e._v("本质是通过动态代理来实现的，主要有以下几个步骤。")]),e._v(" "),v("p",[e._v("1 ）获取增强器，例如被 Aspect 注解修饰的类。")]),e._v(" "),v("p",[e._v("2 ）在创建每一个 bean 时，会检查是否有增强器能应用于这个 bean，简单理解就是该 bean 是否在该增强器指定\n的 execution 表达式中。如果是，则将增强器作为拦截器参数，使用动态代理创建 bean 的代理对象实例。")]),e._v(" "),v("p",[e._v("3 ）当我们调用被增强过的 bean 时，就会走到代理类中，从而可以触发增强器，本质跟拦截器类似。")]),e._v(" "),v("p",[e._v("5.6、多个AOP的顺序怎么定？")]),e._v(" "),v("p",[e._v("通过 Ordered 和 PriorityOrdered 接口进行排序。PriorityOrdered 接口的优先级比 Ordered 更高，如果同时实\n现 PriorityOrdered 或 Ordered 接口，则再按 order 值排序，值越小的优先级越高。")]),e._v(" "),v("p",[v("strong",[e._v("5.7、Spring 的 AOP 有哪几种创建代理的方式？")])]),e._v(" "),v("p",[e._v("Spring 中的 AOP 目前支持 JDK 动态代理和 Cglib 代理。")]),e._v(" "),v("p",[e._v("通常来说：如果被代理对象实现了接口，则使用 JDK 动态代理，否则使用 Cglib 代理。另外，也可以通过指定\nproxyTargetClass=true 来实现强制走 Cglib 代理。")]),e._v(" "),v("p",[v("strong",[e._v("5.8、JDK 动态代理和 Cglib 代理的区别？")])]),e._v(" "),v("p",[e._v("1 ）JDK 动态代理本质上是实现了被代理对象的接口，而 Cglib 本质上是继承了被代理对象，覆盖其中的方法。")]),e._v(" "),v("p",[e._v("2 ）JDK 动态代理只能对实现了接口的类生成代理，Cglib 则没有这个限制。但是 Cglib 因为使用继承实现，所以\nCglib 无法代理被 final 修饰的方法或类。")]),e._v(" "),v("p",[e._v("3 ）在调用代理方法上，JDK 是通过反射机制调用，Cglib是通过FastClass 机制直接调用。FastClass 简单的理解，\n就是使用 index 作为入参，可以直接定位到要调用的方法直接进行调用。")]),e._v(" "),v("p",[e._v("4 ）在性能上，JDK1.7 之前，由于使用了 FastClass 机制，Cglib 在执行效率上比 JDK 快，但是随着 JDK 动态代理\n的不断优化，从 JDK 1.7 开始，JDK 动态代理已经明显比 Cglib 更快了。")]),e._v(" "),v("p",[v("strong",[e._v("5.9、JDK 动态代理为什么只能对实现了接口的类生成代理？")])]),e._v(" "),v("p",[e._v("根本原因是通过 JDK 动态代理生成的类已经继承了 Proxy 类，所以无法再使用继承的方式去对类实现代理。")]),e._v(" "),v("p",[v("strong",[e._v("5.10、Spring 的事务传播行为有哪些？")])]),e._v(" "),v("p",[e._v("1 ）REQUIRED：Spring 默认的事务传播级别，如果上下文中已经存在事务，那么就加入到事务中执行，如果当前\n上下文中不存在事务，则新建事务执行。")]),e._v(" "),v("p",[e._v("2 ）REQUIRES_NEW：每次都会新建一个事务，如果上下文中有事务，则将上下文的事务挂起，当新建事务执行完\n成以后，上下文事务再恢复执行。")]),e._v(" "),v("p",[e._v("3 ）SUPPORTS：如果上下文存在事务，则加入到事务执行，如果没有事务，则使用非事务的方式执行。")]),e._v(" "),v("p",[e._v("4 ）MANDATORY：上下文中必须要存在事务，否则就会抛出异常。")]),e._v(" "),v("p",[e._v("5 ）NOT_SUPPORTED ：如果上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务。")]),e._v(" "),v("p",[e._v("6 ）NEVER：上下文中不能存在事务，否则就会抛出异常。")]),e._v(" "),v("p",[e._v("7 ）NESTED：嵌套事务。如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。")]),e._v(" "),v("p",[v("strong",[e._v("5.11、Spring 的事务隔离级别？")])]),e._v(" "),v("p",[e._v("Spring 的事务隔离级别底层其实是基于数据库的，Spring 并没有自己的一套隔离级别。")]),e._v(" "),v("p",[e._v("DEFAULT：使用数据库的默认隔离级别。")]),e._v(" "),v("p",[e._v("READ_UNCOMMITTED：读未提交，最低的隔离级别，会读取到其他事务还未提交的内容，存在脏读。")]),e._v(" "),v("p",[e._v("READ_COMMITTED：读已提交，读取到的内容都是已经提交的，可以解决脏读，但是存在不可重复读。")]),e._v(" "),v("p",[e._v("REPEATABLE_READ：可重复读，在一个事务中多次读取时看到相同的内容，可以解决不可重复读，但是存在幻")]),e._v(" "),v("p",[e._v("读。")]),e._v(" "),v("p",[e._v("SERIALIZABLE：串行化，最高的隔离级别，对于同一行记录，写会加写锁，读会加读锁。在这种情况下，只有读")]),e._v(" "),v("p",[e._v("读能并发执行，其他并行的读写、写读、写写操作都是冲突的，需要串行执行。可以防止脏读、不可重复度、幻")]),e._v(" "),v("p",[e._v("读，没有并发事务问题。")]),e._v(" "),v("p",[v("strong",[e._v("5.12、Spring 的事务隔离级别是如何做到和数据库不一致的？")])]),e._v(" "),v("p",[e._v("比如数据库是可重复读，Spring 是读已提交，这是怎么实现的？")]),e._v(" "),v("p",[e._v("Spring 的事务隔离级别本质上还是通过数据库来控制的，具体是在执行事务前先执行命令修改数据库隔离级别，\n命令格式如下：")]),e._v(" "),v("p",[v("strong",[e._v("5.13、Spring 事务的实现原理？")])]),e._v(" "),v("p",[e._v("Spring 事务的底层实现主要使用的技术：AOP（动态代理） + ThreadLocal + try/catch。")]),e._v(" "),v("p",[e._v("动态代理：基本所有要进行逻辑增强的地方都会用到动态代理，AOP 底层也是通过动态代理实现。")]),e._v(" "),v("p",[e._v("ThreadLocal：主要用于线程间的资源隔离，以此实现不同线程可以使用不同的数据源、隔离级别等等。")]),e._v(" "),v("p",[e._v("try/catch：最终是执行 commit 还是 rollback，是根据业务逻辑处理是否抛出异常来决定。")]),e._v(" "),v("p",[e._v("Spring 事务的核心逻辑伪代码如下：")]),e._v(" "),v("p",[e._v("详细流程如下图所示：")]),e._v(" "),v("p",[e._v("SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public void invokeWithinTransaction() {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// 1.事务资源准备\ntry {\n// 2.业务逻辑处理，也就是调用被代理的方法\n} catch (Exception e) {\n// 3.出现异常，进行回滚并将异常抛出\n} finally {\n// 现场还原：还原旧的事务信息\n}\n// 4.正常执行，进行事务的提交\n// 返回业务逻辑处理结果\n}\n")])])]),v("p",[v("strong",[e._v("5.14、Spring 怎么解决循环依赖的问题？")])]),e._v(" "),v("p",[e._v("Spring 是通过提前暴露 bean 的引用来解决的，具体如下。")]),e._v(" "),v("p",[e._v("Spring 首先使用构造函数创建一个 “不完整” 的 bean 实例（之所以说不完整，是因为此时该 bean 实例还未初始\n化），并且提前曝光该 bean 实例的 ObjectFactory（提前曝光就是将 ObjectFactory 放到 singletonFactories 缓\n存）.")]),e._v(" "),v("p",[e._v("通过 ObjectFactory 我们可以拿到该 bean 实例的引用，如果出现循环引用，我们可以通过缓存中的\nObjectFactory 来拿到 bean 实例，从而避免出现循环引用导致的死循环。")]),e._v(" "),v("p",[e._v("举个例子：A 依赖了 B，B 也依赖了 A，那么依赖注入过程如下。")]),e._v(" "),v("p",[e._v("检查 A 是否在缓存中，发现不存在，进行实例化")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("通过构造函数创建 bean A，并通过 ObjectFactory 提前曝光 bean A\nA 走到属性填充阶段，发现依赖了 B，所以开始实例化 B。\n首先检查 B 是否在缓存中，发现不存在，进行实例化\n通过构造函数创建 bean B，并通过 ObjectFactory 曝光创建的 bean B\nB 走到属性填充阶段，发现依赖了 A，所以开始实例化 A。\n检查 A 是否在缓存中，发现存在，拿到 A 对应的 ObjectFactory 来获得 bean A，并返回。\nB 继续接下来的流程，直至创建完毕，然后返回 A 的创建流程，A 同样继续接下来的流程，直至创建完毕。\n这边通过缓存中的 ObjectFactory 拿到的 bean 实例虽然拿到的是 “不完整” 的 bean 实例，但是由于是单\n例，所以后续初始化完成后，该 bean 实例的引用地址并不会变，所以最终我们看到的还是完整 bean 实\n例。\n")])])]),v("p",[v("strong",[e._v("5.15、Spring 能解决构造函数循环依赖吗？")])]),e._v(" "),v("p",[e._v("答案是不行的，对于使用构造函数注入产生的循环依赖，Spring 会直接抛异常。")]),e._v(" "),v("p",[e._v("为什么无法解决构造函数循环依赖？")]),e._v(" "),v("p",[e._v("上面解决逻辑的第一句话：“首先使用构造函数创建一个 “不完整” 的 bean 实例”，从这句话可以看出，构造函数循\n环依赖是无法解决的，因为当构造函数出现循环依赖，我们连 “不完整” 的 bean 实例都构建不出来。")]),e._v(" "),v("p",[v("strong",[e._v("5.16、Spring 三级缓存")])]),e._v(" "),v("p",[e._v("Spring 的三级缓存其实就是解决循环依赖时所用到的三个缓存。")]),e._v(" "),v("p",[e._v("singletonObjects：正常情况下的 bean 被创建完毕后会被放到该缓存，key：beanName，value：bean 实例。")]),e._v(" "),v("p",[e._v("singletonFactories：上面说的提前曝光的 ObjectFactory 就会被放到该缓存中，key：beanName，value：\nObjectFactory。")]),e._v(" "),v("p",[e._v("earlySingletonObjects：该缓存用于存放 ObjectFactory 返回的 bean，也就是说对于一个 bean，ObjectFactory\n只会被用一次，之后就通过 earlySingletonObjects 来获取，key：beanName，value：早期 bean 实例。")]),e._v(" "),v("p",[v("strong",[e._v("5.17、@Resource 和 @Autowire 的区别？")])]),e._v(" "),v("p",[e._v("1 ）@Resource 和 @Autowired 都可以用来装配 bean")]),e._v(" "),v("p",[e._v("2 ）@Autowired 默认按类型装配，默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的\nrequired属性为false。")]),e._v(" "),v("p",[e._v("3 ）@Resource 如果指定了 name 或 type，则按指定的进行装配；如果都不指定，则优先按名称装配，当找不到\n与名称匹配的 bean 时才按照类型进行装配。")]),e._v(" "),v("p",[v("strong",[e._v("5.18、@Autowire 怎么使用名称来注入？")])]),e._v(" "),v("p",[e._v("配合 @Qualifier 使用，如下所示：")]),e._v(" "),v("p",[v("strong",[e._v("5.19、@PostConstruct 修饰的方法里用到了其他 bean 实例，会有问题吗？")])]),e._v(" "),v("p",[e._v("该题可以拆解成下面 3 个问题：")]),e._v(" "),v("p",[e._v("1 ）@PostConstruct 修饰的方法被调用的时间")]),e._v(" "),v("p",[e._v("2 ）bean 实例依赖的其他 bean 被注入的时间，也可理解为属性的依赖注入时间")]),e._v(" "),v("p",[e._v("3 ）步骤 2 的时间是否早于步骤 1 ：如果是，则没有问题，如果不是，则有问题")]),e._v(" "),v("p",[e._v("解析：")]),e._v(" "),v("p",[v("strong",[e._v("5.20、bean 的 init-method 属性指定的方法里用到了其他 bean 实例，会有问题吗？")])]),e._v(" "),v("p",[e._v("该题同上面这题类似，只是将 @PostConstruct 换成了 init-method 属性。")]),e._v(" "),v("p",[e._v("答案是不会有问题。同上面一样，init-method 属性指定的方法也是在 initializeBean 方法里被触发，属于初始化\nbean 阶段。")]),e._v(" "),v("p",[v("strong",[e._v("5.21、要在 Spring IoC 容器构建完毕之后执行一些逻辑，怎么实现？")])]),e._v(" "),v("p",[e._v("1 ）比较常⻅的方法是使用事件监听器，实现 ApplicationListener 接口，监听 ContextRefreshedEvent 事件。")]),e._v(" "),v("p",[e._v("2 ）还有一种比较少⻅的方法是实现 SmartLifecycle 接口，并且 isAutoStartup 方法返回 true，则会在\nfinishRefresh() 方法中被触发。")]),e._v(" "),v("p",[e._v("两种方式都是在 finishRefresh 中被触发，SmartLifecycle在ApplicationListener之前。")]),e._v(" "),v("p",[v("strong",[e._v("5.22、Spring 中的常⻅扩展点有哪些？")])]),e._v(" "),v("p",[e._v("1 ）ApplicationContextInitializer")]),e._v(" "),v("p",[e._v("initialize 方法，在 Spring 容器刷新前触发，也就是 refresh 方法前被触发。")]),e._v(" "),v("p",[e._v("2 ）BeanFactoryPostProcessor")]),e._v(" "),v("p",[e._v("postProcessBeanFactory 方法，在加载完 Bean 定义之后，创建 Bean 实例之前被触发，通常使用该扩展点来加\n载一些自己的 bean 定义。")]),e._v(" "),v("p",[e._v("3 ）BeanPostProcessor")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('@Component\npublic class Test {\n@Autowired\n@Qualifier("userService")\nprivate UserService userService;\n}\n')])])]),v("ol",[v("li",[e._v("PostConstruct 注解被封装在 CommonAnnotationBeanPostProcessor中，具体触发时间是在\npostProcessBeforeInitialization 方法，从 doCreateBean 维度看，则是在 initializeBean 方法里，\n属于初始化 bean 阶段。")]),e._v(" "),v("li",[e._v("属性的依赖注入是在 populateBean 方法里，属于属性填充阶段。")]),e._v(" "),v("li",[e._v("属性填充阶段位于初始化之前，所以本题答案为没有问题。")])]),e._v(" "),v("p",[e._v("postProcessBeforeInitialization 方法，执行 bean 的初始化方法前被触发；postProcessAfterInitialization 方\n法，执行 bean 的初始化方法后被触发。")]),e._v(" "),v("p",[e._v("4 ）@PostConstruct")]),e._v(" "),v("p",[e._v("该注解被封装在 CommonAnnotationBeanPostProcessor 中，具体触发时间是在\npostProcessBeforeInitialization 方法。")]),e._v(" "),v("p",[e._v("5 ）InitializingBean")]),e._v(" "),v("p",[e._v("afterPropertiesSet 方法，在 bean 的属性填充之后，初始化方法（init-method）之前被触发，该方法的作用基\n本等同于 init-method，主要用于执行初始化相关操作。")]),e._v(" "),v("p",[e._v("6 ）ApplicationListener，事件监听器")]),e._v(" "),v("p",[e._v("onApplicationEvent 方法，根据事件类型触发时间不同，通常使用的 ContextRefreshedEvent 触发时间为上下文\n刷新完毕，通常用于 IoC 容器构建结束后处理一些自定义逻辑。")]),e._v(" "),v("p",[e._v("7 ）@PreDestroy")]),e._v(" "),v("p",[e._v("该注解被封装在 DestructionAwareBeanPostProcessor 中，具体触发时间是在 postProcessBeforeDestruction\n方法，也就是在销毁对象之前触发。")]),e._v(" "),v("p",[e._v("8 ）DisposableBean")]),e._v(" "),v("p",[e._v("destroy 方法，在 bean 的销毁阶段被触发，该方法的作用基本等同于 destroy-method，主用用于执行销毁相关\n操作。")]),e._v(" "),v("p",[v("strong",[e._v("5.23、Spring中如何让两个bean按顺序加载？")])]),e._v(" "),v("p",[e._v("1 ）使用 @DependsOn、depends-on")]),e._v(" "),v("p",[e._v("2 ）让后加载的类依赖先加载的类")]),e._v(" "),v("p",[e._v("3 ）使用扩展点提前加载，例如：BeanFactoryPostProcessor")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Component\npublic class A {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Autowire\nprivate B b;\n}\n")])])]),v("p",[v("strong",[e._v("5.24、使用 Mybatis 时，调用 DAO接口时是怎么调用到 SQL 的？")])]),e._v(" "),v("p",[e._v("简单点说，当我们使用 Spring+MyBatis 时：")]),e._v(" "),v("p",[e._v("1 、DAO接口会被加载到 Spring 容器中，通过动态代理来创建")]),e._v(" "),v("p",[e._v("2 、XML中的SQL会被解析并保存到本地缓存中，key是SQL 的 namespace + id，value 是SQL的封装")]),e._v(" "),v("p",[e._v("3 、当我们调用DAO接口时，会走到代理类中，通过接口的全路径名，从步骤 2 的缓存中找到对应的SQL，然后执\n行并返回结果")]),e._v(" "),v("h2",{attrs:{id:"第六章-redis"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第六章-redis"}},[e._v("#")]),e._v(" 第六章：Redis")]),e._v(" "),v("p",[v("strong",[e._v("6.1、Redis 是单线程还是多线程？")])]),e._v(" "),v("p",[e._v("这个问题应该已经看到过无数次了，最近 redis 6 出来之后又被翻出来了。")]),e._v(" "),v("p",[e._v("redis 4.0 之前，redis 是 "),v("strong",[e._v("完全单线程的")]),e._v(" 。")]),e._v(" "),v("p",[e._v("redis 4.0 时，redis 引入了多线程，但是 "),v("strong",[e._v("额外的线程只是用于后台处理")]),e._v(" ，例如：删除对象，核心流程还是完全单线\n程的。这也是为什么有些人说 4.0 是单线程的，因为他们指的是核心流程是单线程的。")]),e._v(" "),v("p",[e._v("这边的核心流程指的是 redis 正常处理客户端请求的流程，通常包括：接收命令、解析命令、执行命令、返回结果\n等。而在最近，redis 6.0 版本又一次引入了多线程概念，与 4.0 不同的是，这次的多线程会涉及到上述的核心流\n程。redis 6.0 中， "),v("strong",[e._v("多线程主要用于网络 I/O 阶段")]),e._v(" ，也就是接收命令和写回结果阶段，而在执行命令阶段，还是由\n单线程串行执行。由于执行时还是串行，因此无需考虑并发安全问题。值得注意的时，redis 中的多线程组不会同\n时存在“读”和“写”，这个多线程组只会同时“读”或者同时“写”。redis 6.0 加入多线程 I/O 之后，处理命令的核心流程\n如下:")]),e._v(" "),v("p",[e._v("1 、当有读事件到来时，主线程将该客户端连接放到全局等待读队列")]),e._v(" "),v("p",[e._v("2 、读取数据：")]),e._v(" "),v("p",[e._v("1 ）主线程将等待读队列的客户端连接通过轮询调度算法分配给 I/O 线程处理；")]),e._v(" "),v("p",[e._v("2 ）同时主线程也会自己负责处理一个客户端连接的读事件；")]),e._v(" "),v("p",[e._v("3 ）当主线程处理完该连接的读事件后，会自旋等待所有 I/O 线程处理完毕")]),e._v(" "),v("p",[e._v("3 、命令执行：主线程按照事件被加入全局等待读队列的顺序（这边保证了执行顺序是正确的），串行执行客户端\n命令，然后将客户端连接放到全局等待写队列")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Component\npublic class TestBean implements BeanFactoryPostProcessor {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('@Override\npublic void postProcessBeanFactory(ConfigurableListableBeanFactory\nconfigurableListableBeanFactory) throws BeansException {\n// 加载bean\nbeanFactory.getBean("a");\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("}\n｝\n")])])]),v("p",[e._v("4 、写回结果：跟等待读队列处理类似，主线程将等待写队列的客户端连接使用轮询调度算法分配给 I/O 线程处")]),e._v(" "),v("p",[e._v("理，同时自己也会处理一个，当主线程处理完毕后，会自旋等待所有 I/O 线程处理完毕，最后清空队列。")]),e._v(" "),v("p",[e._v("大致流程图如下：")]),e._v(" "),v("p",[v("strong",[e._v("6.2、为什么 Redis 是单线程？")])]),e._v(" "),v("p",[e._v("在 redis 6.0 之前，redis 的核心操作是单线程的。")]),e._v(" "),v("p",[e._v("因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，redis 的瓶颈最有可能是机器内存的大小\n或者网络带宽。")]),e._v(" "),v("p",[e._v("既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入\n上下文切换、加锁等等，会带来额外的性能消耗。")]),e._v(" "),v("p",[e._v("而随着近些年互联网的不断发展，大家对于缓存的性能要求也越来越高了，因此 redis 也开始在逐渐往多线程方向\n发展。")]),e._v(" "),v("p",[e._v("最近的 6.0 版本就对核心流程引入了多线程，主要用于解决 redis 在网络 I/O 上的性能瓶颈。而对于核心的命令执\n行阶段，目前还是单线程的。")]),e._v(" "),v("p",[v("strong",[e._v("6.3、Redis 为什么使用单进程、单线程也很快？")])]),e._v(" "),v("p",[e._v("主要有以下几点：")]),e._v(" "),v("p",[e._v("1 ）基于内存的操作")]),e._v(" "),v("p",[e._v("2 ）使用了 I/O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器")]),e._v(" "),v("p",[e._v("3 ）单线程可以避免不必要的上下文切换和竞争条件，减少了这方面的性能消耗。")]),e._v(" "),v("p",[e._v("4 ）以上这三点是 redis 性能高的主要原因，其他的还有一些小优化，例如：对数据结构进行了优化，简单动态字\n符串、压缩列表等。")]),e._v(" "),v("p",[v("strong",[e._v("6.4、Redis 在项目中的使用场景")])]),e._v(" "),v("p",[e._v("缓存（核心）、分布式锁（set + lua 脚本）、排行榜（zset）、计数（incrby）、消息队列（stream）、地理位\n置（geo）、访客统计（hyperloglog）等。")]),e._v(" "),v("p",[v("strong",[e._v("6.5、Redis 常⻅的数据结构")])]),e._v(" "),v("p",[e._v("基础的 5 种：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("String：字符串，最基础的数据类型。\nList：列表。\nHash：哈希对象。\nSet：集合。\nSorted Set：有序集合，Set 的基础上加了个分值。\n高级的 4 种：\nHyperLogLog：通常用于基数统计。使用少量固定大小的内存，来统计集合中唯一元素的数量。统计结果不\n是精确值，而是一个带有0.81%标准差（standard error）的近似值。所以，HyperLogLog适用于一些对于\n统计结果精确度要求不是特别高的场景，例如网站的UV统计。\nGeo：redis 3.2 版本的新特性。可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作：获取 2\n个位置的距离、根据给定地理位置坐标获取指定范围内的地理位置集合。\nBitmap：位图。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Stream：主要用于消息队列，类似于 kafka，可以认为是 pub/sub 的改进版。提供了消息的持久化和主备复\n制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢\n失。\n")])])]),v("p",[v("strong",[e._v("6.6、Sorted Set底层数据结构")])]),e._v(" "),v("p",[e._v("Sorted Set（有序集合）当前有两种编码：ziplist、skiplist")]),e._v(" "),v("p",[e._v("ziplist：使用压缩列表实现，当保存的元素⻓度都小于 64 字节，同时数量小于 128 时，使用该编码方式，否则会使\n用 skiplist。这两个参数可以通过 zset-max-ziplist-entries、zset-max-ziplist-value 来自定义修改。")]),e._v(" "),v("p",[e._v("skiplist：zset实现，一个zset同时包含一个字典（dict）和一个跳跃表（zskiplist）")]),e._v(" "),v("p",[v("strong",[e._v("6.7、Sorted Set 为什么同时使用字典和跳跃表？")])]),e._v(" "),v("p",[e._v("主要是为了提升性能。")]),e._v(" "),v("p",[e._v("单独使用字典：在执行范围型操作，比如 zrank、zrange，字典需要进行排序，至少需要 O(NlogN) 的时间复杂度\n及额外 O(N) 的内存空间。")]),e._v(" "),v("p",[e._v("单独使用跳跃表：根据成员查找分值操作的复杂度从 O(1) 上升为 O(logN)。")]),e._v(" "),v("p",[v("strong",[e._v("6.8、Sorted Set 为什么使用跳跃表，而不是红黑树？")])]),e._v(" "),v("p",[e._v("主要有以下几个原因：")]),e._v(" "),v("p",[e._v("1 ）跳表的性能和红黑树差不多。")]),e._v(" "),v("p",[e._v("2 ）跳表更容易实现和调试。")]),e._v(" "),v("p",[v("strong",[e._v("6.9、Hash 对象底层结构")])]),e._v(" "),v("p",[e._v("Hash 对象当前有两种编码：ziplist、hashtable")]),e._v(" "),v("p",[e._v("ziplist：使用压缩列表实现，每当有新的键值对要加入到哈希对象时，程序会先将保存了键的节点推入到压缩列表\n的表尾，然后再将保存了值的节点推入到压缩列表表尾。")]),e._v(" "),v("p",[e._v("因此： 1 ）保存了同一键值对的两个节点总是紧挨在一起，保存键的节点在前，保存值的节点在后；")]),e._v(" "),v("p",[e._v("2 ）先添加到哈希对象中的键值对会被放在压缩列表的表头方向，而后来添加的会被放在表尾方向。")]),e._v(" "),v("p",[e._v("hashtable：使用字典作为底层实现，哈希对象中的每个键值对都使用一个字典键值来保存，跟 java 中的\nHashMap 类似。")]),e._v(" "),v("p",[v("strong",[e._v("6.10、Hash 对象的扩容流程")])]),e._v(" "),v("p",[e._v("hash 对象在扩容时使用了一种叫“渐进式 rehash”的方式，步骤如下：")]),e._v(" "),v("p",[e._v("1 ）计算新表 size、掩码，为新表 ht[1] 分配空间，让字典同时持有 ht[0] 和 ht[1] 两个哈希表。")]),e._v(" "),v("p",[e._v("2 ）将 rehash 索引计数器变量 rehashidx 的值设置为 0 ，表示 rehash 正式开始。")]),e._v(" "),v("p",[e._v("3 ）在 rehash 进行期间，每次对字典执行添加、删除、査找、更新操作时，程序除了执行指定的操作以外，还会\n触发额外的 rehash 操作，在源码中的 _dictRehashStep 方法。")]),e._v(" "),v("p",[e._v("_dictRehashStep：从名字也可以看出来，大意是 rehash 一步，也就是 rehash 一个索引位置。")]),e._v(" "),v("p",[e._v("该方法会从 ht[0] 表的 rehashidx 索引位置上开始向后查找，找到第一个不为空的索引位置，将该索引位置的所有\n节点 rehash 到 ht[1]，当本次 rehash 工作完成之后，将 ht[0] 索引位置为 rehashidx 的节点清空，同时将\nrehashidx 属性的值加一。")]),e._v(" "),v("p",[e._v("4 ）将 rehash 分摊到每个操作上确实是非常妙的方式，但是万一此时服务器比较空闲，一直没有什么操作，难道\nredis 要一直持有两个哈希表吗？")]),e._v(" "),v("p",[e._v("答案当然不是的。我们知道，redis 除了文件事件外，还有时间事件，redis 会定期触发时间事件，这些时间事件\n用于执行一些后台操作，其中就包含 rehash 操作：当 redis 发现有字典正在进行 rehash 操作时，会花费 1 毫秒的\n时间，一起帮忙进行 rehash。")]),e._v(" "),v("p",[e._v("5 ）随着操作的不断执行，最终在某个时间点上，ht[0] 的所有键值对都会被 rehash 至 ht[1]，此时 rehash 流程完\n成，会执行最后的清理工作：释放 ht[0] 的空间、将 ht[0] 指向 ht[1]、重置 ht[1]、重置 rehashidx 的值为 -1。")]),e._v(" "),v("p",[v("strong",[e._v("6.11、渐进式 rehash 的优点")])]),e._v(" "),v("p",[e._v("渐进式 rehash 的好处在于它采取分而治之的方式，将 rehash 键值对所需的计算工作均摊到对字典的每个添加、\n删除、查找和更新操作上，从而避免了集中式 rehash 而带来的庞大计算量。")]),e._v(" "),v("p",[e._v("在进行渐进式 rehash 的过程中，字典会同时使用 ht[0] 和 ht[1] 两个哈希表， 所以在渐进式 rehash 进行期间，\n字典的删除、査找、更新等操作会在两个哈希表上进行。例如，要在字典里面査找一个键的话，程序会先在 ht[0]\n里面进行査找，如果没找到的话，就会继续到 ht[1] 里面进行査找，诸如此类。")]),e._v(" "),v("p",[e._v("另外，在渐进式 rehash 执行期间，新增的键值对会被直接保存到 ht[1], ht[0] 不再进行任何添加操作，这样就保\n证了 ht[0] 包含的键值对数量会只减不增，并随着 rehash 操作的执行而最终变成空表。")]),e._v(" "),v("p",[v("strong",[e._v("6.12、rehash 流程在数据量大的时候会有什么问题吗（Hash 对象的扩容流程在数据量大的时候会有什么问题\n吗）")])]),e._v(" "),v("p",[e._v("1 ）扩容期开始时，会先给 ht[1] 申请空间，所以在整个扩容期间，会同时存在 ht[0] 和 ht[1]，会占用额外的空\n间。")]),e._v(" "),v("p",[e._v("2 ）扩容期间同时存在 ht[0] 和 ht[1]，查找、删除、更新等操作有概率需要操作两张表，耗时会增加。")]),e._v(" "),v("p",[e._v("3 ）redis 在内存使用接近 maxmemory 并且有设置驱逐策略的情况下，出现 rehash 会使得内存占用超过\nmaxmemory，触发驱逐淘汰操作，导致 master/slave 均有有大量的 key 被驱逐淘汰，从而出现 master/slave\n主从不一致。")]),e._v(" "),v("p",[v("strong",[e._v("6.13、Redis 的网络事件处理器（Reactor 模式）")])]),e._v(" "),v("p",[e._v("redis 基于 reactor 模式开发了自己的网络事件处理器，由 4 个部分组成：套接字、I/O 多路复用程序、文件事件分\n派器（dispatcher）、以及事件处理器。")]),e._v(" "),v("p",[v("strong",[e._v("套接字")]),e._v(" ：socket 连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时， 就会产\n生一个相应的文件事件。因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。")]),e._v(" "),v("p",[v("strong",[e._v("I/O 多路复用程序")]),e._v(" ：提供 select、epoll、evport、kqueue 的实现，会根据当前系统自动选择最佳的方式。负责监\n听多个套接字，当套接字产生事件时，会向文件事件分派器传送那些产生了事件的套接字。当多个文件事件并发出\n现时， I/O 多路复用程序会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序、同步、每\n次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后，才会继续传送下\n一个套接字。")]),e._v(" "),v("p",[v("strong",[e._v("文件事件分派器")]),e._v(" ：接收 I/O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理\n器。")]),e._v(" "),v("p",[v("strong",[e._v("事件处理器")]),e._v(" ：事件处理器就是一个个函数， 定义了某个事件发生时， 服务器应该执行的动作。例如：建立连接、\n命令查询、命令写入、连接关闭等等。")]),e._v(" "),v("p",[v("strong",[e._v("6.14、Redis 删除过期键的策略（缓存失效策略、数据过期策略）")])]),e._v(" "),v("p",[e._v("定时删除：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除\n操作。对内存最友好，对 CPU 时间最不友好。")]),e._v(" "),v("p",[e._v("惰性删除：放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键；如果没有过\n期，就返回该键。对 CPU 时间最优化，对内存最不友好。")]),e._v(" "),v("p",[e._v("定期删除：每隔一段时间，默认100ms，程序就对数据库进行一次检査，删除里面的过期键。至 于要删除多少过\n期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。")]),e._v(" "),v("p",[e._v("Redis 使用惰性删除和定期删除。")]),e._v(" "),v("p",[v("strong",[e._v("6.15、Redis 的内存淘汰（驱逐）策略")])]),e._v(" "),v("p",[e._v("当 redis 的内存空间（maxmemory 参数配置）已经用满时，redis 将根据配置的驱逐策略（maxmemory-policy\n参数配置），进行相应的动作。")]),e._v(" "),v("p",[e._v("网上很多资料都是写 6 种，但是其实当前 redis 的淘汰策略已经有 8 种了，多余的两种是 Redis 4.0 新增的，基于\nLFU（Least Frequently Used）算法实现的。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("noeviction：默认策略，不淘汰任何 key，直接返回错误\nallkeys-lru：在所有的 key 中，使用 LRU 算法淘汰部分 key\nallkeys-lfu：在所有的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增\nallkeys-random：在所有的 key 中，随机淘汰部分 key\nvolatile-lru：在设置了过期时间的 key 中，使用 LRU 算法淘汰部分 key\nvolatile-lfu：在设置了过期时间的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增\nvolatile-random：在设置了过期时间的 key 中，随机淘汰部分 key\nvolatile-ttl：在设置了过期时间的 key 中，挑选 TTL（time to live，剩余时间）短的 key 淘汰\n")])])]),v("p",[v("strong",[e._v("6.16、Redis 的 LRU 算法怎么实现的？")])]),e._v(" "),v("p",[e._v("Redis 在 redisObject 结构体中定义了一个⻓度 24 bit 的 unsigned 类型的字段（unsigned lru:LRU_BITS），在\nLRU 算法中用来存储对象最后一次被命令程序访问的时间。")]),e._v(" "),v("p",[e._v("具体的 LRU 算法经历了两个版本。")]),e._v(" "),v("p",[v("strong",[e._v("版本 1 ：随机选取 N 个淘汰法。")])]),e._v(" "),v("p",[e._v("最初 Redis 是这样实现的：随机选 N（默认 5 ） 个 key，把空闲时间（idle time）最大的那个 key 移除。这边的 N\n可通过 maxmemory-samples 配置项修改。")]),e._v(" "),v("p",[e._v("就是这么简单，简单得让人不敢相信了，而且十分有效。")]),e._v(" "),v("p",[e._v("但是这个算法有个明显的缺点：每次都是随机从 N 个里选择 1 个，并没有利用前一轮的历史信息。其实在上一轮\n移除 key 的过程中，其实是知道了 N 个 key 的 idle time 的情况的，那在下一轮移除 key 时，其实可以利用上一\n轮的这些信息。这也是 Redis 3.0 的优化思想。")]),e._v(" "),v("p",[v("strong",[e._v("版本 2 ：Redis 3.0 对 LRU 算法进行改进，引入了缓冲池（pool，默认 16 ）的概念。")])]),e._v(" "),v("p",[e._v("当每一轮移除 key 时，拿到了 N（默认 5 ）个 key 的 idle time，遍历处理这 N 个 key，如果 key 的 idle time 比\npool 里面的 key 的 idle time 还要大，就把它添加到 pool 里面去。")]),e._v(" "),v("p",[e._v("当 pool 放满之后，每次如果有新的 key 需要放入，需要将 pool 中 idle time 最小的一个 key 移除。这样相当于\npool 里面始终维护着还未被淘汰的 idle time 最大的 16 个 key。")]),e._v(" "),v("p",[e._v("当我们每轮要淘汰的时候，直接从 pool 里面取出 idle time 最大的 key（只取 1 个），将之淘汰掉。")]),e._v(" "),v("p",[e._v("整个流程相当于随机取 5 个 key 放入 pool，然后淘汰 pool 中空闲时间最大的 key，然后再随机取 5 个 key放入\npool，继续淘汰 pool 中空闲时间最大的 key，一直持续下去。")]),e._v(" "),v("p",[e._v("在进入淘汰前会计算出需要释放的内存大小，然后就一直循环上述流程，直至释放足够的内存。")]),e._v(" "),v("p",[v("strong",[e._v("6.17、Redis 的持久化机制有哪几种，各自的实现原理和优缺点？")])]),e._v(" "),v("p",[e._v("Redis 的持久化机制有：RDB、AOF、混合持久化（RDB+AOF，Redis 4.0引入）。")]),e._v(" "),v("p",[v("strong",[e._v("1 ）RDB")])]),e._v(" "),v("p",[v("strong",[e._v("描述")]),e._v(" ：类似于快照。在某个时间点，将 Redis 在内存中的数据库状态（数据库的键值对等信息）保存到磁盘里\n面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。")]),e._v(" "),v("p",[v("strong",[e._v("命令")]),e._v(" ：有两个 Redis 命令可以用于生成 RDB 文件，一个是 SAVE，另一个是 BGSAVE。")]),e._v(" "),v("p",[v("strong",[e._v("开启")]),e._v(" ：使用 save point 配置，满足 save point 条件后会触发 BGSAVE 来存储一次快照。")]),e._v(" "),v("p",[e._v("save point 格式：save ，含义是 Redis 如果在 seconds 秒内数据发生了 changes 次改变，就保存快照文件。例\n如 Redis 默认就配置了以下 3 个：")]),e._v(" "),v("p",[v("strong",[e._v("关闭")]),e._v(' ： 1 ）注释掉所有save point 配置可以关闭 RDB 持久化。 2 ）在所有 save point 配置后增加：save ""，该配\n置可以删除所有之前配置的 save point。')]),e._v(" "),v("p",[e._v("SAVE ：生成 RDB 快照文件，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，所以通常不会直接使")]),e._v(" "),v("p",[e._v("用该命令。")]),e._v(" "),v("p",[v("strong",[e._v("BGSAVE")]),e._v(" ：fork 子进程来生成 RDB 快照文件，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请\n求，详细过程如下图：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("save 900 1 #900秒内有 1 个key发生了变化，则触发保存RDB文件\nsave 300 10 #300秒内有 10 个key发生了变化，则触发保存RDB文件\nsave 60 10000 #60秒内有 10000 个key发生了变化，则触发保存RDB文件\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('save ""\n')])])]),v("p",[v("strong",[e._v("fork")]),e._v(" ：在 Linux 系统中，调用 fork() 时，会创建出一个新进程，称为子进程，子进程会拷⻉父进程的 page\ntable。如果进程占用的内存越大，进程的 page table 也会越大，那么 fork 也会占用更多的时间。如果 Redis 占\n用的内存很大，那么在 fork 子进程时，则会出现明显的停顿现象。")]),e._v(" "),v("p",[v("strong",[e._v("RDB 的优点")])]),e._v(" "),v("p",[e._v("1 ）RDB 文件是是经过压缩的二进制文件，占用空间很小，它保存了 Redis 某个时间点的数据集，很适合用于做备\n份。 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB\n文件。这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。")]),e._v(" "),v("p",[e._v("2 ）RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）\n将它传送到别的数据中心。")]),e._v(" "),v("p",[e._v("3 ）RDB 可以最大化 redis 的性能。父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进\n程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。")]),e._v(" "),v("p",[e._v("4 ）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。")]),e._v(" "),v("p",[v("strong",[e._v("RDB 的缺点")])]),e._v(" "),v("p",[e._v("1 ）RDB 在服务器故障时容易造成数据的丢失。RDB 允许我们通过修改 save point 配置来控制持久化的频率。但\n是，因为 RDB 文件需要保存整个数据集的状态， 所以它是一个比较重的操作，如果频率太频繁，可能会对 Redis\n性能产生影响。所以通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可\n能丢失 5 分钟数据。")]),e._v(" "),v("p",[e._v("2 ）RDB 保存时使用 fork 子进程进行数据的持久化，如果数据比较大的话，fork 可能会非常耗时，造成 Redis 停\n止处理服务N毫秒。如果数据集很大且 CPU 比较繁忙的时候，停止服务的时间甚至会到一秒。")]),e._v(" "),v("p",[e._v("3 ）Linux fork 子进程采用的是 copy-on-write 的方式。在 Redis 执行 RDB 持久化期间，如果 client 写入数据很\n频繁，那么将增加 Redis 占用的内存，最坏情况下，内存的占用将达到原先的 2 倍。刚 fork 时，主进程和子进程\n共享内存，但是随着主进程需要处理写操作，主进程需要将修改的⻚面拷⻉一份出来，然后进行修改。极端情况\n下，如果所有的⻚面都被修改，则此时的内存占用是原先的 2 倍。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）AOF")])]),e._v(" "),v("p",[v("strong",[e._v("描述")]),e._v(" ：保存 Redis 服务器所执行的所有写操作命令来记录数据库状态，并在服务器启动时，通过重新执行这些命\n令来还原数据集。")]),e._v(" "),v("p",[v("strong",[e._v("开启")]),e._v(" ：AOF 持久化默认是关闭的，可以通过配置：appendonly yes 开启。")]),e._v(" "),v("p",[v("strong",[e._v("关闭")]),e._v(" ：使用配置 appendonly no 可以关闭 AOF 持久化。")]),e._v(" "),v("p",[e._v("AOF 持久化功能的实现可以分为三个步骤：命令追加、文件写入、文件同步。")]),e._v(" "),v("p",[e._v("命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态\n的 aof 缓冲区（aof_buf）的末尾。")]),e._v(" "),v("p",[e._v("文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。")]),e._v(" "),v("p",[e._v("Linux 操作系统中为了提升性能，使用了⻚缓存（page cache）。当我们将 aof_buf 的内容写到磁盘上时，此时\n数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync /\nfdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。")]),e._v(" "),v("p",[e._v("serverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，\n来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。")]),e._v(" "),v("p",[v("strong",[e._v("appendfsync 参数有三个选项")]),e._v(" ：")]),e._v(" "),v("ol",[v("li",[e._v("always：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。")]),e._v(" "),v("li",[e._v("everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过\n一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专⻔负责执行，即\n每秒刷盘 1 次。")]),e._v(" "),v("li",[e._v("no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统\n来决定。即不执行刷盘，让操作系统自己执行刷盘。")])]),e._v(" "),v("p",[e._v("AOF 的优点")]),e._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[e._v("AOF 比 RDB可靠。你可以设置不同的 fsync 策略：no、everysec 和 always。默认是 everysec，在这种配置\n下，redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据。")]),e._v(" "),v("li",[e._v("AOF文件是一个纯追加的日志文件。即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已\n满，写入中途停机等等）， 我们也可以使用 redis-check-aof 工具也可以轻易地修复这种问题。")]),e._v(" "),v("li",[e._v("当 AOF文件太大时，Redis 会自动在后台进行重写：重写后的新 AOF 文件包含了恢复当前数据集所需的最小\n命令集合。整个重写是绝对安全，因为重写是在一个新的文件上进行，同时 Redis 会继续往旧的文件追加数\n据。当新文件重写完毕，Redis 会把新旧文件进行切换，然后开始把数据写到新文件上。")]),e._v(" "),v("li",[e._v("AOF 文件有序地保存了对数据库执行的所有写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常\n容易被人读懂， 对文件进行分析（parse）也很轻松。如果你不小心执行了 FLUSHALL 命令把所有数据刷掉\n了，但只要 AOF 文件没有被重写，那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启\nRedis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。\n"),v("strong",[e._v("AOF 的缺点")])]),e._v(" "),v("li",[e._v("对于相同的数据集，AOF 文件的大小一般会比 RDB 文件大。")]),e._v(" "),v("li",[e._v("根据所使用的 fsync 策略，AOF 的速度可能会比 RDB 慢。通常 fsync 设置为每秒一次就能获得比较高的性\n能，而关闭 fsync 可以让 AOF 的速度和 RDB 一样快。")]),e._v(" "),v("li",[e._v("AOF 在过去曾经发生过这样的 bug ：因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢\n复成保存时的原样。（举个例子，阻塞命令 BRPOPLPUSH 就曾经引起过这样的 bug ） 。虽然这种 bug 在\nAOF 文件中并不常⻅， 但是相较而言， RDB 几乎是不可能出现这种 bug 的。\n"),v("strong",[e._v("3 ）混合持久化")])])]),e._v(" "),v("p",[v("strong",[e._v("描述")]),e._v(" ：混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化只发生于 AOF 重写过程。\n使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。")]),e._v(" "),v("p",[e._v("整体格式为：[RDB file][AOF tail]")]),e._v(" "),v("p",[v("strong",[e._v("开启")]),e._v(" ：混合持久化的配置参数为 aof-use-rdb-preamble，配置为 yes 时开启混合持久化，在 redis 4 刚引入时，\n默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。")]),e._v(" "),v("p",[v("strong",[e._v("关闭")]),e._v(" ：使用 aof-use-rdb-preamble no 配置即可关闭混合持久化。")]),e._v(" "),v("p",[e._v("混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子\n进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）\n的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧\n的的 AOF 文件。")]),e._v(" "),v("p",[v("strong",[e._v("优点")]),e._v(" ：结合 RDB 和 AOF 的优点, 更快的重写和恢复。")]),e._v(" "),v("p",[v("strong",[e._v("缺点")]),e._v(" ：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。")]),e._v(" "),v("p",[v("strong",[e._v("6.18、为什么需要 AOF 重写？")])]),e._v(" "),v("p",[e._v("AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越\n来越多，文件的体积也会越来越大。")]),e._v(" "),v("p",[e._v("如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积\n越大，使用 AOF 文件来进行数据还原所需的时间就越多。")]),e._v(" "),v("p",[e._v("举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就")]),e._v(" "),v("p",[e._v("需要使用 100 条记录。")]),e._v(" "),v("p",[e._v("然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。")]),e._v(" "),v("p",[e._v("为了处理这种情况， Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下， 对 AOF 文件进行重建\n（rebuild）。")]),e._v(" "),v("p",[v("strong",[e._v("6.19、介绍下 AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题？")])]),e._v(" "),v("p",[e._v("描述：Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件包含重建当前数据集所需的最少命令。\n具体过程是遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这\n个键值对的多条命令。")]),e._v(" "),v("p",[v("strong",[e._v("命令")]),e._v(" ：有两个 Redis 命令可以用于触发 AOF 重写，一个是 BGREWRITEAOF 、另一个是 REWRITEAOF 命令；")]),e._v(" "),v("p",[v("strong",[e._v("开启")]),e._v(" ：AOF 重写由两个参数共同控制，auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size，同时满足这\n两个条件，则触发 AOF 后台重写 BGREWRITEAOF。")]),e._v(" "),v("p",[v("strong",[e._v("关闭")]),e._v(" ：auto-aof-rewrite-percentage 0，指定 0 的百分比，以禁用自动AOF重写功能。")]),e._v(" "),v("p",[e._v("REWRITEAOF：进行 AOF 重写，但是会阻塞主进程，服务器将无法处理客户端发来的命令请求，通常不会直接使")]),e._v(" "),v("p",[e._v("用该命令。")]),e._v(" "),v("p",[e._v("BGREWRITEAOF：fork 子进程来进行 AOF 重写，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理\n请求。")]),e._v(" "),v("p",[e._v("REWRITEAOF 和 BGREWRITEAOF 的关系与 SAVE 和 BGSAVE 的关系类似。")]),e._v(" "),v("p",[v("strong",[e._v("AOF 后台重写存在的问题")])]),e._v(" "),v("p",[e._v("AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重\n写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的\n数据库状态和重写后的 AOF 文件保存的数据库状态不一致。")]),e._v(" "),v("p",[v("strong",[e._v("如何解决 AOF 后台重写存在的数据不一致问题")])]),e._v(" "),v("p",[e._v("为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程\n之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓\n冲区。")]),e._v(" "),v("p",[e._v("这样一来可以保证：")]),e._v(" "),v("p",[e._v("1 、现有 AOF 文件的处理工作会如常进行。这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。")]),e._v(" "),v("p",[e._v("2 、从创建子进程开始，也就是 AOF 重写开始，服务器执行的所有写命令会被记录到 AOF 重写缓冲区里面。")]),e._v(" "),v("p",[e._v("// 当前AOF文件比上次重写后的AOF文件大小的增⻓比例超过 100")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("auto-aof-rewrite-percentage 100\n// 当前AOF文件的文件大小大于64MB\nauto-aof-rewrite-min-size 64mb\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("auto-aof-rewrite-percentage 0\n")])])]),v("p",[e._v("这样，当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工\n作：")]),e._v(" "),v("p",[e._v("1 、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前\n的数据库状态一致。")]),e._v(" "),v("p",[e._v("2 、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。")]),e._v(" "),v("p",[e._v("之后，父进程就可以继续像往常一样接受命令请求了。")]),e._v(" "),v("p",[v("strong",[e._v("6.20、RDB、AOF、混合持久，我应该用哪一个？")])]),e._v(" "),v("p",[e._v("一般来说， 如果想尽量保证数据安全性， 你应该同时使用 RDB 和 AOF 持久化功能，同时可以开启混合持久化。")]),e._v(" "),v("p",[e._v("如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。")]),e._v(" "),v("p",[e._v("如果你的数据是可以丢失的，则可以关闭持久化功能，在这种情况下，Redis 的性能是最高的。")]),e._v(" "),v("p",[e._v("使用 Redis 通常都是为了提升性能，而如果为了不丢失数据而将 appendfsync 设置为 always 级别时，对 Redis\n的性能影响是很大的，在这种不能接受数据丢失的场景，其实可以考虑直接选择 MySQL 等类似的数据库。")]),e._v(" "),v("p",[v("strong",[e._v("6.21、同时开启RDB和AOF，服务重启时如何加载？")])]),e._v(" "),v("p",[e._v("简单来说，如果同时启用了 AOF 和 RDB，Redis 重新启动时，会使用 AOF 文件来重建数据集，因为通常来说，\nAOF 的数据会更完整。")]),e._v(" "),v("p",[e._v("而在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。")]),e._v(" "),v("p",[e._v("完整流程如下图所示：")]),e._v(" "),v("p",[v("strong",[e._v("6.22、Redis 怎么保证高可用、有哪些集群模式？")])]),e._v(" "),v("p",[e._v("主从复制、哨兵模式、集群模式。")]),e._v(" "),v("p",[v("strong",[e._v("6.23、主从复制")])]),e._v(" "),v("p",[e._v("在当前最新的 Redis 6.0 中，主从复制的完整过程如下：")]),e._v(" "),v("p",[v("strong",[e._v("1 ）开启主从复制")])]),e._v(" "),v("p",[e._v("通常有以下三种方式：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("在 slave 直接执行命令：slaveof\n在 slave 配置文件中加入：slaveof\n使用启动命令：--slaveof\n")])])]),v("p",[e._v("注：在 Redis 5.0 之后，slaveof 相关命令和配置已经被替换成 replicaof，例如 replicaof 。为了兼容旧版本，通\n过配置的方式仍然支持 slaveof，但是通过命令的方式则不行了。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）建立套接字（socket）连接")])]),e._v(" "),v("p",[e._v("slave 将根据指定的 IP 地址和端口，向 master 发起套接字（socket）连接，master 在接受（accept） slave 的\n套接字连接之后，为该套接字创建相应的客户端状态，此时连接建立完成。")]),e._v(" "),v("p",[v("strong",[e._v("3 ）发送PING命令")])]),e._v(" "),v("p",[e._v("slave 向 master 发送一个 PING 命令，以检査套接字的读写状态是否正常、 master 能否正常处理命令请求。")]),e._v(" "),v("p",[v("strong",[e._v("4 ）身份验证")])]),e._v(" "),v("p",[e._v("slave 向 master 发送 AUTH password 命令来进行身份验证。")]),e._v(" "),v("p",[v("strong",[e._v("5 ）发送端口信息")])]),e._v(" "),v("p",[e._v("在身份验证通过后后， slave 将向 master 发送自己的监听端口号， master 收到后记录在 slave 所对应的客户端\n状态的 slave_listening_port 属性中。")]),e._v(" "),v("p",[v("strong",[e._v("6 ）发送IP地址")])]),e._v(" "),v("p",[e._v("如果配置了 slave_announce_ip，则 slave 向 master 发送 slave_announce_ip 配置的 IP 地址， master 收到后\n记录在 slave 所对应的客户端状态的 slave_ip 属性。")]),e._v(" "),v("p",[e._v("该配置是用于解决服务器返回内网 IP 时，其他服务器无法访问的情况。可以通过该配置直接指定公网 IP。")]),e._v(" "),v("p",[v("strong",[e._v("7 ）发送CAPA")])]),e._v(" "),v("p",[e._v("CAPA 全称是 capabilities，这边表示的是同步复制的能力。slave 会在这一阶段发送 capa 告诉 master 自己具备\n的（同步）复制能力， master 收到后记录在 slave 所对应的客户端状态的 slave_capa 属性。")]),e._v(" "),v("p",[v("strong",[e._v("8 ）数据同步")])]),e._v(" "),v("p",[e._v("slave 将向 master 发送 PSYNC 命令， master 收到该命令后判断是进行部分重同步还是完整重同步，然后根据策\n略进行数据的同步。")]),e._v(" "),v("p",[v("strong",[e._v("9 ）命令传播")])]),e._v(" "),v("p",[e._v("当完成了同步之后，就会进入命令传播阶段，这时 master 只要一直将自己执行的写命令发送给 slave ，而 slave\n只要一直接收并执行 master 发来的写命令，就可以保证 master 和 slave 一直保持一致了。")]),e._v(" "),v("p",[e._v("以部分重同步为例，主从复制的核心步骤流程图如下：")]),e._v(" "),v("p",[e._v("6.24、哨兵")]),e._v(" "),v("p",[e._v("哨兵（Sentinel） 是 Redis 的高可用性解决方案：由一个或多个 Sentinel 实例组成的 Sentinel 系统可以监视任意\n多个主服务器，以及这些主服务器属下的所有从服务器。")]),e._v(" "),v("p",[e._v("Sentinel 可以在被监视的主服务器进入下线状态时，自动将下线主服务器的某个从服务器升级为新的主服务器，\n然后由新的主服务器代替已下线的主服务器继续处理命令请求。")]),e._v(" "),v("p",[v("strong",[e._v("1 ）哨兵故障检测")])]),e._v(" "),v("p",[v("strong",[e._v("检查主观下线状态")])]),e._v(" "),v("p",[e._v("在默认情况下，Sentinel 会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其\n他 Sentinel 在内）发送 PING 命令，并通过实例返回的 PING 命令回复来判断实例是否在线。")]),e._v(" "),v("p",[e._v("如果一个实例在 down-after-miliseconds 毫秒内，连续向 Sentinel 返回无效回复，那么 Sentinel 会修改这个实\n例所对应的实例结构，在结构的 flags 属性中设置 SRI_S_DOWN 标识，以此来表示这个实例已经进入主观下线状\n态。")]),e._v(" "),v("p",[v("strong",[e._v("检查客观下线状态")])]),e._v(" "),v("p",[e._v("当 Sentinel 将一个主服务器判断为主观下线之后，为了确定这个主服务器是否真的下线了，它会向同样监视这一\n服务器的其他 Sentinel 进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下\n线）。")]),e._v(" "),v("p",[e._v("当 Sentinel 从其他 Sentinel 那里接收到足够数量（quorum，可配置）的已下线判断之后，Sentinel 就会将服务\n器置为客观下线，在 flags 上打上 SRI_O_DOWN 标识，并对主服务器执行故障转移操作。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）哨兵故障转移流程")])]),e._v(" "),v("p",[e._v("当哨兵监测到某个主节点客观下线之后，就会开始故障转移流程。核心流程如下：")]),e._v(" "),v("ol",[v("li",[e._v("发起一次选举，选举出领头 Sentinel")]),e._v(" "),v("li",[e._v("领头 Sentinel 在已下线主服务器的所有从服务器里面，挑选出一个从服务器，并将其升级为新的主服务器。")]),e._v(" "),v("li",[e._v("领头 Sentinel 将剩余的所有从服务器改为复制新的主服务器。")]),e._v(" "),v("li",[e._v("领头 Sentinel 更新相关配置信息，当这个旧的主服务器重新上线时，将其设置为新的主服务器的从服务器。")])]),e._v(" "),v("p",[v("strong",[e._v("6.25、集群模式")])]),e._v(" "),v("p",[e._v("哨兵模式最大的缺点就是所有的数据都放在一台服务器上，无法较好的进行水平扩展。")]),e._v(" "),v("p",[e._v("为了解决哨兵模式存在的问题，集群模式应运而生。在高可用上，集群基本是直接复用的哨兵模式的逻辑，并且针\n对水平扩展进行了优化。")]),e._v(" "),v("p",[e._v("集群模式具备的特点如下：")]),e._v(" "),v("ol",[v("li",[e._v("采取去中心化的集群模式，将数据按槽存储分布在多个 Redis 节点上。集群共有 16384 个槽，每个节点负责\n处理部分槽。")]),e._v(" "),v("li",[e._v("使用 CRC16 算法来计算 key 所属的槽：crc16(key,keylen) & 16383。")]),e._v(" "),v("li",[e._v("所有的 Redis 节点彼此互联，通过 PING-PONG 机制来进行节点间的心跳检测。")]),e._v(" "),v("li",[e._v("分片内采用一主多从保证高可用，并提供复制和故障恢复功能。在实际使用中，通常会将主从分布在不同机\n房，避免机房出现故障导致整个分片出问题，下面的架构图就是这样设计的。")]),e._v(" "),v("li",[e._v("客户端与 Redis 节点直连，不需要中间代理层（proxy）。客户端不需要连接集群所有节点，连接集群中任\n何一个可用节点即可。")])]),e._v(" "),v("p",[e._v("集群的架构图如下所示：")]),e._v(" "),v("p",[e._v("6.26、集群选举")]),e._v(" "),v("p",[e._v("故障转移的第一步就是选举出新的主节点，以下是集群选举新的主节点的方法：")]),e._v(" "),v("p",[e._v("1 ）当从节点发现自己正在复制的主节点进入已下线状态时，会发起一次选举：将 currentEpoch（配置纪元）加\n1 ，然后向集群广播一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST 消息，要求所有收到这条消息、并且具\n有投票权的主节点向这个从节点投票。")]),e._v(" "),v("p",[e._v("2 ）其他节点收到消息后，会判断是否要给发送消息的节点投票，判断流程如下：")]),e._v(" "),v("ol",[v("li",[e._v("当前节点是 slave，或者当前节点是 master，但是不负责处理槽，则当前节点没有投票权，直接返回。")]),e._v(" "),v("li",[e._v("请求节点的 currentEpoch 小于当前节点的 currentEpoch，校验失败返回。因为发送者的状态与当前集群状\n态不一致，可能是⻓时间下线的节点刚刚上线，这种情况下，直接返回即可。")]),e._v(" "),v("li",[e._v("当前节点在该 currentEpoch 已经投过票，校验失败返回。")]),e._v(" "),v("li",[e._v("请求节点是 master，校验失败返回。")]),e._v(" "),v("li",[e._v("请求节点的 master 为空，校验失败返回。")]),e._v(" "),v("li",[e._v("请求节点的 master 没有故障，并且不是手动故障转移，校验失败返回。因为手动故障转移是可以在 master\n正常的情况下直接发起的。")]),e._v(" "),v("li",[e._v("上一次为该master的投票时间，在cluster_node_timeout的 2 倍范围内，校验失败返回。这个用于使获胜从\n节点有时间将其成为新主节点的消息通知给其他从节点，从而避免另一个从节点发起新一轮选举又进行一次\n没必要的故障转移")]),e._v(" "),v("li",[e._v("请求节点宣称要负责的槽位，是否比之前负责这些槽位的节点，具有相等或更大的 configEpoch，如果不\n是，校验失败返回。")])]),e._v(" "),v("p",[e._v("如果通过以上所有校验，那么主节点将向要求投票的从节点返回一条 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK\n消息，表示这个主节点支持从节点成为新的主节点。")]),e._v(" "),v("p",[e._v("3 ）每个参与选举的从节点都会接收 CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK 消息，并根据自己收到了多少条\n这种消息来统计自己获得了多少个主节点的支持。")]),e._v(" "),v("p",[e._v("4 ）如果集群里有N个具有投票权的主节点，那么当一个从节点收集到大于等于N/2+1 张支持票时，这个从节点就\n会当选为新的主节点。因为在每一个配置纪元里面，每个具有投票权的主节点只能投一次票，所以如果有 N个主\n节点进行投票，那么具有大于等于 N/2+1 张支持票的从节点只会有一个，这确保了新的主节点只会有一个。")]),e._v(" "),v("p",[e._v("5 ）如果在一个配置纪元里面没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行\n选举，直到选出新的主节点为止。")]),e._v(" "),v("p",[e._v("这个选举新主节点的方法和选举领头 Sentinel 的方法非常相似，因为两者都是基于 Raft 算法的领头选举（leader\nelection）方法来实现的。")]),e._v(" "),v("p",[v("strong",[e._v("6.27、如何保证集群在线扩容的安全性？（Redis 集群要增加分片，槽的迁移怎么保证无损）")])]),e._v(" "),v("p",[e._v("例如：集群已经对外提供服务，原来有 3 分片，准备新增 2 个分片，怎么在不下线的情况下，无损的从原有的 3 个分\n片指派若干个槽给这 2 个分片？")]),e._v(" "),v("p",[e._v("Redis 使用了 ASK 错误来保证在线扩容的安全性。")]),e._v(" "),v("p",[e._v("在槽的迁移过程中若有客户端访问，依旧先访问源节点，源节点会先在自己的数据库里面査找指定的键，如果找到\n的话，就直接执行客户端发送的命令。")]),e._v(" "),v("p",[e._v("如果没找到，说明该键可能已经被迁移到目标节点了，源节点将向客户端返回一个 ASK 错误，该错误会指引客户\n端转向正在导入槽的目标节点，并再次发送之前想要执行的命令，从而获取到结果。")]),e._v(" "),v("p",[v("strong",[e._v("6.28、Redis 事务的实现")])]),e._v(" "),v("p",[e._v("一个事务从开始到结束通常会经历以下 3 个阶段：")]),e._v(" "),v("p",[e._v("1 ）事务开始：multi 命令将执行该命令的客户端从非事务状态切换至事务状态，底层通过 flags 属性标识。")]),e._v(" "),v("p",[e._v("2 ）命令入队：当客户端处于事务状态时，服务器会根据客户端发来的命令执行不同的操作：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("exec、discard、watch、multi 命令会被立即执行\n其他命令不会立即执行，而是将命令放入到一个事务队列，然后向客户端返回 QUEUED 回复。\n")])])]),v("p",[e._v("3 ）事务执行：当一个处于事务状态的客户端向服务器发送 exec 命令时，服务器会遍历事务队列，执行队列中的\n所有命令，最后将结果全部返回给客户端。")]),e._v(" "),v("p",[e._v("不过 redis 的事务并不推荐在实际中使用，如果要使用事务，推荐使用 Lua 脚本，redis 会保证一个 Lua 脚本里的\n所有命令的原子性。")]),e._v(" "),v("p",[v("strong",[e._v("6.29、Redis 的 Java 客户端有哪些？官方推荐哪个？")])]),e._v(" "),v("p",[e._v("Redis 官网展示的 Java 客户端如下图所示，其中官方推荐的是标星的 3 个：Jedis、Redisson 和 lettuce。")]),e._v(" "),v("p",[v("strong",[e._v("6.30、Redis 里面有 1 亿个 key，其中有 10 个 key 是包含 java，如何将它们全部找出来？")])]),e._v(" "),v("p",[e._v("1 ）keys "),v("em",[e._v("java")]),e._v(" 命令，该命令性能很好，但是在数据量特别大的时候会有性能问题")]),e._v(" "),v("p",[e._v("2 ）scan 0 MATCH "),v("em",[e._v("java")]),e._v(" 命令，基于游标的迭代器，更好的选择")]),e._v(" "),v("p",[e._v("SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一\n个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。")]),e._v(" "),v("p",[e._v("当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时，\n表示迭代已结束。")]),e._v(" "),v("p",[v("strong",[e._v("6.31、使用过 Redis 做消息队列么？")])]),e._v(" "),v("p",[e._v("Redis 本身提供了一些组件来实现消息队列的功能，但是多多少少都存在一些缺点，相比于市面上成熟的消息队\n列，例如 Kafka、Rocket MQ 来说并没有优势，因此目前我们并没有使用 Redis 来做消息队列。")]),e._v(" "),v("p",[e._v("关于 Redis 做消息队列的常⻅方案主要有以下：")]),e._v(" "),v("p",[e._v("1 ）Redis 5.0 之前可以使用 List（blocking）、Pub/Sub 等来实现轻量级的消息发布订阅功能组件，但是这两种\n实现方式都有很明显的缺点，两者中相对完善的 Pub/Sub 的主要缺点就是消息无法持久化，如果出现网络断开、\nRedis 宕机等，消息就会被丢弃。")]),e._v(" "),v("p",[e._v("2 ）为了解决 Pub/Sub 模式等的缺点，Redis 在 5.0 引入了全新的 Stream，Stream 借鉴了很多 Kafka 的设计思\n想，有以下几个特点：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的\n访问位置，还能保证消息不丢失。\n引入了消费者组的概念，不同组接收到的数据完全一样（前提是条件一样），但是组内的消费者则是竞争关\n系。\n")])])]),v("p",[e._v("Redis Stream 相比于 pub/sub 已经有很明显的改善，但是相比于 Kafka，其实没有优势，同时存在：尚未经过大\n量验证、成本较高、不支持分区（partition）、无法支持大规模数据等问题。")]),e._v(" "),v("p",[v("strong",[e._v("6.32、Redis 和 Memcached 的比较")])]),e._v(" "),v("p",[e._v("1 ）数据结构：memcached 支持简单的 key-value 数据结构，而 redis 支持丰富的数据结构：String、List、\nSet、Hash、SortedSet 等。")]),e._v(" "),v("p",[e._v("2 ）数据存储：memcached 和 redis 的数据都是全部在内存中。")]),e._v(" "),v("p",[e._v("网上有一种说法 “当物理内存用完时，Redis可以将一些很久没用到的 value 交换到磁盘，同时在内存中清除”，这\n边指的是 redis 里的虚拟内存（Virtual Memory）功能，该功能在 Redis 2.0 被引入，但是在 Redis 2.4 中被默认\n关闭，并标记为废弃，而在后续版中被完全移除。")]),e._v(" "),v("p",[e._v("3 ）持久化：memcached 不支持持久化，redis 支持将数据持久化到磁盘")]),e._v(" "),v("p",[e._v("4 ）灾难恢复：实例挂掉后，memcached 数据不可恢复，redis 可通过 RDB、AOF 恢复，但是还是会有数据丢失\n问题")]),e._v(" "),v("p",[e._v("5 ）事件库：memcached 使用 Libevent 事件库，redis 自己封装了简易事件库 AeEvent")]),e._v(" "),v("p",[e._v("6 ）过期键删除策略：memcached 使用惰性删除，redis 使用惰性删除+定期删除")]),e._v(" "),v("p",[e._v("7 ）内存驱逐（淘汰）策略：memcached 主要为 LRU 算法，redis 当前支持 8 种淘汰策略，⻅本文第 16 题")]),e._v(" "),v("p",[e._v("8 ）性能比较")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("按“CPU 单核” 维度比较：由于 Redis 只使用单核，而 Memcached 可以使用多核，所以在比较上：在处理小\n数据时，平均每一个核上 Redis 比 Memcached 性能更高，而在 100k 左右的大数据时， Memcached 性能\n要高于 Redis。\n按“实例”维度进行比较：由于 Memcached 多线程的特性，在 Redis 6.0 之前，通常情况下 Memcached 性\n能是要高于 Redis 的，同时实例的 CPU 核数越多，Memcached 的性能优势越大。\n至于网上说的 redis 的性能比 memcached 快很多，这个说法就离谱。\n")])])]),v("p",[v("strong",[e._v("6.33、Redis 实现分布式锁")])]),e._v(" "),v("p",[v("strong",[e._v("1 ）加锁")])]),e._v(" "),v("p",[e._v("加锁通常使用 set 命令来实现，伪代码如下：")]),e._v(" "),v("p",[e._v("几个参数的意义如下：")]),e._v(" "),v("p",[e._v("key、value：键值对")]),e._v(" "),v("p",[e._v("PX milliseconds：设置键的过期时间为 milliseconds 毫秒。")]),e._v(" "),v("p",[e._v("NX：只在键不存在时，才对键进行设置操作。SET key value NX 效果等同于 SETNX key value。")]),e._v(" "),v("p",[e._v("PX、expireTime 参数则是用于解决没有解锁导致的死锁问题。因为如果没有过期时间，万一程序员写的代码有\nbug 导致没有解锁操作，则就出现了死锁，因此该参数起到了一个“兜底”的作用。")]),e._v(" "),v("p",[e._v("NX 参数用于保证在多个线程并发 set 下，只会有 1 个线程成功，起到了锁的“唯一”性。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）解锁")])]),e._v(" "),v("p",[e._v("解锁需要两步操作：")]),e._v(" "),v("p",[e._v("1 ）查询当前“锁”是否还是我们持有，因为存在过期时间，所以可能等你想解锁的时候，“锁”已经到期，然后被其他\n线程获取了，所以我们在解锁前需要先判断自己是否还持有“锁”")]),e._v(" "),v("p",[e._v("2 ）如果“锁”还是我们持有，则执行解锁操作，也就是删除该键值对，并返回成功；否则，直接返回失败。")]),e._v(" "),v("p",[e._v("由于当前 Redis 还没有原子命令直接支持这两步操作，所以当前通常是使用 Lua 脚本来执行解锁操作，Redis 会\n保证脚本里的内容执行是一个原子操作。")]),e._v(" "),v("p",[e._v("脚本代码如下，逻辑比较简单：")]),e._v(" "),v("p",[e._v("两个参数的意义如下：")]),e._v(" "),v("p",[e._v("KEYS[1]：我们要解锁的 key")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("set key value PX milliseconds NX\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('if redis.call("get",KEYS[ 1 ]) == ARGV[ 1 ]\nthen\nreturn redis.call("del",KEYS[ 1 ])\nelse\nreturn 0\nend\n')])])]),v("p",[e._v("ARGV[1]：我们加锁时的 value，用于判断当“锁”是否还是我们持有，如果被其他线程持有了，value 就会发生变\n化。")]),e._v(" "),v("p",[e._v("上述方法是 Redis 当前实现分布式锁的主流方法，可能会有一些小优区别，但是核心都是这个思路。看着好像没\n啥毛病，但是真的是这个样子吗？让我们继续往下看。")]),e._v(" "),v("p",[v("strong",[e._v("6.34、Redis 分布式锁过期了，还没处理完怎么办？")])]),e._v(" "),v("p",[e._v("为了防止死锁，我们会给分布式锁加一个过期时间，但是万一这个时间到了，我们业务逻辑还没处理完，怎么办？")]),e._v(" "),v("p",[e._v("首先，我们在设置过期时间时要结合业务场景去考虑，尽量设置一个比较合理的值，就是理论上正常处理的话，在\n这个过期时间内是一定能处理完毕的。")]),e._v(" "),v("p",[e._v("之后，我们再来考虑对这个问题进行兜底设计。")]),e._v(" "),v("p",[e._v("关于这个问题，目前常⻅的解决方法有两种：")]),e._v(" "),v("ol",[v("li",[e._v("守护线程“续命”：额外起一个线程，定期检查线程是否还持有锁，如果有则延⻓过期时间。Redisson 里面就\n实现了这个方案，使用“看⻔狗”定期检查（每1/3的锁时间检查 1 次），如果线程还持有锁，则刷新过期时\n间。")]),e._v(" "),v("li",[e._v("超时回滚：当我们解锁时发现锁已经被其他线程获取了，说明此时我们执行的操作已经是“不安全”的了，此\n时需要进行回滚，并返回失败。")])]),e._v(" "),v("p",[e._v("同时，需要进行告警，人为介入验证数据的正确性，然后找出超时原因，是否需要对超时时间进行优化等等。")]),e._v(" "),v("p",[v("strong",[e._v("6.35、守护线程续命的方案有什么问题吗？")])]),e._v(" "),v("p",[e._v("Redisson 使用看⻔狗（守护线程）“续命”的方案在大多数场景下是挺不错的，也被广泛应用于生产环境，但是在\n极端情况下还是会存在问题。")]),e._v(" "),v("p",[e._v("问题例子如下：")]),e._v(" "),v("ol",[v("li",[e._v("线程 1 首先获取锁成功，将键值对写入 redis 的 master 节点")]),e._v(" "),v("li",[e._v("在 redis 将该键值对同步到 slave 节点之前，master 发生了故障")]),e._v(" "),v("li",[e._v("redis 触发故障转移，其中一个 slave 升级为新的 master")]),e._v(" "),v("li",[e._v("此时新的 master 并不包含线程 1 写入的键值对，因此线程 2 尝试获取锁也可以成功拿到锁")]),e._v(" "),v("li",[e._v("此时相当于有两个线程获取到了锁，可能会导致各种预期之外的情况发生，例如最常⻅的脏数据")])]),e._v(" "),v("p",[e._v("解决方法：上述问题的根本原因主要是由于 redis 异步复制带来的数据不一致问题导致的，因此解决的方向就是保\n证数据的一致。")]),e._v(" "),v("p",[e._v("当前比较主流的解法和思路有两种：")]),e._v(" "),v("p",[e._v("1 ）Redis 作者提出的 RedLock； 2 ）Zookeeper 实现的分布式锁。")]),e._v(" "),v("p",[v("strong",[e._v("6.36、RedLock")])]),e._v(" "),v("p",[e._v("首先，该方案也是基于文章开头的那个方案（set加锁、lua脚本解锁）进行改良的，所以 antirez 只描述了差异的\n地方，大致方案如下。")]),e._v(" "),v("p",[e._v("假设我们有 N 个 Redis 主节点，例如 N = 5，这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统，\n为了取到锁，客户端应该执行以下操作:")]),e._v(" "),v("ol",[v("li",[e._v("获取当前时间，以毫秒为单位。")]),e._v(" "),v("li",[e._v("依次尝试从 5 个实例，使用相同的 key 和随机值（例如UUID）获取锁。当向Redis 请求获取锁时，客户端应")])]),e._v(" "),v("p",[e._v("该设置一个超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，则超时时间")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("应该在 5-50 毫秒之间。这样可以防止客户端在试图与一个宕机的 Redis 节点对话时⻓时间处于阻塞状态。如\n果一个实例不可用，客户端应该尽快尝试去另外一个Redis实例请求获取锁。\n")])])]),v("ol",{attrs:{start:"3"}},[v("li",[e._v("客户端通过当前时间减去步骤 1 记录的时间来计算获取锁使用的时间。当且仅当从大多数（N/2+1，这里是 3\n个节点）的Redis节点都取到锁，并且获取锁使用的时间小于锁失效时间时，锁才算获取成功。")]),e._v(" "),v("li",[e._v("如果取到了锁，其真正有效时间等于初始有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。")]),e._v(" "),v("li",[e._v("如果由于某些原因未能获得锁（无法在至少N/2+1个Redis实例获取锁、或获取锁的时间超过了有效时间），\n客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到\n锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。")])]),e._v(" "),v("p",[e._v("可以看出，该方案为了解决数据不一致的问题，直接舍弃了异步复制，只使用 master 节点，同时由于舍弃了\nslave，为了保证可用性，引入了 N 个节点，官方建议是 5 。")]),e._v(" "),v("p",[e._v("该方案看着挺美好的，但是实际上我所了解到的在实际生产上应用的不多，主要有两个原因： 1 ）该方案的成本似\n乎有点高，需要使用 5 个实例； 2 ）该方案一样存在问题。")]),e._v(" "),v("p",[e._v("该方案主要存以下问题：")]),e._v(" "),v("ol",[v("li",[e._v("严重依赖系统时钟。如果线程 1 从 3 个实例获取到了锁，但是这 3 个实例中的某个实例的系统时间走的稍微快\n一点，则它持有的锁会提前过期被释放，当他释放后，此时又有 3 个实例是空闲的，则线程 2 也可以获取到\n锁，则可能出现两个线程同时持有锁了。")]),e._v(" "),v("li",[e._v("如果线程 1 从 3 个实例获取到了锁，但是万一其中有 1 台重启了，则此时又有 3 个实例是空闲的，则线程 2 也可\n以获取到锁，此时又出现两个线程同时持有锁了。")])]),e._v(" "),v("p",[e._v("针对以上问题其实后续也有人给出一些相应的解法，但是整体上来看还是不够完美，所以目前实际应用得不是那么\n多。")]),e._v(" "),v("p",[v("strong",[e._v("6.37、使用缓存时，先操作数据库 or 先操作缓存")])]),e._v(" "),v("p",[v("strong",[e._v("1 ）先操作数据库")])]),e._v(" "),v("p",[e._v("案例如下，有两个并发的请求，一个写请求，一个读请求，流程如下：")]),e._v(" "),v("p",[e._v("可能存在的脏数据时间范围：更新数据库后，失效缓存前。这个时间范围很小，通常不会超过几毫秒。")]),e._v(" "),v("p",[e._v("2 ）先操作缓存")]),e._v(" "),v("p",[e._v("案例如下，有两个并发的请求，一个写请求，一个读请求，流程如下：")]),e._v(" "),v("p",[e._v("可能存在的脏数据时间范围：更新数据库后，下一次对该数据的更新前。这个时间范围不确定性很大，情况如下：")]),e._v(" "),v("p",[e._v("如果下一次对该数据的更新⻢上就到来，那么会失效缓存，脏数据的时间就很短。")]),e._v(" "),v("p",[e._v("如果下一次对该数据的更新要很久才到来，那这期间缓存保存的一直是脏数据，时间范围很⻓。")]),e._v(" "),v("p",[e._v("结论：通过上述案例可以看出，先操作数据库和先操作缓存都会存在脏数据的情况。但是相比之下，先操作数据")]),e._v(" "),v("p",[e._v("库，再操作缓存是更优的方式，即使在并发极端情况下，也只会出现很小量的脏数据。")]),e._v(" "),v("p",[e._v("6.38、为什么是让缓存失效，而不是更新缓存？")]),e._v(" "),v("p",[e._v("1 ）更新缓存")]),e._v(" "),v("p",[e._v("案例如下，有两个并发的写请求，流程如下：")]),e._v(" "),v("p",[e._v("分析：数据库中的数据是请求B的，缓存中的数据是请求A的，数据库和缓存存在数据不一致。")]),e._v(" "),v("p",[e._v("2 ）失效（删除）缓存")]),e._v(" "),v("p",[e._v("案例如下，有两个并发的写请求，流程如下：")]),e._v(" "),v("p",[e._v("分析：由于是删除缓存，所以不存在数据不一致的情况。")]),e._v(" "),v("p",[e._v("结论：通过上述案例，可以很明显的看出，失效缓存是更优的方式。")]),e._v(" "),v("p",[e._v("6.39、如何保证数据库和缓存的数据一致性？")]),e._v(" "),v("p",[e._v("在上文的案例中，无论是先操作数据库，还是先操作缓存，都会存在脏数据的情况，有办法避免吗？")]),e._v(" "),v("p",[e._v("答案是有的， 由于数据库和缓存是两个不同的数据源，要保证其数据一致性，其实就是典型的分布式事务场景，可")]),e._v(" "),v("p",[e._v("以引入分布式事务来解决，常⻅的有：2PC、TCC、MQ事务消息等。")]),e._v(" "),v("p",[e._v("但是引入分布式事务必然会带来性能上的影响，这与我们当初引入缓存来提升性能的目的是相违背的。")]),e._v(" "),v("p",[e._v("所以在实际使用中，通常不会去保证缓存和数据库的强一致性，而是做出一定的牺牲，保证两者数据的最终一致")]),e._v(" "),v("p",[e._v("性。")]),e._v(" "),v("p",[e._v("如果是实在无法接受脏数据的场景，则比较合理的方式是放弃使用缓存，直接走数据库。")]),e._v(" "),v("p",[e._v("保证数据库和缓存数据最终一致性的常用方案如下：")]),e._v(" "),v("p",[e._v("1 ）更新数据库，数据库产生 binlog。")]),e._v(" "),v("p",[e._v("2 ）监听和消费 binlog，执行失效缓存操作。")]),e._v(" "),v("p",[e._v("3 ）如果步骤 2 失效缓存失败，则引入重试机制，将失败的数据通过MQ方式进行重试，同时考虑是否需要引入幂等\n机制。")]),e._v(" "),v("p",[e._v("兜底：当出现未知的问题时，及时告警通知，人为介入处理。")]),e._v(" "),v("p",[e._v("人为介入是终极大法，那些外表看着光鲜艳丽的应用，其背后大多有一群苦逼的程序员，在不断的修复各种脏数据")]),e._v(" "),v("p",[e._v("和bug。")]),e._v(" "),v("p",[v("strong",[e._v("6.40、缓存穿透")])]),e._v(" "),v("p",[e._v("描述：访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下\n一次同样会打到数据库上。")]),e._v(" "),v("p",[e._v("此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一\n样，起不到任何作用。")]),e._v(" "),v("p",[v("strong",[e._v("解决方案：")])]),e._v(" "),v("p",[v("strong",[e._v("1 ）接口校验。")]),e._v(" 在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以这\n种场景最大的可能性是遭受了非法攻击。可以在最外层先做一层校验：用户鉴权、数据合法性校验等，例如商品查\n询中，商品的ID是正整数，则可以直接对非正整数直接过滤等等。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）缓存空值。")]),e._v(" 当访问缓存和DB都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要\n根据产品业务特性来设置。")]),e._v(" "),v("p",[v("strong",[e._v("3 ）布隆过滤器。")]),e._v(" 使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查\n询缓存和数据库。")]),e._v(" "),v("p",[v("strong",[e._v("6.41、布隆过滤器")])]),e._v(" "),v("p",[e._v("布隆过滤器的特点是判断不存在的，则一定不存在；判断存在的，大概率存在，但也有小概率不存在。并且这个概\n率是可控的，我们可以让这个概率变小或者变高，取决于用户本身的需求。")]),e._v(" "),v("p",[e._v("布隆过滤器由一个 bitSet 和 一组 Hash 函数（算法）组成，是一种空间效率极高的概率型算法和数据结构，主要\n用来判断一个元素是否在集合中存在。")]),e._v(" "),v("p",[e._v("在初始化时，bitSet 的每一位被初始化为 0 ，同时会定义 Hash 函数，例如有 3 组 Hash 函数：hash1、hash2、\nhash3。")]),e._v(" "),v("p",[v("strong",[e._v("写入流程")])]),e._v(" "),v("p",[e._v("当我们要写入一个值时，过程如下，以“Java”为例：")]),e._v(" "),v("p",[e._v("1 ）首先将“Java”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为： 1 、 7 、 10 。")]),e._v(" "),v("p",[e._v("2 ）将 bitSet 的这 3 个下标标记为 1 。")]),e._v(" "),v("p",[e._v("假设我们还有另外两个值：C 和 C#，按上面的流程跟 3 组 Hash 函数分别计算，结果如下：")]),e._v(" "),v("p",[e._v("C ：Hash 函数计算 bitSet 下标为： 1 、 7 、 11")]),e._v(" "),v("p",[e._v("C## ：Hash 函数计算 bitSet 下标为： 4 、 10 、 11")]),e._v(" "),v("p",[e._v("查询流程")]),e._v(" "),v("p",[e._v("当我们要查询一个值时，过程如下，同样以“Java”为例：：")]),e._v(" "),v("p",[e._v("1 ）首先将“Java”跟 3 组 Hash 函数分别计算，得到 bitSet 的下标为： 1 、 7 、 10 。")]),e._v(" "),v("p",[e._v("2 ）查看 bitSet 的这 3 个下标是否都为 1 ，如果这 3 个下标不都为 1 ，则说明该值必然不存在，如果这 3 个下标都为\n1 ，则只能说明可能存在，并不能说明一定存在。")]),e._v(" "),v("p",[e._v("其实上图的例子已经说明了这个问题了，当我们只有值“Java”和“C#”时，bitSet 下标为 1 的有： 1 、 4 、 7 、 10 、\n11 。")]),e._v(" "),v("p",[e._v("当我们又加入值“C”时，bitSet 下标为 1 的还是这 5 个，所以当 bitSet 下标为 1 的为： 1 、 4 、 7 、 10 、 11 时，我们无\n法判断值“C”存不存在。")]),e._v(" "),v("p",[e._v("其根本原因是，不同的值在跟 Hash 函数计算后，可能会得到相同的下标，所以某个值的标记位，可能会被其他值\n给标上了。")]),e._v(" "),v("p",[e._v("这也是为啥布隆过滤器只能判断某个值可能存在，无法判断必然存在的原因。但是反过来，如果该值根据 Hash 函\n数计算的标记位没有全部都为 1 ，那么则说明必然不存在，这个是肯定的。")]),e._v(" "),v("p",[e._v("降低这种误判率的思路也比较简单：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("一个是加大 bitSet 的⻓度，这样不同的值出现“冲突”的概率就降低了，从而误判率也降低。\n提升 Hash 函数的个数，Hash 函数越多，每个值对应的 bit 越多，从而误判率也降低。\n布隆过滤器的误判率还有专⻔的推导公式，有兴趣的可以去搜相关的文章和论文查看。\n")])])]),v("p",[v("strong",[e._v("6.42、缓存击穿")])]),e._v(" "),v("p",[e._v("描述：某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最终都\n会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。")]),e._v(" "),v("p",[e._v("解决方案：")]),e._v(" "),v("p",[v("strong",[e._v("1 ）加互斥锁。")]),e._v(" 在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁\n就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。")]),e._v(" "),v("p",[e._v("关于互斥锁的选择，网上看到的大部分文章都是选择 Redis 分布式锁，因为这个可以保证只有一个请求会走到数\n据库，这是一种思路。")]),e._v(" "),v("p",[e._v("但是其实仔细想想的话，这边其实没有必要保证只有一个请求走到数据库，只要保证走到数据库的请求能大大降低\n即可，所以还有另一个思路是 JVM 锁。")]),e._v(" "),v("p",[e._v("JVM 锁保证了在单台服务器上只有一个请求走到数据库，通常来说已经足够保证数据库的压力大大降低，同时在\n性能上比分布式锁更好。")]),e._v(" "),v("p",[e._v("需要注意的是，无论是使用“分布式锁”，还是“JVM 锁”，加锁时要按 key 维度去加锁。")]),e._v(" "),v("p",[e._v("我看网上很多文章都是使用一个“固定的 key”加锁，这样会导致不同的 key 之间也会互相阻塞，造成性能严重损\n耗。")]),e._v(" "),v("p",[e._v("使用 redis 分布式锁的伪代码，仅供参考：")]),e._v(" "),v("p",[e._v("2 ）热点数据不过期 。直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。")]),e._v(" "),v("p",[e._v("这种方式适用于比较极端的场景，例如流量特别特别大的场景，使用时需要考虑业务能接受数据不一致的时间，还")]),e._v(" "),v("p",[e._v("有就是异常情况的处理，不要到时候缓存刷新不上，一直是脏数据，那就凉了。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public Object getData(String key) throws InterruptedException {\nObject value = redis.get(key);\n// 缓存值过期\nif (value == null) {\n// lockRedis：专⻔用于加锁的redis；\n// "empty"：加锁的值随便设置都可以\nif (lockRedis.set(key, "empty", "PX", lockExpire, "NX")) {\ntry {\n// 查询数据库，并写到缓存，让其他线程可以直接走缓存\nvalue = getDataFromDb(key);\nredis.set(key, value, "PX", expire);\n} catch (Exception e) {\n// 异常处理\n} finally {\n// 释放锁\nlockRedis.delete(key);\n}\n} else {\n// sleep50ms后，进行重试\nThread.sleep( 50 );\nreturn getData(key);\n}\n}\nreturn value;\n}\n')])])]),v("p",[e._v("6.43、缓存雪崩")]),e._v(" "),v("p",[e._v("描述：大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力\n骤增，引起雪崩，甚至导致数据库被打挂。")]),e._v(" "),v("p",[e._v("缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。")]),e._v(" "),v("p",[e._v("解决方案：")]),e._v(" "),v("p",[v("strong",[e._v("1 ）过期时间打散。")]),e._v(" 既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加\n上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）热点数据不过期。")]),e._v(" 该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。")]),e._v(" "),v("p",[v("strong",[e._v("3 ）加互斥锁。")]),e._v(" 该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程原\n地阻塞等待第一个线程的计算结果，然后直接走缓存即可。")]),e._v(" "),v("h2",{attrs:{id:"第七章-分布式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第七章-分布式"}},[e._v("#")]),e._v(" 第七章：分布式")]),e._v(" "),v("p",[e._v("7.1、分布式都有哪些内容？")]),e._v(" "),v("p",[e._v("分布式分为分布式缓存(Redis)、分布式锁(Redis或Zookeeper)、分布式服务(Dubbo或SpringCloud)、分布式服务\n协调(Zookeeper)、分布式消息队列(Kafka、RabbitMq)、分布式Session、分布式事务、分布式搜索\n(elastaticSearch)等。")]),e._v(" "),v("p",[v("strong",[e._v("7.2、分布式有哪些理论？")])]),e._v(" "),v("p",[e._v("CAP、BASE。")]),e._v(" "),v("p",[e._v("分布式CAP理论，任何一个分布式系统都无法同时满足Consistency（一致性）、Availability（可用性）、\nPartition tolerance（分区容错性） 这三个基本需求。最多只能满足其中两项。Partition tolerance（分区容错\n性） 是必须的，因此一般是CP，或者AP。")]),e._v(" "),v("p",[e._v("BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短\n语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基\n于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根\n据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。")]),e._v(" "),v("p",[v("strong",[e._v("7.3、Dubbo 和 Spring Cloud 有什么区别？")])]),e._v(" "),v("p",[e._v("1 ）通信方式不同")]),e._v(" "),v("p",[e._v("1 、Dubbo 使用的是 RPC 通信，而 Spring Cloud 使用的是 HTTP RESTFul 方式。")]),e._v(" "),v("p",[e._v("2 、Dubbo 由于是二进制的传输，占用带宽会更少（基于netty等）；SpringCloud 是http协议传输，带宽会比较\n较多，同时使用http协议（http+restful api）一般会使用JSON报文，消耗会更大。")]),e._v(" "),v("p",[e._v("3 、Dubbo 的开发难度较大，原因是 Dubbo 的jar包依赖（存在代码级别的强依赖）问题很多大型工程无法解决；\nSpringCloud的接口协议约定比较自由且松散，需要有强有力的行政措施来限制接口无序升级。")]),e._v(" "),v("p",[e._v("4 、Dubbo 的改进是通过 Dubbofilter ，很多东⻄没有，需要自己继承，如监控，如日志，如限流，如追踪。")]),e._v(" "),v("p",[e._v("Spring Cloud具有配置管理、服务发现、断路器、智能路由、微代理、控制总线、一次性token、全局锁、选主、\n分布式会话和集群状态等，满足了构建微服务所需的所有解决方案。")]),e._v(" "),v("p",[e._v("2 ）组成部分不同")]),e._v(" "),v("p",[e._v("7.4、什么是RPC？为什么要有 RPC，HTTP 不好么？")]),e._v(" "),v("p",[e._v("RPC 就是 Remote Procedure Call，远程过程调用，它相对应的是本地过程调用。")]),e._v(" "),v("p",[v("strong",[e._v("RPC 和 HTTP 就不是一个层级的东⻄，所以严格意义上这两个没有可比性，也不应该来作比较。")])]),e._v(" "),v("p",[e._v("HTTP 只是传输协议，协议只是规范了一定的交流格式，而且 RPC 是早于 HTTP 的，所以真要问也是问有 RPC 为\n什么还要 HTTP。")]),e._v(" "),v("p",[e._v("RPC 对比的是本地过程调用，是用来作为分布式系统之间的通信，它可以用 HTTP 来传输，也可以基于 TCP 自定\n义协议传输。")]),e._v(" "),v("p",[e._v("HTTP 协议比较冗余，所以 RPC 大多都是基于 TCP 自定义协议，定制化的才是最适合自己的。")]),e._v(" "),v("p",[e._v("当然也有基于 HTTP 协议的 RPC 框架，毕竟 HTTP 是公开的协议，比较通用，像 HTTP2 已经做了相应的压缩了，")]),e._v(" "),v("p",[e._v("而且系统之间的调用都在内网，所以说影响也不会很大。")]),e._v(" "),v("p",[e._v("7.5、如果让你设计一个 RPC 框架，如何设计？")]),e._v(" "),v("p",[e._v("首先需要实现高性能的网络传输，可以采用 Netty 来实现，不用自己重复造轮子，然后需要自定义协议，毕竟远\n程交互都需要遵循一定的协议，然后还需要定义好序列化协议，网络的传输毕竟都是二进制流传输的。")]),e._v(" "),v("p",[e._v("然后可以搞一套描述服务的语言，即 IDL（Interface description language），让所有的服务都用 IDL 定义，再由\n框架转换为特定编程语言的接口，这样就能跨语言了。")]),e._v(" "),v("p",[e._v("此时最近基本的功能已经有了，但是只是最基础的，工业级的话首先得易用，所以框架需要把上述的细节对使用者\n进行屏蔽，让他们感觉不到本地调用和远程调用的区别，所以需要代理实现。")]),e._v(" "),v("p",[e._v("然后还需要实现集群功能，因此的要服务发现、注册等功能，所以需要注册中心，当然细节还是需要屏蔽的。")]),e._v(" "),v("p",[e._v("最后还需要一个完善的监控机制，埋点上报调用情况等等，便于运维。")]),e._v(" "),v("p",[v("strong",[e._v("7.6、请说一下服务暴露的流程？")])]),e._v(" "),v("p",[e._v("服务的暴露起始于 Spring IOC 容器刷新完毕之后，会根据配置参数组装成 URL， 然后根据 URL 的参数来进行本\n地或者远程调用。")]),e._v(" "),v("p",[e._v("会通过 proxyFactory.getInvoker，利用 javassist 来进行动态代理，封装真的实现类，然后再通过 URL 参数\n选择对应的协议来进行 protocol.export，默认是 Dubbo 协议。")]),e._v(" "),v("p",[e._v("在第一次暴露的时候会调用 createServer 来创建 Server，默认是 NettyServer。")]),e._v(" "),v("p",[e._v("然后将 export 得到的 exporter 存入一个 Map 中，供之后的远程调用查找，然后会向注册中心注册提供者的信\n息。")]),e._v(" "),v("p",[v("strong",[e._v("7.7、服务引入的流程是什么？")])]),e._v(" "),v("p",[e._v("服务的引入时机有两种，第一种是饿汉式，第二种是懒汉式。")]),e._v(" "),v("p",[e._v("饿汉式就是加载完毕就会引入，懒汉式是只有当这个服务被注入到其他类中时启动引入流程，默认是懒汉式。")]),e._v(" "),v("p",[e._v("会先根据配置参数组装成 URL ，一般而言我们都会配置的注册中心，所以会构建 RegistryDirectory 向注册中心注\n册消费者的信息，并且订阅提供者、配置、路由等节点。")]),e._v(" "),v("p",[e._v("得知提供者的信息之后会进入 Dubbo 协议的引入，会创建 Invoker ，期间会包含 NettyClient，来进行远程通\n信，最后通过 Cluster 来包装 Invoker，默认是 FailoverCluster，最终返回代理类。")]),e._v(" "),v("p",[v("strong",[e._v("7.8、服务调用的流程是什么？")])]),e._v(" "),v("p",[e._v("调用某个接口的方法会调用之前生成的代理类，然后会从 cluster 中经过路由的过滤、负载均衡机制选择一个\ninvoker 发起远程调用，此时会记录此请求和请求的 ID 等待服务端的响应。")]),e._v(" "),v("p",[e._v("服务端接受请求之后会通过参数找到之前暴露存储的 map，得到相应的 exporter ，然后最终调用真正的实现类，\n再组装好结果返回，这个响应会带上之前请求的 ID。")]),e._v(" "),v("p",[e._v("消费者收到这个响应之后会通过 ID 去找之前记录的请求，然后找到请求之后将响应塞到对应的 Future 中，唤醒\n等待的线程，最后消费者得到响应，一个流程完毕。")]),e._v(" "),v("p",[e._v("关键的就是 cluster、路由、负载均衡，然后 Dubbo 默认是异步的，所以请求和响应是如何对应上的。")]),e._v(" "),v("p",[e._v("7.9、什么是SPI？")]),e._v(" "),v("p",[e._v("不论是从 Dubbo 协议，还是 cluster ，什么 export 方法等等无处不是 SPI 的影子，所以如果是问 Dubbo 方面的\n问题，问 SPI 是毋庸置疑的，因为源码里 SPI 无处不在，而且 SPI 也是 Dubbo 可扩展性的基石。")]),e._v(" "),v("p",[e._v("SPI 是 Service Provider Interface，主要用于框架中，框架定义好接口，不同的使用者有不同的需求，因此需要有\n不同的实现，而 SPI 就通过定义一个特定的位置，Java SPI 约定在 Classpath 下的 META-INF/services/ 目录里创\n建一个 "),v("strong",[e._v("以服务接口命名的文件")]),e._v(" ，然后 "),v("strong",[e._v("文件里面记录的是此 jar 包提供的具体实现类的全限定名")]),e._v(" 。")]),e._v(" "),v("p",[e._v("所以就可以通过接口找到对应的文件，获取具体的实现类然后加载即可，做到了灵活的替换具体的实现类。")]),e._v(" "),v("p",[v("strong",[e._v("7.10、Dubbo 不用 JDK 的 SPI，而是要自己实现?")])]),e._v(" "),v("p",[e._v("因为 Java SPI 在查找扩展实现类的时候遍历 SPI 的配置文件并且 "),v("strong",[e._v("将实现类全部实例化")]),e._v(" ，假设一个实现类初始化过\n程比较消耗资源且耗时，但是你的代码里面又用不上它，这就产生了资源的浪费。")]),e._v(" "),v("p",[e._v("因此 Dubbo 就自己实现了一个 SPI，给每个实现类配了个名字，通过名字去文件里面找到对应的实现类全限定名\n然后加载实例化，按需加载。")]),e._v(" "),v("p",[v("strong",[e._v("7.11、Dubbo 为什么默认用 Javassist？")])]),e._v(" "),v("p",[v("strong",[e._v("速度快，且字节码生成方便。")])]),e._v(" "),v("p",[e._v("ASM 比 Javassist 更快，但是没有快一个数量级，而Javassist 只需用字符串拼接就可以生成字节码，而 ASM 需要\n手工生成，成本较高，比较麻烦。")]),e._v(" "),v("p",[v("strong",[e._v("7.12、为什么需要锁？")])]),e._v(" "),v("p",[e._v("原因其实很简单：因为我们想让同一时刻只有一个线程在执行某段代码。")]),e._v(" "),v("p",[e._v("因为如果同时出现多个线程去执行，可能会带来我们不想要的结果，可能是数据错误，也可能是服务宕机等等。")]),e._v(" "),v("p",[e._v("以淘宝双 11 为例，在 0 点这一刻，如果有几十万甚至上百万的人同时去查看某个商品的详情，这时候会触发商品的\n查询，如果我们不做控制，全部走到数据库去，那是有可能直接将数据库打垮的。")]),e._v(" "),v("p",[e._v("这个时候一个比较常用的做法就是进行加锁，只让 1 个线程去查询，其他线程待等待这个线程的查询结果后，直接\n拿结果。在这个例子中，锁用于控制访问数据库的流量，最终起到了保护系统的作用。")]),e._v(" "),v("p",[e._v("再举个例子，某平台做活动“秒杀茅台”，假如活动只秒杀 1 瓶，但是同时有 10 万人在同一时刻去抢，如果底层不做\n控制，有 10000 个人抢到了，额外的 9999 瓶平台就要自己想办法解决了。此时，我们可以在底层通过加锁或者隐\n式加锁的方式来解决这个问题。")]),e._v(" "),v("p",[e._v("此外，锁也经常用来解决并发下的数据安全方面的问题，这里就不一一举例了。")]),e._v(" "),v("p",[v("strong",[e._v("7.13、为什么需要分布式锁？")])]),e._v(" "),v("p",[e._v("分布式锁是锁的一种，通常用来跟 JVM 锁做区别。")]),e._v(" "),v("p",[e._v("JVM 锁就是我们常说的 synchronized、Lock。")]),e._v(" "),v("p",[e._v("JVM 锁只能作用于单个 JVM，可以简单理解为就是单台服务器（容器），而对于多台服务器之间，JVM 锁则没法\n解决，这时候就需要引入分布式锁。")]),e._v(" "),v("p",[e._v("7.14、实现分布式锁的方式")]),e._v(" "),v("p",[e._v("实现分布式锁的方式其实很多，只要能保证对于抢夺“锁”的系统来说，这个东⻄是唯一的，那么就能用于实现分布")]),e._v(" "),v("p",[e._v("式锁。")]),e._v(" "),v("p",[e._v("举个简单的例子，有一个 MySQL 数据库 Order，Order 库里有个 Lock 表只有一条记录，该记录有个状态字段\nlock_status，默认为 0 ，表示空闲状态，可以修改为 1 ，表示成功获取锁。")]),e._v(" "),v("p",[e._v("我们的订单系统部署在 100 台服务器上，这 100 台服务器可以在“同一时刻”对上述的这 1 条记录执行修改，修改内容\n都是从 0 修改为 1 ，但是 MysQL 会保证最终只会有 1 个线程修改成功。因此，这条记录其实就可以用于做分布式\n锁。")]),e._v(" "),v("p",[e._v("常⻅实现分布式锁的方式有：数据库、Redis、Zookeeper。这其中又以 Redis 最为常⻅。")]),e._v(" "),v("p",[v("strong",[e._v("7.15、分布式锁如何实现？")])]),e._v(" "),v("p",[v("strong",[e._v("RedLock")])]),e._v(" "),v("p",[e._v("首先，该方案也是基于之前的那个方案（set加锁、lua脚本解锁）进行改良的，所以 antirez 只描述了差异的地\n方，大致方案如下。")]),e._v(" "),v("p",[e._v("假设我们有 N 个 Redis 主节点，例如 N = 5，这些节点是完全独立的，我们不使用复制或任何其他隐式协调系统，\n为了取到锁，客户端应该执行以下操作:")]),e._v(" "),v("p",[e._v("1 、获取当前时间，以毫秒为单位。")]),e._v(" "),v("p",[e._v("2 、依次尝试从 5 个实例，使用相同的 key 和随机值（例如UUID）获取锁。当向Redis 请求获取锁时，客户端应该\n设置一个超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，则超时时间应该在\n5-50 毫秒之间。这样可以防止客户端在试图与一个宕机的 Redis 节点对话时⻓时间处于阻塞状态。如果一个实例\n不可用，客户端应该尽快尝试去另外一个Redis实例请求获取锁。")]),e._v(" "),v("p",[e._v("3 、客户端通过当前时间减去步骤 1 记录的时间来计算获取锁使用的时间。当且仅当从大多数（N/2+1，这里是 3 个\n节点）的Redis节点都取到锁，并且获取锁使用的时间小于锁失效时间时，锁才算获取成功。")]),e._v(" "),v("p",[e._v("4 、如果取到了锁，其有效时间等于有效时间减去获取锁所使用的时间（步骤 3 计算的结果）。")]),e._v(" "),v("p",[e._v("5 、如果由于某些原因未能获得锁（无法在至少N/2+1个Redis实例获取锁、或获取锁的时间超过了有效时间），客\n户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是\n客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。")]),e._v(" "),v("p",[e._v("可以看出，该方案为了解决数据不一致的问题，直接舍弃了异步复制，只使用 master 节点，同时由于舍弃了\nslave，为了保证可用性，引入了 N 个节点，官方建议是 5 。")]),e._v(" "),v("p",[e._v("该方案看着挺美好的，但是实际上我所了解到的在实际生产上应用的不多，主要有两个原因： 1 ）该方案的成本似\n乎有点高，需要使用 5 个实例； 2 ）该方案一样存在问题。")]),e._v(" "),v("p",[e._v("该方案主要存以下问题：")]),e._v(" "),v("p",[e._v("1 ）严重依赖系统时钟。如果线程 1 从 3 个实例获取到了锁，但是这 3 个实例中的某个实例的系统时间走的稍微快一\n点，则它持有的锁会提前过期被释放，当他释放后，此时又有 3 个实例是空闲的，则线程 2 也可以获取到锁，则可\n能出现两个线程同时持有锁了。")]),e._v(" "),v("p",[e._v("2 ）如果线程 1 从 3 个实例获取到了锁，但是万一其中有 1 台重启了，则此时又有 3 个实例是空闲的，则线程 2 也可以\n获取到锁，此时又出现两个线程同时持有锁了。")]),e._v(" "),v("p",[e._v("针对以上问题其实后续也有人给出一些相应的解法，但是整体上来看还是不够完美，所以目前实际应用得不是那么")]),e._v(" "),v("p",[e._v("多。")]),e._v(" "),v("p",[v("strong",[e._v("Zookeeper 实现分布式锁")])]),e._v(" "),v("p",[e._v("Zookeeper 的分布式锁实现方案如下：")]),e._v(" "),v("p",[e._v("1 ）创建一个锁目录 /locks，该节点为持久节点")]),e._v(" "),v("p",[e._v("2 ）想要获取锁的线程都在锁目录下创建一个临时顺序节点")]),e._v(" "),v("p",[e._v("3 ）获取锁目录下所有子节点，对子节点按节点自增序号从小到大排序")]),e._v(" "),v("p",[e._v("4 ）判断本节点是不是第一个子节点，如果是，则成功获取锁，开始执行业务逻辑操作；如果不是，则监听自己的\n上一个节点的删除事件")]),e._v(" "),v("p",[e._v("5 ）持有锁的线程释放锁，只需删除当前节点即可。")]),e._v(" "),v("p",[e._v("6 ）当自己监听的节点被删除时，监听事件触发，则回到第 3 步重新进行判断，直到获取到锁。")]),e._v(" "),v("p",[e._v("由于 Zookeeper 保证了数据的强一致性，因此不会存在之前 Redis 方案中的问题，整体上来看还是比较不错的。")]),e._v(" "),v("p",[e._v("Zookeeper 的主要问题在于性能不如 Redis 那么好，当申请锁和释放锁的频率较高时，会对集群造成压力，此时\n集群的稳定性可用性能可能又会遭受挑战。")]),e._v(" "),v("p",[v("strong",[e._v("7.16、分布式锁如何选型？")])]),e._v(" "),v("p",[e._v("当前主流的方案有两种：")]),e._v(" "),v("p",[e._v("1 ）Redis 的 set 加锁+lua 脚本解锁方案，至于是不是用守护线程续命可以结合自己的场景去决定，个人建议还是\n可以使用的。")]),e._v(" "),v("p",[e._v("2 ）Zookeeper 方案")]),e._v(" "),v("p",[e._v("通常情况下，对于数据的安全性要求没那么高的，可以采用 Redis 的方案，对数据安全性要求比较高的可以采用\nZookeeper 的方案。")]),e._v(" "),v("p",[v("strong",[e._v("7.17、Zookeeper做为注册中心，主要存储哪些数据？存储在哪里？")])]),e._v(" "),v("p",[e._v("ip、端口，还有心跳机制。数据存储在Zookeeper的节点上面。")]),e._v(" "),v("p",[v("strong",[e._v("7.18、Zookeeper 和 Eureka 的区别")])]),e._v(" "),v("p",[e._v("Eureka和Zookeeper都是CAP定理中的实现，Eureka（保证AP），Zookeeper（保证CP）。")]),e._v(" "),v("p",[e._v("Zookeeper保证CP，当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但\n不能接受服务直接down掉不可用。也就是说服务注册功能对可用性的要求要高于一致性、但是zk会出现这样一种\n情况当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举\nleader的时间太⻓， 30 ～120s.选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。在云部署\n的环境下，因网络问题使得zk集群失去master节点是较大概率会发生的事，虽然服务能够最终恢复，但是漫⻓的\n选举时间导致的注册⻓期不可用是不能容忍的。")]),e._v(" "),v("p",[e._v("Eureka吸取了Zookeeper的经验，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉\n不会影响正常节点的工作剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册或时\n如果发现连接生败，则会自动切换至其它节点，只要有一台Eureka还在就能保证注册服务可用（保证可用性）只\n不过查到的信息可能不是最新的（不保证强一致性）。除此之外，Eureka还有一种自我保护机制如果在 15 分钟内")]),e._v(" "),v("p",[e._v("超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种\n情况∶")]),e._v(" "),v("p",[e._v("1 ）Eureka不再从注册列表中移除因为⻓时间没收到心跳而应该过期的服务")]),e._v(" "),v("p",[e._v("2 ）Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其它节点上（即保证当前节点依然可用）")]),e._v(" "),v("p",[e._v("3 ）当网络稳定时，当前实例新的注册信息会被同步到其它节点中")]),e._v(" "),v("p",[e._v("因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服\n务瘫痪。")]),e._v(" "),v("p",[e._v("Zookeeper的设计理念就是分布式协调服务，保证数据（配置数据，状态数据）在多个服务系统之间保证一致\n性，这也不难看出Zookeeper是属于CP特性（Zookeeper的核心算法是ZAB，保证分布式系统下，数据如何在多\n个服务之间保证数据同步）。Eureka是吸取Zookeeper问题的经验，先保证可用性。")]),e._v(" "),v("p",[v("strong",[e._v("7.19、Kafka相对其他消息队列，有什么特点？")])]),e._v(" "),v("p",[e._v("持久化：Kafka的持久化能力比较好，通过磁盘持久化。而RabbitMQ是通过内存持久化的。")]),e._v(" "),v("p",[e._v("吞吐量：Rocket的并发量非常高。")]),e._v(" "),v("p",[e._v("消息处理：RabbitMQ的消息不支持批量处理，而RocketMQ和Kafka支持批量处理。")]),e._v(" "),v("p",[e._v("高可用：RabbitMQ采用主从模式。Kafka也是主从模式，通过Zookeeper管理，选举Leader，还有Replication副\n本。")]),e._v(" "),v("p",[e._v("事务：RocketMQ支持事务，而Kafka和RabbitMQ不支持。")]),e._v(" "),v("p",[v("strong",[e._v("7.20、Kafka 高效文件存储设计特点有哪些？")])]),e._v(" "),v("p",[e._v("1 ）Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定")]),e._v(" "),v("p",[e._v("期清除或删除已经消费完文件，减少磁盘占用。")]),e._v(" "),v("p",[e._v("2 ）通过索引信息可以快速定位 message 和确定 response 的最大大小。")]),e._v(" "),v("p",[e._v("3 ）通过 index 元数据全部映射到 memory，可以避免 segment file 的 IO 磁盘操作。")]),e._v(" "),v("p",[e._v("4 ）通过索引文件稀疏存储，可以大幅降低 index 文件元数据占用空间大小。")]),e._v(" "),v("p",[v("strong",[e._v("7.21、Kafka的ISR机制是什么？")])]),e._v(" "),v("p",[e._v("Kafka的核心机制，就是ISR机制。")]),e._v(" "),v("p",[e._v("这个机制简单来说，就是会自动给每个Partition维护一个ISR列表，这个列表里一定会有Leader，然后还会包含跟\nLeader保持同步的Follower。也就是说，只要Leader的某个Follower一直跟他保持数据同步，那么就会存在于ISR\n列表里。")]),e._v(" "),v("p",[e._v("但是如果Follower因为自身发生一些问题，导致不能及时的从Leader同步数据过去，那么这个Follower就会被认\n为是“out-of-sync”，从ISR列表里踢出去。所以大家先得明白这个ISR是什么，说白了，就是Kafka自动维护和监控\n哪些Follower及时的跟上了Leader的数据同步。")]),e._v(" "),v("p",[v("strong",[e._v("7.22、Kafka 如何解决数据丢失问题？")])]),e._v(" "),v("p",[e._v("1 、每个Partition都至少得有 1 个Follower在ISR列表里，跟上了Leader的数据同步。")]),e._v(" "),v("p",[e._v("2 、每次写入数据的时候，都要求至少写入Partition Leader成功，同时还有至少一个ISR里的Follower也写入成\n功，才算这个写入是成功了")]),e._v(" "),v("p",[e._v("3 、如果不满足上述两个条件，那就一直写入失败，让生产系统不停的尝试重试，直到满足上述两个条件，然后才\n能认为写入成功")]),e._v(" "),v("p",[e._v("4 、按照上述思路去配置相应的参数，才能保证写入Kafka的数据不会丢失")]),e._v(" "),v("p",[e._v("好！现在咱们来分析一下上面几点要求。")]),e._v(" "),v("p",[e._v("第一条，必须要求至少一个Follower在ISR列表里")]),e._v(" "),v("p",[e._v("那必须的啊，要是Leader没有Follower了，或者是Follower都没法及时同步Leader数据，那么这个事儿肯定就没\n法弄下去了。")]),e._v(" "),v("p",[e._v("第二条，每次写入数据的时候，要求leader写入成功以外，至少一个ISR里的Follower也写成功。大家看下面的\n图，这个要求就是保证说，每次写数据，必须是leader和follower都写成功了，才能算是写成功，保证一条数据必\n须有两个以上的副本。这个时候万一leader宕机，就可以切换到那个follower上去，那么Follower上是有刚写入的\n数据的，此时数据就不会丢失了。")]),e._v(" "),v("h2",{attrs:{id:"第八章-设计模式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第八章-设计模式"}},[e._v("#")]),e._v(" 第八章：设计模式")]),e._v(" "),v("p",[e._v("8.1、说下你知道的设计模式有哪些？")]),e._v(" "),v("p",[e._v("下面 3 种类型中各挑几个常⻅的或者你用过的说就能够了。")]),e._v(" "),v("p",[e._v("创建性模式：")]),e._v(" "),v("p",[e._v("单例模式、工厂模式、抽象工厂模式、建造者模式、原型模式")]),e._v(" "),v("p",[e._v("结构型模式：")]),e._v(" "),v("p",[e._v("适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式，代理模式")]),e._v(" "),v("p",[e._v("行为型模式：")]),e._v(" "),v("p",[e._v("模板方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、接解释器模式、状态模式、策略")]),e._v(" "),v("p",[e._v("模式、职责链模式、访问者模式。")]),e._v(" "),v("p",[e._v("8.2、工厂方法模式和抽象工厂模式有什么区别？")]),e._v(" "),v("p",[e._v("工厂方法模式：")]),e._v(" "),v("p",[e._v("一个抽象产品类，能够派生出多个具体产品类。 一个抽象工厂类，能够派生出多个具体工厂类。每一个具体工厂")]),e._v(" "),v("p",[e._v("类只能建立一个具体产品类的实例。")]),e._v(" "),v("p",[e._v("抽象工厂模式：")]),e._v(" "),v("p",[e._v("多个抽象产品类，每一个抽象产品类能够派生出多个具体产品类。 一个抽象工厂类，能够派生出多个具体工厂")]),e._v(" "),v("p",[e._v("类。每一个具体工厂类能够建立多个具体产品类的实例。")]),e._v(" "),v("p",[e._v("区别：")]),e._v(" "),v("p",[e._v("工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个。工厂方法模式的具体工厂类只能建立一个具体产品类")]),e._v(" "),v("p",[e._v("的实例，而抽象工厂模式能够建立多个。")]),e._v(" "),v("p",[e._v("8.3、JDK 中用到了哪些设计模式？")]),e._v(" "),v("p",[e._v("几乎每一种设计模式都被用到了 JDK 的源码中，下面列举一些常⻅的：")]),e._v(" "),v("p",[e._v("抽象工厂模式")]),e._v(" "),v("p",[e._v("建造者模式")]),e._v(" "),v("p",[e._v("原型模式")]),e._v(" "),v("p",[e._v("适配器模式")]),e._v(" "),v("p",[e._v("装饰器模式")]),e._v(" "),v("p",[e._v("享元模式")]),e._v(" "),v("p",[e._v("代理模式")]),e._v(" "),v("p",[e._v("责任链模式")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("javax.xml.parsers.DocumentBuilderFactory#newInstance()\njavax.xml.transform.TransformerFactory#newInstance()\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.lang.StringBuilder#append()\njava.lang.StringBuffer#append()\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.lang.Object#clone()\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.util.Arrays#asList()\njava.util.Collections#list()\n")])])]),v("p",[e._v("IO 流的子类")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.util.Collections#synchronizedXXX()\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.lang.Integer#valueOf(int)\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.lang.reflect.Proxy\njavax.inject.Inject\n")])])]),v("p",[v("strong",[e._v("8.4、Spring 中用到了哪些设计模式？")])]),e._v(" "),v("p",[e._v("1 ）单例设计模式 : Spring 中的 Bean 默认都是单例的；")]),e._v(" "),v("p",[e._v("2 ）代理设计模式 : Spring AOP 功能的实现；")]),e._v(" "),v("p",[e._v("3 ）工厂设计模式 : Spring 使用工厂模式经过 BeanFactory、ApplicationContext 建立 Bean 对象；")]),e._v(" "),v("p",[e._v("4 ）模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操做的类，它\n们就使用到了模板模式；")]),e._v(" "),v("p",[e._v("5 ）装饰器设计模式 : 咱们的项目须要链接多个数据库，并且不一样的客户在每次访问中根据须要会去访问不一样\n的数据库。这种模式让咱们能够根据客户的需求可以动态切换不一样的数据源；")]),e._v(" "),v("p",[e._v("6 ）观察者模式：Spring 事件驱动模型就是观察者模式很经典的一个应用；")]),e._v(" "),v("p",[e._v("7 ）适配器模式：Spring AOP 的加强或通知（Advice）使用到了适配器模式、SpringMVC 中也是用到了适配器模\n式适配 Controller。")]),e._v(" "),v("p",[v("strong",[e._v("8.5、设计模式六大原则是什么？")])]),e._v(" "),v("p",[e._v("1 ）单一职责原则：一个方法 一个类只负责一个职责，各个职责的程序改动，不影响其它程序。")]),e._v(" "),v("p",[e._v("2 ）开闭原则：对扩展开放，对修改关闭。即在不修改一个软件实体的基础上去扩展其余功能。")]),e._v(" "),v("p",[e._v("3 ）里氏代换原则：在软件系统中，一个能够接受基类对象的地方必然能够接受一个子类对象。")]),e._v(" "),v("p",[e._v("4 ）依赖倒转原则：针对于接口编程，依赖于抽象而不依赖于具体。")]),e._v(" "),v("p",[e._v("5 ）接口隔离原则：使用多个隔离的接口取代一个统一的接口。下降类与类之间的耦合度。")]),e._v(" "),v("p",[e._v("6 ）迪米特原则：一个实体应当尽可能少的与其余实体之间发生相互做用，使得系统功能模块相对独立。")]),e._v(" "),v("p",[v("strong",[e._v("8.6、单例模式的优缺点？")])]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("优势：\n因为在系统内存中只存在一个对象，所以能够节约系统资源，对于一些须要频繁建立和销毁的对象单例模式\n无疑能够提升系统的性能。\n缺点：\n")])])]),v("p",[e._v("因为单例模式中没有抽象层，所以单例类的扩展有很大的困难。滥用单例将带来一些负面问题，如为了节省资源将\n数据库链接池对象设计为的单例类，可能会致使共享链接池对象的程序过多而出现链接池溢出；若是实例化的对象\n⻓时间不被利用，系统会认为是垃圾而被回收，这将致使对象状态的丢失。")]),e._v(" "),v("p",[v("strong",[e._v("8.7、请手写一下单例模式？")])]),e._v(" "),v("p",[v("strong",[e._v("1. 懒汉式：用到时再去建立")])]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("java.util.logging.Logger#log()\njavax.servlet.Filter#doFilter()\n")])])]),v("ol",{attrs:{start:"2"}},[v("li",[v("p",[e._v("饿汉式：初始化时即建立，用到时直接返回")])]),e._v(" "),v("li",[v("p",[e._v("静态内部类【推荐】")])]),e._v(" "),v("li",[v("p",[e._v("双重校验锁【推荐】")])])]),e._v(" "),v("p",[e._v("public class Singleton{\nprivate static Singleton instance;\nprivate Singleton(){};")]),e._v(" "),v("p",[e._v("public static synchronized Singleton getInstance(){\nif(instance == null){\ninstance = new Singleton();\n}\nreturn instance;\n}\n}")]),e._v(" "),v("p",[e._v("public class Singleton{\nprivate static Singleton instance = new Singleton();\nprivate Singleton(){};")]),e._v(" "),v("p",[e._v("public static Singleton getInstance(){\nreturn instance;\n}\n}")]),e._v(" "),v("p",[e._v("public class Singleton{\nprivate static class SingletonHolder{\nprivate static final Singleton INSTTANCE = new Singleton();\n}")]),e._v(" "),v("p",[e._v("private Singleton(){};")]),e._v(" "),v("p",[e._v("public static final Singleton getInstance(){\nreturn SingletonHolder.INSTTANCE;\n}\n}")]),e._v(" "),v("p",[e._v("public class Singleton{\nprivate volatile static Singleton singleton;\nprivate Singleton(){};")]),e._v(" "),v("p",[e._v("public static Singleton getSingleton(){\nif(singleton == null){\nsynchronized(Singleton.class){\nif(singleton == null){")]),e._v(" "),v("p",[e._v("8.8、请说一下观察者模式。")]),e._v(" "),v("p",[e._v("消息队列（MQ），一种能实现生产者到消费者单向通信的通信模型，这也是现在常用的主流中间件。常⻅有")]),e._v(" "),v("p",[e._v("RabbitMQ、ActiveMQ、Kafka等 他们的特点也有很多比如 "),v("strong",[e._v("解偶")]),e._v(" 、 "),v("strong",[e._v("异步")]),e._v(" 、 "),v("strong",[e._v("广播")]),e._v(" 、 "),v("strong",[e._v("削峰")]),e._v(" 等等多种优势特点。")]),e._v(" "),v("p",[e._v("在设计模式中也有一种模式能有效的达到 "),v("strong",[e._v("解偶")]),e._v(" 、 "),v("strong",[e._v("异步")]),e._v(" 的特点，那就是 "),v("strong",[e._v("观察者模式")]),e._v(" 又称为 "),v("strong",[e._v("发布订阅模式")]),e._v(" 。")]),e._v(" "),v("p",[e._v("举一个例子，就好比微信朋友圈，以当前个人作为订阅者，好友作为主题。一个人发一条动态朋友圈出去，他的好\n友都能看到这个朋友圈，并且可以在自主选择点赞或者评论。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Subject（主题）: 主要由类实现的可观察的接口，通知观察者使用attach方法，以及取消观察的detach方\n法。\nConcreteSubject（具体主题）: 是一个实现主题接口的类，处理观察者的变化\nObserve（观察者）: 观察者是一个抽象类或接口，根据主题中的更改而进行更新。\n")])])]),v("p",[e._v("先创建一个主题定义，定义添加删除关系以及通知订阅者")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("singleton = new Singleton();\n}\n}\n}\nreturn singleton;\n}\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public interface Subject {\n// 添加订阅关系\nvoid attach(Observer observer);\n// 移除订阅关系\nvoid detach(Observer observer);\n// 通知订阅者\nvoid notifyObservers(String message);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class ConcreteSubject implements Subject {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// 订阅者容器\nprivate List<Observer> observers = new ArrayList<Observer>();\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Override\npublic void attach(Observer observer) {\n// 添加订阅关系\nobservers.add(observer);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Override\npublic void detach(Observer observer) {\n// 移除订阅关系\nobservers.remove(observer);\n")])])]),v("p",[e._v("其次再创建的具体主题，并且构建一个容器来维护订阅关系，支持添加删除关系，以及通知订阅者。")]),e._v(" "),v("p",[e._v("创建一个观察者接口，方便我们管理")]),e._v(" "),v("p",[e._v("最后就是创建具体的观察者类，实现观察者接口的update方法，处理本身的业务逻辑")]),e._v(" "),v("p",[e._v("}")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("@Override\npublic void notifyObservers(String message) {\n// 通知订阅者们\nfor (Observer observer : observers) {\nobserver.update(message);\n}\n}\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public interface Observer {\n// 处理业务逻辑\nvoid update(String message);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class FriendOneObserver implements Observer {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('@Override\npublic void update(String message) {\n// 模拟处理业务逻辑\nSystem.out.println("FriendOne 知道了你发动态了" + message);\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class test {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static void main(String[] args) {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("ConcreteSubject subject = new ConcreteSubject();\n// 这里假设是添加好友\nsubject.attach(new FriendOneObserver());\nFriendTwoObserver twoObserver = new FriendTwoObserver();\nsubject.attach(twoObserver);\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('// 发送朋友圈动态\nsubject.notifyObservers("第一个朋友圈消息");\n// 输出结果： FriendOne 知道了你发动态了第一个朋友圈消息\n// FriendTwo 知道了你发动态了第一个朋友圈消息\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// 这里发现 twoObserver 是个推荐卖茶叶的，删除好友\nsubject.detach(twoObserver);\n")])])]),v("p",[e._v("最后就是看测试结果了，通过ConcreteSubject 维护了一个订阅关系，在通过notifyObservers 方法通知订阅者之\n后，观察者都获取到消息从而处理自己的业务逻辑。")]),e._v(" "),v("p",[v("strong",[e._v("8.9、请说一下策略模式。")])]),e._v(" "),v("p",[e._v("定义一系列算法，封装每个算法，并使他们可以互换，不同的策略可以让算法独立于使用它们的客户而变化。 策\n略模式是属于行为型设计模式，主要是针对不同的策略做出对应行为，达到行为解偶")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Strategy（抽象策略）：抽象策略类，并且定义策略执行入口\nConcreteStrategy（具体策略）：实现抽象策略，实现algorithm方法\nContext（环境）：运行特定的策略类。\n")])])]),v("p",[e._v("举个例子，汽⻋的不同档(concreteStrategy）就好比不同的策略，驾驶者选择几档则汽⻋按几档的速度前进，整\n个选择权在驾驶者（context）手中。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("这里是用接口的形式，还有一种方式可以用抽象方法 abstract 来写也是一样的。具体就看大家自己选择了。\n")])])]),v("p",[e._v("public abstract class GearStrategyAbstract { // 定义策略执行方法 abstract void algorithm(String")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("param); }\n")])])]),v("p",[e._v("其次定义具体档位策略，实现algorithm方法。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('subject.notifyObservers("第二个朋友圈消息");\n// 输出结果：FriendOne 知道了你发动态了第二个朋友圈消息\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public interface GearStrategy {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// 定义策略执行方法\nvoid algorithm(String param);\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class GearStrategyOne implements GearStrategy {\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('@Override\npublic void algorithm(String param) {\nSystem.out.println("当前档位" + param);\n}\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public class Context {\n// 缓存所有的策略，当前是无状态的，可以共享策略类对象\nprivate static final Map<String, GearStrategy> strategies = new HashMap<>();\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('// 第一种写法\nstatic {\nstrategies.put("one", new GearStrategyOne());\n}\n')])])]),v("p",[e._v("最后就是实现运行时环境（Context），你可以定义成StrategyFactory，但都是一个意思。")]),e._v(" "),v("p",[e._v("在main方法里面的测试demo，可以看到通过不同的type类型，可以实现不同的策略，这就是策略模式主要思\n想。")]),e._v(" "),v("p",[e._v("在Context里面定义了两种写法：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("第一种是维护了一个strategies的Map容器。用这种方式就需要判断每种策略是否可以共享使用，它只是作为\n算法的实现。\n第二种是直接通过有状态的类，每次根据类型new一个新的策略类对象。这个就需要根据实际业务场景去做\n的判断。\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public static GearStrategy getStrategy(String type) {\nif (type == null || type.isEmpty()) {\nthrow new IllegalArgumentException("type should not be empty.");\n}\nreturn strategies.get(type);\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('// 第二种写法\npublic static GearStrategy getStrategySecond(String type) {\nif (type == null || type.isEmpty()) {\nthrow new IllegalArgumentException("type should not be empty.");\n}\nif (type.equals("one")) {\nreturn new GearStrategyOne();\n}\nreturn null;\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v('public static void main(String[] args) {\n// 测试结果\nGearStrategy strategyOne = Context.getStrategy("one");\nstrategyOne.algorithm("1档");\n// 结果：当前档位 1 档\nGearStrategy strategyTwo = Context.getStrategySecond("one");\nstrategyTwo.algorithm("1档");\n// 结果：当前档位 1 档\n}\n')])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("}\n")])])]),v("h2",{attrs:{id:"第九章-集合"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第九章-集合"}},[e._v("#")]),e._v(" 第九章：集合")]),e._v(" "),v("p",[v("strong",[e._v("9.1、介绍下 HashMap 的底层数据结构")])]),e._v(" "),v("p",[e._v("在 JDK 1.8，HashMap 底层是由 “数组+链表+红黑树” 组成，如下图所示，而在 JDK 1.8 之前是由 “数组+链表” 组\n成，就是下图去掉红黑树")]),e._v(" "),v("p",[e._v("9.2、为什么使用“数组+链表”？")]),e._v(" "),v("p",[e._v("使用 “数组+链表” 是为了解决 hash 冲突的问题。")]),e._v(" "),v("p",[e._v("数组和链表有如下特点：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("数组：查找容易，通过 index 快速定位；插入和删除困难，需要移动插入和删除位置之后的节点；\n链表：查找困难，需要从头结点或尾节点开始遍历，直到寻找到目标节点；插入和删除容易，只需修改目标\n节点前后节点的 next 或 prev 属性即可；\nHashMap 巧妙的将数组和链表结合在一起，发挥两者各自的优势，使用一种叫做 “拉链法” 的方式来解决哈\n希冲突。\n首先通过 index 快速定位到索引位置，这边利用了数组的优点；然后遍历链表找到节点，进行节点的新增/修\n改/删除操作，这边利用了链表的优点。简直，完美。\n")])])]),v("p",[v("strong",[e._v("9.3、为什么要改成“数组+链表+红黑树”？")])]),e._v(" "),v("p",[e._v("通过上题可以看出，“数组+链表” 已经充分发挥了这两种数据结构的优点，是个很不错的组合了。")]),e._v(" "),v("p",[e._v("但是这种组合仍然存在问题，就是在定位到索引位置后，需要先遍历链表找到节点，这个地方如果链表很⻓的话，\n也就是 hash 冲突很严重的时候，会有查找性能问题，因此在 JDK1.8中，通过引入红黑树，来优化这个问题。")]),e._v(" "),v("p",[e._v("使用链表的查找性能是 O(n)，而使用红黑树是 O(logn).")]),e._v(" "),v("p",[e._v("9.4、那在什么时候用链表？什么时候用红黑树？")]),e._v(" "),v("p",[e._v("对于插入，默认情况下是使用链表节点。当同一个索引位置的节点在新增后超过 8 个（阈值 8 ）：如果此时数组⻓")]),e._v(" "),v("p",[e._v("度大于等于 64 ，则会触发链表节点转红黑树节点（treeifyBin）；而如果数组⻓度小于 64 ，则不会触发链表转红\n黑树，而是会进行扩容，因为此时的数据量还比较小。")]),e._v(" "),v("p",[e._v("对于移除，当同一个索引位置的节点在移除后达到 6 个（阈值 6 ），并且该索引位置的节点为红黑树节点，会触发\n红黑树节点转链表节点（untreeify）。")]),e._v(" "),v("p",[v("strong",[e._v("9.5、为什么链表转红黑树的阈值是 8 ？")])]),e._v(" "),v("p",[e._v("我们平时在进行方案设计时，必须考虑的两个很重要的因素是：时间和空间。对于 HashMap 也是同样的道理，简\n单来说，阈值为 8 是在时间和空间上权衡的结果。")]),e._v(" "),v("p",[e._v("红黑树节点大小约为链表节点的 2 倍，在节点太少时，红黑树的查找性能优势并不明显，付出 2 倍空间的代价作者\n觉得不值得。")]),e._v(" "),v("p",[e._v("理想情况下，使用随机的哈希码，节点分布在 hash 桶中的频率遵循泊松分布，按照泊松分布的公式计算，链表中\n节点个数为 8 时的概率为 0.00000006（ "),v("strong",[e._v("就我们这QPS不到 10 的系统，根本不可能遇到嘛")]),e._v(" ），这个概率足够低了，\n并且到 8 个节点时，红黑树的性能优势也会开始展现出来，因此 8 是一个较合理的数字。")]),e._v(" "),v("p",[v("strong",[e._v("9.6、那为什么转回链表节点是用的 6 而不是复用 8 ？")])]),e._v(" "),v("p",[e._v("如果我们设置节点多于 8 个转红黑树，少于 8 个就⻢上转链表，当节点个数在 8 徘徊时，就会频繁进行红黑树和链表\n的转换，造成性能的损耗。")]),e._v(" "),v("p",[v("strong",[e._v("9.7、HashMap 有哪些重要属性？分别用于做什么的？")])]),e._v(" "),v("p",[e._v("除了用来存储我们的节点 table 数组外，HashMap 还有以下几个重要属性：")]),e._v(" "),v("p",[e._v("1 ）size：HashMap 已经存储的节点个数；")]),e._v(" "),v("p",[e._v("2 ）threshold： 1 ）扩容阈值（主要），当 HashMap 的个数达到该值，触发扩容。 2 ）初始化时的容量，在我们\n新建 HashMap 对象时， threshold 还会被用来存初始化时的容量。HashMap 直到我们第一次插入节点时，才会\n对 table 进行初始化，避免不必要的空间浪费。")]),e._v(" "),v("p",[e._v("3 ）loadFactor：负载因子，扩容阈值 = 容量 * 负载因子。")]),e._v(" "),v("p",[v("strong",[e._v("9.8、HashMap 的默认初始容量是多少？HashMap 的容量有什么限制吗？")])]),e._v(" "),v("p",[e._v("默认初始容量是 16 。HashMap 的容量必须是 2 的N次方，HashMap 会根据我们传入的容量计算一个“大于等于该\n容量的最小的 2 的 N 次方”，例如传 16 ，容量为 16 ；传 17 ，容量为 32 。")]),e._v(" "),v("p",[v("strong",[e._v("9.9、“大于等于该容量的最小的 2 的N次方”是怎么算的？")])]),e._v(" "),v("p",[e._v("我们先不看第一行“int n = cap - 1”，先看下面的 5 行计算。")]),e._v(" "),v("p",[e._v("|=（或等于）：这个符号比较少⻅，但是“+=”应该都⻅过，看到这你应该明白了。例如：a |= b ，可以转成：a =\na | b。")]),e._v(" "),v("blockquote",[v("blockquote",[v("blockquote",[v("p",[e._v("（无符号右移）：例如 a >>> b 指的是将 a 向右移动 b 指定的位数，右移后左边空出的位用零来填充，移出右\n边的位被丢弃。")])])])]),e._v(" "),v("p",[e._v("假设 n 的值为 0010 0001，则该计算如下图：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("static final int tableSizeFor(int cap) {\nint n = cap - 1 ;\nn |= n >>> 1 ;\nn |= n >>> 2 ;\nn |= n >>> 4 ;\nn |= n >>> 8 ;\nn |= n >>> 16 ;\nreturn (n < 0 )? 1 : (n >= MAXIMUM_CAPACITY)? MAXIMUM_CAPACITY : n + 1 ;\n}\n")])])]),v("p",[e._v("相信你应该看出来，这 5 个公式会通过最高位的 1 ，拿到 2 个 1 、 4 个 1 、 8 个 1 、 16 个 1 、 32 个 1 。当然，有多少个 1 ，")]),e._v(" "),v("p",[e._v("取决于我们的入参有多大，但我们肯定的是经过这 5 个计算，得到的值是一个低位全是 1 的值，最后返回的时候")]),e._v(" "),v("p",[e._v("+1，则会得到 1 个比n 大的 2 的N次方。")]),e._v(" "),v("p",[e._v("这时再看开头的 cap - 1 就很简单了，这是为了处理 cap 本身就是 2 的N次方的情况。")]),e._v(" "),v("p",[e._v("计算机底层是二进制的，移位和或运算是非常快的，所以这个方法的效率很高。")]),e._v(" "),v("p",[e._v("PS：这是 HashMap 中非常巧妙的设计。")]),e._v(" "),v("p",[v("strong",[e._v("9.10、HashMap 的容量必须是 2 的 N 次方，这是为什么？")])]),e._v(" "),v("p",[e._v("核心目的是：实现节点均匀分布，减少 hash 冲突。")]),e._v(" "),v("p",[e._v("计算索引位置的公式为：(n - 1) & hash，当 n 为 2 的 N 次方时，n - 1 为低位全是 1 的值，此时任何值跟 n - 1 进\n行 & 运算的结果为该值的低 N 位，达到了和取模同样的效果，实现了均匀分布。实际上，这个设计就是基于公\n式：x mod 2^n = x & (2^n - 1)，因为 & 运算比 mod 具有更高的效率。")]),e._v(" "),v("p",[e._v("如下图，当 n 不为 2 的 N 次方时，hash 冲突的概率明显增大。")]),e._v(" "),v("p",[v("strong",[e._v("9.11、HashMap 的插入流程是怎么样的？")])]),e._v(" "),v("p",[v("strong",[e._v("9.12、插入流程的图里刚开始有个计算 key 的 hash 值，是怎么设计的？")])]),e._v(" "),v("p",[e._v("源码如下：拿到 key 的 hashCode，并将 hashCode 的高 16 位和 hashCode 进行异或（XOR）运算，得到最终的\nhash 值。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("static final int hash(Object key) {\nint h;\nreturn (key == null)? 0 : (h = key.hashCode()) ^ (h >>> 16 );\n}\n")])])]),v("p",[v("strong",[e._v("9.13、为什么要将 hashCode 的高 16 位参与运算？")])]),e._v(" "),v("p",[e._v("主要是为了在 table 的⻓度较小的时候，让高位也参与运算，并且不会有太大的开销。")]),e._v(" "),v("p",[e._v("例如下图，如果 "),v("strong",[e._v("高位不参与运算")]),e._v(" ，由于 n - 1 是 0000 0111，所以结果只取决于 hash 值的低 3 位，无论高位怎么变\n化，结果都是一样的。")]),e._v(" "),v("p",[e._v("如果我们将 高位参与运算 ，则索引计算结果就不会仅取决于低位。")]),e._v(" "),v("p",[v("strong",[e._v("9.14、扩容（resize）流程介绍下？")])]),e._v(" "),v("p",[v("strong",[e._v("9.15、红黑树和链表都是通过 e.hash & oldCap == 0 来定位在新表的索引位置，这是为什么？")])]),e._v(" "),v("p",[e._v("请看对下面的例子。")]),e._v(" "),v("p",[e._v("扩容前 table 的容量为 16 ，a 节点和 b 节点在扩容前处于同一索引位置。")]),e._v(" "),v("p",[e._v("扩容后，table ⻓度为 32 ，新表的 n - 1 只比老表的 n - 1 在高位多了一个 1 （图中标红）。")]),e._v(" "),v("p",[e._v("因为 2 个节点在老表是同一个索引位置，因此计算新表的索引位置时，只取决于新表在高位多出来的这一位（图")]),e._v(" "),v("p",[e._v("中标红），而这一位的值刚好等于 oldCap。")]),e._v(" "),v("p",[e._v("因为只取决于这一位，所以只会存在两种情况： 1 ） (e.hash & oldCap) == 0 ，则新表索引位置为“原索引位置” ；\n2 ）(e.hash & oldCap) != 0，则新表索引位置为“原索引 + oldCap 位置”。")]),e._v(" "),v("p",[v("strong",[e._v("9.16、HashMap 是线程安全的吗？")])]),e._v(" "),v("p",[e._v("不是。HashMap 在并发下存在数据覆盖、遍历的同时进行修改会抛出 ConcurrentModificationException 异常等\n问题，JDK 1.8 之前还存在死循环问题。")]),e._v(" "),v("p",[v("strong",[e._v("9.17、介绍一下死循环问题？")])]),e._v(" "),v("p",[e._v("导致死循环的根本原因是 JDK 1.7 扩容采用的是“头插法”，会导致同一索引位置的节点在扩容后顺序反掉，在并发\n插入触发扩容时形成环，从而产生死循环。")]),e._v(" "),v("p",[e._v("而 JDK 1.8 之后采用的是“尾插法”，扩容后节点顺序不会反掉，不存在死循环问题。")]),e._v(" "),v("p",[e._v("JDK 1.7.0 的扩容代码如下，用例子来看会好理解点。")]),e._v(" "),v("p",[e._v("PS：这个流程较难理解，建议对着代码自己模拟走一遍。")]),e._v(" "),v("p",[e._v("例子：我们有 1 个容量为 2 的 HashMap，loadFactor=0.75，此时线程 1 和线程 2 同时往该 HashMap 插入一个数\n据，都触发了扩容流程，接着有以下流程。")]),e._v(" "),v("p",[e._v("1 ）在 2 个线程都插入节点，触发扩容流程之前，此时的结构如下图。")]),e._v(" "),v("p",[e._v("2 ）线程 1 进行扩容，执行到代码：Entry<K,V> next = e.next 后被调度挂起，此时的结构如下图。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("void transfer(Entry[] newTable) {\nEntry[] src = table;\nint newCapacity = newTable.length;\nfor (int j = 0 ; j < src.length; j++) {\nEntry<K,V> e = src[j];\nif (e != null) {\nsrc[j] = null;\ndo {\nEntry<K,V> next = e.next;\nint i = indexFor(e.hash, newCapacity);\ne.next = newTable[i];\nnewTable[i] = e;\ne = next;\n} while (e != null);\n}\n}\n}\n")])])]),v("p",[e._v("3 ）线程 1 被挂起后，线程 2 进入扩容流程，并走完整个扩容流程，此时的结构如下图。")]),e._v(" "),v("p",[e._v("由于两个线程操作的是同一个 table，所以该图又可以画成如下图。")]),e._v(" "),v("p",[e._v("4 ）线程 1 恢复后，继续走完第一次的循环流程，此时的结构如下图。")]),e._v(" "),v("p",[e._v("5 ）线程 1 继续走完第二次循环，此时的结构如下图。")]),e._v(" "),v("p",[e._v("6 ）线程 1 继续执行第三次循环，执行到 e.next = newTable[i] 时形成环，执行完第三次循环的结构如下图。")]),e._v(" "),v("p",[e._v("如果此时线程 1 调用 map.get(11) ，悲剧就出现了——无限循环（死循环）。")]),e._v(" "),v("p",[v("strong",[e._v("9.18、总结下 JDK 1.8 主要进行了哪些优化？")])]),e._v(" "),v("p",[e._v("JDK 1.8 的主要优化之前我们都聊过了，主要有以下几点：")]),e._v(" "),v("p",[e._v("1 ）底层数据结构从“数组+链表”改成“数组+链表+红黑树”，主要是优化了 hash 冲突较严重时，链表过⻓的查找性\n能：O(n) -> O(logn)。")]),e._v(" "),v("p",[e._v("2 ）计算 table 初始容量的方式发生了改变，老的方式是从 1 开始不断向左进行移位运算，直到找到大于等于入参容\n量的值；新的方式则是通过“5个移位+或等于运算”来计算。")]),e._v(" "),v("p",[e._v("// JDK 1.7.0")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public HashMap(int initialCapacity, float loadFactor) {\n// 省略\n// Find a power of 2 >= initialCapacity\nint capacity = 1 ;\nwhile (capacity < initialCapacity)\ncapacity <<= 1 ;\n// ... 省略\n}\n// JDK 1.8.0_191\nstatic final int tableSizeFor(int cap) {\nint n = cap - 1 ;\n")])])]),v("p",[e._v("3 ）优化了 hash 值的计算方式，老的通过一顿瞎JB操作，新的只是简单的让高 16 位参与了算。")]),e._v(" "),v("p",[e._v("4 ）扩容时插入方式从“头插法”改成“尾插法”，避免了并发下的死循环。")]),e._v(" "),v("p",[e._v("5 ）扩容时计算节点在新表的索引位置方式从“h & (length-1)”改成“hash & oldCap”，性能可能提升不大，但设计\n更巧妙、更优雅。")]),e._v(" "),v("p",[v("strong",[e._v("9.19、Hashtable 是怎么加锁的 ？")])]),e._v(" "),v("p",[e._v("Hashtable 通过 synchronized 修饰方法来加锁，从而实现线程安全。")]),e._v(" "),v("p",[v("strong",[e._v("9.20、LinkedHashMap 和 TreeMap 排序的区别？")])]),e._v(" "),v("p",[e._v("LinkedHashMap 和 TreeMap 都是提供了排序支持的 Map，区别在于支持的排序方式不同：")]),e._v(" "),v("p",[e._v("LinkedHashMap：保存了数据的插入顺序，也可以通过参数设置，保存数据的访问顺序。")]),e._v(" "),v("p",[e._v("TreeMap：底层是红黑树实现。可以指定比较器（Comparator 比较器），通过重写 compare 方法来自定义排\n序；如果没有指定比较器，TreeMap 默认是按 Key 的升序排序（如果 key 没有实现 Comparable接口，则会抛异\n常）。")]),e._v(" "),v("p",[v("strong",[e._v("9.21、HashMap 和 Hashtable 的区别？")])]),e._v(" "),v("p",[e._v("HashMap 允许 key 和 value 为 null，Hashtable 不允许。")]),e._v(" "),v("p",[e._v("HashMap 的默认初始容量为 16 ，Hashtable 为 11 。")]),e._v(" "),v("p",[e._v("HashMap 的扩容为原来的 2 倍，Hashtable 的扩容为原来的 2 倍加 1 。")]),e._v(" "),v("p",[e._v("HashMap 是非线程安全的，Hashtable 是线程安全的，使用 synchronized 修饰方法实现线程安全。")]),e._v(" "),v("p",[e._v("HashMap 的 hash 值重新计算过，Hashtable 直接使用 hashCode。")]),e._v(" "),v("p",[e._v("HashMap 去掉了 Hashtable 中的 contains 方法。")]),e._v(" "),v("p",[e._v("HashMap 继承自 AbstractMap 类，Hashtable 继承自 Dictionary 类。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("n |= n >>> 1 ;\nn |= n >>> 2 ;\nn |= n >>> 4 ;\nn |= n >>> 8 ;\nn |= n >>> 16 ;\nreturn (n < 0 )? 1 : (n >= MAXIMUM_CAPACITY)? MAXIMUM_CAPACITY : n + 1 ;\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public synchronized V get(Object key) {\n// ...\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public synchronized V put(K key, V value) {\n// ...\n}\n")])])]),v("p",[e._v("HashMap 的性能比 Hashtable 高，因为 Hashtable 使用 synchronized 实现线程安全，还有就是 HashMap 1.8\n之后底层数据结构优化成 “数组+链表+红黑树”，在极端情况下也能提升性能。")]),e._v(" "),v("p",[v("strong",[e._v("9.22、介绍下 ConcurrenHashMap，要讲出 1.7 和 1.8 的区别？")])]),e._v(" "),v("p",[e._v("ConcurrentHashMap 是 HashMap 的线程安全版本，和 HashMap 一样，在JDK 1.8 中进行了较大的优化。")]),e._v(" "),v("p",[e._v("JDK1.7：底层结构为：分段的数组+链表；实现线程安全的方式：分段锁（Segment，继承了ReentrantLock），\n如下图所示。")]),e._v(" "),v("p",[e._v("JDK1.8：底层结构为：数组+链表+红黑树；实现线程安全的方式：CAS + Synchronized")]),e._v(" "),v("p",[e._v("区别：")]),e._v(" "),v("p",[e._v("1 ）JDK1.8 中降低锁的粒度。JDK1.7 版本锁的粒度是基于 Segment 的，包含多个节点（HashEntry），而 JDK1.8\n锁的粒度就是单节点（Node）。")]),e._v(" "),v("p",[e._v("2 ）JDK1.8 版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用 synchronized 来进行同步，\n所以不需要分段锁的概念，也就不需要 Segment 这种数据结构了，当前还保留仅为了兼容。")]),e._v(" "),v("p",[e._v("3 ）JDK1.8 使用红黑树来优化链表，跟 HashMap 一样，优化了极端情况下，链表过⻓带来的性能问题。")]),e._v(" "),v("p",[e._v("4 ）JDK1.8 使用内置锁 synchronized 来代替重入锁 ReentrantLock，synchronized 是官方一直在不断优化的，\n现在性能已经比较可观，也是官方推荐使用的加锁方式。")]),e._v(" "),v("p",[v("strong",[e._v("9.23、ConcurrentHashMap 的并发扩容")])]),e._v(" "),v("p",[e._v("ConcurrentHashMap 在扩容时会计算出一个步⻓（stride），最小值是 16 ，然后给当前扩容线程分配“一个步⻓”\n的节点数，例如 16 个，让该线程去对这 16 个节点进行扩容操作（将节点从老表移动到新表）。")]),e._v(" "),v("p",[e._v("如果在扩容结束前又来一个线程，则也会给该线程分配一个步⻓的节点数让该线程去扩容。依次类推，以达到多线\n程并发扩容的效果。")]),e._v(" "),v("p",[e._v("例如： 64 要扩容到 128 ，步⻓为 16 ，则第一个线程会负责第 113 （索引 112 ）~128（索引 127 ）的节点，第二个线\n程会负责第 97 （索引 96 ）~112（索引 111 ）的节点，依次类推。")]),e._v(" "),v("p",[e._v("具体处理（该流程后续可能会替换成流程图）：")]),e._v(" "),v("p",[e._v("1 ）如果索引位置上为null，则直接使用 CAS 将索引位置赋值为 ForwardingNode（hash值为-1），表示已经处理\n过，这个也是触发并发扩容的关键点。")]),e._v(" "),v("p",[e._v("2 ）如果索引位置的节点 f 的 hash 值为 MOVED（-1），则代表节点 f 是 ForwardingNode 节点，只有\nForwardingNode 的 hash 值为 -1，意味着该节点已经处理过了，则跳过该节点继续往下处理。")]),e._v(" "),v("p",[e._v("3 ）否则，对索引位置的节点 f 对象使用 synchronized 进行加锁，遍历链表或红黑树，如果找到 key 和入参相同\n的，则替换掉 value 值；如果没找到，则新增一个节点。如果是链表，同时判断是否需要转红黑树。处理完在索\n引位置的节点后，会将该索引位置赋值为 ForwardingNode，表示该位置已经处理过。")]),e._v(" "),v("p",[v("strong",[e._v("ForwardingNode")]),e._v(" ：一个特殊的 Node 节点，hash 值为-1（源码中定义成 MOVED），其中存储 nextTable 的引\n用。 只有发生扩容的时候，ForwardingNode才会发挥作用，作为一个占位符放在 table 中表示当前节点已经被处\n理（或则为 null ）。")]),e._v(" "),v("p",[v("strong",[e._v("9.24、ConcurrenHashMap 和 Hashtable 的区别？")])]),e._v(" "),v("p",[v("strong",[e._v("1 ）底层数据结构：")])]),e._v(" "),v("p",[e._v("ConcurrentHashMap： 1 ）JDK1.7 采用 分段的数组+链表 实现； 2 ）JDK1.8 采用 数组+链表+红黑树，跟 JDK1.8\n的 HashMap 的底层数据结构一样。")]),e._v(" "),v("p",[e._v("Hashtable： 采用 数组+链表 的形式，跟 JDK1.8 之前的 HashMap 的底层数据结构类似。")]),e._v(" "),v("p",[v("strong",[e._v("2 ）实现线程安全的方式（重要）：")])]),e._v(" "),v("p",[e._v("ConcurrentHashMap：")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("JDK1.7：使用分段锁（Segment）保证线程安全，每个分段（Segment）包含若干个 HashEntry，当并发访\n问不同分段的数据时，不会产生锁竞争，从而提升并发性能。")])]),e._v(" "),v("li",[v("p",[e._v("JDK1.8：使用 synchronized + CAS 的方式保证线程安全，每次只锁一个节点（Node），进一步降低锁粒\n度，降低锁冲突的概率，从而提升并发性能。")])])]),e._v(" "),v("p",[e._v("Hashtable：使用 synchronized 修饰方法来保证线程安全，每个实例对象只有一把锁，并发性能较低，相当于串\n行访问。")]),e._v(" "),v("p",[v("strong",[e._v("9.25、ConcurrentHashMap 的 size() 方法怎么实现的？")])]),e._v(" "),v("p",[e._v("JDK 1.7：先尝试在不加锁的情况下尝进行统计 size，最多统计 3 次，如果连续两次统计之间没有任何对 segment\n的修改操作，则返回统计结果。否则，对每个segment 进行加锁，然后统计出结果，返回结果。")]),e._v(" "),v("p",[e._v("JDK 1.8：直接统计 baseCount 和 counterCells 的 value 值，返回的是一个近似值，如果有并发的插入或删除，\n实际的数量可能会有所不同。")]),e._v(" "),v("p",[e._v("该统计方式改编自 LongAdder 和 Striped64，这两个类在 JDK 1.8 中被引入，出自并发大神 Doug Lea 之手，是\n原子类（AtomicLong 等）的优化版本，主要优化了在并发竞争下，AtomicLong 由于 CAS 失败的带来的性能损\n耗。")]),e._v(" "),v("p",[e._v("值得注意的是，JDK1.8中，提供了另一个统计的方法 mappingCount，实现和 size 一样，只是返回的类型改成了\nlong，这也是官方推荐的方式。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public int size() {\nlong n = sumCount();\nreturn ((n < 0L)? 0 :\n(n > (long)Integer.MAX_VALUE)? Integer.MAX_VALUE :\n")])])]),v("p",[e._v("类 介绍 使用场景")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("Hashtable\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("早期的线程安全 Map，直接通过在方法加 synchronized 实现线程\n安全\n")])])]),v("p",[e._v("现在理论")]),e._v(" "),v("p",[e._v("上不会使")]),e._v(" "),v("p",[e._v("用")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("CocurrentHashMap 线程安全的 Map，通过 synchronized+ CAS 实现线程安全\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("LinkedHashMap\n能记录访问顺序或插入顺序的 Map，通过 head、tail 属性维护有序\n双向链表，通过 Entry 的 after、before 属性维护节点的顺序\n")])])]),v("p",[e._v("需要记录")]),e._v(" "),v("p",[e._v("访问顺序")]),e._v(" "),v("p",[e._v("或插入顺")]),e._v(" "),v("p",[e._v("序")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("TreeMap\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("通过实现 Comparator 实现自定义顺序的 Map，如果没有指定\nComparator 则会按 key 的升序排序，key 如果没有实现\nComparable接口，则会抛异常\n")])])]),v("p",[e._v("需要自定")]),e._v(" "),v("p",[e._v("义排序")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("HashMap 最通用的 Map，非线程安全、无序\n")])])]),v("p",[e._v("无特殊需")]),e._v(" "),v("p",[e._v("求都可使")]),e._v(" "),v("p",[e._v("用")]),e._v(" "),v("p",[v("strong",[e._v("9.26、比较下常⻅的几种 Map，在使用时怎么选择？")])]),e._v(" "),v("p",[v("strong",[e._v("9.27、ArrayList 和 Vector 的区别")])]),e._v(" "),v("p",[e._v("Vector 和 ArrayList 的实现几乎是一样的，区别在于：")]),e._v(" "),v("p",[e._v("1 ）最重要的的区别： Vector 在方法上使用了 synchronized 来保证线程安全，同时由于这个原因，在性能上\nArrayList 会有更好的表现。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("(int)n);\n}\n// 一个ConcurrentHashMap包含的映射数量可能超过int上限，\n// 所以应该使用这个方法来代替size()\npublic long mappingCount() {\nlong n = sumCount();\nreturn (n < 0L)? 0L : n; // ignore transient negative values\n}\nfinal long sumCount() {\nCounterCell[] as = counterCells; CounterCell a;\nlong sum = baseCount;\nif (as != null) {\nfor (int i = 0 ; i < as.length; ++i) {\nif ((a = as[i]) != null)\nsum += a.value;\n}\n}\nreturn sum;\n}\n")])])]),v("p",[e._v("2 ） Vector 扩容后容量默认变为原来 2 倍，而 ArrayList 为原来的 1.5 倍。")]),e._v(" "),v("p",[e._v("有类似关系的还有：StringBuilder 和 StringBuffer、HashMap 和 Hashtable。")]),e._v(" "),v("p",[v("strong",[e._v("9.28、ArrayList 和 LinkedList 的区别")])]),e._v(" "),v("p",[e._v("1 ）ArrayList 底层基于动态数组实现，LinkedList 底层基于双向链表实现。")]),e._v(" "),v("p",[e._v("2 ）对于随机访问（按 index 访问，get/set方法）：ArrayList 通过 index 直接定位到数组对应位置的节点，而\nLinkedList需要从头结点或尾节点开始遍历，直到寻找到目标节点，因此在效率上 ArrayList 优于 LinkedList。")]),e._v(" "),v("p",[e._v("3 ）对于随机插入和删除：ArrayList 需要移动目标节点后面的节点（使用System.arraycopy 方法移动节点），而\nLinkedList 只需修改目标节点前后节点的 next 或 prev 属性即可，因此在效率上 LinkedList 优于 ArrayList。")]),e._v(" "),v("p",[e._v("4 ）对于顺序插入和删除：由于 ArrayList 不需要移动节点，因此在效率上比 LinkedList 更好。这也是为什么在实\n际使用中 ArrayList 更多，因为大部分情况下我们的使用都是顺序插入。")]),e._v(" "),v("p",[e._v("5 ）两者都不是线程安全的。")]),e._v(" "),v("p",[e._v("6 ）内存空间占用： ArrayList 的空 间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的\n空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放直接后继和直接前驱以及数\n据）。")]),e._v(" "),v("p",[v("strong",[e._v("9.29、HashSet 是如何保证不重复的？")])]),e._v(" "),v("p",[e._v("HashSet 底层使用 HashMap 来实现，⻅下面的源码，元素放在 HashMap 的 key 里，value 为固定的 Object 对\n象。当 add 时调用 HashMap 的 put 方法，如果元素不存在，则返回 null 表示 add 成功，否则 add 失败。")]),e._v(" "),v("p",[e._v("由于 HashMap 的 Key 值本身就不允许重复，HashSet 正好利用 HashMap 中 key 不重复的特性来校验重复元\n素，非常的巧妙。")]),e._v(" "),v("p",[v("strong",[e._v("9.30、TreeSet 清楚吗？能详细说下吗？")])]),e._v(" "),v("p",[e._v("“TreeSet 和 TreeMap 的关系” 和上面说的 “HashSet 和 HashMap 的关系” 几乎一致。")]),e._v(" "),v("p",[e._v("TreeSet 底层默认使用 TreeMap 来实现。而 TreeMap 通过实现 Comparator（或 Key 实现 Comparable）来实\n现自定义顺序。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("private transient HashMap<E,Object> map;\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("// Dummy value to associate with an Object in the backing Map\nprivate static final Object PRESENT = new Object();\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public boolean add(E e) {\nreturn map.put(e, PRESENT)==null;\n}\n")])])]),v("p",[v("strong",[e._v("9.31、介绍下 CopyOnWriteArrayList？")])]),e._v(" "),v("p",[e._v("CopyOnWriteArrayList 是 ArrayList 的线程安全版本，也是大名鼎鼎的 copy-on-write（COW，写时复制）的一\n种实现。")]),e._v(" "),v("p",[e._v("在读操作时不加锁，跟ArrayList类似；在写操作时，复制出一个新的数组，在新数组上进行操作，操作完了，将\n底层数组指针指向新数组。适合使用在读多写少的场景。")]),e._v(" "),v("p",[e._v("例如 add(E e) 方法的操作流程如下：使用 ReentrantLock 加锁，拿到原数组的length，使用 Arrays.copyOf 方法\n从原数组复制一个新的数组（length+1），将要添加的元素放到新数组的下标length位置，最后将底层数组指针\n指向新数组。")]),e._v(" "),v("p",[v("strong",[e._v("9.32、Comparable 和 Comparator 比较？")])]),e._v(" "),v("p",[e._v("1 ）Comparable 是排序接口，一个类实现了 Comparable接口，意味着“该类支持排序”。Comparator 是比较\n器，我们可以实现该接口，自定义比较算法，创建一个 “该类的比较器” 来进行排序。")]),e._v(" "),v("p",[e._v("2 ）Comparable 相当于“内部比较器”，而 Comparator 相当于“外部比较器”。")]),e._v(" "),v("p",[e._v("3 ）Comparable 的耦合性更强，Comparator 的灵活性和扩展性更优。")]),e._v(" "),v("p",[e._v("4 ）Comparable 可以用作类的默认排序方法，而 Comparator 则用于默认排序不满足时，提供自定义排序。")]),e._v(" "),v("p",[e._v("耦合性和扩展性的问题，举个简单的例子：")]),e._v(" "),v("p",[e._v("当实现类实现了 Comparable 接口，但是已有的 compareTo 方法的比较算法不满足当前需求，此时如果想对两\n个类进行比较，有两种办法：")]),e._v(" "),v("p",[e._v("1 ）修改实现类的源代码，修改 compareTo 方法，但是这明显不是一个好方案，因为这个实现类的默认比较算法\n可能已经在其他地方使用了，此时如果修改可能会造成影响，所以一般不会这么做。")]),e._v(" "),v("p",[e._v("2 ）实现 Comparator 接口，自定义一个比较器，该方案会更优，自定义的比较器只用于当前逻辑，其他已有的逻\n辑不受影响。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("private transient NavigableMap<E,Object> m;\nprivate static final Object PRESENT = new Object();\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("TreeSet(NavigableMap<E,Object> m) {\nthis.m = m;\n}\npublic TreeSet() {\nthis(new TreeMap<E,Object>());\n}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public boolean add(E e) {\nreturn m.put(e, PRESENT)==null;\n}\n")])])]),v("p",[v("strong",[e._v("9.33、List、Set、Map三者的区别?")])]),e._v(" "),v("p",[e._v("List（对付顺序的好帮手）： 存储的对象是可重复的、有序的。")]),e._v(" "),v("p",[e._v("Set（注重独一无二的性质）：存储的对象是不可重复的、无序的。")]),e._v(" "),v("p",[e._v("Map（用 Key 来搜索的专业户）: 存储键值对（key-value），不能包含重复的键（key），每个键只能映射到一个\n值。")]),e._v(" "),v("p",[v("strong",[e._v("9.34、Map、List、Set 分别说下你了解到它们有的线程安全类和线程不安全的类？")])]),e._v(" "),v("p",[v("strong",[e._v("Map")])]),e._v(" "),v("p",[e._v("线程安全：CocurrentHashMap、Hashtable")]),e._v(" "),v("p",[e._v("线程不安全：HashMap、LinkedHashMap、TreeMap、WeakHashMap")]),e._v(" "),v("p",[v("strong",[e._v("List")])]),e._v(" "),v("p",[e._v("线程安全：Vector（线程安全版的ArrayList）、Stack（继承Vector，增加pop、push方法）、\nCopyOnWriteArrayList")]),e._v(" "),v("p",[e._v("线程不安全：ArrayList、LinkedList")]),e._v(" "),v("p",[v("strong",[e._v("Set")])]),e._v(" "),v("p",[e._v("线程安全：CopyOnWriteArraySet（底层使用CopyOnWriteArrayList，通过在插入前判断是否存在实现 Set 不重\n复的效果）")]),e._v(" "),v("p",[e._v("线程不安全：HashSet（基于 HashMap）、LinkedHashSet（基于 LinkedHashMap）、TreeSet（基于\nTreeMap）、EnumSet")]),e._v(" "),v("p",[v("strong",[e._v("9.35、Collection 与 Collections的区别")])]),e._v(" "),v("p",[e._v("Collection：集合类的一个顶级接口，提供了对集合对象进行基本操作的通用接口方法。Collection接口的意义是\n为各种具体的集合提供了最大化的统一操作方式，常⻅的 List 与 Set 就是直接继承 Collection 接口。")]),e._v(" "),v("p",[e._v("Collections：集合类的一个工具类/帮助类，提供了一系列静态方法，用于对集合中元素进行排序、搜索以及线程\n安全等各种操作。")]),e._v(" "),v("h2",{attrs:{id:"第十章-并发编程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#第十章-并发编程"}},[e._v("#")]),e._v(" 第十章：并发编程")]),e._v(" "),v("p",[v("strong",[e._v("10.1、wait() 和 sleep() 方法的区别")])]),e._v(" "),v("p",[e._v("来源不同：sleep() 来自 Thread 类，wait() 来自 Object 类。")]),e._v(" "),v("p",[e._v("对于同步锁的影响不同：sleep() 不会该表同步锁的行为，如果当前线程持有同步锁，那么 sleep 是不会让线程释\n放同步锁的。wait() 会释放同步锁，让其他线程进入 synchronized 代码块执行。")]),e._v(" "),v("p",[e._v("使用范围不同：sleep() 可以在任何地方使用。wait() 只能在同步控制方法或者同步控制块里面使用，否则会抛\nIllegalMonitorStateException。")]),e._v(" "),v("p",[e._v("恢复方式不同：两者会暂停当前线程，但是在恢复上不太一样。sleep() 在时间到了之后会重新恢复；wait() 则需\n要其他线程调用同一对象的 notify()/nofityAll() 才能重新恢复。")]),e._v(" "),v("p",[v("strong",[e._v("10.2、线程的 sleep() 方法和 yield() 方法有什么区别？")])]),e._v(" "),v("p",[e._v("线程执行 sleep() 方法后进入超时等待（TIMED_WAITING）状态，而执行 yield() 方法后进入就绪（READY）状\n态。")]),e._v(" "),v("p",[e._v("sleep() 方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程运行的机会；yield() 方法只会\n给相同优先级或更高优先级的线程以运行的机会。")]),e._v(" "),v("p",[v("strong",[e._v("10.3、线程的 join() 方法是干啥用的？")])]),e._v(" "),v("p",[e._v("用于等待当前线程终止。如果一个线程A执行了 threadB.join() 语句，其含义是：当前线程A等待 threadB 线程终\n止之后才从 threadB.join() 返回继续往下执行自己的代码。")]),e._v(" "),v("p",[v("strong",[e._v("10.4、编写多线程程序有几种实现方式？")])]),e._v(" "),v("p",[e._v("通常来说，可以认为有三种方式： 1 ）继承 Thread 类； 2 ）实现 Runnable 接口； 3 ）实现 Callable 接口。其中，\nThread 其实也是实现了 Runable 接口。Runnable 和 Callable 的主要区别在于是否有返回值。")]),e._v(" "),v("p",[v("strong",[e._v("10.5、Thread 调用 start() 方法和调用 run() 方法的区别？")])]),e._v(" "),v("p",[e._v("run()：普通的方法调用，在主线程中执行，不会新建一个线程来执行。")]),e._v(" "),v("p",[e._v("start()：新启动一个线程，这时此线程处于就绪（可运行）状态，并没有运行，一旦得到 CPU 时间片，就开始执\n行 run() 方法。")]),e._v(" "),v("p",[v("strong",[e._v("10.6、线程的状态流转")])]),e._v(" "),v("p",[e._v("一个线程可以处于以下状态之一：")]),e._v(" "),v("p",[e._v("NEW：新建但是尚未启动的线程处于此状态，没有调用 start() 方法。")]),e._v(" "),v("p",[e._v("RUNNABLE：包含就绪（READY）和运行中（RUNNING）两种状态。线程调用 start() 方法会会进入就绪\n（READY）状态，等待获取 CPU 时间片。如果成功获取到 CPU 时间片，则会进入运行中（RUNNING）状态。")]),e._v(" "),v("p",[e._v("BLOCKED：线程在进入同步方法/同步块（synchronized）时被阻塞，等待同步锁的线程处于此状态。")]),e._v(" "),v("p",[e._v("WAITING：无限期等待另一个线程执行特定操作的线程处于此状态，需要被显示的唤醒，否则会一直等待下去。\n例如对于 Object.wait()，需要等待另一个线程执行 Object.notify() 或 Object.notifyAll()；对于 Thread.join()，则\n需要等待指定的线程终止。")]),e._v(" "),v("p",[e._v("TIMED_WAITING：在指定的时间内等待另一个线程执行某项操作的线程处于此状态。跟 WAITING 类似，区别在\n于该状态有超时时间参数，在超时时间到了后会自动唤醒，避免了无期限的等待。")]),e._v(" "),v("p",[e._v("TERMINATED：执行完毕已经退出的线程处于此状态。")]),e._v(" "),v("p",[e._v("线程在给定的时间点只能处于一种状态。这些状态是虚拟机状态，不反映任何操作系统线程状态。")]),e._v(" "),v("p",[v("strong",[e._v("10.7、synchronized 和 Lock 的区别")])]),e._v(" "),v("p",[e._v("1 ）Lock 是一个接口；synchronized 是 Java 中的关键字，synchronized 是内置的语言实现；")]),e._v(" "),v("p",[e._v("2 ）Lock 在发生异常时，如果没有主动通过 unLock() 去释放锁，很可能会造成死锁现象，因此使用 Lock 时需要\n在 finally 块中释放锁；synchronized 不需要手动获取锁和释放锁，在发生异常时，会自动释放锁，因此不会导致\n死锁现象发生；")]),e._v(" "),v("p",[e._v("3 ）Lock 的使用更加灵活，可以有响应中断、有超时时间等；而 synchronized 却不行，使用 synchronized 时，\n等待的线程会一直等待下去，直到获取到锁；")]),e._v(" "),v("p",[e._v("4 ）在性能上，随着近些年 synchronized 的不断优化，Lock 和 synchronized 在性能上已经没有很明显的差距\n了，所以性能不应该成为我们选择两者的主要原因。官方推荐尽量使用 synchronized，除非 synchronized 无法\n满足需求时，则可以使用 Lock。")]),e._v(" "),v("p",[v("strong",[e._v("10.8、为什么说 synchronized 是一种悲观锁？乐观锁的实现原理又是什么？什么是CAS，它有什么特性？")])]),e._v(" "),v("p",[e._v("synchronized 显然是一个悲观锁，因为它的并发策略是悲观的：")]),e._v(" "),v("p",[e._v("不管是否会产生竞争，任何的数据操作都必须加锁，用户态核心态转换，维护锁计数器和检查是否有被阻塞的线程\n需要被唤醒等操作。随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略。先进行操作，如果没有\n其他线程征用数据，那么就操作成功了；")]),e._v(" "),v("p",[e._v("如果共享数据有征用，产生了冲突，就再进行其他的补偿措施。这种乐观的并发策略的许多实现不需要线程池挂\n起，所以被称为非阻塞同步。")]),e._v(" "),v("p",[v("strong",[e._v("乐观锁的核心算法是 CAS（Compareand Swap，比较并交换），它涉及到三个操作数：内存值、预期值、新\n值。并且仅当预期值和内存值相同时才将内存值修改为新值。")])]),e._v(" "),v("p",[e._v("这样处理的逻辑是，首先检查某块内存的值是否跟之前读取的一样，如果不一样则表示此内存值已经被别的线程更\n改，舍弃本次操作，否则说明期间没有其他线程对此内存值操作，可以把新值设置给此块内存。")]),e._v(" "),v("p",[e._v("CAS 具有原子性，它的原子性由 CPU 硬件指令实现保证，即使用 JNI 调用 Native 方法调用由 C++ 编写的硬件级\n指令，JDK中提供了 Unsafe 类执行这些操作。")]),e._v(" "),v("p",[e._v("任何技术都要找到适合的场景，都不是万能的，CAS 机制也一样，也有副作用。")]),e._v(" "),v("p",[e._v("问题 1 ：")]),e._v(" "),v("p",[e._v("作为乐观锁的一种实现，当多线程竞争资源激烈的情况下，而且锁定的资源处理耗时，那么其他线程就要考虑自旋")]),e._v(" "),v("p",[e._v("的次数限制，避免过度的消耗 CPU。")]),e._v(" "),v("p",[e._v("另外，可以使用 LongAdder 来解决，LongAdder 以空间换时间的方式，来解决 CAS 大量失败后⻓时间占用 CPU\n资源，加大了系统性能开销的问题。")]),e._v(" "),v("p",[e._v("问题 2 ：")]),e._v(" "),v("p",[e._v("A--\x3eB---\x3eA 问题，假设有一个变量 A ，修改为B，然后又修改为了 A，实际已经修改过了，但 CAS 可能无法感知，\n造成了不合理的值修改操作。")]),e._v(" "),v("p",[e._v("整数类型还好，如果是对象引用类型，包含了多个变量，那怎么办？即加个版本号或时间戳")]),e._v(" "),v("p",[e._v("JDK 中 java.util.concurrent.atomic 并发包下，提供了 AtomicStampedReference，通过为引用建立个 Stamp 类\n似版本号的方式，确保 CAS 操作的正确性。")]),e._v(" "),v("p",[v("strong",[e._v("10.9、synchronized 各种加锁场景的作用范围")])]),e._v(" "),v("p",[e._v("1 ）作用于非静态方法，锁住的是对象实例（this），每一个对象实例有一个锁。")]),e._v(" "),v("p",[e._v("2 ）作用于静态方法，锁住的是类的Class对象，因为Class的相关数据存储在永久代元空间，元空间是全局共享\n的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程。")]),e._v(" "),v("p",[e._v("3 ）作用于 Lock.class，锁住的是 Lock 的Class对象，也是全局只有一个。")]),e._v(" "),v("p",[e._v("4 ）作用于 this，锁住的是对象实例，每一个对象实例有一个锁。")]),e._v(" "),v("p",[e._v("5 ）作用于静态成员变量，锁住的是该静态成员变量对象，由于是静态变量，因此全局只有一个。")]),e._v(" "),v("p",[e._v("10.10、如何检测死锁？")]),e._v(" "),v("p",[e._v("死锁的四个必要条件：")]),e._v(" "),v("p",[e._v("1 ）互斥条件：进程对所分配到的资源进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其")]),e._v(" "),v("p",[e._v("他进程请求该资源，则请求进程只能等待。")]),e._v(" "),v("p",[e._v("2 ）请求和保持条件：进程已经获得了至少一个资源，但又对其他资源发出请求，而该资源已被其他进程占有，此")]),e._v(" "),v("p",[e._v("时该进程的请求被阻塞，但又对自己获得的资源保持不放。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public synchronized void method() {}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static synchronized void method() {}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("synchronized (Lock.class) {}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("synchronized (this) {}\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("public static Object monitor = new Object();\nsynchronized (monitor) {}\n")])])]),v("p",[e._v("3 ）不可剥夺条件：进程已获得的资源在未使用完毕之前，不可被其他进程强行剥夺，只能由自己释放。")]),e._v(" "),v("p",[e._v("4 ）环路等待条件：存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请")]),e._v(" "),v("p",[e._v("求。即存在一个处于等待状态的进程集合{Pl, P2, ..., pn}，其中 Pi 等待的资源被 P(i+1) 占有（i=0, 1, ..., n-1)，Pn\n等待的资源被 P0占 有，如下图所示。")]),e._v(" "),v("p",[e._v("10.11、怎么预防死锁？")]),e._v(" "),v("p",[e._v("预防死锁的方式就是打破四个必要条件中的任意一个即可。")]),e._v(" "),v("p",[e._v("1 ）打破互斥条件：在系统里取消互斥。若资源不被一个进程独占使用，那么死锁是肯定不会发生的。但一般来说")]),e._v(" "),v("p",[e._v("在所列的四个条件中，“互斥”条件是无法破坏的。因此，在死锁预防里主要是破坏其他几个必要条件，而不去涉及")]),e._v(" "),v("p",[e._v("破坏“互斥”条件。。")]),e._v(" "),v("p",[e._v("2 ）打破请求和保持条件： 1 ）采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待。")]),e._v(" "),v("p",[e._v("2 ）每个进程提出新的资源申请前，必须先释放它先前所占有的资源。")]),e._v(" "),v("p",[e._v("3 ）打破不可剥夺条件：当进程占有某些资源后又进一步申请其他资源而无法满足，则该进程必须释放它原来占有")]),e._v(" "),v("p",[e._v("的资源。")]),e._v(" "),v("p",[e._v("4 ）打破环路等待条件：实现资源有序分配策略，将系统的所有资源统一编号，所有进程只能采用按序号递增的形")]),e._v(" "),v("p",[e._v("式申请资源。")]),e._v(" "),v("p",[v("strong",[e._v("10.12、为什么要使用线程池？直接new个线程不是很舒服？")])]),e._v(" "),v("p",[e._v("如果我们在方法中直接new一个线程来处理，当这个方法被调用频繁时就会创建很多线程，不仅会消耗系统资源，\n还会降低系统的稳定性，一不小心把系统搞崩了，就可以直接去财务那结帐了。")]),e._v(" "),v("p",[e._v("如果我们合理的使用线程池，则可以避免把系统搞崩的窘境。总得来说，使用线程池可以带来以下几个好处：")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("降低资源消耗。通过重复利用已创建的线程，降低线程创建和销毁造成的消耗。\n提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。\n增加线程的可管理型。线程是稀缺资源，使用线程池可以进行统一分配，调优和监控。\n")])])]),v("p",[e._v("10.13、线程池的核心属性有哪些？")]),e._v(" "),v("p",[e._v("threadFactory（线程工厂）：用于创建工作线程的工厂。")]),e._v(" "),v("p",[e._v("corePoolSize（核心线程数）：当线程池运行的线程少于 corePoolSize 时，将创建一个新线程来处理请求，即使\n其他工作线程处于空闲状态。")]),e._v(" "),v("p",[e._v("workQueue（队列）：用于保留任务并移交给工作线程的阻塞队列。")]),e._v(" "),v("p",[e._v("maximumPoolSize（最大线程数）：线程池允许开启的最大线程数。")]),e._v(" "),v("p",[e._v("handler（拒绝策略）：往线程池添加任务时，将在下面两种情况触发拒绝策略： 1 ）线程池运行状态不是\nRUNNING； 2 ）线程池已经达到最大线程数，并且阻塞队列已满时。")]),e._v(" "),v("p",[e._v("keepAliveTime（保持存活时间）：如果线程池当前线程数超过 corePoolSize，则多余的线程空闲时间超过\nkeepAliveTime 时会被终止。")]),e._v(" "),v("p",[v("strong",[e._v("10.14、说下线程池的运作流程。")])]),e._v(" "),v("p",[e._v("10.15、线程池有几种状态，每个状态分别代表什么含义？")]),e._v(" "),v("p",[e._v("线程池目前有 5 个状态：")]),e._v(" "),v("p",[e._v("RUNNING：接受新任务并处理排队的任务。")]),e._v(" "),v("p",[e._v("SHUTDOWN：不接受新任务，但处理排队的任务。")]),e._v(" "),v("p",[e._v("STOP：不接受新任务，不处理排队的任务，并中断正在进行的任务。")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("TIDYING：所有任务都已终止，workerCount 为零，线程转换到 TIDYING 状态将运行 terminated() 钩子方\n法。\nTERMINATED：terminated() 已完成。\n")])])]),v("p",[v("strong",[e._v("10.16、线程池中的状态之间是怎么流转的？")])]),e._v(" "),v("p",[e._v("10.17、线程池有哪些队列？")]),e._v(" "),v("p",[e._v("常⻅的阻塞队列有以下几种：")]),e._v(" "),v("p",[e._v("ArrayBlockingQueue：基于数组结构的有界阻塞队列，按先进先出对元素进行排序。")]),e._v(" "),v("p",[e._v("LinkedBlockingQueue：基于链表结构的有界/无界阻塞队列，按先进先出对元素进行排序，吞吐量通常高于\nArrayBlockingQueue。Executors.newFixedThreadPool 使用了该队列。")]),e._v(" "),v("p",[e._v("SynchronousQueue：不是一个真正的队列，而是一种在线程之间移交的机制。要将一个元素放入\nSynchronousQueue 中，必须有另一个线程正在等待接受这个元素。如果没有线程等待，并且线程池的当前大小\n小于最大值，那么线程池将创建一个线程，否则根据拒绝策略，这个任务将被拒绝。使用直接移交将更高效，因为\n任务会直接移交给执行它的线程，而不是被放在队列中，然后由工作线程从队列中提取任务。只有当线程池是无界\n的或者可以拒绝任务时，该队列才有实际价值。Executors.newCachedThreadPool使用了该队列。")]),e._v(" "),v("p",[e._v("PriorityBlockingQueue：具有优先级的无界队列，按优先级对元素进行排序。元素的优先级是通过自然顺序或\nComparator 来定义的。")]),e._v(" "),v("p",[v("strong",[e._v("10.18、使用队列有什么需要注意的吗？")])]),e._v(" "),v("p",[e._v("使用有界队列时，需要注意线程池满了后，被拒绝的任务如何处理。")]),e._v(" "),v("p",[e._v("使用无界队列时，需要注意如果任务的提交速度大于线程池的处理速度，可能会导致内存溢出。")]),e._v(" "),v("p",[e._v("抛出异常 返回特殊值 一直阻塞 超时退出")]),e._v(" "),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("插入 add(e) offer(e) put(e) offer(e,time,unit)\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("移除 remove() poll() take() poll(time,out)\n")])])]),v("div",{staticClass:"language- extra-class"},[v("pre",{pre:!0,attrs:{class:"language-text"}},[v("code",[e._v("检查 element() peek() 不可用 不可用\n")])])]),v("p",[e._v("10.19、线程池有哪些拒绝策略？")]),e._v(" "),v("p",[e._v("AbortPolicy：中止策略。默认的拒绝策略，直接抛出 RejectedExecutionException。调用者可以捕获这个异常，\n然后根据需求编写自己的处理代码。")]),e._v(" "),v("p",[e._v("DiscardPolicy：抛弃策略。什么都不做，直接抛弃被拒绝的任务。")]),e._v(" "),v("p",[e._v("DiscardOldestPolicy：抛弃最老策略。抛弃阻塞队列中最老的任务，相当于就是队列中下一个将要被执行的任\n务，然后重新提交被拒绝的任务。如果阻塞队列是一个优先队列，那么“抛弃最旧的”策略将导致抛弃优先级最高的\n任务，因此最好不要将该策略和优先级队列放在一起使用。")]),e._v(" "),v("p",[e._v("CallerRunsPolicy：调用者运行策略。在调用者线程中执行该任务。该策略实现了一种调节机制，该策略既不会抛\n弃任务，也不会抛出异常，而是将任务回退到调用者（调用线程池执行任务的主线程），由于执行任务需要一定时\n间，因此主线程至少在一段时间内不能提交任务，从而使得线程池有时间来处理完正在执行的任务。")]),e._v(" "),v("p",[v("strong",[e._v("10.20、线程只能在任务到达时才启动吗？")])]),e._v(" "),v("p",[e._v("默认情况下，即使是核心线程也只能在新任务到达时才创建和启动。但是我们可以使用 prestartCoreThread（启\n动一个核心线程）或 prestartAllCoreThreads（启动全部核心线程）方法来提前启动核心线程。")]),e._v(" "),v("p",[v("strong",[e._v("10.21、核心线程怎么实现一直存活？")])]),e._v(" "),v("p",[e._v("阻塞队列方法有四种形式，它们以不同的方式处理操作，如下表。")]),e._v(" "),v("p",[e._v("核心线程在获取任务时，通过阻塞队列的 take() 方法实现的一直阻塞（存活）。")]),e._v(" "),v("p",[v("strong",[e._v("10.22、非核心线程如何实现在 keepAliveTime 后死亡？")])]),e._v(" "),v("p",[e._v("原理同上，也是利用阻塞队列的方法，在获取任务时通过阻塞队列的 poll(time,unit) 方法实现的在延迟死亡。")]),e._v(" "),v("p",[v("strong",[e._v("10.23、非核心线程能成为核心线程吗？")])]),e._v(" "),v("p",[e._v("虽然我们一直讲着核心线程和非核心线程，但是其实线程池内部是不区分核心线程和非核心线程的。只是根据当前\n线程池的工作线程数来进行调整，因此看起来像是有核心线程于非核心线程。")]),e._v(" "),v("p",[v("strong",[e._v("10.24、如何终止线程池？")])]),e._v(" "),v("p",[e._v("终止线程池主要有两种方式：")]),e._v(" "),v("p",[e._v("shutdown：“温柔”的关闭线程池。不接受新任务，但是在关闭前会将之前提交的任务处理完毕。")]),e._v(" "),v("p",[e._v("shutdownNow：“粗暴”的关闭线程池，也就是直接关闭线程池，通过 Thread#interrupt() 方法终止所有线程，不\n会等待之前提交的任务执行完毕。但是会返回队列中未处理的任务。")]),e._v(" "),v("p",[v("strong",[e._v("10.25、Executors 提供了哪些创建线程池的方法？")])]),e._v(" "),v("p",[e._v("newFixedThreadPool：固定线程数的线程池。corePoolSize = maximumPoolSize，keepAliveTime为 0 ，工作队\n列使用无界的LinkedBlockingQueue。适用于为了满足资源管理的需求，而需要限制当前线程数量的场景，适用\n于负载比较重的服务器。")]),e._v(" "),v("p",[e._v("newSingleThreadExecutor：只有一个线程的线程池。corePoolSize = maximumPoolSize = 1，keepAliveTime\n为 0 ， 工作队列使用无界的LinkedBlockingQueue。适用于需要保证顺序的执行各个任务的场景。")]),e._v(" "),v("p",[e._v("newCachedThreadPool： 按需要创建新线程的线程池。核心线程数为 0 ，最大线程数为 Integer.MAX_VALUE，\nkeepAliveTime为 60 秒，工作队列使用同步移交 SynchronousQueue。该线程池可以无限扩展，当需求增加时，\n可以添加新的线程，而当需求降低时会自动回收空闲线程。适用于执行很多的短期异步任务，或者是负载较轻的服\n务器。")]),e._v(" "),v("p",[e._v("newScheduledThreadPool：创建一个以延迟或定时的方式来执行任务的线程池，工作队列为\nDelayedWorkQueue。适用于需要多个后台线程执行周期任务。")]),e._v(" "),v("p",[e._v("newWorkStealingPool：JDK 1.8 新增，用于创建一个可以窃取的线程池，底层使用 ForkJoinPool 实现。")]),e._v(" "),v("p",[v("strong",[e._v("10.26、线程池里有个 ctl，你知道它是如何设计的吗？")])]),e._v(" "),v("p",[e._v("ctl 是一个打包两个概念字段的原子整数。")]),e._v(" "),v("p",[e._v("1 ）workerCount：指示线程的有效数量；")]),e._v(" "),v("p",[e._v("2 ）runState：指示线程池的运行状态，有 RUNNING、SHUTDOWN、STOP、TIDYING、TERMINATED 等状态。")]),e._v(" "),v("p",[e._v("int 类型有 32 位，其中 ctl 的低 29 为用于表示 workerCount，高 3 位用于表示 runState，如下图所示。")]),e._v(" "),v("p",[e._v("例如，当我们的线程池运行状态为 RUNNING，工作线程个数为 3 ，则此时 ctl 的原码为：1010 0000 0000 0000\n0000 0000 0000 0011")]),e._v(" "),v("p",[v("strong",[e._v("10.27、ctl 为什么这么设计？有什么好处吗？")])]),e._v(" "),v("p",[e._v("ctl 这么设计的主要好处是将对 runState 和 workerCount 的操作封装成了一个原子操作。")]),e._v(" "),v("p",[e._v("runState 和 workerCount 是线程池正常运转中的 2 个最重要属性，线程池在某一时刻该做什么操作，取决于这 2\n个属性的值。")]),e._v(" "),v("p",[e._v("因此无论是查询还是修改，我们必须保证对这 2 个属性的操作是属于“同一时刻”的，也就是原子操作，否则就会出\n现错乱的情况。如果我们使用 2 个变量来分别存储，要保证原子性则需要额外进行加锁操作，这显然会带来额外的\n开销，而将这 2 个变量封装成 1 个 AtomicInteger 则不会带来额外的加锁开销，而且只需使用简单的位操作就能分\n别得到 runState 和 workerCount。")]),e._v(" "),v("p",[e._v("由于这个设计，workerCount 的上限 CAPACITY = (1 << 29) - 1，对应的二进制原码为：0001 1111 1111 1111\n1111 1111 1111 1111（不用数了， 29 个 1 ）。")]),e._v(" "),v("p",[e._v("通过 ctl 得到 runState，只需通过位操作：ctl & ~CAPACITY。")]),e._v(" "),v("p",[e._v("~（按位取反），于是“~CAPACITY”的值为：1110 0000 0000 0000 0000 0000 0000 0000，只有高 3 位为 1 ，与 ctl\n进行 & 操作，结果为 ctl 高 3 位的值，也就是 runState。")]),e._v(" "),v("p",[e._v("通过 ctl 得到 workerCount 则更简单了，只需通过位操作：c & CAPACITY。")]),e._v(" "),v("p",[v("strong",[e._v("10.28、在我们实际使用中，线程池的大小配置多少合适？")])]),e._v(" "),v("p",[e._v("要想合理的配置线程池大小，首先我们需要区分任务是计算密集型还是I/O密集型。")]),e._v(" "),v("p",[e._v("对于计算密集型，设置 线程数 = CPU数 + 1，通常能实现最优的利用率。")]),e._v(" "),v("p",[e._v("对于I/O密集型，网上常⻅的说法是设置 线程数 = CPU数 * 2 ，这个做法是可以的，但其实并不是最优的。")]),e._v(" "),v("p",[e._v("在我们日常的开发中，我们的任务几乎是离不开I/O的，常⻅的网络I/O（RPC调用）、磁盘I/O（数据库操作），\n并且I/O的等待时间通常会占整个任务处理时间的很大一部分，在这种情况下，开启更多的线程可以让 CPU 得到更\n充分的使用，一个较合理的计算公式如下：")]),e._v(" "),v("p",[e._v("线程数 = CPU数 * CPU利用率 * (任务等待时间 / 任务计算时间 + 1)")]),e._v(" "),v("p",[e._v("例如我们有个定时任务，部署在 4 核的服务器上，该任务有100ms在计算，900ms在I/O等待，则线程数约为：4 *\n1 * (1 + 900 / 100) = 40个。")]),e._v(" "),v("p",[e._v("当然，具体我们还要结合实际的使用场景来考虑。")])])}),[],!1,null,null,null);v.default=_.exports}}]);
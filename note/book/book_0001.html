<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>JAVA核心面试知识整理 | MyReader</title>
    <meta name="generator" content="VuePress 1.9.8">
    
    <meta name="description" content="md文档在线阅读器">
    
    <link rel="preload" href="/MyReader/assets/css/0.styles.daea2cfa.css" as="style"><link rel="preload" href="/MyReader/assets/js/app.5ccfdbdc.js" as="script"><link rel="preload" href="/MyReader/assets/js/3.ead5ad5d.js" as="script"><link rel="preload" href="/MyReader/assets/js/1.f20a062a.js" as="script"><link rel="preload" href="/MyReader/assets/js/12.69678de1.js" as="script"><link rel="prefetch" href="/MyReader/assets/js/10.22c8a0fe.js"><link rel="prefetch" href="/MyReader/assets/js/11.f767c270.js"><link rel="prefetch" href="/MyReader/assets/js/13.f5c290da.js"><link rel="prefetch" href="/MyReader/assets/js/14.8d514af4.js"><link rel="prefetch" href="/MyReader/assets/js/4.9136a982.js"><link rel="prefetch" href="/MyReader/assets/js/5.bdf5bec2.js"><link rel="prefetch" href="/MyReader/assets/js/6.3fd0a10d.js"><link rel="prefetch" href="/MyReader/assets/js/7.6ab1a038.js"><link rel="prefetch" href="/MyReader/assets/js/8.b601f399.js"><link rel="prefetch" href="/MyReader/assets/js/9.52794b11.js">
    <link rel="stylesheet" href="/MyReader/assets/css/0.styles.daea2cfa.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>MyReader</h3> <p class="description" data-v-59e6cb88>md文档在线阅读器</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2023
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/MyReader/" class="home-link router-link-active"><!----> <span class="site-name">MyReader</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/MyReader/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      XDS 博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/xdsdao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://blog.csdn.net/xds666" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><!----> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>5</h3> <h6 data-v-1fad0c41>文章</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>0</h3> <h6 data-v-1fad0c41>标签</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/MyReader/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      XDS 博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/xdsdao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://blog.csdn.net/xds666" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/MyReader/" class="sidebar-heading clickable router-link-active"><span>导航栏</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/MyReader/" aria-current="page" class="sidebar-link">学前必读</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/MyReader/note/blog/blog_0001" class="sidebar-heading clickable"><span>文章导航</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/MyReader/note/blog/blog_0001.html" class="sidebar-link">vuepress Github Actions</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/MyReader/note/book/book_0001" class="sidebar-heading clickable open active"><span>电子书导航</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/MyReader/note/book/book_0001.html" aria-current="page" class="active sidebar-link">《JAVA核心面试知识整理》</a></li><li><a href="/MyReader/note/book/book_0002.html" class="sidebar-link">《Java开发手册(黄山版)》</a></li><li><a href="/MyReader/note/book/book_0003.html" class="sidebar-link">《22年大厂offer必备Java面试题》</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>JAVA核心面试知识整理</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2023
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">JAVA核心面试知识整理</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>xds</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>2023/2/21</span></i> <!----> <!----></div></div> <div class="theme-reco-content content__default"><h2 id="_1-目录"><a href="#_1-目录" class="header-anchor">#</a> 1. 目录</h2> <ul><li><ol><li>目录</li></ol></li> <li><ol start="2"><li>JVM</li></ol> <ul><li>2.1. 线程</li> <li>2.2. JVM内存区域
<ul><li>2.2.1. 程序计数器 ( 线程私有 )</li> <li>2.2.2. 虚拟机栈 ( 线程私有 )</li> <li>2.2.3. 本地方法区 ( 线程私有 )</li> <li>2.2.4. 堆（ Heap- 线程共享） - 运行时数据区</li> <li>2.2.5. 方法区 / 永久代（线程共享）</li></ul></li> <li>2.3. JVM运行时内存
<ul><li>2.3.1. 新生代
<ul><li>2.3.1.1. Eden区</li> <li>2.3.1.2. ServivorFrom</li> <li>2.3.1.3. ServivorTo</li> <li>2.3.1.4. MinorGC的过程（复制-&gt;清空-&gt;互换）
<ul><li>1 ：eden、servicorFrom 复制到ServicorTo，年龄+1</li> <li>2 ：清空eden、servicorFrom</li> <li>3 ：ServicorTo和ServicorFrom互换</li></ul></li></ul></li> <li>2.3.2. 老年代</li> <li>2.3.3. 永久代
<ul><li>2.3.3.1. JAVA8与元数据</li></ul></li></ul></li> <li>2.4. 垃圾回收与算法
<ul><li>2.4.1. 如何确定垃圾
<ul><li>2.4.1.1. 引用计数法...............................................................................................................................................</li> <li>2.4.1.2. 可达性分析...............................................................................................................................................</li></ul></li> <li>2.4.2. 标记清除算法（Mark-Sweep）</li> <li>2.4.3. 复制算法（ copying ）</li> <li>2.4.4. 标记整理算法 (Mark-Compact)</li> <li>2.4.5. 分代收集算法
<ul><li>2.4.5.1. 新生代与复制算法</li> <li>2.4.5.2. 老年代与标记复制算法</li></ul></li></ul></li> <li>2.5. JAVA 四中引用类型
<ul><li>2.5.1. 强引用</li> <li>2.5.2. 软引用</li> <li>2.5.3. 弱引用</li> <li>2.5.4. 虚引用</li></ul></li> <li>2.6. GC分代收集算法 VS 分区收集算法
<ul><li>2.6.1. 分代收集算法
<ul><li>2.6.1.1. 在新生代-复制算法</li> <li>2.6.1.2. 在老年代-标记整理算法</li></ul></li> <li>2.6.2. 分区收集算法</li></ul></li> <li>2.7. GC垃圾收集器
<ul><li>2.7.1. Serial 垃圾收集器（单线程、复制算法）</li> <li>2.7.2. ParNew 垃圾收集器（ Serial+ 多线程）</li> <li>2.7.3. Parallel Scavenge 收集器（多线程复制算法、高效）</li> <li>2.7.4. Serial Old 收集器（单线程标记整理算法 ）</li> <li>2.7.5. Parallel Old 收集器（多线程标记整理算法）</li> <li>2.7.6. CMS 收集器（多线程标记清除算法）
<ul><li>2.7.6.1. 初始标记</li> <li>2.7.6.2. 并发标记</li> <li>2.7.6.3. 重新标记</li> <li>2.7.6.4. 并发清除</li></ul></li> <li>2.7.7. G1 收集器</li></ul></li> <li>2.8. JAVA IO/NIO
<ul><li>2.8.1. 阻塞 IO 模型</li> <li>2.8.2. 非阻塞 IO 模型</li> <li>2.8.3. 多路复用 IO 模型</li> <li>2.8.4. 信号驱动 IO 模型</li> <li>2.8.5. 异步 IO 模型</li> <li>2.8.1. JAVA IO 包</li> <li>2.8.2. JAVA NIO
<ul><li>2.8.2.1. NIO的缓冲区</li> <li>2.8.2.2. NIO的非阻塞</li></ul></li> <li>2.8.3. Channel</li> <li>2.8.4. Buffer</li> <li>2.8.5. Selector</li></ul></li> <li>2.9. JVM 类加载机制
- 2.9.1.1. 加载
- 2.9.1.2. 验证
- 2.9.1.3. 准备
- 2.9.1.4. 解析
- 2.9.1.5. 符号引用
- 2.9.1.6. 直接引用
- 2.9.1.7. 初始化
- 2.9.1.8. 类构造器&lt;client&gt;
<ul><li>2.9.2. 类加载器
<ul><li>2.9.2.1. 启动类加载器(Bootstrap ClassLoader)</li> <li>2.9.2.2. 扩展类加载器(Extension ClassLoader)</li> <li>2.9.2.3. 应用程序类加载器(Application ClassLoader)：</li></ul></li> <li>2.9.3. 双亲委派</li> <li>2.9.4. OSGI （动态模型系统）
<ul><li>2.9.4.1. 动态改变构造</li> <li>2.9.4.2. 模块化编程与热插拔</li></ul></li></ul></li></ul></li> <li><ol start="3"><li>JAVA 集合</li></ol> <ul><li>3.1. 接口继承关系和实现</li> <li>3.2. LIST
<ul><li>3.2.1. ArrayList （数组）</li> <li>3.2.2. Vector （数组实现、线程同步）</li> <li>3.2.3. LinkList （链表）</li></ul></li> <li>3.3. SET
- 3.3.1.1. HashSet（Hash表）
- 3.3.1.2. TreeSet（二叉树）
- 3.3.1.3. LinkHashSet（HashSet+LinkedHashMap）</li> <li>3.4. MAP
<ul><li>3.4.1. HashMap （数组 + 链表 + 红黑树）
<ul><li>3.4.1.1. JAVA7实现</li> <li>3.4.1.2. JAVA8实现</li></ul></li> <li>3.4.2. ConcurrentHashMap..................................................................................................................
<ul><li>3.4.2.1. Segment段</li> <li>3.4.2.2. 线程安全（Segment 继承 ReentrantLock 加锁）</li> <li>3.4.2.3. 并行度（默认 16 ）</li> <li>3.4.2.4. Java8实现 （引入了红黑树）</li></ul></li></ul></li> <li>3.4.3. HashTable （线程安全）</li> <li>3.4.4. TreeMap （可排序）</li> <li>3.4.5. LinkHashMap （记录插入顺序）</li></ul></li> <li><ol start="4"><li>JAVA 多线程并发</li></ol> <ul><li>4.1.1. JAVA 并发知识库</li> <li>4.1.2. JAVA 线程实现 / 创建方式
<ul><li>4.1.2.1. 继承Thread类</li> <li>4.1.2.2. 实现Runnable接口。</li> <li>4.1.2.3. ExecutorService、Callable&lt;Class&gt;、Future有返回值线程</li> <li>4.1.2.4. 基于线程池的方式</li></ul></li> <li>4.1.3. 4 种线程池
<ul><li>4.1.3.1. newCachedThreadPool</li> <li>4.1.3.2. newFixedThreadPool</li> <li>4.1.3.3. newScheduledThreadPool</li> <li>4.1.3.4. newSingleThreadExecutor</li></ul></li> <li>4.1.4. 线程生命周期 ( 状态 )
<ul><li>4.1.4.1. 新建状态（NEW）</li> <li>4.1.4.2. 就绪状态（RUNNABLE）：</li> <li>4.1.4.3. 运行状态（RUNNING）：</li> <li>4.1.4.4. 阻塞状态（BLOCKED）：
<ul><li>等待阻塞（o.wait-&gt;等待对列）：</li> <li>同步阻塞(lock-&gt;锁池)</li> <li>其他阻塞(sleep/join)</li></ul></li> <li>4.1.4.5. 线程死亡（DEAD）
<ul><li>正常结束</li> <li>异常结束</li> <li>调用stop</li></ul></li></ul></li> <li>4.1.5. 终止线程 4 种方式
<ul><li>4.1.5.1. 正常运行结束</li> <li>4.1.5.2. 使用退出标志退出线程</li> <li>4.1.5.3. Interrupt方法结束线程</li> <li>4.1.5.4. stop方法终止线程（线程不安全）</li></ul></li> <li>4.1.6. sleep 与 wait 区别</li> <li>4.1.7. start 与 run 区别</li> <li>4.1.8. JAVA 后台线程</li> <li>4.1.9. JAVA 锁
<ul><li>4.1.9.1. 乐观锁</li> <li>4.1.9.2. 悲观锁</li> <li>4.1.9.3. 自旋锁
<ul><li>自旋锁的优缺点</li> <li>自旋锁时间阈值（1.6引入了适应性自旋锁）</li> <li>自旋锁的开启</li></ul></li> <li>4.1.9.4. Synchronized同步锁
<ul><li>Synchronized作用范围</li> <li>Synchronized核心组件</li> <li>Synchronized实现</li></ul></li> <li>4.1.9.5. ReentrantLock
<ul><li>Lock接口的主要方法</li> <li>非公平锁</li> <li>公平锁</li> <li>ReentrantLock 与synchronized</li> <li>ReentrantLock实现</li> <li>Condition类和Object类锁方法区别区别</li> <li>tryLock和lock和lockInterruptibly的区别</li></ul></li> <li>4.1.9.6. Semaphore信号量
<ul><li>实现互斥锁（计数器为 1 ）</li> <li>代码实现</li> <li>Semaphore 与ReentrantLock</li></ul></li> <li>4.1.9.7. AtomicInteger</li></ul></li> <li>4.1.9.8. 可重入锁（递归锁）</li> <li>4.1.9.9. 公平锁与非公平锁
<ul><li>公平锁（Fair）</li> <li>非公平锁（Nonfair）</li></ul></li> <li>4.1.9.10. ReadWriteLock读写锁
<ul><li>读锁........................................................................................................................................................................</li> <li>写锁........................................................................................................................................................................</li></ul></li> <li>4.1.9.11. 共享锁和独占锁
<ul><li>独占锁</li> <li>共享锁</li></ul></li> <li>4.1.9.12. 重量级锁（Mutex Lock）</li> <li>4.1.9.13. 轻量级锁
<ul><li>锁升级</li></ul></li> <li>4.1.9.14. 偏向锁</li> <li>4.1.9.15. 分段锁</li> <li>4.1.9.16. 锁优化
<ul><li>减少锁持有时间</li> <li>减小锁粒度</li> <li>锁分离</li> <li>锁粗化</li> <li>锁消除</li></ul></li></ul></li> <li>4.1.10. 线程基本方法
<ul><li>4.1.10.1. 线程等待（wait）</li> <li>4.1.10.2. 线程睡眠（sleep）</li> <li>4.1.10.3. 线程让步（yield）</li> <li>4.1.10.4. 线程中断（interrupt）</li> <li>4.1.10.5. Join等待其他线程终止</li> <li>4.1.10.6. 为什么要用join()方法？</li> <li>4.1.10.7. 线程唤醒（notify）</li> <li>4.1.10.8. 其他方法：</li></ul></li> <li>4.1.11. 线程上下文切换
<ul><li>4.1.11.1. 进程</li> <li>4.1.11.2. 上下文</li> <li>4.1.11.3. 寄存器</li> <li>4.1.11.4. 程序计数器</li> <li>4.1.11.5. PCB-“切换桢”</li> <li>4.1.11.6. 上下文切换的活动：</li> <li>4.1.11.7. 引起线程上下文切换的原因</li></ul></li> <li>4.1.12. 同步锁与死锁
<ul><li>4.1.12.1. 同步锁</li> <li>4.1.12.2. 死锁</li></ul></li> <li>4.1.13. 线程池原理
<ul><li>4.1.13.1. 线程复用</li> <li>4.1.13.2. 线程池的组成</li> <li>4.1.13.3. 拒绝策略</li> <li>4.1.13.4. Java线程池工作过程</li></ul></li> <li>4.1.14. JAVA 阻塞队列原理
<ul><li>4.1.14.1. 阻塞队列的主要方法
<ul><li>插入操作：</li> <li>获取数据操作：</li></ul></li> <li>4.1.14.2. Java中的阻塞队列</li> <li>4.1.14.3. ArrayBlockingQueue（公平、非公平）</li> <li>4.1.14.4. LinkedBlockingQueue（两个独立锁提高并发）</li> <li>4.1.14.5. PriorityBlockingQueue（compareTo排序实现优先）..............................................................</li> <li>4 .1.14.6. DelayQueue（缓存失效、定时任务 ）</li> <li>4.1.14.7. SynchronousQueue（不存储数据、可用于传递数据）</li> <li>4.1.14.8. LinkedTransferQueue......................................................................................................................
<ul><li>4.1.14.9. LinkedBlockingDeque</li></ul></li> <li>4.1.15. CyclicBarrier 、 CountDownLatch 、 Semaphore 的用法
<ul><li>4.1.15.1. CountDownLatch（线程计数器 ）</li> <li>4.1.15.2. CyclicBarrier（回环栅栏-等待至barrier状态再全部同时执行）</li> <li>4.1.15.3. Semaphore（信号量-控制同时访问的线程个数）</li></ul></li> <li>4.1.16. volatile 关键字的作用（变量可见性、禁止重排序）
- 变量可见性
- 禁止重排序
- 比sychronized更轻量级的同步锁
- 适用场景</li> <li>4.1.17. 如何在两个线程之间共享数据
- 将数据抽象成一个类，并将数据的操作作为这个类的方法
- Runnable对象作为一个类的内部类</li> <li>4.1.18. ThreadLocal 作用（线程本地存储）
- ThreadLocalMap（线程的一个属性）
- 使用场景</li> <li>4.1.19. synchronized 和 ReentrantLock 的区别
<ul><li>4.1.19.1. 两者的共同点：</li> <li>4.1.19.2. 两者的不同点：</li></ul></li> <li>4.1.20. ConcurrentHashMap 并发
<ul><li>4.1.20.1. 减小锁粒度</li> <li>4.1.20.2. ConcurrentHashMap分段锁
<ul><li>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成</li></ul></li></ul></li> <li>4.1.21. Java 中用到的线程调度
<ul><li>4.1.21.1. 抢占式调度：</li> <li>4.1.21.2. 协同式调度：</li> <li>4.1.21.3. JVM的线程调度实现（抢占式调度）</li> <li>4.1.21.4. 线程让出cpu的情况：</li></ul></li> <li>4.1.22. 进程调度算法
<ul><li>4.1.22.1. 优先调度算法</li> <li>4.1.22.2. 高优先权优先调度算法</li> <li>4.1.22.3. 基于时间片的轮转调度算法</li></ul></li> <li>4.1.23. 什么是 CAS （比较并交换-乐观锁机制-锁自旋）
<ul><li>4.1.23.1. 概念及特性</li> <li>4.1.23.2. 原子包 java.util.concurrent.atomic（锁自旋）</li> <li>4.1.23.3. ABA问题</li></ul></li> <li>4.1.24. 什么是 AQS （抽象的队列同步器）
- Exclusive独占资源-ReentrantLock
- Share共享资源-Semaphore/CountDownLatch
- 同步器的实现是ABS核心（state资源状态计数）
- ReentrantReadWriteLock实现独占和共享两种方式</li></ul></li> <li><ol start="5"><li>JAVA 基础</li></ol> <ul><li>5.1.1. JAVA 异常分类及处理
<ul><li>5.1.1.1. 概念</li> <li>5.1.1.2. 异常分类
<ul><li>Error</li> <li>Exception（RuntimeException、CheckedException）</li></ul></li> <li>5.1.1.3. 异常的处理方式
<ul><li>遇到问题不进行具体处理，而是继续抛给调用者 （throw,throws）</li> <li>try catch 捕获异常针对性处理方式</li></ul></li> <li>5.1.1.4. Throw和throws的区别：
<ul><li>位置不同</li> <li>功能不同：</li></ul></li></ul></li> <li>5.1.2. JAVA 反射
<ul><li>5.1.2.1. 动态语言</li> <li>5.1.2.2. 反射机制概念 （运行状态中知道类所有的属性和方法）</li> <li>5.1.2.3. 反射的应用场合
<ul><li>编译时类型和运行时类型</li> <li>的编译时类型无法获取具体方法</li></ul></li> <li>5.1.2.4. Java反射API
<ul><li>反射API用来生成JVM中的类、接口或则对象的信息。</li></ul></li> <li>5.1.2.5. 反射使用步骤（获取Class对象、调用对象方法）</li> <li>5.1.2.6. 获取Class对象的 3 种方法
<ul><li>调用某个对象的getClass()方法</li> <li>调用某个类的class属性来获取该类对应的Class对象</li> <li>使用Class类中的forName()静态方法(最安全/性能最好)</li></ul></li> <li>5.1.2.7. 创建对象的两种方法
<ul><li>Class对象的newInstance()</li> <li>调用Constructor对象的newInstance()</li></ul></li></ul></li> <li>5.1.3. JAVA 注解
<ul><li>5.1.3.1. 概念</li> <li>5.1.3.2. 4 种标准元注解......................................................................................................................................
<ul><li>@Target修饰的对象范围</li> <li>@Retention定义 被保留的时间长短</li></ul></li> <li>@Documented描述-javadoc</li> <li>@Inherited阐述了某个被标注的类型是被继承的</li> <li>5.1.3.3. 注解处理器.............................................................................................................................................</li></ul></li> <li>5.1.4. JAVA 内部类
<ul><li>5.1.4.1. 静态内部类.............................................................................................................................................</li> <li>5.1.4.2. 成员内部类.............................................................................................................................................</li> <li>5.1.4.3. 局部内部类（定义在方法中的类）</li> <li>5.1.4.4. 匿名内部类（要继承一个父类或者实现一个接口、直接使用new来生成一个对象的引用）</li></ul></li> <li>5.1.5. JAVA 泛型
<ul><li>5.1.5.1. 泛型方法（&lt;E&gt;）</li> <li>5.1.5.2. 泛型类&lt;T&gt;</li> <li>5.1.5.3. 类型通配符?</li> <li>5.1.5.4. 类型擦除</li></ul></li> <li>5.1.6. JAVA 序列化 ( 创建可复用的 Java 对象 )
- 保存(持久化)对象及其状态到内存或者磁盘
- 序列化对象以字节数组保持-静态成员不保存
- 序列化用户远程对象传输
- Serializable实现序列化
- ObjectOutputStream和ObjectInputStream对对象进行序列化及反序列化...............................................
- writeObject 和 readObject自定义序列化策略
- 序列化 ID.............................................................................................................................................................
- 序列化并不保存静态变量
- 序列化子父类说明
- Transient 关键字阻止该变量被序列化到文件中</li> <li>5 .1.7. JAVA 复制
<ul><li>5.1.7.1. 直接赋值复制</li> <li>5.1.7.2. 浅复制（复制引用但不复制引用的对象）</li> <li>5.1.7.3. 深复制（复制对象和其应用对象）</li> <li>5.1.7.4. 序列化（深clone一中实现）</li></ul></li></ul></li> <li><ol start="6"><li>SPRING 原理</li></ol> <ul><li>6.1.1. Spring 特点
<ul><li>6.1.1.1. 轻量级</li></ul></li> <li>6.1.1.2. 控制反转</li> <li>6.1.1.3. 面向切面</li> <li>6.1.1.4. 容器</li> <li>6.1.1.5. 框架集合</li></ul></li> <li>6.1.2. Spring 核心组件</li> <li>6.1.3. Spring 常用模块</li> <li>6.1.4. Spring 主要包</li> <li>6.1.5. Spring 常用注解</li> <li>6.1.6. Spring 第三方结合</li> <li>6.1.7. Spring IOC 原理
<ul><li>6.1.7.1. 概念</li> <li>6.1.7.2. Spring容器高层视图</li> <li>6.1.7.3. IOC容器实现
<ul><li>BeanFactory-框架基础设施
<ul><li>1.1..1.1.1 BeanDefinitionRegistry注册表.................................................................................................</li> <li>1.1..1.1.2 BeanFactory 顶层接口</li> <li>1.1..1.1.3 ListableBeanFactory</li> <li>1.1..1.1.4 HierarchicalBeanFactory父子级联..........................................................................................</li> <li>1.1..1.1.5 ConfigurableBeanFactory</li> <li>1.1..1.1.6 AutowireCapableBeanFactory自动装配</li> <li>1.1..1.1. 7 SingletonBeanRegistry运行期间注册单例Bean</li> <li>1.1..1.1.8 依赖日志框框</li></ul></li> <li>ApplicationContext面向开发应用</li> <li>WebApplication体系架构</li></ul></li> <li>6.1.7.4. Spring Bean 作用域
<ul><li>singleton：单例模式（多线程下不安全）</li> <li>prototype:原型模式每次使用时创建</li> <li>Request：一次request一个实例</li> <li>session</li> <li>global Session</li></ul></li> <li>6.1.7.5. Spring Bean 生命周期
<ul><li>实例化</li> <li>IOC依赖注入</li> <li>setBeanName实现</li> <li>BeanFactoryAware实现</li> <li>ApplicationContextAware实现.........................................................................................................................</li> <li>postProcessBeforeInitialization接口实现-初始化预处理</li> <li>init-method</li> <li>postProcessAfterInitialization</li> <li>Destroy过期自动清理阶段</li> <li>destroy-method自配置清理</li></ul></li> <li>6.1.7.6. Spring 依赖注入四种方式
<ul><li>构造器注入</li> <li>setter方法注入</li> <li>静态工厂注入</li> <li>实例工厂</li></ul></li> <li>6.1.7.7. 5 种不同方式的自动装配</li></ul></li> <li>6.1.8. Spring APO 原理
<ul><li>6.1.8.1. 概念</li> <li>6.1.8.2. AOP核心概念</li> <li>6.1.8.1. AOP两种代理方式
<ul><li>JDK动态接口代理</li> <li>CGLib动态代理</li></ul></li> <li>6.1.8.2. 实现原理</li></ul></li> <li>6.1.9. Spring MVC 原理
<ul><li>6.1.9.1. MVC流程
<ul><li>Http请求到DispatcherServlet</li> <li>HandlerMapping寻找处理器</li> <li>调用处理器Controller
<ul><li>Controller调用业务逻辑处理后，返回ModelAndView</li> <li>DispatcherServlet查询ModelAndView</li> <li>ModelAndView反馈浏览器HTTP</li></ul></li> <li>6.1.9.1. MVC常用注解</li></ul></li> <li>6.1.10. Spring Boot 原理
<ul><li><ol><li>创建独立的Spring应用程序</li></ol></li> <li><ol start="2"><li>嵌入的Tomcat，无需部署WAR文件</li></ol></li> <li><ol start="3"><li>简化Maven配置</li></ol></li> <li><ol start="4"><li>自动配置Spring</li></ol></li> <li><ol start="5"><li>提供生产就绪型功能，如指标，健康检查和外部配置</li></ol></li> <li><ol start="6"><li>绝对没有代码生成和对XML没有要求配置 [1]</li></ol></li></ul></li> <li>6.1.11. JPA 原理
<ul><li>6.1.11.1. 事务</li> <li>6.1.11.2. 本地事务</li> <li>6.1.11.1. 分布式事务</li> <li>6.1.11.1. 两阶段提交
<ul><li>1 准备阶段</li> <li>2 提交阶段：</li></ul></li></ul></li> <li>6.1.12. Mybatis 缓存
<ul><li>6.1.12.1. Mybatis的一级缓存原理（sqlsession级别）</li> <li>6.1.12.2. 二级缓存原理（mapper基本）
<ul><li>具体使用需要配置：</li></ul></li></ul></li> <li>6.1.13. Tomcat 架构</li></ul></li> <li><ol start="7"><li>微服务</li></ol> <ul><li>7.1.1. 服务注册发现
<ul><li>7.1.1.1. 客户端注册（zookeeper）</li> <li>7.1.1.2. 第三方注册（独立的服务Registrar）</li> <li>7.1.1.3. 客户端发现.............................................................................................................................................</li> <li>7.1.1.4. 服务端发现.............................................................................................................................................</li> <li>7.1.1.5. Consul</li> <li>7.1.1.6. Eureka</li> <li>7.1.1.7. SmartStack</li> <li>7.1.1.8. Etcd</li></ul></li> <li>7.1.2. API 网关
<ul><li>7.1.2.1. 请求转发</li> <li>7.1.2.2. 响应合并</li> <li>7.1.2.3. 协议转换</li> <li>7.1.2.4. 数据转换</li> <li>7.1.2.5. 安全认证</li></ul></li> <li>7.1.3. 配置中心
<ul><li>7.1.3.1. zookeeper配置中心</li> <li>7.1.3.2. 配置中心数据分类</li></ul></li> <li>7.1.4. 事件调度（ kafka ）</li> <li>7.1.5. 服务跟踪（starter-sleuth）</li> <li>7.1.6. 服务熔断（ Hystrix ）
<ul><li>7.1.6.1. Hystrix断路器机制</li></ul></li> <li>7.1.7. API 管理</li></ul></li> <li><ol start="8"><li>NETTY 与 RPC</li></ol> <ul><li>8.1.1. Netty 原理</li> <li>8.1.2. Netty 高性能
<ul><li>8.1.2.1. 多路复用通讯方式</li> <li>8.1.2.1. 异步通讯NIO</li> <li>8.1.2.2. 零拷贝（DIRECT BUFFERS使用堆外直接内存）</li> <li>8.1.2.3. 内存池（基于内存池的缓冲区重用机制）</li> <li>8.1.2.4. 高效的Reactor线程模型
<ul><li>Reactor单线程模型</li> <li>Reactor多线程模型</li> <li>主从Reactor多线程模型</li></ul></li> <li>8.1.2.5. 无锁设计、线程绑定</li> <li>8.1.2.6. 高性能的序列化框架
<ul><li>小包封大包，防止网络阻塞</li> <li>软中断Hash值和CPU绑定.............................................................................................................................</li></ul></li></ul></li> <li>8.1.3. Netty RPC 实现
<ul><li>8.1.3.1. 概念</li> <li>8.1.3.2. 关键技术</li> <li>8.1.3.3. 核心流程</li> <li>8.1.3.1. 消息编解码.............................................................................................................................................
<ul><li>息数据结构（接口名称+方法名+参数类型和参数值+超时时间+ requestID）</li> <li>序列化</li></ul></li> <li>8.1.3.1. 通讯过程
<ul><li>核心问题(线程暂停、消息乱序)</li> <li>通讯流程</li> <li>requestID生成-AtomicLong</li> <li>存放回调对象callback到全局ConcurrentHashMap</li> <li>synchronized获取回调对象callback的锁并自旋wait</li> <li>监听消息的线程收到消息，找到callback上的锁并唤醒</li></ul></li></ul></li> <li>8.1.4. RMI 实现方式
<ul><li>8.1.4.1. 实现步骤</li></ul></li> <li>8.1.5. Protoclol Buffer
<ul><li>8.1.5.1. 特点</li></ul></li> <li>8.1.6. Thrift</li></ul></li> <li><ol start="9"><li>网络</li></ol> <ul><li>9.1.1. 网络 7 层架构</li> <li>9.1.2. TCP/IP 原理
<ul><li>9.1.2.1. 网络访问层(Network Access Layer)</li> <li>9.1.2.2. 网络层(Internet Layer)</li> <li>9.1.2.3. 传输层(Tramsport Layer-TCP/UDP)</li> <li>9.1.2.4. 应用层(Application Layer)....................................................................................................................</li></ul></li> <li>9.1.3. TCP 三次握手 / 四次挥手
<ul><li>9.1.3.1. 数据包说明.............................................................................................................................................</li> <li>9.1.3.2. 三次握手</li> <li>9.1.3.3. 四次挥手</li></ul></li> <li>9.1.4. HTTP 原理
<ul><li>9.1.4.1. 传输流程
<ul><li>1 ：地址解析</li> <li>2 ：封装HTTP请求数据包</li> <li>3 ：封装成TCP包并建立连接</li> <li>4 ：客户机发送请求命</li> <li>5 ：服务器响应....................................................................................................................................................</li> <li>6 ：服务器关闭TCP连接</li></ul></li> <li>9.1.4.2. HTTP状态</li> <li>9.1.4.3. HTTPS
<ul><li>建立连接获取证书</li> <li>证书验证</li> <li>数据加密和传输</li></ul></li></ul></li> <li>9.1.5. CDN 原理
<ul><li>9.1.5.1. 分发服务系统</li> <li>9.1.5.2. 负载均衡系统：</li> <li>9.1.5.3. 管理系统：.............................................................................................................................................</li></ul></li></ul></li> <li><ol start="10"><li>日志</li></ol> <ul><li>10.1.1. Slf4j</li> <li>10.1.2. Log4j</li> <li>10.1.3. LogBack
<ul><li>10.1.3.1. Logback优点</li></ul></li> <li>10.1.4. ELK</li></ul></li> <li><ol start="11"><li>ZOOKEEPER</li></ol> <ul><li>11.1.1. Zookeeper 概念</li> <li>11.1.1. Zookeeper 角色
<ul><li>11.1.1.1. Leader</li> <li>11.1.1.2. Follower</li> <li>11.1.1.3. Observer</li> <li>11.1.1.1. ZAB协议
<ul><li>事务编号 Zxid（事务请求计数器+ epoch）</li> <li>epoch</li> <li>Zab协议有两种模式-恢复模式（选主）、广播模式（同步）</li> <li>ZAB协议 4 阶段</li> <li>Leader election（选举阶段-选出准Leader）</li> <li>Discovery（发现阶段-接受提议、生成epoch、接受epoch）</li> <li>Synchronization（同步阶段-同步follower副本）</li> <li>Broadcast（广播阶段-leader消息广播）</li> <li>ZAB协议JAVA实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段））</li></ul></li> <li>11.1.1.2. 投票机制</li></ul></li> <li>11.1.2. Zookeeper 工作原理（原子广播）</li> <li>11.1.3. Znode 有四种形式的目录节点</li></ul></li> <li><ol start="12"><li>KAFKA</li></ol> <ul><li>12.1.1. Kafka 概念</li> <li>12.1.2. Kafka 数据存储设计
<ul><li>12.1.2.1. partition的数据文件（offset，MessageSize，data）</li> <li>12.1.2.2. 数据文件分段segment（顺序读写、分段命令、二分查找）</li> <li>12.1.2.3. 数据文件索引（分段索引、稀疏存储）</li></ul></li> <li>12.1.3. 生产者设计
<ul><li>12.1.3.1. 负载均衡（partition会均衡分布到不同broker上）</li> <li>12.1.3.2. 批量发送</li> <li>12.1.3.3. 压缩（GZIP或Snappy）</li></ul></li> <li>12.1.1. 消费者设计
<ul><li>12.1.1.1. Consumer Group</li></ul></li></ul></li> <li><ol start="13"><li>RABBITMQ</li></ol> <ul><li>13.1.1. 概念</li> <li>13.1.2. RabbitMQ 架构
<ul><li>13.1.2.1. Message</li> <li>13.1.2.2. Publisher</li> <li>13.1.2.3. Exchange（将消息路由给队列 ）</li> <li>13.1.2.4. Binding（消息队列和交换器之间的关联）</li> <li>13.1.2.5. Queue</li> <li>13.1.2.6. Connection</li> <li>13.1.2.7. Channel</li> <li>13.1.2.8. Consumer</li> <li>13.1.2.9. Virtual Host</li> <li>13.1.2.10. Broker</li></ul></li> <li>13.1.3. Exchange 类型
<ul><li>13.1.3.1. Direct键（routing key）分布：</li> <li>13.1.3.2. Fanout（广播分发）</li> <li>13.1.3.3. topic 交换器（模式匹配）</li></ul></li></ul></li> <li><ol start="14"><li>HBASE</li></ol> <ul><li>14.1.1. 概念</li> <li>14.1.2. 列式存储</li> <li>14.1.3. Hbase 核心概念
<ul><li>14.1.3.1. Column Family列族</li> <li>14.1.3.2. Rowkey（Rowkey查询，Rowkey范围扫描，全表扫描）</li> <li>14.1.3.3. Region分区</li> <li>14.1.3.4. TimeStamp多版本</li></ul></li> <li>14.1.4. Hbase 核心架构
<ul><li>14.1.4.1. Client：</li> <li>14.1.4.2. Zookeeper：....................................................................................................................................</li> <li>14.1.4.3. Hmaster</li> <li>14.1.4.4. HregionServer</li> <li>14.1.4.5. Region寻址方式（通过zookeeper .META）</li> <li>14.1.4.6. HDFS</li></ul></li> <li>14.1.5. Hbase 的写逻辑
<ul><li>14.1.5.1. Hbase的写入流程
<ul><li>获取RegionServer</li> <li>请求写Hlog</li> <li>请求写MemStore</li></ul></li> <li>14.1.5.2. MemStore刷盘
<ul><li>全局内存控制</li> <li>MemStore达到上限...........................................................................................................................................</li> <li>RegionServer的Hlog数量达到上限</li> <li>手工触发</li> <li>关闭RegionServer触发</li> <li>Region使用HLOG恢复完数据后触发............................................................................................................</li></ul></li></ul></li> <li>14.1.6. HBase vs Cassandra</li></ul></li> <li><ol start="15"><li>MONGODB</li></ol> <ul><li>15.1.1. 概念</li> <li>15.1.2. 特点</li></ul></li> <li><ol start="16"><li>CASSANDRA</li></ol> <ul><li>16.1.1. 概念</li> <li>16.1.2. 数据模型
<ul><li>Key Space（对应SQL数据库中的database）</li> <li>Key（对应SQL数据库中的主键）</li> <li>column（对应SQL数据库中的列）</li> <li>super column（SQL数据库不支持）</li> <li>Standard Column Family（相对应SQL数据库中的table）</li> <li>Super Column Family（SQL数据库不支持）</li></ul></li> <li>16.1.3. Cassandra 一致 Hash 和虚拟节点
<ul><li>一致性Hash（多米诺down机）</li> <li>虚拟节点（down机多节点托管）</li></ul></li> <li>16.1.4. Gossip 协议
<ul><li>Gossip节点的通信方式及收敛性
<ul><li>Gossip两个节点（A、B）之间存在三种通信方式（push、pull、push&amp;pull）</li> <li>gossip的协议和seed list（防止集群分列）</li></ul></li></ul></li> <li>16.1.5. 数据复制
<ul><li>Partitioners（计算primary key token的hash函数）</li> <li>两种可用的复制策略：
<ul><li>SimpleStrategy：仅用于单数据中心，</li> <li>点中。 将第一个replica放在由partitioner确定的节点中，其余的replicas放在上述节点顺时针方向的后续节</li> <li>NetworkTopologyStrategy：可用于较复杂的多数据中心。</li> <li>可以指定在每个数据中心分别存储多少份replicas。</li></ul></li></ul></li> <li>16.1.6. 数据写请求和协调者
<ul><li>协调者(coordinator)</li></ul></li> <li>16.1.7. 数据读请求和后台修复</li> <li>16.1.8. 数据存储（CommitLog、MemTable、SSTable）
<ul><li>SSTable文件构成（BloomFilter、index、data、static）</li></ul></li> <li>16.1.9. 二级索引（对要索引的 value 摘要，生成 RowKey ）</li> <li>16.1.10. 数据读写
<ul><li>数据写入和更新（数据追加）
<ul><li>数据的写和删除效率极高</li> <li>错误恢复简单</li> <li>读的复杂度高</li></ul></li> <li>数据删除（column 的墓碑）
<ul><li>墓碑......................................................................................................................................................................</li> <li>垃圾回收compaction</li> <li>数据读取（memtable+SStables）</li></ul></li> <li>行缓存和键缓存请求流程图
<ul><li>Row Cache（SSTables中频繁被访问的数据）</li> <li>Bloom Filter（查找数据可能对应的SSTable）</li> <li>Partition Key Cache（查找数据可能对应的Partition key）</li> <li>Partition Summary（内存中存储一些partition index的样本）</li> <li>Partition Index（磁盘中）</li> <li>Compression offset map（磁盘中）</li></ul></li></ul></li></ul></li> <li><ol start="17"><li>设计模式</li></ol> <ul><li>17.1.1. 设计原则</li> <li>17.1.2. 工厂方法模式</li> <li>17.1.3. 抽象工厂模式</li> <li>17.1.4. 单例模式</li> <li>17.1.5. 建造者模式</li> <li>17.1.6. 原型模式</li> <li>17.1.7. 适配器模式</li> <li>17.1.8. 装饰器模式</li> <li>17.1.9. 代理模式</li> <li>17.1.10. 外观模式</li> <li>17.1.11. 桥接模式</li> <li>17.1.12. 组合模式</li> <li>17.1.13. 享元模式</li> <li>17.1.14. 策略模式</li> <li>17.1.15. 模板方法模式</li> <li>17.1.16. 观察者模式</li> <li>17.1.17. 迭代子模式</li> <li>17.1.18. 责任链模式</li> <li>17.1.19. 命令模式</li> <li>1 7.1.20. 备忘录模式</li> <li>17.1.21. 状态模式</li> <li>17.1.22. 访问者模式</li> <li>17.1.23. 中介者模式</li> <li>17.1.24. 解释器模式</li></ul></li> <li><ol start="18"><li>负载均衡</li></ol> <ul><li>18.1.1. 四层负载均衡 vs 七层负载均衡
<ul><li>18.1.1.1. 四层负载均衡（目标地址和端口交换）
<ul><li>F5：硬件负载均衡器，功能很好，但是成本很高。</li> <li>lvs：重量级的四层负载软件。</li> <li>nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活。</li> <li>haproxy：模拟四层转发，较灵活。</li></ul></li> <li>18.1.1.2. 七层负载均衡（内容交换）
<ul><li>haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；</li> <li>nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；</li> <li>apache：功能较差</li> <li>Mysql proxy：功能尚可。</li></ul></li></ul></li> <li>18.1.2. 负载均衡算法 / 策略
<ul><li>18.1.2.1. 轮循均衡（Round Robin）</li> <li>18.1.2.2. 权重轮循均衡（Weighted Round Robin）</li> <li>18.1.2.3. 随机均衡（Random）</li> <li>18.1.2.4. 权重随机均衡（Weighted Random）</li> <li>18.1.2.5. 响应速度均衡（Response Time探测时间）</li> <li>18.1.2.6. 最少连接数均衡（Least Connection）</li> <li>18.1.2.7. 处理能力均衡（CPU、内存）</li> <li>18.1.2.8. DNS响应均衡（Flash DNS）</li> <li>18.1.2.9. 哈希算法</li> <li>18.1.2.10. IP地址散列（保证客户端服务器对应关系稳定）</li> <li>18.1.2.11. URL散列</li></ul></li> <li>18.1.3. LVS
<ul><li>18.1.3.1. LVS原理
<ul><li>IPVS</li></ul></li> <li>18.1.3.1. LVS NAT 模式</li> <li>18.1.3.2. LVS DR 模式（局域网改写mac地址）</li> <li>18.1.3.3. LVS TUN 模式（IP封装、跨网段）</li> <li>18.1.3.4. LVS FULLNAT模式</li></ul></li> <li>18.1.4. Keepalive</li> <li>18.1.5. Nginx 反向代理负载均衡
<ul><li>18.1.5.1. upstream_module和健康检测</li> <li>18.1.5.1. proxy_pass请求转发</li></ul></li> <li>18.1.6. HAProxy</li></ul></li> <li><ol start="19"><li>数据库</li></ol> <ul><li>19.1.1. 存储引擎
<ul><li>19.1.1.1. 概念</li> <li>19.1.1.2. InnoDB（B+树）</li> <li>19.1.1.3. TokuDB（Fractal Tree-节点带数据）</li> <li>19.1.1.4. MyIASM</li> <li>19.1.1.5. Memory</li></ul></li> <li>19.1.2. 索引
<ul><li>19.1.2.1. 常见索引原则有
<ul><li>1.选择唯一性索引</li> <li>2.为经常需要排序、分组和联合操作的字段建立索引：</li> <li>3 ．为常作为查询条件的字段建立索引。</li> <li>4 ．限制索引的数目：</li> <li>尽量使用数据量少的索引</li> <li>尽量使用前缀来索引</li> <li>7 ．删除不再使用或者很少使用的索引</li> <li>8 最左前缀匹配原则，非常重要的原则。</li> <li>10 尽量选择区分度高的列作为索引</li> <li>11 .索引列不能参与计算，保持列“干净”：带函数的查询不参与索引。</li> <li>12 .尽量的扩展索引，不要新建索引。</li></ul></li></ul></li> <li>19.1.3. 数据库三范式
<ul><li>19.1.3.1. 第一范式(1st NF －列都是不可再分)</li> <li>19.1.3.2. 第二范式(2nd NF－每个表只描述一件事情)</li> <li>19.1.3.3. 第三范式(3rd NF－ 不存在对非主键列的传递依赖)</li></ul></li> <li>19.1.4. 数据库是事务
- 原子性（Atomicity）
- 一致性（Consistency）
- 隔离性（Isolation）
- 永久性（Durability）</li> <li>19.1.5. 存储过程 ( 特定功能的 SQL 语句集 )
<ul><li>存储过程优化思路：</li></ul></li> <li>19.1.6. 触发器 ( 一段能自动执行的程序 )</li> <li>19.1.7. 数据库并发策略
<ul><li>19.1.7.1. 乐观锁</li> <li>19.1.7.2. 悲观锁</li> <li>19.1.7.3. 时间戳</li></ul></li> <li>19.1.8. 数据库锁
<ul><li>19.1.8.1. 行级锁</li> <li>19.1.8.2. 表级锁</li> <li>19.1.8.1. 页级锁</li></ul></li> <li>19.1.9. 基于 Redis 分布式锁</li> <li>19.1.10. 分区分表
- 垂直切分(按照功能模块)
- 水平切分(按照规则划分存储)</li> <li>19.1.11. 两阶段提交协议
<ul><li>19.1.11.1. 准备阶段</li> <li>19.1.11.2. 提交阶段</li> <li>19.1.11.3. 缺点
<ul><li>同步阻塞问题</li> <li>单点故障</li> <li>数据不一致（脑裂问题）</li> <li>二阶段无法解决的问题（数据状态不确定）</li></ul></li></ul></li> <li>19.1.12. 三阶段提交协议
<ul><li>19.1.12.1. CanCommit阶段</li> <li>19.1.12.2. PreCommit阶段</li> <li>19.1.12.3. doCommit阶段</li></ul></li> <li>19.1.13. 柔性事务
<ul><li>19.1.13.1. 柔性事务
<ul><li>两阶段型</li> <li>补偿型</li> <li>异步确保型</li> <li>最大努力通知型（多次尝试）</li></ul></li></ul></li> <li>19.1.14. CAP
<ul><li>一致性（C）：</li> <li>可用性（A）：</li> <li>分区容忍性（P）：</li></ul></li></ul></li> <li><ol start="20"><li>一致性算法</li></ol> <ul><li>20.1.1. Paxos
<ul><li>Paxos三种角色：Proposer，Acceptor，Learners
<ul><li>Proposer：</li> <li>Acceptor：</li> <li>Learner：</li></ul></li> <li>Paxos算法分为两个阶段。具体如下：
<ul><li>阶段一（准leader确定 ）：</li> <li>阶段二（leader确认）：</li></ul></li></ul></li> <li>20.1.2. Zab
- 1.崩溃恢复：主要就是Leader选举过程
- 2.数据同步：Leader服务器与其他服务器进行数据同步
- 3.消息广播：Leader服务器将数据发送给其他服务器</li> <li>20.1.3. Raft
<ul><li>20.1.3.1. 角色
<ul><li>Leader（领导者-日志管理）</li> <li>Follower（追随者-日志同步）</li> <li>Candidate（候选者-负责选票）</li></ul></li> <li>20.1.3.2. Term（任期）</li> <li>20.1.3.3. 选举（Election）
<ul><li>选举定时器</li></ul></li> <li>20.1.3.4. 安全性（Safety）</li> <li>20.1.3.5. raft协议和zab协议区别</li></ul></li> <li>20.1.4. NWR
- N：在分布式存储系统中，有多少份备份数据
- W：代表一次成功的更新操作要求至少有w份数据写入成功
- R： 代表一次成功的读数据操作要求至少有R份数据成功读取</li> <li>20.1.5. Gossip</li> <li>20.1.6. 一致性 Hash
<ul><li>20.1.6.1. 一致性Hash特性</li> <li>20.1.6.2. 一致性Hash原理
<ul><li>1.建构环形hash 空间：</li> <li>2.把需要缓存的内容(对象)映射到hash 空间</li> <li>3.把服务器(节点)映射到hash 空间</li> <li>4.把对象映射到服务节点</li> <li>考察cache 的变动</li> <li>虚拟节点</li></ul></li></ul></li></ul></li> <li><ol start="21"><li>JAVA 算法</li></ol> <ul><li>21.1.1. 二分查找</li> <li>21.1.2. 冒泡排序算法</li> <li>21.1.3. 插入排序算法</li> <li>21.1.4. 快速排序算法</li> <li>21.1.1. 希尔排序算法</li> <li>21.1.2. 归并排序算法</li> <li>21.1.3. 桶排序算法</li> <li>21.1.4. 基数排序算法</li> <li>21.1.5. 剪枝算法</li> <li>21.1.6. 回溯算法</li> <li>21.1.7. 最短路径算法</li> <li>21.1.8. 最大子数组算法</li> <li>21.1.9. 最长公共子序算法</li> <li>21.1.10. 最小生成树算法</li></ul></li> <li><ol start="22"><li>数据结构</li></ol> <ul><li>22.1.1. 栈（ stack ）</li> <li>22.1.2. 队列（ queue ）</li> <li>22.1.3. 链表（ Link ）</li> <li>22.1.4. 散列表（ Hash Table ）</li> <li>22.1.5. 排序二叉树
<ul><li>22.1.5.1. 插入操作</li> <li>22.1.5.2. 删除操作</li> <li>22.1.5.3. 查询操作</li></ul></li> <li>22.1.6. 红黑树
<ul><li>22.1.6.1. 红黑树的特性</li> <li>22.1.6.1. 左旋</li> <li>22.1.6.1. 右旋</li> <li>22.1.6.1. 添加</li> <li>22.1.6.2. 删除</li></ul></li> <li>22.1.7. B-TREE</li> <li>22.1.8. 位图</li></ul></li> <li><ol start="23"><li>加密算法</li></ol> <ul><li>23.1.1. AES</li> <li>23.1.2. RSA</li> <li>23.1.3. CRC............................................................................................................................................</li> <li>23.1.4. MD5</li></ul></li> <li><ol start="24"><li>分布式缓存</li></ol> <ul><li>24.1.1. 缓存雪崩</li> <li>24.1.2. 缓存穿透</li> <li>24.1.3. 缓存预热</li> <li>24.1.4. 缓存更新</li> <li>24.1.5. 缓存降级</li></ul></li> <li><ol start="25"><li>HADOOP</li></ol> <ul><li>25.1.1. 概念</li> <li>25.1.2. HDFS
<ul><li>25.1.2.1. Client</li> <li>25.1.2.2. NameNode</li> <li>25.1.2.3. Secondary NameNode</li> <li>25.1.2.4. DataNode.........................................................................................................................................</li></ul></li> <li>25.1.3. MapReduce
<ul><li>25.1.3.1. Client</li> <li>25.1.3.2. JobTracker</li> <li>25.1.3.3. TaskTracker</li> <li>25.1.3.4. Task</li> <li>25.1.3.5. Reduce Task 执行过程</li></ul></li> <li>25.1.4. Hadoop MapReduce 作业的生命周期
- 1.作业提交与初始化...........................................................................................................................................
- 2.任务调度与监控。...........................................................................................................................................
- 3.任务运行环境准备...........................................................................................................................................
- 4.任务执行
- 5.作业完成。</li></ul></li> <li><ol start="26"><li>SPARK</li></ol> <ul><li>26.1.1. 概念</li> <li>26.1.2. 核心架构
- Spark Core
- Spark SQL
- Spark Streaming
- Mllib
- GraphX</li> <li>26.1.3. 核心组件
- Cluster Manager-制整个集群，监控worker
- Worker节点-负责控制计算节点
- Driver： 运行Application 的main()函数.........................................................................................................
- Executor：执行器，是为某个Application运行在worker node上的一个进程</li> <li>26.1.4. SPARK 编程模型</li> <li>26.1.5. SPARK 计算模型</li> <li>26.1.6. SPARK 运行流程
- 1. 构建Spark Application的运行环境，启动SparkContext
- 动StandaloneExecutorbackend， 2. SparkContext向资源管理器（可以是Standalone，Mesos，Yarn）申请运行Executor资源，并启
- 3. Executor向SparkContext申请Task
- 4. SparkContext将应用程序分发给Executor
- 后由Task Scheduler将Task发送给Executor运行 5. SparkContext构建成DAG图，将DAG图分解成Stage、将Taskset发送给Task Scheduler，最
- 6. Task在Executor上运行，运行完释放所有资源...................................................................................</li> <li>26.1.7. SPARK RDD 流程</li> <li>26.1.8. SPARK RDD
<ul><li>（ 1 ）RDD的创建方式...........................................................................................................................................</li> <li>（ 2 ）RDD的两种操作算子（转换（Transformation）与行动（Action））</li></ul></li></ul></li> <li><ol start="27"><li>STORM</li></ol> <ul><li>27.1.1. 概念</li> <li>27.1.1. 集群架构
<ul><li>27.1.1.1. Nimbus（master-代码分发给Supervisor）</li> <li>27.1.1.2. Supervisor（slave-管理Worker进程的启动和终止）</li> <li>27.1.1.3. Worker（具体处理组件逻辑的进程）</li> <li>27.1.1.4. Task</li> <li>27.1.1.5. ZooKeeper</li></ul></li> <li>27.1.2. 编程模型（spout-&gt;tuple-&gt;bolt）
<ul><li>27.1.2.1. Topology</li> <li>27.1.2.2. Spout..................................................................................................................................................</li> <li>27.1.2.3. Bolt</li> <li>27.1.2.4. Tuple</li> <li>27.1.2.5. Stream</li></ul></li> <li>27.1.3. Topology 运行
- (1). Worker（进程） (2). Executor（线程） (3). Task
<ul><li>27.1.3.1. Worker( 1 个worker进程执行的是 1 个topology的子集)</li> <li>27.1.3.2. Executor(executor是 1 个被worker进程启动的单独线程)</li> <li>27.1.3.3. Task(最终运行spout或bolt中代码的单元)</li></ul></li> <li>27.1.4. Storm Streaming Grouping
<ul><li>27.1.4.1. huffle Grouping</li> <li>27.1.4.2. Fields Grouping</li> <li>27.1.4.3. All grouping ：广播</li> <li>27.1.4.4. Global grouping</li> <li>27.1.4.5. None grouping ：不分组</li> <li>27.1.4.6. Direct grouping ：直接分组 指定分组</li></ul></li></ul></li> <li><ol start="28"><li>YARN</li></ol> <ul><li>28.1.1. 概念</li> <li>28.1.2. ResourceManager</li> <li>28.1.3. NodeManager</li> <li>28.1.4. ApplicationMaster</li> <li>28.1.5. YARN运行流程</li></ul></li> <li><ol start="29"><li>机器学习</li></ol> <ul><li>29.1.1. 决策树</li> <li>29.1.2. 随机森林算法</li> <li>29.1.3. 逻辑回归</li> <li>29.1.4. SVM............................................................................................................................................</li> <li>29.1.5. 朴素贝叶斯</li> <li>29.1.6. K 最近邻算法</li> <li>29.1.7. K 均值算法</li> <li>29.1.8. Adaboost 算法</li> <li>29.1.9. 神经网络</li> <li>29.1.10. 马尔可夫</li></ul></li> <li><ol start="30"><li>云计算</li></ol> <ul><li>30.1.1. SaaS</li> <li>30.1.2. PaaS</li> <li>30.1.3. IaaS</li> <li>30.1.4. Docker
<ul><li>30.1.4.1. 概念</li> <li>30.1.4.2. Namespaces</li> <li>30.1.4.3. 进程(CLONE_NEWPID 实现的进程隔离)......................................................................................</li> <li>30.1.4.4. Libnetwork与网络隔离</li> <li>30.1.4.5. 资源隔离与CGroups</li> <li>30.1.4.6. 镜像与UnionFS</li> <li>30.1.4.7. 存储驱动</li></ul></li></ul></li> <li>30.1.5. Openstack</li></ul> <h2 id="_2-jvm"><a href="#_2-jvm" class="header-anchor">#</a> 2. JVM</h2> <div class="language- extra-class"><pre class="language-text"><code>(1) 基本概念：
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>JVM是可运行Java代码的假想计算机 ，包括一套字节码指令集、一组寄存器、一个栈、
一个垃圾回收，堆 和 一个存储方法域。JVM是运行在操作系统之上的，它与硬件没有直接
的交互。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>(2) 运行过程：
</code></pre></div><p>我们都知道Java源文件，通过编译器，能够生产相应的.Class文件，也就是字节码文件，</p> <p>而字节码文件又通过Java虚拟机中的解释器，编译成特定机器上的机器码 。</p> <p>也就是如下：</p> <p>① Java源文件—-&gt;编译器—-&gt;字节码文件</p> <p>② 字节码文件—-&gt;JVM—-&gt;机器码</p> <p>每一种平台的解释器是不同的，但是实现的虚拟机是相同的，这也就是Java为什么能够</p> <p>跨平台的原因了 ，当一个程序从开始运行，这时虚拟机就开始实例化了，多个程序启动就会</p> <p>存在多个虚拟机实例。程序退出或者关闭，则虚拟机实例消亡，多个虚拟机实例之间数据不</p> <p>能共享。</p> <h3 id="_2-1-线程"><a href="#_2-1-线程" class="header-anchor">#</a> 2.1. 线程</h3> <p>这里所说的线程指程序执行过程中的一个线程实体。JVM 允许一个应用并发执行多个线程。</p> <p>Hotspot JVM 中的 Java 线程与原生操作系统线程有直接的映射关系。当线程本地存储、缓</p> <p>冲区分配、同步对象、栈、程序计数器等准备好以后，就会创建一个操作系统原生线程。</p> <p>Java 线程结束，原生线程随之被回收。操作系统负责调度所有线程，并把它们分配到任何可</p> <p>用的 CPU 上。当原生线程初始化完毕，就会调用 Java 线程的 run() 方法。当线程结束时，</p> <div class="language- extra-class"><pre class="language-text"><code>会释放原生线程和 Java 线程的所有资源。
</code></pre></div><p>Hotspot JVM 后台运行的系统线程主要有下面几个：</p> <div class="language- extra-class"><pre class="language-text"><code>虚拟机线程
（VM thread）
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>这个线程等待 JVM 到达安全点操作出现。这些操作必须要在独立的线程里执行，因为当
堆修改无法进行时，线程都需要 JVM 位于安全点。这些操作的类型有：stop-the-
world 垃圾回收、线程栈 dump、线程暂停、线程偏向锁（biased locking）解除。
周期性任务线程 这线程负责定时器事件（也就是中断），用来调度周期性操作的执行。
GC 线程 这些线程支持 JVM 中不同的垃圾回收活动。
编译器线程 这些线程在运行时将字节码动态编译成本地平台相关的机器码。
信号分发线程 这个线程接收发送到 JVM 的信号并调用适当的 JVM 方法处理。
</code></pre></div><h3 id="_2-2-jvm内存区域"><a href="#_2-2-jvm内存区域" class="header-anchor">#</a> 2.2. JVM内存区域</h3> <p>JVM 内存区域主要分为线程私有区域【程序计数器、虚拟机栈、本地方法区】、线程共享区
域【JAVA堆、方法区】、直接内存。</p> <p>线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁(在Hotspot
VM 内, 每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的
生/死对应)。</p> <p>线程共享区域随虚拟机的启动/关闭而创建/销毁。
直接内存并不是JVM运行时数据区的一部分, 但也会被频繁的使用: 在JDK 1.4引入的NIO提
供了基于Channel与Buffer的IO方式, 它可以使用Native函数库直接分配堆外内存, 然后使用
DirectByteBuffer对象作为这块内存的引用进行操作(详见: Java I/O 扩展), 这样就避免了在Java
堆和Native堆中来回复制数据, 因此在一些场景中可以显著提高性能。</p> <h4 id="_2-2-1-程序计数器-线程私有"><a href="#_2-2-1-程序计数器-线程私有" class="header-anchor">#</a> 2.2.1. 程序计数器 ( 线程私有 )</h4> <p>一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的
程序计数器，这类内存也称为“线程私有”的内存。</p> <p>正在执行java 方法的话，计数器记录的是虚拟机字节码指令的地址（当前指令的地址）。如
果还是Native方法，则为空。</p> <div class="language- extra-class"><pre class="language-text"><code>这个内存区域是唯一一个在虚拟机中没有规定任何OutOfMemoryError情况的区域。
</code></pre></div><h4 id="_2-2-2-虚拟机栈-线程私有"><a href="#_2-2-2-虚拟机栈-线程私有" class="header-anchor">#</a> 2.2.2. 虚拟机栈 ( 线程私有 )</h4> <p>是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）
用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成
的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。</p> <p>栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接
(Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。栈帧随着方法调用而创</p> <p>建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异
常）都算作方法结束。</p> <h4 id="_2-2-3-本地方法区-线程私有"><a href="#_2-2-3-本地方法区-线程私有" class="header-anchor">#</a> 2.2.3. 本地方法区 ( 线程私有 )</h4> <p>本地方法区和Java Stack作用类似, 区别是虚拟机栈为执行Java方法服务, 而本地方法栈则为
Native方法服务, 如果一个VM实现使用C-linkage模型来支持Native调用, 那么该栈将会是一个
C栈，但HotSpot VM直接就把本地方法栈和虚拟机栈合二为一。</p> <h4 id="_2-2-4-堆-heap-线程共享-运行时数据区"><a href="#_2-2-4-堆-heap-线程共享-运行时数据区" class="header-anchor">#</a> 2.2.4. 堆（ Heap- 线程共享） - 运行时数据区</h4> <p>是被线程共享的一块内存区域，创建的对象和数组都保存在Java 堆内存中，也是垃圾收集器进行
垃圾收集的最重要的内存区域。由于现代VM采用 <strong>分代收集算法</strong> , 因此Java堆从GC的角度还可以
细分为: <strong>新生代</strong> (Eden区、From Survivor区和To Survivor区)和 <strong>老年代。</strong></p> <h4 id="_2-2-5-方法区-永久代-线程共享"><a href="#_2-2-5-方法区-永久代-线程共享" class="header-anchor">#</a> 2.2.5. 方法区 / 永久代（线程共享）</h4> <p>即我们常说的 <strong>永久代(Permanent Generation)</strong> , 用于存储 <strong>被JVM加载的类信息</strong> 、 <strong>常量</strong> 、 <strong>静
态变量</strong> 、 <strong>即时编译器编译后的代码</strong> 等数据. HotSpot VM把GC分代收集扩展至方法区, 即 <strong>使用Java
堆的永久代来实现方法区</strong> , 这样HotSpot的垃圾收集器就可以像管理Java堆一样管理这部分内存,
而不必为方法区开发专门的内存管理器(永久带的内存回收的主要目标是针对 <strong>常量池的回收</strong> 和 <strong>类型
的卸载</strong> , 因此收益一般很小)。
运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版
本、字段、方法、接口等描述等信息外，还有一项信息是常量池</p> <p>（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加
载后存放到方法区的运行时常量池中。 Java虚拟机对Class文件的每一部分（自然也包括常量
池）的格式都有严格的规定，每一个字节用于存储哪种数据都必须符合规范上的要求，这样才会
被虚拟机认可、装载和执行。</p> <h3 id="_2-3-jvm运行时内存"><a href="#_2-3-jvm运行时内存" class="header-anchor">#</a> 2.3. JVM运行时内存</h3> <p>Java堆从GC的角度还可以细分为: <strong>新生代</strong> (Eden区、From Survivor区和To Survivor区)和 <strong>老年
代。</strong></p> <h4 id="_2-3-1-新生代"><a href="#_2-3-1-新生代" class="header-anchor">#</a> 2.3.1. 新生代</h4> <p>是用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁触发
MinorGC进行垃圾回收。新生代又分为 Eden区、ServivorFrom、ServivorTo三个区。</p> <h5 id="_2-3-1-1-eden区"><a href="#_2-3-1-1-eden区" class="header-anchor">#</a> 2.3.1.1. Eden区</h5> <div class="language- extra-class"><pre class="language-text"><code>Java新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老
年代）。当Eden区内存不够的时候就会触发MinorGC，对新生代区进行
一次垃圾回收。
</code></pre></div><h5 id="_2-3-1-2-servivorfrom"><a href="#_2-3-1-2-servivorfrom" class="header-anchor">#</a> 2.3.1.2. ServivorFrom</h5> <div class="language- extra-class"><pre class="language-text"><code>上一次GC的幸存者，作为这一次GC的被扫描者。
</code></pre></div><h5 id="_2-3-1-3-servivorto"><a href="#_2-3-1-3-servivorto" class="header-anchor">#</a> 2.3.1.3. ServivorTo</h5> <div class="language- extra-class"><pre class="language-text"><code>保留了一次MinorGC过程中的幸存者。
</code></pre></div><h5 id="_2-3-1-4-minorgc的过程-复制-清空-互换"><a href="#_2-3-1-4-minorgc的过程-复制-清空-互换" class="header-anchor">#</a> 2.3.1.4. MinorGC的过程（复制-&gt;清空-&gt;互换）</h5> <div class="language- extra-class"><pre class="language-text"><code>MinorGC采用复制算法。
</code></pre></div><h6 id="_1-eden、servicorfrom-复制到servicorto-年龄-1"><a href="#_1-eden、servicorfrom-复制到servicorto-年龄-1" class="header-anchor">#</a> 1 ：eden、servicorFrom 复制到ServicorTo，年龄+1</h6> <p>首先，把Eden和ServivorFrom区域中存活的对象复制到ServicorTo区域（如果有对象的年
龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果ServicorTo不
够位置了就放到老年区）；</p> <h6 id="_2-清空eden、servicorfrom"><a href="#_2-清空eden、servicorfrom" class="header-anchor">#</a> 2 ：清空eden、servicorFrom</h6> <div class="language- extra-class"><pre class="language-text"><code>然后，清空Eden和ServicorFrom中的对象；
</code></pre></div><h6 id="_3-servicorto和servicorfrom互换"><a href="#_3-servicorto和servicorfrom互换" class="header-anchor">#</a> 3 ：ServicorTo和ServicorFrom互换</h6> <p>最后，ServicorTo和ServicorFrom互换，原ServicorTo成为下一次GC时的ServicorFrom
区。</p> <h4 id="_2-3-2-老年代"><a href="#_2-3-2-老年代" class="header-anchor">#</a> 2.3.2. 老年代</h4> <p>主要存放应用程序中生命周期长的内存对象。
老年代的对象比较稳定，所以MajorGC不会频繁执行。在进行MajorGC前一般都先进行
了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足
够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。</p> <p>MajorGC采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没
有标记的对象。MajorGC的耗时比较长，因为要扫描再回收。MajorGC会产生内存碎片，为了减
少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的
时候，就会抛出OOM（Out of Memory）异常。</p> <h4 id="_2-3-3-永久代"><a href="#_2-3-3-永久代" class="header-anchor">#</a> 2.3.3. 永久代</h4> <p>指内存的永久保存区域，主要存放Class和Meta（元数据）的信息,Class在被加载的时候被
放入永久区域，它和和存放实例的区域不同,GC不会在主程序运行期对永久区域进行清理。所以这
也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。</p> <h5 id="_2-3-3-1-java8与元数据"><a href="#_2-3-3-1-java8与元数据" class="header-anchor">#</a> 2.3.3.1. JAVA8与元数据</h5> <p>在Java8中，永久代已经被移除，被一个称为“元数据区”（元空间）的区域所取代。元空间
的本质和永久代类似，元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用
本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入 native
memory, 字符串池和类的静态变量放入java 堆中，这样可以加载多少类的元数据就不再由
MaxPermSize控制, 而由系统的实际可用空间来控制。</p> <h3 id="_2-4-垃圾回收与算法"><a href="#_2-4-垃圾回收与算法" class="header-anchor">#</a> 2.4. 垃圾回收与算法</h3> <h4 id="_2-4-1-如何确定垃圾"><a href="#_2-4-1-如何确定垃圾" class="header-anchor">#</a> 2.4.1. 如何确定垃圾</h4> <h5 id="_2-4-1-1-引用计数法"><a href="#_2-4-1-1-引用计数法" class="header-anchor">#</a> 2.4.1.1. 引用计数法...............................................................................................................................................</h5> <p>在Java中，引用和对象是有关联的。如果要操作对象则必须用引用进行。因此，很显然一个简单
的办法是通过引用计数来判断一个对象是否可以回收。简单说，即一个对象如果没有任何与之关
联的引用，即他们的引用计数都不为 0 ，则说明对象不太可能再被用到，那么这个对象就是可回收
对象。</p> <h5 id="_2-4-1-2-可达性分析"><a href="#_2-4-1-2-可达性分析" class="header-anchor">#</a> 2.4.1.2. 可达性分析...............................................................................................................................................</h5> <p>为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。通过一系列的“GC roots”
对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。</p> <p>要注意的是，不可达对象不等价于可回收对象，不可达对象变为可回收对象至少要经过两次标记
过程。两次标记后仍然是可回收对象，则将面临回收。</p> <h4 id="_2-4-2-标记清除算法-mark-sweep"><a href="#_2-4-2-标记清除算法-mark-sweep" class="header-anchor">#</a> 2.4.2. 标记清除算法（Mark-Sweep）</h4> <p>最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记出所有需要回收的对象，清
除阶段回收被标记的对象所占用的空间。如图</p> <p>从图中我们就可以发现，该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可
利用空间的问题。</p> <h4 id="_2-4-3-复制算法-copying"><a href="#_2-4-3-复制算法-copying" class="header-anchor">#</a> 2.4.3. 复制算法（ copying ）</h4> <p>为了解决Mark-Sweep算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小
的两块。每次只使用其中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用
的内存清掉，如图：</p> <p>这种算法虽然实现简单，内存效率高，不易产生碎片，但是最大的问题是可用内存被压缩到了原
本的一半。且存活对象增多的话，Copying算法的效率会大大降低。</p> <h4 id="_2-4-4-标记整理算法-mark-compact"><a href="#_2-4-4-标记整理算法-mark-compact" class="header-anchor">#</a> 2.4.4. 标记整理算法 (Mark-Compact)</h4> <p>结合了以上两个算法，为了避免缺陷而提出。标记阶段和Mark-Sweep算法相同，标记后不是清
理对象，而是将存活对象移向内存的一端。然后清除端边界外的对象。如图：</p> <h4 id="_2-4-5-分代收集算法"><a href="#_2-4-5-分代收集算法" class="header-anchor">#</a> 2.4.5. 分代收集算法</h4> <p>分代收集法是目前大部分JVM所采用的方法，其核心思想是根据对象存活的不同生命周期将内存
划分为不同的域，一般情况下将GC堆划分为老生代(Tenured/Old Generation)和新生代(Young
Generation)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃
圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。</p> <h5 id="_2-4-5-1-新生代与复制算法"><a href="#_2-4-5-1-新生代与复制算法" class="header-anchor">#</a> 2.4.5.1. 新生代与复制算法</h5> <p>目前大部分JVM的GC对于新生代都采取Copying算法，因为新生代中每次垃圾回收都要
回收大部分对象，即要复制的操作比较少，但通常并不是按照 1 ： 1 来划分新生代。一般将新生代
划分为一块较大的Eden空间和两个较小的Survivor空间(From Space, To Space)，每次使用
Eden空间和其中的一块Survivor空间，当进行回收时，将该两块空间中还存活的对象复制到另
一块Survivor空间中。</p> <h5 id="_2-4-5-2-老年代与标记复制算法"><a href="#_2-4-5-2-老年代与标记复制算法" class="header-anchor">#</a> 2.4.5.2. 老年代与标记复制算法</h5> <p>而老年代因为每次只回收少量对象，因而采用Mark-Compact算法。</p> <ol><li>JAVA虚拟机提到过的处于方法区的永生代(Permanet Generation)，它用来存储class类，
常量，方法描述等。对永生代的回收主要包括废弃常量和无用的类。</li> <li>对象的内存分配主要在新生代的Eden Space和Survivor Space的From Space(Survivor目
前存放对象的那一块)，少数情况会直接分配到老生代。</li> <li>当新生代的Eden Space和From Space空间不足时就会发生一次GC，进行GC后，Eden
Space和From Space区的存活对象会被挪到To Space，然后将Eden Space和From
Space进行清理。</li> <li>如果To Space无法足够存储某个对象，则将这个对象存储到老生代。</li> <li>在进行GC后，使用的便是Eden Space和To Space了，如此反复循环。</li> <li>当对象在Survivor区躲过一次GC后，其年龄就会+1。默认情况下年龄到达 15 的对象会被
移到老生代中。</li></ol> <h3 id="_2-5-java-四中引用类型"><a href="#_2-5-java-四中引用类型" class="header-anchor">#</a> 2.5. JAVA 四中引用类型</h3> <h4 id="_2-5-1-强引用"><a href="#_2-5-1-强引用" class="header-anchor">#</a> 2.5.1. 强引用</h4> <p>在Java中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引
用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即
使该对象以后永远都不会被用到JVM也不会回收。因此强引用是造成Java内存泄漏的主要原因之
一。</p> <h4 id="_2-5-2-软引用"><a href="#_2-5-2-软引用" class="header-anchor">#</a> 2.5.2. 软引用</h4> <p>软引用需要用SoftReference 类来实现，对于只有软引用的对象来说，当系统内存足够时它
不会被回收，当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。</p> <h4 id="_2-5-3-弱引用"><a href="#_2-5-3-弱引用" class="header-anchor">#</a> 2.5.3. 弱引用</h4> <p>弱引用需要用WeakReference类来实现，它比软引用的生存期更短，对于只有弱引用的对象
来说，只要垃圾回收机制一运行，不管JVM的内存空间是否足够，总会回收该对象占用的内存。</p> <h4 id="_2-5-4-虚引用"><a href="#_2-5-4-虚引用" class="header-anchor">#</a> 2.5.4. 虚引用</h4> <p>虚引用需要PhantomReference类来实现，它不能单独使用，必须和引用队列联合使用。虚
引用的主要作用是跟踪对象被垃圾回收的状态。</p> <h3 id="_2-6-gc分代收集算法-vs-分区收集算法"><a href="#_2-6-gc分代收集算法-vs-分区收集算法" class="header-anchor">#</a> 2.6. GC分代收集算法 VS 分区收集算法</h3> <h4 id="_2-6-1-分代收集算法"><a href="#_2-6-1-分代收集算法" class="header-anchor">#</a> 2.6.1. 分代收集算法</h4> <p>当前主流VM垃圾收集都采用”分代收集”(Generational Collection)算法, 这种算法会根据
对象存活周期的不同将内存划分为几块, 如JVM中的 新生代、老年代、永久代，这样就可以根据
各年代特点分别采用最适当的GC算法</p> <h5 id="_2-6-1-1-在新生代-复制算法"><a href="#_2-6-1-1-在新生代-复制算法" class="header-anchor">#</a> 2.6.1.1. 在新生代-复制算法</h5> <div class="language- extra-class"><pre class="language-text"><code>每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量
存活对象的复制成本就可以完成收集.
</code></pre></div><h5 id="_2-6-1-2-在老年代-标记整理算法"><a href="#_2-6-1-2-在老年代-标记整理算法" class="header-anchor">#</a> 2.6.1.2. 在老年代-标记整理算法</h5> <div class="language- extra-class"><pre class="language-text"><code>因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标
记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存.
</code></pre></div><h4 id="_2-6-2-分区收集算法"><a href="#_2-6-2-分区收集算法" class="header-anchor">#</a> 2.6.2. 分区收集算法</h4> <p>分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的
好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是
整个堆), 从而减少一次GC所产生的停顿。</p> <h3 id="_2-7-gc垃圾收集器"><a href="#_2-7-gc垃圾收集器" class="header-anchor">#</a> 2.7. GC垃圾收集器</h3> <p>Java堆内存被划分为新生代和年老代两部分，新生代主要使用复制和标记-清除垃圾回收算法；
年老代主要使用标记-整理垃圾回收算法，因此java虚拟中针对新生代和年老代分别提供了多种不
同的垃圾收集器，JDK1.6中Sun HotSpot虚拟机的垃圾收集器如下：</p> <h4 id="_2-7-1-serial-垃圾收集器-单线程、复制算法"><a href="#_2-7-1-serial-垃圾收集器-单线程、复制算法" class="header-anchor">#</a> 2.7.1. Serial 垃圾收集器（单线程、复制算法）</h4> <p>Serial（英文连续）是最基本垃圾收集器，使用复制算法，曾经是JDK1.3.1之前新生代唯一的垃圾</p> <p>收集器。Serial是一个单线程的收集器，它不但只会使用一个CPU或一条线程去完成垃圾收集工
作，并且在进行垃圾收集的同时，必须暂停其他所有的工作线程，直到垃圾收集结束。</p> <p>Serial垃圾收集器虽然在收集垃圾过程中需要暂停所有其他的工作线程，但是它简单高效，对于限
定单个CPU环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此Serial</p> <p>垃圾收集器依然是java虚拟机运行在Client模式下默认的新生代垃圾收集器。</p> <h4 id="_2-7-2-parnew-垃圾收集器-serial-多线程"><a href="#_2-7-2-parnew-垃圾收集器-serial-多线程" class="header-anchor">#</a> 2.7.2. ParNew 垃圾收集器（ Serial+ 多线程）</h4> <p>ParNew垃圾收集器其实是Serial收集器的多线程版本，也使用复制算法，除了使用多线程进行垃</p> <p>圾收集之外，其余的行为和Serial收集器完全一样，ParNew垃圾收集器在垃圾收集过程中同样也
要暂停所有其他的工作线程。</p> <p>ParNew收集器默认开启和CPU数目相同的线程数，可以通过-XX:ParallelGCThreads参数来限</p> <p>制垃圾收集器的线程数。【Parallel：平行的】
ParNew虽然是除了多线程外和Serial收集器几乎完全一样，但是ParNew垃圾收集器是很多java</p> <p>虚拟机运行在Server模式下新生代的默认垃圾收集器。</p> <h4 id="_2-7-3-parallel-scavenge-收集器-多线程复制算法、高效"><a href="#_2-7-3-parallel-scavenge-收集器-多线程复制算法、高效" class="header-anchor">#</a> 2.7.3. Parallel Scavenge 收集器（多线程复制算法、高效）</h4> <p>Parallel Scavenge收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃</p> <p>圾收集器，它重点关注的是程序达到一个可控制的吞吐量（Thoughput，CPU用于运行用户代码
的时间/CPU总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)），</p> <p>高吞吐量可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适用于在后台运算而
不需要太多交互的任务。自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个</p> <p>重要区别。</p> <h4 id="_2-7-4-serial-old-收集器-单线程标记整理算法"><a href="#_2-7-4-serial-old-收集器-单线程标记整理算法" class="header-anchor">#</a> 2.7.4. Serial Old 收集器（单线程标记整理算法 ）</h4> <p>Serial Old是Serial垃圾收集器年老代版本，它同样是个单线程的收集器，使用标记-整理算法，
这个收集器也主要是运行在Client默认的java虚拟机默认的年老代垃圾收集器。</p> <p>在Server模式下，主要有两个用途：</p> <ol><li>在JDK1.5之前版本中与新生代的Parallel Scavenge收集器搭配使用。</li> <li>作为年老代中使用CMS收集器的后备垃圾收集方案。
新生代Serial与年老代Serial Old搭配垃圾收集过程图：</li></ol> <p>新生代Parallel Scavenge收集器与ParNew收集器工作原理类似，都是多线程的收集器，都使
用的是复制算法，在垃圾收集过程中都需要暂停所有的工作线程。新生代Parallel</p> <p>Scavenge/ParNew与年老代Serial Old搭配垃圾收集过程图：</p> <h4 id="_2-7-5-parallel-old-收集器-多线程标记整理算法"><a href="#_2-7-5-parallel-old-收集器-多线程标记整理算法" class="header-anchor">#</a> 2.7.5. Parallel Old 收集器（多线程标记整理算法）</h4> <p>Parallel Old收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.6
才开始提供。</p> <p>在JDK1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器，只
能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old正是为了在年老代同样提供吞</p> <p>吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代Parallel Scavenge
和年老代Parallel Old收集器的搭配策略。</p> <p>新生代Parallel Scavenge和年老代Parallel Old收集器搭配运行过程图：</p> <h4 id="_2-7-6-cms-收集器-多线程标记清除算法"><a href="#_2-7-6-cms-收集器-多线程标记清除算法" class="header-anchor">#</a> 2.7.6. CMS 收集器（多线程标记清除算法）</h4> <p>Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾</p> <p>回收停顿时间，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。
最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。</p> <p>CMS工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下 4 个阶段：</p> <h5 id="_2-7-6-1-初始标记"><a href="#_2-7-6-1-初始标记" class="header-anchor">#</a> 2.7.6.1. 初始标记</h5> <div class="language- extra-class"><pre class="language-text"><code>只是标记一下GC Roots能直接关联的对象，速度很快，仍然需要暂停所有的工作线程。
</code></pre></div><h5 id="_2-7-6-2-并发标记"><a href="#_2-7-6-2-并发标记" class="header-anchor">#</a> 2.7.6.2. 并发标记</h5> <div class="language- extra-class"><pre class="language-text"><code>进行GC Roots跟踪的过程，和用户线程一起工作，不需要暂停工作线程。
</code></pre></div><h5 id="_2-7-6-3-重新标记"><a href="#_2-7-6-3-重新标记" class="header-anchor">#</a> 2.7.6.3. 重新标记</h5> <div class="language- extra-class"><pre class="language-text"><code>为了修正在并发标记期间，因用户程序继续运行而导致标记产生变动的那一部分对象的标记
记录，仍然需要暂停所有的工作线程。
</code></pre></div><h5 id="_2-7-6-4-并发清除"><a href="#_2-7-6-4-并发清除" class="header-anchor">#</a> 2.7.6.4. 并发清除</h5> <div class="language- extra-class"><pre class="language-text"><code>清除GC Roots不可达对象，和用户线程一起工作，不需要暂停工作线程。由于耗时最长的并
发标记和并发清除过程中，垃圾收集线程可以和用户现在一起并发工作，所以总体上来看
CMS收集器的内存回收和用户线程是一起并发地执行。
CMS收集器工作过程：
</code></pre></div><h4 id="_2-7-7-g1-收集器"><a href="#_2-7-7-g1-收集器" class="header-anchor">#</a> 2.7.7. G1 收集器</h4> <p>Garbage first垃圾收集器是目前垃圾收集器理论发展的最前沿成果，相比与CMS收集器，G1收
集器两个最突出的改进是：</p> <ol><li>基于标记-整理算法，不产生内存碎片。</li> <li>可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。</li></ol> <p>G1收集器避免全区域垃圾收集，它把堆内存划分为大小固定的几个独立区域，并且跟踪这些区域
的垃圾收集进度，同时在后台维护一个优先级列表，每次根据所允许的收集时间，优先回收垃圾</p> <p>最多的区域。区域划分和优先级区域回收机制，确保G1收集器可以在有限时间获得最高的垃圾收
集效率。</p> <h3 id="_2-8-java-io-nio"><a href="#_2-8-java-io-nio" class="header-anchor">#</a> 2.8. JAVA IO/NIO</h3> <h4 id="_2-8-1-阻塞-io-模型"><a href="#_2-8-1-阻塞-io-模型" class="header-anchor">#</a> 2.8.1. 阻塞 IO 模型</h4> <p>最传统的一种IO模型，即在读写数据过程中会发生阻塞现象。当用户线程发出IO请求之后，内
核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用
户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程，用</p> <p>户线程才解除block状态。典型的阻塞IO模型的例子为：data = socket.read();如果数据没有就
绪，就会一直阻塞在read方法。</p> <h4 id="_2-8-2-非阻塞-io-模型"><a href="#_2-8-2-非阻塞-io-模型" class="header-anchor">#</a> 2.8.2. 非阻塞 IO 模型</h4> <p>当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个
error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备
好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。
所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO
不会交出CPU，而会一直占用CPU。典型的非阻塞IO模型一般如下：</p> <div class="language- extra-class"><pre class="language-text"><code>while(true){
data = socket.read();
if(data!= error){
处理数据
break;
}
</code></pre></div><h3 id=""><a href="#" class="header-anchor">#</a> }</h3> <p>但是对于非阻塞IO就有一个非常严重的问题，在while循环中需要不断地去询问内核数据是否就
绪，这样会导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。</p> <h4 id="_2-8-3-多路复用-io-模型"><a href="#_2-8-3-多路复用-io-模型" class="header-anchor">#</a> 2.8.3. 多路复用 IO 模型</h4> <p>多路复用IO模型是目前使用得比较多的模型。Java NIO实际上就是多路复用IO。在多路复用IO
模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真
正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个
socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有
socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。在Java NIO中，是通
过selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这
种方式会导致用户线程的阻塞。多路复用IO模式，通过一个线程就可以管理多个socket，只有当
socket真正有读写事件发生才会占用资源来进行实际的读写操作。因此，多路复用IO比较适合连
接数比较多的情况。</p> <p>另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态
时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效
率要比用户线程要高的多。</p> <p>不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件
逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件
迟迟得不到处理，并且会影响新的事件轮询。</p> <h4 id="_2-8-4-信号驱动-io-模型"><a href="#_2-8-4-信号驱动-io-模型" class="header-anchor">#</a> 2.8.4. 信号驱动 IO 模型</h4> <p>在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函
数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到
信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。</p> <h4 id="_2-8-5-异步-io-模型"><a href="#_2-8-5-异步-io-模型" class="header-anchor">#</a> 2.8.5. 异步 IO 模型</h4> <p>异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就
可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，
它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内
核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程
发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要实际的整个IO操作是如何
进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接
去使用数据了。</p> <p>也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完
成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的
读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据
已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号
表示IO操作已经完成，不需要再在用户线程中调用IO函数进行实际的读写操作。</p> <p>注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。</p> <p>更多参考： <a href="http://www.importnew.com/19816.html" target="_blank" rel="noopener noreferrer">http://www.importnew.com/19816.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h4 id="_2-8-1-java-io-包"><a href="#_2-8-1-java-io-包" class="header-anchor">#</a> 2.8.1. JAVA IO 包</h4> <h4 id="_2-8-2-java-nio"><a href="#_2-8-2-java-nio" class="header-anchor">#</a> 2.8.2. JAVA NIO</h4> <p>NIO主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。传统IO基于字节流和字
符流进行操作，而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区
中，或者从缓冲区写入到通道中。Selector(选择区)用于监听多个通道的事件（比如：连接打开，
数据到达）。因此，单个线程可以监听多个数据通道。</p> <p>NIO和传统IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。</p> <h5 id="_2-8-2-1-nio的缓冲区"><a href="#_2-8-2-1-nio的缓冲区" class="header-anchor">#</a> 2.8.2.1. NIO的缓冲区</h5> <p>Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何
地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓
存到一个缓冲区。NIO的缓冲导向方法不同。数据读取到一个它稍后处理的缓冲区，需要时可在
缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所
有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的
数据。</p> <h5 id="_2-8-2-2-nio的非阻塞"><a href="#_2-8-2-2-nio的非阻塞" class="header-anchor">#</a> 2.8.2.2. NIO的非阻塞</h5> <p>IO的各种流是阻塞的。这意味着，当一个线程调用read() 或 write()时，该线程被阻塞，直到有
一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。 NIO的非阻塞模式，
使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可
用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以
继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它
完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上
执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。</p> <h4 id="_2-8-3-channel"><a href="#_2-8-3-channel" class="header-anchor">#</a> 2.8.3. Channel</h4> <p>首先说一下Channel，国内大多翻译成“通道”。Channel和IO中的Stream(流)是差不多一个
等级的。只不过Stream是单向的，譬如：InputStream, OutputStream，而Channel是双向
的，既可以用来进行读操作，又可以用来进行写操作。
NIO中的Channel的主要实现有：</p> <ol><li>FileChannel</li> <li>DatagramChannel</li> <li>SocketChannel</li> <li>ServerSocketChannel
这里看名字就可以猜出个所以然来：分别可以对应文件IO、UDP和TCP（Server和Client）。
下面演示的案例基本上就是围绕这 4 个类型的Channel进行陈述的。</li></ol> <h4 id="_2-8-4-buffer"><a href="#_2-8-4-buffer" class="header-anchor">#</a> 2.8.4. Buffer</h4> <p>Buffer，故名思意，缓冲区，实际上是一个容器，是一个连续数组。Channel提供从文件、
网络读取数据的渠道，但是读取或写入的数据都必须经由Buffer。</p> <p>上面的图描述了从一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送
数据时，必须先将数据存入Buffer中，然后将Buffer中的内容写入通道。服务端这边接收数据必
须通过Channel将数据读入到Buffer中，然后再从Buffer中取出数据来处理。</p> <p>在NIO中，Buffer是一个顶层父类，它是一个抽象类，常用的Buffer的子类有：
ByteBuffer、IntBuffer、 CharBuffer、 LongBuffer、 DoubleBuffer、FloatBuffer、
ShortBuffer</p> <h4 id="_2-8-5-selector"><a href="#_2-8-5-selector" class="header-anchor">#</a> 2.8.5. Selector</h4> <p>Selector类是NIO的核心类，Selector能够检测多个注册的通道上是否有事件发生，如果有事
件发生，便获取事件然后针对每个事件进行相应的响应处理。这样一来，只是用一个单线程就可
以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用
函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护
多个线程，并且避免了多线程之间的上下文切换导致的开销。</p> <h3 id="_2-9-jvm-类加载机制"><a href="#_2-9-jvm-类加载机制" class="header-anchor">#</a> 2.9. JVM 类加载机制</h3> <p>JVM类加载机制分为五个部分：加载，验证，准备，解析，初始化，下面我们就分别来看一下这
五个过程。</p> <h5 id="_2-9-1-1-加载"><a href="#_2-9-1-1-加载" class="header-anchor">#</a> 2.9.1.1. 加载</h5> <p>加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对
象，作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个Class文件获取，这里既
可以从ZIP包中读取（比如从jar包和war包中读取），也可以在运行时计算生成（动态代理），
也可以由其它文件生成（比如将JSP文件转换成对应的Class类）。</p> <h5 id="_2-9-1-2-验证"><a href="#_2-9-1-2-验证" class="header-anchor">#</a> 2.9.1.2. 验证</h5> <p>这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并
且不会危害虚拟机自身的安全。</p> <h5 id="_2-9-1-3-准备"><a href="#_2-9-1-3-准备" class="header-anchor">#</a> 2.9.1.3. 准备</h5> <p>准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使
用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为：</p> <p>public static int v = 8080;
实际上变量v在准备阶段过后的初始值为 0 而不是 8080 ，将v赋值为 8080 的put static指令是
程序被编译后，存放于类构造器&lt;client&gt;方法之中。
但是注意如果声明为：</p> <p>public static final int v = 8080;
在编译阶段会为v生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将v
赋值为 8080 。</p> <h5 id="_2-9-1-4-解析"><a href="#_2-9-1-4-解析" class="header-anchor">#</a> 2.9.1.4. 解析</h5> <p>解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是class文件中
的：</p> <ol><li>CONSTANT_Class_info</li> <li>CONSTANT_Field_info</li> <li>CONSTANT_Method_info
等类型的常量。</li></ol> <h5 id="_2-9-1-5-符号引用"><a href="#_2-9-1-5-符号引用" class="header-anchor">#</a> 2.9.1.5. 符号引用</h5> <div class="language- extra-class"><pre class="language-text"><code> 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟
机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引
用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。
</code></pre></div><h5 id="_2-9-1-6-直接引用"><a href="#_2-9-1-6-直接引用" class="header-anchor">#</a> 2.9.1.6. 直接引用</h5> <div class="language- extra-class"><pre class="language-text"><code> 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有
了直接引用，那引用的目标必定已经在内存中存在。
</code></pre></div><h5 id="_2-9-1-7-初始化"><a href="#_2-9-1-7-初始化" class="header-anchor">#</a> 2.9.1.7. 初始化</h5> <p>初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载
器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。</p> <h5 id="_2-9-1-8-类构造器-client"><a href="#_2-9-1-8-类构造器-client" class="header-anchor">#</a> 2.9.1.8. 类构造器&lt;client&gt;</h5> <p>初始化阶段是执行类构造器&lt;client&gt;方法的过程。&lt;client&gt;方法是由编译器自动收集类中的类变
量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证子&lt;client&gt;方法执行之前，父类
的&lt;client&gt;方法已经执行完毕，如果一个类中没有对静态变量赋值也没有静态语句块，那么编译
器可以不为这个类生成&lt;client&gt;()方法。</p> <p>注意以下几种情况不会执行类初始化：</p> <ol><li>通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。</li> <li>定义对象数组，不会触发该类的初始化。</li> <li>常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触
发定义常量所在的类。</li> <li>通过类名获取Class对象，不会触发类的初始化。</li> <li>通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初
始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。</li> <li>通过ClassLoader默认的loadClass方法，也不会触发初始化动作。</li></ol> <h4 id="_2-9-2-类加载器"><a href="#_2-9-2-类加载器" class="header-anchor">#</a> 2.9.2. 类加载器</h4> <p>虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提
供了 3 种类加载器：</p> <h5 id="_2-9-2-1-启动类加载器-bootstrap-classloader"><a href="#_2-9-2-1-启动类加载器-bootstrap-classloader" class="header-anchor">#</a> 2.9.2.1. 启动类加载器(Bootstrap ClassLoader)</h5> <ol><li>负责加载 JAVA_HOME\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被
虚拟机认可（按文件名识别，如rt.jar）的类。</li></ol> <h5 id="_2-9-2-2-扩展类加载器-extension-classloader"><a href="#_2-9-2-2-扩展类加载器-extension-classloader" class="header-anchor">#</a> 2.9.2.2. 扩展类加载器(Extension ClassLoader)</h5> <ol start="2"><li>负责加载 JAVA_HOME\lib\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类
库。</li></ol> <h5 id="_2-9-2-3-应用程序类加载器-application-classloader"><a href="#_2-9-2-3-应用程序类加载器-application-classloader" class="header-anchor">#</a> 2.9.2.3. 应用程序类加载器(Application ClassLoader)：</h5> <ol start="3"><li>负责加载用户路径（classpath）上的类库。
JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承java.lang.ClassLoader
实现自定义的类加载器。</li></ol> <h4 id="_2-9-3-双亲委派"><a href="#_2-9-3-双亲委派" class="header-anchor">#</a> 2.9.3. 双亲委派</h4> <p>当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父
类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，
只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的
Class），子类加载器才会尝试自己去加载。</p> <p>采用双亲委派的一个好处是比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载
器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载
器最终得到的都是同样一个Object对象。</p> <h4 id="_2-9-4-osgi-动态模型系统"><a href="#_2-9-4-osgi-动态模型系统" class="header-anchor">#</a> 2.9.4. OSGI （动态模型系统）</h4> <p>OSGi(Open Service Gateway Initiative)，是面向Java的动态模型系统，是Java动态化模块化系</p> <p>统的一系列规范。</p> <h5 id="_2-9-4-1-动态改变构造"><a href="#_2-9-4-1-动态改变构造" class="header-anchor">#</a> 2.9.4.1. 动态改变构造</h5> <p>OSGi 服务平台提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使</p> <p>这些耦合度可管理，OSGi技术提供一种面向服务的架构，它能使这些组件动态地发现对方。</p> <h5 id="_2-9-4-2-模块化编程与热插拔"><a href="#_2-9-4-2-模块化编程与热插拔" class="header-anchor">#</a> 2.9.4.2. 模块化编程与热插拔</h5> <p>OSGi旨在为实现Java程序的模块化编程提供基础条件，基于OSGi的程序很可能可以实现模块级</p> <p>的热插拔功能，当程序升级更新时，可以只停用、重新安装然后启动程序的其中一部分，这对企
业级程序开发来说是非常具有诱惑力的特性。</p> <p>OSGi 描绘了一个很美好的模块化开发目标，而且定义了实现这个目标的所需要服务与架构，同时
也有成熟的框架进行实现支持。但并非所有的应用都适合采用OSGi作为基础架构，它在提供强大</p> <p>功能同时，也引入了额外的复杂度，因为它不遵守了类加载的双亲委托模型。</p> <h2 id="_3-java-集合"><a href="#_3-java-集合" class="header-anchor">#</a> 3. JAVA 集合</h2> <h3 id="_3-1-接口继承关系和实现"><a href="#_3-1-接口继承关系和实现" class="header-anchor">#</a> 3.1. 接口继承关系和实现</h3> <p>集合类存放于Java.util包中，主要有 3 种：set(集）、list(列表包含Queue）和map(映射)。</p> <ol><li>Collection：Collection是集合List、Set、Queue的最基本的接口。</li> <li>Iterator：迭代器，可以通过迭代器遍历集合中的数据</li> <li>Map：是映射表的基础接口</li></ol> <h3 id="_3-2-list"><a href="#_3-2-list" class="header-anchor">#</a> 3.2. LIST</h3> <div class="language- extra-class"><pre class="language-text"><code>Java的List是非常常用的数据类型。List是有序的Collection。Java List一共三个实现类：
分别是ArrayList、Vector和LinkedList。
</code></pre></div><h4 id="_3-2-1-arraylist-数组"><a href="#_3-2-1-arraylist-数组" class="header-anchor">#</a> 3.2.1. ArrayList （数组）</h4> <p>ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数
组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要将已经有数
组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进
行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。</p> <h4 id="_3-2-2-vector-数组实现、线程同步"><a href="#_3-2-2-vector-数组实现、线程同步" class="header-anchor">#</a> 3.2.2. Vector （数组实现、线程同步）</h4> <p>Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一
个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，
访问它比访问ArrayList慢。</p> <h4 id="_3-2-3-linklist-链表"><a href="#_3-2-3-linklist-链表" class="header-anchor">#</a> 3.2.3. LinkList （链表）</h4> <p>LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较
慢。另外，他还提供了List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆
栈、队列和双向队列使用。</p> <h3 id="_3-3-set"><a href="#_3-3-set" class="header-anchor">#</a> 3.3. SET</h3> <p>Set注重独一无二的性质,该体系集合用于存储无序(存入和取出的顺序不一定相同)元素，值不能重
复。对象的相等性本质是对象hashCode值（java是依据对象的内存地址计算出的此序号）判断
的，如果想要让两个不同的对象视为相等的，就必须覆盖Object的hashCode方法和equals方
法。</p> <h5 id="_3-3-1-1-hashset-hash表"><a href="#_3-3-1-1-hashset-hash表" class="header-anchor">#</a> 3.3.1.1. HashSet（Hash表）</h5> <p>哈希表边存放的是哈希值。HashSet存储元素的顺序并不是按照存入时的顺序（和List显然不
同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的
hashcode方法来获取的, HashSet首先判断两个元素的哈希值，如果哈希值一样，接着会比较
equals方法 如果 equls结果为true ，HashSet就视为同一个元素。如果equals 为false就不是
同一个元素。</p> <p>哈希值相同equals为false的元素是怎么存储呢,就是在同样的哈希值下顺延（可以认为哈希值相
同的元素放在一个哈希桶中）。也就是哈希一样的存一列。如图 1 表示hashCode值不相同的情
况；图 2 表示hashCode值相同，但equals不相同的情况。</p> <p>HashSet通过hashCode值来确定元素在内存中的位置。一个hashCode位置上可以存放多个元
素。</p> <h5 id="_3-3-1-2-treeset-二叉树"><a href="#_3-3-1-2-treeset-二叉树" class="header-anchor">#</a> 3.3.1.2. TreeSet（二叉树）</h5> <ol><li>TreeSet()是使用二叉树的原理对新add()的对象按照指定的顺序排序（升序、降序），每增
加一个对象都会进行排序，将对象插入的二叉树指定的位置。</li> <li>Integer和String对象都可以进行默认的TreeSet排序，而自定义类的对象是不可以的，自
己定义的类必须实现Comparable接口，并且覆写相应的compareTo()函数，才可以正常使
用。</li> <li>在覆写compare()函数时，要返回相应的值才能使TreeSet按照一定的规则来排序</li> <li>比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整
数、零或正整数。</li></ol> <h5 id="_3-3-1-3-linkhashset-hashset-linkedhashmap"><a href="#_3-3-1-3-linkhashset-hashset-linkedhashmap" class="header-anchor">#</a> 3.3.1.3. LinkHashSet（HashSet+LinkedHashMap）</h5> <p>对于 LinkedHashSet 而言，它继承与HashSet、又基于LinkedHashMap 来实现的。
LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法
操作上又与HashSet相同，因此LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并
通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap来实现，在相关操
作上与父类HashSet的操作相同，直接调用父类HashSet的方法即可。</p> <h3 id="_3-4-map"><a href="#_3-4-map" class="header-anchor">#</a> 3.4. MAP</h3> <h4 id="_3-4-1-hashmap-数组-链表-红黑树"><a href="#_3-4-1-hashmap-数组-链表-红黑树" class="header-anchor">#</a> 3.4.1. HashMap （数组 + 链表 + 红黑树）</h4> <p>HashMap根据键的hashCode值存储数据，大多数情况下可以直接定位到它的值，因而具有很快
的访问速度，但遍历顺序却是不确定的。 HashMap最多只允许一条记录的键为null，允许多条记
录的值为null。HashMap非线程安全，即任一时刻可以有多个线程同时写HashMap，可能会导
致数据的不一致。如果需要满足线程安全，可以用 Collections 的synchronizedMap 方法使
HashMap 具有线程安全的能力，或者使用ConcurrentHashMap。我们用下面这张图来介绍
HashMap 的结构。</p> <h5 id="_3-4-1-1-java7实现"><a href="#_3-4-1-1-java7实现" class="header-anchor">#</a> 3.4.1.1. JAVA7实现</h5> <p>大方向上，HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色
的实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。</p> <ol><li><p>capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。</p></li> <li><p>loadFactor：负载因子，默认为 0.75。</p></li> <li><p>threshold：扩容的阈值，等于 capacity * loadFactor</p></li></ol> <h5 id="_3-4-1-2-java8实现"><a href="#_3-4-1-2-java8实现" class="header-anchor">#</a> 3.4.1.2. JAVA8实现</h5> <p>Java8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑
树 组成。</p> <p>根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的
具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决
于链表的长度，为 O(n)。为了降低这部分的开销，在 Java8 中，当链表中的元素超过了 8 个以后，
会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。</p> <h4 id="_3-4-2-concurrenthashmap"><a href="#_3-4-2-concurrenthashmap" class="header-anchor">#</a> 3.4.2. ConcurrentHashMap..................................................................................................................</h4> <h5 id="_3-4-2-1-segment段"><a href="#_3-4-2-1-segment段" class="header-anchor">#</a> 3.4.2.1. Segment段</h5> <p>ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一
些。整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的
意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个
segment。</p> <h5 id="_3-4-2-2-线程安全-segment-继承-reentrantlock-加锁"><a href="#_3-4-2-2-线程安全-segment-继承-reentrantlock-加锁" class="header-anchor">#</a> 3.4.2.2. 线程安全（Segment 继承 ReentrantLock 加锁）</h5> <p>简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承
ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每
个 Segment 是线程安全的，也就实现了全局的线程安全。</p> <h5 id="_3-4-2-3-并行度-默认-16"><a href="#_3-4-2-3-并行度-默认-16" class="header-anchor">#</a> 3.4.2.3. 并行度（默认 16 ）</h5> <p>concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16 ，
也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支
持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时
候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实
每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。</p> <h5 id="_3-4-2-4-java8实现-引入了红黑树"><a href="#_3-4-2-4-java8实现-引入了红黑树" class="header-anchor">#</a> 3.4.2.4. Java8实现 （引入了红黑树）</h5> <p>Java8 对 ConcurrentHashMap 进行了比较大的改动,Java8 也引入了红黑树。</p> <h3 id="_3-4-3-hashtable-线程安全"><a href="#_3-4-3-hashtable-线程安全" class="header-anchor">#</a> 3.4.3. HashTable （线程安全）</h3> <p>Hashtable是遗留类，很多映射的常用功能与HashMap类似，不同的是它承自Dictionary类，
并且是线程安全的，任一时间只有一个线程能写 Hashtable，并发性不如 ConcurrentHashMap，
因为ConcurrentHashMap引入了分段锁。Hashtable不建议在新代码中使用，不需要线程安全
的场合可以用HashMap替换，需要线程安全的场合可以用ConcurrentHashMap替换。</p> <h3 id="_3-4-4-treemap-可排序"><a href="#_3-4-4-treemap-可排序" class="header-anchor">#</a> 3.4.4. TreeMap （可排序）</h3> <p>TreeMap实现SortedMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，
也可以指定排序的比较器，当用Iterator遍历TreeMap时，得到的记录是排过序的。</p> <p>如果使用排序的映射，建议使用TreeMap。</p> <p>在使用TreeMap时，key必须实现Comparable 接口或者在构造 TreeMap传入自定义的
Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。</p> <p>参考：https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html</p> <h3 id="_3-4-5-linkhashmap-记录插入顺序"><a href="#_3-4-5-linkhashmap-记录插入顺序" class="header-anchor">#</a> 3.4.5. LinkHashMap （记录插入顺序）</h3> <p>LinkedHashMap 是HashMap 的一个子类，保存了记录的插入顺序，在用Iterator 遍历
LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。
参考 1 ：http://www.importnew.com/28263.html</p> <p>参考 2 ：http://www.importnew.com/20386.html#comment- 648123</p> <h2 id="_4-java-多线程并发"><a href="#_4-java-多线程并发" class="header-anchor">#</a> 4. JAVA 多线程并发</h2> <h3 id="_4-1-1-java-并发知识库"><a href="#_4-1-1-java-并发知识库" class="header-anchor">#</a> 4.1.1. JAVA 并发知识库</h3> <h3 id="_4-1-2-java-线程实现-创建方式"><a href="#_4-1-2-java-线程实现-创建方式" class="header-anchor">#</a> 4.1.2. JAVA 线程实现 / 创建方式</h3> <h4 id="_4-1-2-1-继承thread类"><a href="#_4-1-2-1-继承thread类" class="header-anchor">#</a> 4.1.2.1. 继承Thread类</h4> <p>Thread类本质上是实现了Runnable接口的一个实例，代表一个线程的实例。启动线程的唯一方
法就是通过Thread类的start()实例方法。start()方法是一个native方法，它将启动一个新线
程，并执行run()方法。
public class MyThread extends Thread {
public void run() {
System.out.println(&quot;MyThread.run()&quot;);
}
}
MyThread myThread1 = new MyThread();
myThread1.start();</p> <h4 id="_4-1-2-2-实现runnable接口。"><a href="#_4-1-2-2-实现runnable接口。" class="header-anchor">#</a> 4.1.2.2. 实现Runnable接口。</h4> <p>如果自己的类已经extends另一个类，就无法直接extends Thread，此时，可以实现一个
Runnable接口。
public class MyThread extends OtherClass implements Runnable {
public void run() {
System.out.println(&quot;MyThread.run()&quot;);
}
}</p> <div class="language- extra-class"><pre class="language-text"><code>//启动MyThread，需要首先实例化一个Thread，并传入自己的MyThread实例：
MyThread myThread = new MyThread();
Thread thread = new Thread(myThread);
thread.start();
//事实上，当传入一个Runnable target参数给Thread后，Thread的run()方法就会调用
target.run()
public void run() {
if (target != null) {
target.run();
}
}
</code></pre></div><h4 id="_4-1-2-3-executorservice、callable-class-、future有返回值线程"><a href="#_4-1-2-3-executorservice、callable-class-、future有返回值线程" class="header-anchor">#</a> 4.1.2.3. ExecutorService、Callable&lt;Class&gt;、Future有返回值线程</h4> <p>有返回值的任务必须实现Callable接口，类似的，无返回值的任务必须Runnable接口。执行
Callable任务后，可以获取一个Future的对象，在该对象上调用get就可以获取到Callable任务
返回的Object了，再结合线程池接口ExecutorService就可以实现传说中有返回结果的多线程
了。</p> <div class="language- extra-class"><pre class="language-text"><code>//创建一个线程池
ExecutorService pool = Executors.newFixedThreadPool(taskSize);
// 创建多个有返回值的任务
List\&lt;Future\&gt; list = new ArrayList\&lt;Future\&gt;();
for (int i = 0; i \&lt; taskSize; i++) {
Callable c = new MyCallable(i + &quot; &quot;);
// 执行任务并获取Future对象
Future f = pool.submit(c);
list.add(f);
}
// 关闭线程池
pool.shutdown();
// 获取所有并发任务的运行结果
for (Future f : list) {
// 从Future对象上获取任务的返回值，并输出到控制台
System.out.println(&quot;res：&quot; + f.get().toString());
}
</code></pre></div><h4 id="_4-1-2-4-基于线程池的方式"><a href="#_4-1-2-4-基于线程池的方式" class="header-anchor">#</a> 4.1.2.4. 基于线程池的方式</h4> <p>线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建，不需要的时候销
毁，是非常浪费资源的。那么我们就可以使用缓存的策略，也就是使用线程池。
// 创建线程池
ExecutorService threadPool = Executors.newFixedThreadPool( 10 );
while(true) {
threadPool.execute(new Runnable() { // 提交多个线程任务，并执行
@Override
public void run() {
System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;);
try {
Thread.sleep( 3000 );
} catch (InterruptedException e) {
e.printStackTrace();
}
}
});
}
}</p> <h3 id="_4-1-3-4-种线程池"><a href="#_4-1-3-4-种线程池" class="header-anchor">#</a> 4.1.3. 4 种线程池</h3> <p>Java里面线程池的顶级接口是 <strong>Executor</strong> ，但是严格意义上讲Executor并不是一个线程池，而
只是一个执行线程的工具。真正的线程池接口是 <strong>ExecutorService</strong> 。</p> <h4 id="_4-1-3-1-newcachedthreadpool"><a href="#_4-1-3-1-newcachedthreadpool" class="header-anchor">#</a> 4.1.3.1. newCachedThreadPool</h4> <p>创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行
很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用 execute 将重用以前构造
的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并
从缓存中移除那些已有 60 秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资
源。</p> <h4 id="_4-1-3-2-newfixedthreadpool"><a href="#_4-1-3-2-newfixedthreadpool" class="header-anchor">#</a> 4.1.3.2. newFixedThreadPool</h4> <p>创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大
多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，
则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何
线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之
前，池中的线程将一直存在。</p> <h4 id="_4-1-3-3-newscheduledthreadpool"><a href="#_4-1-3-3-newscheduledthreadpool" class="header-anchor">#</a> 4.1.3.3. newScheduledThreadPool</h4> <p>创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。</p> <div class="language- extra-class"><pre class="language-text"><code>ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool( 3 );
scheduledThreadPool.schedule(newRunnable(){
@Override
public void run() {
System.out.println(&quot;延迟三秒&quot;);
}
}, 3, TimeUnit.SECONDS);
scheduledThreadPool.scheduleAtFixedRate(newRunnable(){
@Override
public void run() {
System.out.println(&quot;延迟 1 秒后每三秒执行一次&quot;);
}
},1,3,TimeUnit.SECONDS);
</code></pre></div><h4 id="_4-1-3-4-newsinglethreadexecutor"><a href="#_4-1-3-4-newsinglethreadexecutor" class="header-anchor">#</a> 4.1.3.4. newSingleThreadExecutor</h4> <p>Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程
池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去！</p> <h3 id="_4-1-4-线程生命周期-状态"><a href="#_4-1-4-线程生命周期-状态" class="header-anchor">#</a> 4.1.4. 线程生命周期 ( 状态 )</h3> <div class="language- extra-class"><pre class="language-text"><code>当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。
在线程的生命周期中，它要经过新建(New)、就绪（Runnable）、运行（Running）、阻塞
(Blocked)和死亡(Dead)5种状态。尤其是当线程启动以后，它不可能一直&quot;霸占&quot;着CPU独自
运行，所以CPU需要在多条线程之间切换，于是线程状态也会多次在运行、阻塞之间切换
</code></pre></div><h4 id="_4-1-4-1-新建状态-new"><a href="#_4-1-4-1-新建状态-new" class="header-anchor">#</a> 4.1.4.1. 新建状态（NEW）</h4> <p>当程序使用new关键字创建了一个线程之后，该线程就处于新建状态，此时仅由JVM为其分配
内存，并初始化其成员变量的值</p> <h4 id="_4-1-4-2-就绪状态-runnable"><a href="#_4-1-4-2-就绪状态-runnable" class="header-anchor">#</a> 4.1.4.2. 就绪状态（RUNNABLE）：</h4> <p>当线程对象调用了start()方法之后，该线程处于就绪状态。Java虚拟机会为其创建方法调用栈和
程序计数器，等待调度运行。</p> <h4 id="_4-1-4-3-运行状态-running"><a href="#_4-1-4-3-运行状态-running" class="header-anchor">#</a> 4.1.4.3. 运行状态（RUNNING）：</h4> <p>如果处于就绪状态的线程获得了CPU，开始执行run()方法的线程执行体，则该线程处于运行状
态。</p> <h4 id="_4-1-4-4-阻塞状态-blocked"><a href="#_4-1-4-4-阻塞状态-blocked" class="header-anchor">#</a> 4.1.4.4. 阻塞状态（BLOCKED）：</h4> <p>阻塞状态是指线程因为某种原因放弃了cpu 使用权，也即让出了cpu timeslice，暂时停止运行。
直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状
态。阻塞的情况分三种：</p> <h5 id="等待阻塞-o-wait-等待对列"><a href="#等待阻塞-o-wait-等待对列" class="header-anchor">#</a> 等待阻塞（o.wait-&gt;等待对列）：</h5> <div class="language- extra-class"><pre class="language-text"><code>运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)
中。
</code></pre></div><h5 id="同步阻塞-lock-锁池"><a href="#同步阻塞-lock-锁池" class="header-anchor">#</a> 同步阻塞(lock-&gt;锁池)</h5> <div class="language- extra-class"><pre class="language-text"><code>运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线
程放入锁池(lock pool)中。
</code></pre></div><h5 id="其他阻塞-sleep-join"><a href="#其他阻塞-sleep-join" class="header-anchor">#</a> 其他阻塞(sleep/join)</h5> <div class="language- extra-class"><pre class="language-text"><code>运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，
JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O
处理完毕时，线程重新转入可运行(runnable)状态。
</code></pre></div><h4 id="_4-1-4-5-线程死亡-dead"><a href="#_4-1-4-5-线程死亡-dead" class="header-anchor">#</a> 4.1.4.5. 线程死亡（DEAD）</h4> <p>线程会以下面三种方式结束，结束后就是死亡状态。</p> <h5 id="正常结束"><a href="#正常结束" class="header-anchor">#</a> 正常结束</h5> <ol><li>run()或call()方法执行完成，线程正常结束。</li></ol> <h5 id="异常结束"><a href="#异常结束" class="header-anchor">#</a> 异常结束</h5> <ol start="2"><li>线程抛出一个未捕获的Exception或Error。</li></ol> <h5 id="调用stop"><a href="#调用stop" class="header-anchor">#</a> 调用stop</h5> <ol start="3"><li>直接调用该线程的stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。</li></ol> <h3 id="_4-1-5-终止线程-4-种方式"><a href="#_4-1-5-终止线程-4-种方式" class="header-anchor">#</a> 4.1.5. 终止线程 4 种方式</h3> <h4 id="_4-1-5-1-正常运行结束"><a href="#_4-1-5-1-正常运行结束" class="header-anchor">#</a> 4.1.5.1. 正常运行结束</h4> <p>程序运行结束，线程自动结束。</p> <h4 id="_4-1-5-2-使用退出标志退出线程"><a href="#_4-1-5-2-使用退出标志退出线程" class="header-anchor">#</a> 4.1.5.2. 使用退出标志退出线程</h4> <p>一般run()方法执行完，线程就会正常结束，然而，常常有些线程是伺服线程。它们需要长时间的
运行，只有在外部某些条件满足的情况下，才能关闭这些线程。使用一个变量来控制循环，例如：
最直接的方法就是设一个boolean类型的标志，并通过设置这个标志为true或false来控制while
循环是否退出，代码示例：</p> <div class="language- extra-class"><pre class="language-text"><code>public class ThreadSafe extends Thread {
public volatile boolean exit = false;
public void run() {
while (!exit){
//do something
}
}
}
</code></pre></div><p>定义了一个退出标志exit，当exit为true时，while循环退出，exit的默认值为false.在定义exit
时，使用了一个Java关键字volatile，这个关键字的目的是使exit同步，也就是说在同一时刻只
能由一个线程来修改exit的值。</p> <h4 id="_4-1-5-3-interrupt方法结束线程"><a href="#_4-1-5-3-interrupt方法结束线程" class="header-anchor">#</a> 4.1.5.3. Interrupt方法结束线程</h4> <div class="language- extra-class"><pre class="language-text"><code>使用interrupt()方法来中断线程有两种情况：
</code></pre></div><ol><li>线程处于阻塞状态：如使用了sleep,同步锁的wait,socket中的receiver,accept等方法时，
会使线程处于阻塞状态。当调用线程的interrupt()方法时，会抛出InterruptException异常。
阻塞中的那个方法抛出这个异常，通过代码捕获该异常，然后break 跳出循环状态，从而让
我们有机会结束这个线程的执行。通常很多人认为只要调用interrupt方法线程就会结束，实
际上是错的， 一定要先捕获InterruptedException异常之后通过break来跳出循环，才能正
常结束run方法。</li> <li>线程未处于阻塞状态：使用isInterrupted()判断线程的中断标志来退出循环。当使用
interrupt()方法时，中断标志就会置true，和使用自定义的标志来控制循环是一样的道理。
public class ThreadSafe extends Thread {
public void run() {
while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出
try{
Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出
}catch(InterruptedException e){
e.printStackTrace();
break;//捕获到异常之后，执行break跳出循环
}
}
}
}</li></ol> <h4 id="_4-1-5-4-stop方法终止线程-线程不安全"><a href="#_4-1-5-4-stop方法终止线程-线程不安全" class="header-anchor">#</a> 4.1.5.4. stop方法终止线程（线程不安全）</h4> <p>程序中可以直接使用thread.stop()来强行终止线程，但是stop方法是很危险的，就象突然关
闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：
thread.stop()调用之后，创建子线程的线程就会抛出ThreadDeatherror的错误，并且会释放子
线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用
thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈
现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因
此，并不推荐使用stop方法来终止线程。</p> <h3 id="_4-1-6-sleep-与-wait-区别"><a href="#_4-1-6-sleep-与-wait-区别" class="header-anchor">#</a> 4.1.6. sleep 与 wait 区别</h3> <ol><li>对于sleep()方法，我们首先要知道该方法是属于Thread类中的。而wait()方法，则是属于</li></ol> <div class="language- extra-class"><pre class="language-text"><code>Object类中的。
</code></pre></div><ol start="2"><li>sleep()方法导致了程序暂停执行指定的时间，让出cpu该其他线程，但是他的监控状态依然</li></ol> <div class="language- extra-class"><pre class="language-text"><code>保持者，当指定的时间到了又会自动恢复运行状态。
</code></pre></div><ol start="3"><li>在调用sleep()方法的过程中，线程不会释放对象锁。</li> <li>而当调用wait()方法的时候，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此</li></ol> <div class="language- extra-class"><pre class="language-text"><code>对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。
</code></pre></div><h3 id="_4-1-7-start-与-run-区别"><a href="#_4-1-7-start-与-run-区别" class="header-anchor">#</a> 4.1.7. start 与 run 区别</h3> <ol><li><strong>start（）</strong> 方法来启动线程，真正实现了多线程运行。这时无需等待 run方法体代码执行完毕，
可以直接继续执行下面的代码。</li> <li>通过调用Thread类的start()方法来启动一个线程， 这时此线程是处于就绪状态， 并没有运
行。</li> <li>方法run()称为线程体，它包含了要执行的这个线程的内容，线程就进入了运行状态，开始运
行run函数当中的代码。 Run方法运行结束， 此线程终止。然后CPU再调度其它线程。</li></ol> <h3 id="_4-1-8-java-后台线程"><a href="#_4-1-8-java-后台线程" class="header-anchor">#</a> 4.1.8. JAVA 后台线程</h3> <ol><li>定义：守护线程--也称“服务线程”，他是后台线程，它有一个特性，即为用户线程 提供 公
共服务，在没有用户线程可服务时会自动离开。</li> <li>优先级：守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务。</li> <li>设置：通过setDaemon(true)来设置线程为“守护线程”；将一个用户线程设置为守护线程
的方式是在 线程对象创建 之前 用线程对象的setDaemon方法。</li> <li>在Daemon线程中产生的新线程也是Daemon的。</li> <li>线程则是JVM级别的，以Tomcat 为例，如果你在Web 应用中启动一个线程，这个线程的
生命周期并不会和Web应用程序保持同步。也就是说，即使你停止了Web应用，这个线程
依旧是活跃的。</li> <li>example: 垃圾回收线程就是一个经典的守护线程，当我们的程序中不再有任何运行的Thread,
程序就不会再产生垃圾，垃圾回收器也就无事可做，所以当垃圾回收线程是JVM上仅剩的线
程时，垃圾回收线程会自动离开。它始终在低级别的状态中运行，用于实时监控和管理系统
中的可回收资源。</li> <li>生命周期：守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周
期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端，但是依
赖于系统，与系统“同生共死”。当JVM中所有的线程都是守护线程的时候，JVM就可以退
出了；如果还有一个或以上的非守护线程则JVM不会退出。</li></ol> <h3 id="_4-1-9-java-锁"><a href="#_4-1-9-java-锁" class="header-anchor">#</a> 4.1.9. JAVA 锁</h3> <h4 id="_4-1-9-1-乐观锁"><a href="#_4-1-9-1-乐观锁" class="header-anchor">#</a> 4.1.9.1. 乐观锁</h4> <p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为
别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数
据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），
如果失败则要重复读-比较-写的操作。</p> <p>java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作，比较当前值跟传入
值是否一样，一样则更新，否则失败。</p> <h4 id="_4-1-9-2-悲观锁"><a href="#_4-1-9-2-悲观锁" class="header-anchor">#</a> 4.1.9.2. 悲观锁</h4> <p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人
会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。
java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，
才会转换为悲观锁，如RetreenLock。</p> <h4 id="_4-1-9-3-自旋锁"><a href="#_4-1-9-3-自旋锁" class="header-anchor">#</a> 4.1.9.3. 自旋锁</h4> <p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁
的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），
等持有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核的切换的消耗。</p> <p>线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程
也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。</p> <p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁
的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p> <h5 id="自旋锁的优缺点"><a href="#自旋锁的优缺点" class="header-anchor">#</a> 自旋锁的优缺点</h5> <p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来
说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会
导致线程发生两次上下文切换！</p> <p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合
使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，同时有大量
线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，
其它需要cup的线程又不能获取到cpu，造成cpu的浪费。所以这种情况下我们要关闭自旋锁；</p> <h5 id="自旋锁时间阈值-1-6引入了适应性自旋锁"><a href="#自旋锁时间阈值-1-6引入了适应性自旋锁" class="header-anchor">#</a> 自旋锁时间阈值（1.6引入了适应性自旋锁）</h5> <p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择
自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而
会影响整体系统的性能。因此自旋的周期选的额外重要！</p> <p>JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应
性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥
有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM 还针对当
前CPU的负荷情况做了较多的优化，如果平均负载小于CPUs则一直自旋，如果有超过(CPUs/2)
个线程正在自旋，则后来线程直接阻塞，如果正在自旋的线程发现Owner发生了变化则延迟自旋
时间（自旋计数）或进入阻塞，如果CPU处于节电模式则停止自旋，自旋时间的最坏情况是CPU
的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差），自旋时会适当放
弃线程优先级之间的差异。</p> <h5 id="自旋锁的开启"><a href="#自旋锁的开启" class="header-anchor">#</a> 自旋锁的开启</h5> <p>JDK1.6中-XX:+UseSpinning开启；</p> <ul><li>XX:PreBlockSpin=10 为自旋次数；</li></ul> <p>JDK1.7后，去掉此参数，由jvm控制；</p> <h4 id="_4-1-9-4-synchronized同步锁"><a href="#_4-1-9-4-synchronized同步锁" class="header-anchor">#</a> 4.1.9.4. Synchronized同步锁</h4> <p>synchronized它可以把任意一个非NULL的对象当作锁。他属于独占式的悲观锁，同时属于可重
入锁。</p> <h5 id="synchronized作用范围"><a href="#synchronized作用范围" class="header-anchor">#</a> Synchronized作用范围</h5> <ol><li>作用于方法时，锁住的是对象的实例(this)；</li> <li>当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen
（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，
会锁所有调用该方法的线程；</li> <li>synchronized 作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。它有多个队列，
当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。</li></ol> <h5 id="synchronized核心组件"><a href="#synchronized核心组件" class="header-anchor">#</a> Synchronized核心组件</h5> <div class="language- extra-class"><pre class="language-text"><code>1) Wait Set：哪些调用wait方法被阻塞的线程被放置在这里；
2) Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中；
3) Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中；
4) OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck；
5) Owner：当前已经获取到所资源的线程被称为Owner；
6) !Owner：当前释放锁的线程。
</code></pre></div><h5 id="synchronized实现"><a href="#synchronized实现" class="header-anchor">#</a> Synchronized实现</h5> <ol><li>JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，
ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将
一部分线程移动到EntryList中作为候选竞争线程。</li> <li>Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定
EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。</li> <li>Owner 线程并不直接把锁传递给OnDeck 线程，而是把锁竞争的权利交给OnDeck，
OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在
JVM中，也把这种选择行为称之为“竞争切换”。</li> <li>OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList
中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify
或者notifyAll唤醒，会重新进去EntryList中。</li> <li>处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统
来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。</li> <li>Synchronized是非公平锁。 Synchronized在线程进入ContentionList时，等待的线程会先
尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是
不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁
资源。
参考：https://blog.csdn.net/zqz_zqz/article/details/70233767</li> <li>每个对象都有个monitor对象，加锁就是在竞争monitor对象，代码块加锁是在前后分别加
上monitorenter和monitorexit指令来实现的，方法加锁是通过一个标记位来判断的</li> <li>synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线
程加锁消耗的时间比有用操作消耗的时间更多。</li> <li>Java1.6，synchronized进行了很多的优化，有适应自旋、锁消除、锁粗化、轻量级锁及偏向
锁等，效率有了本质上的提高。在之后推出的Java1.7与1.8中，均对该关键字的实现机理做
了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。</li> <li>锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀；</li> <li>JDK 1.6中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking来禁用偏向锁。</li></ol> <h4 id="_4-1-9-5-reentrantlock"><a href="#_4-1-9-5-reentrantlock" class="header-anchor">#</a> 4.1.9.5. ReentrantLock</h4> <p>ReentantLock继承接口Lock并实现了接口中定义的方法，他是一种可重入锁，除了能完
成synchronized所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等
避免多线程死锁的方法。</p> <h5 id="lock接口的主要方法"><a href="#lock接口的主要方法" class="header-anchor">#</a> Lock接口的主要方法</h5> <ol><li>void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁. 相反, 如果锁已经
被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁.</li> <li>boolean tryLock()：如果锁可用, 则获取锁, 并立即返回true, 否则返回false. 该方法和
lock()的区别在于, tryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程被禁用,
当前线程仍然继续往下执行代码. 而lock()方法则是一定要获取到锁, 如果锁不可用, 就一
直等待, 在未获得锁之前,当前线程并不继续向下执行.</li> <li>void unlock()：执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程
并不持有锁, 却执行该方法, 可能导致异常的发生.</li> <li>Condition newCondition()：条件对象，获取等待通知组件。该组件和当前的锁绑定，
当前线程只有获取了锁，才能调用该组件的await()方法，而调用后，当前线程将缩放锁。</li> <li>getHoldCount() ：查询当前线程保持此锁的次数，也就是执行此线程执行lock方法的次
数。</li> <li>getQueueLength（）：返回正等待获取此锁的线程估计数，比如启动 10 个线程， 1 个
线程获得锁，此时返回的是 9</li> <li>getWaitQueueLength：（Condition condition）返回等待与此锁相关的给定条件的线
程估计数。比如 10 个线程，用同一个condition对象，并且此时这 10 个线程都执行了
condition对象的await方法，那么此时执行此方法返回 10</li> <li>hasWaiters(Condition condition)：查询是否有线程等待与此锁有关的给定条件
(condition)，对于指定contidion对象，有多少线程执行了condition.await方法</li> <li>hasQueuedThread(Thread thread)：查询给定线程是否等待获取此锁</li> <li>hasQueuedThreads()：是否有线程等待此锁</li> <li>isFair()：该锁是否公平锁</li> <li>isHeldByCurrentThread()： 当前线程是否保持锁锁定，线程的执行lock方法的前后分
别是false和true</li> <li>isLock()：此锁是否有任意线程占用</li> <li>lockInterruptibly（）：如果当前线程未被中断，获取锁</li> <li>tryLock（）：尝试获得锁，仅在调用时锁未被线程占用，获得锁</li> <li>tryLock(long timeout TimeUnit unit)：如果锁在给定等待时间内没有被另一个线程保持，
则获取该锁。</li></ol> <h5 id="非公平锁"><a href="#非公平锁" class="header-anchor">#</a> 非公平锁</h5> <p>JVM按随机、就近原则分配锁的机制则称为不公平锁，ReentrantLock 在构造函数中提供了
是否公平锁的初始化方式，默认为非公平锁。非公平锁实际执行的效率要远远超出公平锁，除非
程序有特殊需要，否则最常用非公平锁的分配机制。</p> <h5 id="公平锁"><a href="#公平锁" class="header-anchor">#</a> 公平锁</h5> <div class="language- extra-class"><pre class="language-text"><code>公平锁指的是锁的分配机制是公平的，通常先对锁提出获取请求的线程会先被分配到锁，
ReentrantLock在构造函数中提供了是否公平锁的初始化方式来定义公平锁。
</code></pre></div><h5 id="reentrantlock-与synchronized"><a href="#reentrantlock-与synchronized" class="header-anchor">#</a> ReentrantLock 与synchronized</h5> <ol><li>ReentrantLock通过方法lock()与unlock()来进行加锁与解锁操作，与synchronized会
被JVM自动解锁机制不同，ReentrantLock加锁后需要手动进行解锁。为了避免程序出
现异常而无法正常解锁的情况，使用ReentrantLock必须在finally控制块中进行解锁操
作。</li> <li>ReentrantLock相比synchronized的优势是可中断、公平锁、多个锁。这种情况下需要
使用ReentrantLock。</li></ol> <h5 id="reentrantlock实现"><a href="#reentrantlock实现" class="header-anchor">#</a> ReentrantLock实现</h5> <div class="language- extra-class"><pre class="language-text"><code>public class MyService {
private Lock lock = new ReentrantLock();
//Lock lock=new ReentrantLock(true);//公平锁
//Lock lock=new ReentrantLock(false);//非公平锁
private Condition condition=lock.newCondition();//创建Condition
public void testMethod() {
try {
lock.lock();//lock加锁
//1：wait 方法等待：
//System.out.println(&quot;开始wait&quot;);
condition.await();
//通过创建Condition对象来使线程wait，必须先执行lock.lock方法获得锁
//:2：signal方法唤醒
condition.signal();//condition对象的signal方法可以唤醒wait线程
for (int i = 0; i \&lt; 5; i++) {
System.out.println(&quot;ThreadName=&quot; + Thread.currentThread().getName()+ (&quot; &quot; + (i + 1)));
}
} catch (InterruptedException e) {
e.printStackTrace();
}
finally
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>{
lock.unlock();
}
}
}
</code></pre></div><h5 id="condition类和object类锁方法区别区别"><a href="#condition类和object类锁方法区别区别" class="header-anchor">#</a> Condition类和Object类锁方法区别区别</h5> <ol><li>Condition类的awiat方法和Object类的wait方法等效</li> <li>Condition类的signal方法和Object类的notify方法等效</li> <li>Condition类的signalAll方法和Object类的notifyAll方法等效</li> <li>ReentrantLock类可以唤醒指定条件的线程，而object的唤醒是随机的</li></ol> <h5 id="trylock和lock和lockinterruptibly的区别"><a href="#trylock和lock和lockinterruptibly的区别" class="header-anchor">#</a> tryLock和lock和lockInterruptibly的区别</h5> <ol><li>tryLock能获得锁就返回true，不能就立即返回false，tryLock(long timeout,TimeUnit
unit)，可以增加时间限制，如果超过该时间段还没获得锁，返回false</li> <li>lock能获得锁就返回true，不能的话一直等待获得锁</li> <li>lock和lockInterruptibly，如果两个线程分别执行这两个方法，但此时中断这两个线程，
lock不会抛出异常，而lockInterruptibly会抛出异常。</li></ol> <h4 id="_4-1-9-6-semaphore信号量"><a href="#_4-1-9-6-semaphore信号量" class="header-anchor">#</a> 4.1.9.6. Semaphore信号量</h4> <p>Semaphore是一种基于计数的信号量。它可以设定一个阈值，基于此，多个线程竞争获取许可信
号，做完自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。Semaphore 可以用来
构建一些对象池，资源池之类的，比如数据库连接池</p> <h5 id="实现互斥锁-计数器为-1"><a href="#实现互斥锁-计数器为-1" class="header-anchor">#</a> 实现互斥锁（计数器为 1 ）</h5> <p>我们也可以创建计数为 1 的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，
表示两种互斥状态。</p> <h5 id="代码实现"><a href="#代码实现" class="header-anchor">#</a> 代码实现</h5> <p>它的用法如下：</p> <div class="language- extra-class"><pre class="language-text"><code>// 创建一个计数阈值为 5 的信号量对象
// 只能 5 个线程同时访问
Semaphore semp = new Semaphore(5);
try { // 申请许可
semp.acquire();
try {
// 业务逻辑
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>} catch (Exception e) {
} finally {
// 释放许可
semp.release();
}
} catch (InterruptedException e) {
}
</code></pre></div><h5 id="semaphore-与reentrantlock"><a href="#semaphore-与reentrantlock" class="header-anchor">#</a> Semaphore 与ReentrantLock</h5> <p>Semaphore基本能完成ReentrantLock 的所有工作，使用方法也与之类似，通过 acquire()与
release()方法来获得和释放临界资源。经实测，Semaphone.acquire()方法默认为可响应中断锁，
与ReentrantLock.lockInterruptibly()作用效果一致，也就是说在等待临界资源的过程中可以被
Thread.interrupt()方法中断。</p> <p>此外，Semaphore也实现了可轮询的锁请求与定时锁的功能，除了方法名tryAcquire与tryLock
不同，其使用方法与ReentrantLock几乎一致。Semaphore也提供了公平与非公平锁的机制，也
可在构造函数中进行设定。</p> <p>Semaphore的锁释放操作也由手动进行，因此与ReentrantLock一样，为避免线程因抛出异常而
无法正常释放锁的情况发生，释放锁的操作也必须在finally代码块中完成。</p> <h4 id="_4-1-9-7-atomicinteger"><a href="#_4-1-9-7-atomicinteger" class="header-anchor">#</a> 4.1.9.7. AtomicInteger</h4> <p>首先说明，此处 AtomicInteger，一个提供原子操作的 Integer 的类，常见的还有
AtomicBoolean、AtomicInteger、AtomicLong、AtomicReference等，他们的实现原理相同，
区别在与运算对象类型的不同。令人兴奋地，还可以通过AtomicReference&lt;V&gt;将一个对象的所
有操作转化成原子操作。</p> <p>我们知道，在多线程程序中，诸如++i 或 i++等运算不具有原子性，是不安全的线程操作之一。
通常我们会使用synchronized将该操作变成一个原子操作，但JVM为此类操作特意提供了一些
同步类，使得使用更方便，且使程序运行效率变得更高。通过相关资料显示，通常AtomicInteger
的性能是ReentantLock的好几倍。</p> <h3 id="_4-1-9-8-可重入锁-递归锁"><a href="#_4-1-9-8-可重入锁-递归锁" class="header-anchor">#</a> 4.1.9.8. 可重入锁（递归锁）</h3> <p>本文里面讲的是广义上的可重入锁，而不是单指JAVA下的ReentrantLock。可重入锁，也叫
做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受
影响。在JAVA环境下 ReentrantLock 和synchronized 都是 可重入锁。</p> <h3 id="_4-1-9-9-公平锁与非公平锁"><a href="#_4-1-9-9-公平锁与非公平锁" class="header-anchor">#</a> 4.1.9.9. 公平锁与非公平锁</h3> <h4 id="公平锁-fair"><a href="#公平锁-fair" class="header-anchor">#</a> 公平锁（Fair）</h4> <p>加锁前检查是否有排队等待的线程，优先排队等待的线程，先来先得</p> <h4 id="非公平锁-nonfair"><a href="#非公平锁-nonfair" class="header-anchor">#</a> 非公平锁（Nonfair）</h4> <p>加锁时不考虑排队等待问题，直接尝试获取锁，获取不到自动到队尾等待</p> <ol><li>非公平锁性能比公平锁高5~10倍，因为公平锁需要在多核的情况下维护一个队列</li> <li>Java中的synchronized是非公平锁，ReentrantLock 默认的lock()方法采用的是非公平锁。</li></ol> <h3 id="_4-1-9-10-readwritelock读写锁"><a href="#_4-1-9-10-readwritelock读写锁" class="header-anchor">#</a> 4.1.9.10. ReadWriteLock读写锁</h3> <p>为了提高性能，Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如
果没有写锁的情况下，读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写
锁，多个读锁不互斥，读锁与写锁互斥，这是由jvm自己控制的，你只要上好相应的锁即可。</p> <h4 id="读锁"><a href="#读锁" class="header-anchor">#</a> 读锁........................................................................................................................................................................</h4> <p>如果你的代码只读数据，可以很多人同时读，但不能同时写，那就上读锁</p> <h4 id="写锁"><a href="#写锁" class="header-anchor">#</a> 写锁........................................................................................................................................................................</h4> <p>如果你的代码修改数据，只能有一个人在写，且不能同时读取，那就上写锁。总之，读的时候上
读锁，写的时候上写锁！</p> <p>Java 中读写锁有个接口java.util.concurrent.locks.ReadWriteLock，也有具体的实现
ReentrantReadWriteLock。</p> <h3 id="_4-1-9-11-共享锁和独占锁"><a href="#_4-1-9-11-共享锁和独占锁" class="header-anchor">#</a> 4.1.9.11. 共享锁和独占锁</h3> <p>java并发包提供的加锁模式分为独占锁和共享锁。</p> <h4 id="独占锁"><a href="#独占锁" class="header-anchor">#</a> 独占锁</h4> <p>独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。
独占锁是一种悲观保守的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线
程都只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。</p> <h4 id="共享锁"><a href="#共享锁" class="header-anchor">#</a> 共享锁</h4> <p>共享锁则允许多个线程同时获取锁，并发访问 共享资源，如：ReadWriteLock。共享锁则是一种
乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。</p> <ol><li>AQS的内部类Node定义了两个常量SHARED和EXCLUSIVE，他们分别标识 AQS队列中等
待线程的锁获取模式。</li> <li>java的并发包中提供了ReadWriteLock，读-写锁。它允许一个资源可以被多个读操作访问，
或者被一个 写操作访问，但两者不能同时进行。</li></ol> <h3 id="_4-1-9-12-重量级锁-mutex-lock"><a href="#_4-1-9-12-重量级锁-mutex-lock" class="header-anchor">#</a> 4.1.9.12. 重量级锁（Mutex Lock）</h3> <p>Synchronized是通过对象内部的一个叫做监视器锁（monitor）来实现的。但是监视器锁本质又
是依赖于底层的操作系统的Mutex Lock来实现的。而操作系统实现线程之间的切换这就需要从用
户态转换到核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么
Synchronized效率低的原因。因此，这种依赖于操作系统Mutex Lock所实现的锁我们称之为
“重量级锁”。JDK中对Synchronized做的种种优化，其核心都是为了减少这种重量级锁的使用。
JDK1.6以后，为了减少获得锁和释放锁所带来的性能消耗，提高性能，引入了“轻量级锁”和
“偏向锁”。</p> <h3 id="_4-1-9-13-轻量级锁"><a href="#_4-1-9-13-轻量级锁" class="header-anchor">#</a> 4.1.9.13. 轻量级锁</h3> <p>锁的状态总共有四种：无锁状态、偏向锁、轻量级锁和重量级锁。</p> <h4 id="锁升级"><a href="#锁升级" class="header-anchor">#</a> 锁升级</h4> <p>随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁（但是锁的升级是单向的，
也就是说只能从低到高升级，不会出现锁的降级）。</p> <p>“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先需要强调一点的是，
轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减少传统的重量
级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前，先明白一点，轻量级锁所适应的场
景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量级锁膨胀
为重量级锁。</p> <h3 id="_4-1-9-14-偏向锁"><a href="#_4-1-9-14-偏向锁" class="header-anchor">#</a> 4.1.9.14. 偏向锁</h3> <p>Hotspot的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争，而且总是由同一线
程多次获得。偏向锁的目的是在某个线程获得锁之后，消除这个线程锁重入（CAS）的开销，看起
来让这个线程得到了偏护。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级
锁执行路径，因为轻量级锁的获取及释放依赖多次CAS 原子指令，而偏向锁只需要在置换
ThreadID的时候依赖一次CAS原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所
以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS 原子指令的性能消耗）。上面说过，轻
量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进
一步提高性能。</p> <h3 id="_4-1-9-15-分段锁"><a href="#_4-1-9-15-分段锁" class="header-anchor">#</a> 4.1.9.15. 分段锁</h3> <p>分段锁也并非一种实际的锁，而是一种思想ConcurrentHashMap是学习分段锁的最好实践</p> <h3 id="_4-1-9-16-锁优化"><a href="#_4-1-9-16-锁优化" class="header-anchor">#</a> 4.1.9.16. 锁优化</h3> <h4 id="减少锁持有时间"><a href="#减少锁持有时间" class="header-anchor">#</a> 减少锁持有时间</h4> <div class="language- extra-class"><pre class="language-text"><code>只用在有线程安全要求的程序上加锁
</code></pre></div><h4 id="减小锁粒度"><a href="#减小锁粒度" class="header-anchor">#</a> 减小锁粒度</h4> <div class="language- extra-class"><pre class="language-text"><code>将大对象（这个对象可能会被很多线程访问），拆成小对象，大大增加并行度，降低锁竞争。
降低了锁的竞争，偏向锁，轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是
ConcurrentHashMap。
</code></pre></div><h4 id="锁分离"><a href="#锁分离" class="header-anchor">#</a> 锁分离</h4> <p>最常见的锁分离就是读写锁ReadWriteLock，根据功能进行分离成读锁和写锁，这样读读不互
斥，读写互斥，写写互斥，即保证了线程安全，又提高了性能，具体也请查看[高并发Java 五]
JDK并发包 1 。读写分离思想可以延伸，只要操作互不影响，锁就可以分离。比如
LinkedBlockingQueue 从头部取出，从尾部放数据</p> <h4 id="锁粗化"><a href="#锁粗化" class="header-anchor">#</a> 锁粗化</h4> <p>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽量短，即在使用完
公共资源后，应该立即释放锁。但是，凡事都有一个度，如果对同一个锁不停的进行请求、同步
和释放，其本身也会消耗系统宝贵的资源，反而不利于性能的优化 。</p> <h4 id="锁消除"><a href="#锁消除" class="header-anchor">#</a> 锁消除</h4> <p>锁消除是在编译器级别的事情。在即时编译器时，如果发现不可能被共享的对象，则可以消除这
些对象的锁操作，多数是因为程序员编码不规范引起。</p> <p>参考：https://www.jianshu.com/p/39628e1180a9</p> <h2 id="_4-1-10-线程基本方法"><a href="#_4-1-10-线程基本方法" class="header-anchor">#</a> 4.1.10. 线程基本方法</h2> <p>线程相关的基本方法有wait，notify，notifyAll，sleep，join，yield等。</p> <h3 id="_4-1-10-1-线程等待-wait"><a href="#_4-1-10-1-线程等待-wait" class="header-anchor">#</a> 4.1.10.1. 线程等待（wait）</h3> <p>调用该方法的线程进入WAITING状态，只有等待另外线程的通知或被中断才会返回，需要注意的
是调用wait()方法后，会释放对象的锁。因此，wait方法一般用在同步方法或同步代码块中。</p> <h3 id="_4-1-10-2-线程睡眠-sleep"><a href="#_4-1-10-2-线程睡眠-sleep" class="header-anchor">#</a> 4.1.10.2. 线程睡眠（sleep）</h3> <p>sleep导致当前线程休眠，与wait方法不同的是sleep不会释放当前占有的锁,sleep(long)会导致
线程进入TIMED-WATING状态，而wait()方法会导致当前线程进入WATING状态</p> <h3 id="_4-1-10-3-线程让步-yield"><a href="#_4-1-10-3-线程让步-yield" class="header-anchor">#</a> 4.1.10.3. 线程让步（yield）</h3> <p>yield会使当前线程让出CPU执行时间片，与其他线程一起重新竞争CPU时间片。一般情况下，
优先级高的线程有更大的可能性成功竞争得到CPU时间片，但这又不是绝对的，有的操作系统对
线程优先级并不敏感。</p> <h3 id="_4-1-10-4-线程中断-interrupt"><a href="#_4-1-10-4-线程中断-interrupt" class="header-anchor">#</a> 4.1.10.4. 线程中断（interrupt）</h3> <p>中断一个线程，其本意是给这个线程一个通知信号，会影响这个线程内部的一个中断标识位。这
个线程本身并不会因此而改变状态(如阻塞，终止等)。</p> <ol><li><p>调用interrupt()方法并不会中断一个正在运行的线程。也就是说处于Running状态的线
程并不会因为被中断而被终止，仅仅改变了内部维护的中断标识位而已。</p></li> <li><p>若调用sleep()而使线程处于TIMED-WATING状态，这时调用interrupt()方法，会抛出
InterruptedException,从而使线程提前结束TIMED-WATING状态。</p></li> <li><p>许多声明抛出InterruptedException的方法(如Thread.sleep(long mills方法))，抛出异
常前，都会清除中断标识位，所以抛出异常后，调用isInterrupted()方法将会返回false。</p></li> <li><p>中断状态是线程固有的一个标识位，可以通过此标识位安全的终止线程。比如,你想终止
一个线程thread的时候，可以调用thread.interrupt()方法，在线程的run方法内部可以
根据thread.isInterrupted()的值来优雅的终止线程。</p></li></ol> <h3 id="_4-1-10-5-join等待其他线程终止"><a href="#_4-1-10-5-join等待其他线程终止" class="header-anchor">#</a> 4.1.10.5. Join等待其他线程终止</h3> <p>join() 方法，等待其他线程终止，在当前线程中调用一个线程的 join() 方法，则当前线程转为阻塞
状态，回到另一个线程结束，当前线程再由阻塞状态变为就绪状态，等待 cpu 的宠幸。</p> <h3 id="_4-1-10-6-为什么要用join-方法"><a href="#_4-1-10-6-为什么要用join-方法" class="header-anchor">#</a> 4.1.10.6. 为什么要用join()方法？</h3> <p>很多情况下，主线程生成并启动了子线程，需要用到子线程返回的结果，也就是需要主线程需要
在子线程结束后再结束，这时候就要用到 join() 方法。
System.out.println(Thread.currentThread().getName() + &quot;线程运行开始!&quot;);
Thread6 thread1 = new Thread6();
thread1.setName(&quot;线程B&quot;);
thread1.join();
System.out.println(&quot;这时thread1执行完毕之后才能执行主线程&quot;);</p> <h3 id="_4-1-10-7-线程唤醒-notify"><a href="#_4-1-10-7-线程唤醒-notify" class="header-anchor">#</a> 4.1.10.7. 线程唤醒（notify）</h3> <p>Object 类中的 notify() 方法，唤醒在此对象监视器上等待的单个线程，如果所有线程都在此对象
上等待，则会选择唤醒其中一个线程，选择是任意的，并在对实现做出决定时发生，线程通过调
用其中一个 wait() 方法，在对象的监视器上等待，直到当前的线程放弃此对象上的锁定，才能继
续执行被唤醒的线程，被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞
争。类似的方法还有 notifyAll() ，唤醒再次监视器上等待的所有线程。</p> <h3 id="_4-1-10-8-其他方法"><a href="#_4-1-10-8-其他方法" class="header-anchor">#</a> 4.1.10.8. 其他方法：</h3> <ol><li><p>sleep()：强迫一个线程睡眠Ｎ毫秒。</p></li> <li><p>isAlive()： 判断一个线程是否存活。</p></li> <li><p>join()： 等待线程终止。</p></li> <li><p>activeCount()： 程序中活跃的线程数。</p></li> <li><p>enumerate()： 枚举程序中的线程。</p></li> <li><p>currentThread()： 得到当前线程。</p></li> <li><p>isDaemon()： 一个线程是否为守护线程。</p></li> <li><p>setDaemon()： 设置一个线程为守护线程。(用户线程和守护线程的区别在于，是否等待主线
程依赖于主线程结束而结束)</p></li> <li><p>setName()： 为线程设置一个名称。</p></li> <li><p>wait()： 强迫一个线程等待。</p></li> <li><p>notify()： 通知一个线程继续运行。</p></li> <li><p>setPriority()： 设置一个线程的优先级。</p></li> <li><p>getPriority():：获得一个线程的优先级。</p></li></ol> <h2 id="_4-1-11-线程上下文切换"><a href="#_4-1-11-线程上下文切换" class="header-anchor">#</a> 4.1.11. 线程上下文切换</h2> <p>巧妙地利用了时间片轮转的方式, CPU给每个任务都服务一定的时间，然后把当前任务的状态保存
下来，在加载下一任务的状态后，继续服务下一任务，任务的状态保存及再加载, 这段过程就叫做
上下文切换。时间片轮转的方式使多个任务在同一颗CPU上执行变成了可能。</p> <h3 id="_4-1-11-1-进程"><a href="#_4-1-11-1-进程" class="header-anchor">#</a> 4.1.11.1. 进程</h3> <div class="language- extra-class"><pre class="language-text"><code>（有时候也称做任务）是指一个程序运行的实例。在Linux系统中，线程就是能并行运行并且
与他们的父进程（创建他们的进程）共享同一地址空间（一段内存区域）和其他资源的轻量
级的进程。
</code></pre></div><h3 id="_4-1-11-2-上下文"><a href="#_4-1-11-2-上下文" class="header-anchor">#</a> 4.1.11.2. 上下文</h3> <div class="language- extra-class"><pre class="language-text"><code>是指某一时间点 CPU 寄存器和程序计数器的内容。
</code></pre></div><h3 id="_4-1-11-3-寄存器"><a href="#_4-1-11-3-寄存器" class="header-anchor">#</a> 4.1.11.3. 寄存器</h3> <div class="language- extra-class"><pre class="language-text"><code>是 CPU 内部的数量较少但是速度很快的内存（与之对应的是 CPU 外部相对较慢的 RAM 主内
存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来提高计算机程序运行的速
度。
</code></pre></div><h3 id="_4-1-11-4-程序计数器"><a href="#_4-1-11-4-程序计数器" class="header-anchor">#</a> 4.1.11.4. 程序计数器</h3> <div class="language- extra-class"><pre class="language-text"><code>是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令
的位置或者下一个将要被执行的指令的位置，具体依赖于特定的系统。
</code></pre></div><h3 id="_4-1-11-5-pcb-切换桢"><a href="#_4-1-11-5-pcb-切换桢" class="header-anchor">#</a> 4.1.11.5. PCB-“切换桢”</h3> <p>上下文切换可以认为是内核（操作系统的核心）在 CPU 上对于进程（包括线程）进行切换，上下
文切换过程中的信息是保存在进程控制块（PCB, process control block）中的。PCB还经常被称
作“切换桢”（switchframe）。信息会一直保存到CPU的内存中，直到他们被再次使用。</p> <h3 id="_4-1-11-6-上下文切换的活动"><a href="#_4-1-11-6-上下文切换的活动" class="header-anchor">#</a> 4.1.11.6. 上下文切换的活动：</h3> <ol><li>挂起一个进程，将这个进程在 CPU 中的状态（上下文）存储于内存中的某处。</li> <li>在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复。</li> <li>跳转到程序计数器所指向的位置（即跳转到进程被中断时的代码行），以恢复该进程在程序
中。</li></ol> <h3 id="_4-1-11-7-引起线程上下文切换的原因"><a href="#_4-1-11-7-引起线程上下文切换的原因" class="header-anchor">#</a> 4.1.11.7. 引起线程上下文切换的原因</h3> <ol><li>当前执行任务的时间片用完之后，系统CPU正常调度下一个任务；</li> <li>当前执行任务碰到IO阻塞，调度器将此任务挂起，继续下一任务；</li> <li>多个任务抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续下一任务；</li> <li>用户代码挂起当前任务，让出CPU时间；</li> <li>硬件中断；</li></ol> <h2 id="_4-1-12-同步锁与死锁"><a href="#_4-1-12-同步锁与死锁" class="header-anchor">#</a> 4.1.12. 同步锁与死锁</h2> <h3 id="_4-1-12-1-同步锁"><a href="#_4-1-12-1-同步锁" class="header-anchor">#</a> 4.1.12.1. 同步锁</h3> <p>当多个线程同时访问同一个数据时，很容易出现问题。为了避免这种情况出现，我们要保证线程
同步互斥，就是指并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。 Java中可
以使用synchronized关键字来取得一个对象的同步锁。</p> <h3 id="_4-1-12-2-死锁"><a href="#_4-1-12-2-死锁" class="header-anchor">#</a> 4.1.12.2. 死锁</h3> <p>何为死锁，就是多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。</p> <h2 id="_4-1-13-线程池原理"><a href="#_4-1-13-线程池原理" class="header-anchor">#</a> 4.1.13. 线程池原理</h2> <p>线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后
启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，
再从队列中取出任务来执行。他的主要特点为：线程复用；控制最大并发数；管理线程。</p> <h3 id="_4-1-13-1-线程复用"><a href="#_4-1-13-1-线程复用" class="header-anchor">#</a> 4.1.13.1. 线程复用</h3> <p>每一个 Thread 的类都有一个 start 方法。 当调用start启动线程时Java虚拟机会调用该类的 run
方法。 那么该类的 run() 方法中就是调用了 Runnable 对象的 run() 方法。 我们可以继承重写
Thread 类，在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。 这就是线程池的实
现原理。循环方法中不断获取 Runnable 是用 Queue 实现的，在获取下一个 Runnable 之前可以
是阻塞的。</p> <h3 id="_4-1-13-2-线程池的组成"><a href="#_4-1-13-2-线程池的组成" class="header-anchor">#</a> 4.1.13.2. 线程池的组成</h3> <p>一般的线程池主要分为以下 4 个组成部分：</p> <ol><li>线程池管理器：用于创建并管理线程池</li> <li>工作线程：线程池中的线程</li> <li>任务接口：每个任务必须实现的接口，用于工作线程调度其运行</li> <li>任务队列：用于存放待处理的任务，提供一种缓冲机制</li></ol> <p>Java 中的线程池是通过Executor 框架实现的，该框架中用到了Executor，Executors，
ExecutorService，ThreadPoolExecutor ，Callable和Future、FutureTask这几个类。</p> <p>ThreadPoolExecutor的构造方法如下：</p> <div class="language- extra-class"><pre class="language-text"><code>public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,
TimeUnit unit, BlockingQueue\&lt;Runnable\&gt; workQueue) {
this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
Executors.defaultThreadFactory(), defaultHandler);
}
</code></pre></div><ol><li>corePoolSize：指定了线程池中的线程数量。</li> <li>maximumPoolSize：指定了线程池中的最大线程数量。</li> <li>keepAliveTime：当前线程池数量超过corePoolSize时，多余的空闲线程的存活时间，即多
次时间内会被销毁。</li> <li>unit：keepAliveTime的单位。</li> <li>workQueue：任务队列，被提交但尚未被执行的任务。</li> <li>threadFactory：线程工厂，用于创建线程，一般用默认的即可。</li> <li>handler：拒绝策略，当任务太多来不及处理，如何拒绝任务。</li></ol> <h3 id="_4-1-13-3-拒绝策略"><a href="#_4-1-13-3-拒绝策略" class="header-anchor">#</a> 4.1.13.3. 拒绝策略</h3> <div class="language- extra-class"><pre class="language-text"><code>线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也
塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
JDK内置的拒绝策略如下：
</code></pre></div><ol><li>AbortPolicy ： 直接抛出异常，阻止系统正常运行。</li> <li>CallerRunsPolicy ： 只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的
任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。</li> <li>DiscardOldestPolicy ： 丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再
次提交当前任务。</li> <li>DiscardPolicy ： 该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢
失，这是最好的一种方案。
以上内置拒绝策略均实现了RejectedExecutionHandler接口，若以上策略仍无法满足实际
需要，完全可以自己扩展RejectedExecutionHandler接口。</li></ol> <h3 id="_4-1-13-4-java线程池工作过程"><a href="#_4-1-13-4-java线程池工作过程" class="header-anchor">#</a> 4.1.13.4. Java线程池工作过程</h3> <ol><li>线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面
有任务，线程池也不会马上执行它们。</li> <li>当调用 execute() 方法添加一个任务时，线程池会做如下判断：
a) 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；
b) 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；
c) 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要
创建非核心线程立刻运行这个任务；
d) 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池
会抛出异常RejectExecutionException。</li> <li>当一个线程完成任务时，它会从队列中取下一个任务来执行。</li> <li>当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运
行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它
最终会收缩到 corePoolSize 的大小。</li></ol> <h2 id="_4-1-14-java-阻塞队列原理"><a href="#_4-1-14-java-阻塞队列原理" class="header-anchor">#</a> 4.1.14. JAVA 阻塞队列原理</h2> <p>阻塞队列，关键字是阻塞，先理解阻塞的含义，在阻塞队列中，线程阻塞有这样的两种情况：</p> <ol><li>当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放</li></ol> <div class="language- extra-class"><pre class="language-text"><code>入队列。
</code></pre></div><ol start="2"><li>当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有</li></ol> <div class="language- extra-class"><pre class="language-text"><code>空的位置，线程被自动唤醒。
</code></pre></div><h3 id="_4-1-14-1-阻塞队列的主要方法"><a href="#_4-1-14-1-阻塞队列的主要方法" class="header-anchor">#</a> 4.1.14.1. 阻塞队列的主要方法</h3> <div class="language- extra-class"><pre class="language-text"><code> 抛出异常：抛出一个异常；
 特殊值：返回一个特殊值（null或false,视情况而定）
 则塞：在成功操作之前，一直阻塞线程
 超时：放弃前只在最大的时间内阻塞
</code></pre></div><h4 id="插入操作"><a href="#插入操作" class="header-anchor">#</a> 插入操作：</h4> <div class="language- extra-class"><pre class="language-text"><code>1 ：public abstract boolean add(E paramE)：将指定元素插入此队列中（如果立即可行
且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则抛
出 IllegalStateException。如果该元素是NULL，则会抛出NullPointerException异常。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>2 ：public abstract boolean offer(E paramE)：将指定元素插入此队列中（如果立即可行
</code></pre></div><p>且不会违反容量限制），成功时返回 true，如果当前没有可用的空间，则返回 false。</p> <div class="language- extra-class"><pre class="language-text"><code>3 ：public abstract void put(E paramE) throws InterruptedException： 将指定元素插
</code></pre></div><p>入此队列中，将等待可用的空间（如果有必要）</p> <div class="language- extra-class"><pre class="language-text"><code>public void put(E paramE) throws InterruptedException {
checkNotNull(paramE);
ReentrantLock localReentrantLock = this.lock;
localReentrantLock.lockInterruptibly();
try {
while (this.count == this.items.length)
this.notFull.await();//如果队列满了，则线程阻塞等待
enqueue(paramE);
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>localReentrantLock.unlock();
} finally {
localReentrantLock.unlock();
}
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>}
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>4 ：offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定的时间
</code></pre></div><p>内，还不能往队列中加入BlockingQueue，则返回失败。</p> <h4 id="获取数据操作"><a href="#获取数据操作" class="header-anchor">#</a> 获取数据操作：</h4> <div class="language- extra-class"><pre class="language-text"><code>1 ：poll(time):取走BlockingQueue里排在首位的对象,若不能立即取出,则可以等time参数
规定的时间,取不到时返回null;
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>2 ：poll(long timeout, TimeUnit unit)：从BlockingQueue取出一个队首的对象，如果在
指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则直到时间超时还没有数
据可取，返回失败。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>3 ：take():取走BlockingQueue里排在首位的对象,若BlockingQueue为空,阻断进入等待状
态直到BlockingQueue有新的数据被加入。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>4.drainTo():一次性从BlockingQueue获取所有可用的数据对象（还可以指定获取数据的个
数），通过该方法，可以提升获取数据效率；不需要多次分批加锁或释放锁。
</code></pre></div><h3 id="_4-1-14-2-java中的阻塞队列"><a href="#_4-1-14-2-java中的阻塞队列" class="header-anchor">#</a> 4.1.14.2. Java中的阻塞队列</h3> <ol><li>ArrayBlockingQueue ：由数组结构组成的有界阻塞队列。</li> <li>LinkedBlockingQueue ：由链表结构组成的有界阻塞队列。</li> <li>PriorityBlockingQueue ：支持优先级排序的无界阻塞队列。</li> <li>DelayQueue：使用优先级队列实现的无界阻塞队列。</li> <li>SynchronousQueue：不存储元素的阻塞队列。</li> <li>LinkedTransferQueue：由链表结构组成的无界阻塞队列。</li> <li>LinkedBlockingDeque：由链表结构组成的双向阻塞队列</li></ol> <h3 id="_4-1-14-3-arrayblockingqueue-公平、非公平"><a href="#_4-1-14-3-arrayblockingqueue-公平、非公平" class="header-anchor">#</a> 4.1.14.3. ArrayBlockingQueue（公平、非公平）</h3> <p>用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下
不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当
队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入
元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐
量。我们可以使用以下代码创建一个公平的阻塞队列：</p> <div class="language- extra-class"><pre class="language-text"><code>ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true);
</code></pre></div><h3 id="_4-1-14-4-linkedblockingqueue-两个独立锁提高并发"><a href="#_4-1-14-4-linkedblockingqueue-两个独立锁提高并发" class="header-anchor">#</a> 4.1.14.4. LinkedBlockingQueue（两个独立锁提高并发）</h3> <p>基于链表的阻塞队列，同ArrayListBlockingQueue类似，此队列按照先进先出（FIFO）的原则对
元素进行排序。而LinkedBlockingQueue之所以能够高效的处理并发数据，还因为其对于生产者
端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发的情况下生产者和消费
者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。</p> <p>LinkedBlockingQueue会默认一个类似无限大小的容量（Integer.MAX_VALUE）。</p> <h3 id="_4-1-14-5-priorityblockingqueue-compareto排序实现优先"><a href="#_4-1-14-5-priorityblockingqueue-compareto排序实现优先" class="header-anchor">#</a> 4.1.14.5. PriorityBlockingQueue（compareTo排序实现优先）..............................................................</h3> <p>是一个支持优先级的无界队列。默认情况下元素采取自然顺序升序排列。可以自定义实现
compareTo()方法来指定元素进行排序规则，或者初始化PriorityBlockingQueue 时，指定构造
参数Comparator来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p> <h3 id="_4-1-14-6-delayqueue-缓存失效、定时任务"><a href="#_4-1-14-6-delayqueue-缓存失效、定时任务" class="header-anchor">#</a> 4 .1.14.6. DelayQueue（缓存失效、定时任务 ）</h3> <p>是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实
现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才
能从队列中提取元素。我们可以将DelayQueue运用在以下应用场景：</p> <ol><li><p>缓存系统的设计：可以用DelayQueue 保存缓存元素的有效期，使用一个线程循环查询
DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。</p></li> <li><p>定时任务调度：使用DelayQueue 保存当天将会执行的任务和执行时间，一旦从
DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。</p></li></ol> <h3 id="_4-1-14-7-synchronousqueue-不存储数据、可用于传递数据"><a href="#_4-1-14-7-synchronousqueue-不存储数据、可用于传递数据" class="header-anchor">#</a> 4.1.14.7. SynchronousQueue（不存储数据、可用于传递数据）</h3> <p>是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。
SynchronousQueue 可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线
程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给
另外一个线程使用，SynchronousQueue 的吞吐量高于LinkedBlockingQueue 和
ArrayBlockingQueue。</p> <h3 id="_4-1-14-8-linkedtransferqueue"><a href="#_4-1-14-8-linkedtransferqueue" class="header-anchor">#</a> 4.1.14.8. LinkedTransferQueue......................................................................................................................</h3> <p>是一个由链表结构组成的无界阻塞TransferQueue 队列。相对于其他阻塞队列，
LinkedTransferQueue多了tryTransfer和transfer方法。</p> <ol><li>transfer方法：如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的
poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如
果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素
被消费者消费了才返回。</li> <li>tryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费
者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否
接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。</li></ol> <p>对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传
入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时
还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。</p> <h4 id="_4-1-14-9-linkedblockingdeque"><a href="#_4-1-14-9-linkedblockingdeque" class="header-anchor">#</a> 4.1.14.9. LinkedBlockingDeque</h4> <p>是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。
双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其
他的阻塞队列，LinkedBlockingDeque 多了addFirst，addLast，offerFirst，offerLast，
peekFirst，peekLast等方法，以First单词结尾的方法，表示插入，获取（peek）或移除双端队
列的第一个元素。以Last单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另
外插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同
于takeFirst，不知道是不是Jdk的bug，使用时还是用带有First和Last后缀的方法更清楚。</p> <p>在初始化LinkedBlockingDeque时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在
“工作窃取”模式中。</p> <h3 id="_4-1-15-cyclicbarrier-、-countdownlatch-、-semaphore-的用法"><a href="#_4-1-15-cyclicbarrier-、-countdownlatch-、-semaphore-的用法" class="header-anchor">#</a> 4.1.15. CyclicBarrier 、 CountDownLatch 、 Semaphore 的用法</h3> <h4 id="_4-1-15-1-countdownlatch-线程计数器"><a href="#_4-1-15-1-countdownlatch-线程计数器" class="header-anchor">#</a> 4.1.15.1. CountDownLatch（线程计数器 ）</h4> <p>CountDownLatch类位于java.util.concurrent包下，利用它可以实现类似计数器的功能。比如有
一个任务A，它要等待其他 4 个任务执行完毕之后才能执行，此时就可以利用CountDownLatch
来实现这种功能了。</p> <div class="language- extra-class"><pre class="language-text"><code>final CountDownLatch latch = new CountDownLatch(2);
new Thread(){public void run() {
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;);
Thread.sleep(3000);
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;);
latch.countDown();
};}.start();
new Thread(){ public void run() {
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;正在执行&quot;);
Thread.sleep(3000);
System.out.println(&quot;子线程&quot;+Thread.currentThread().getName()+&quot;执行完毕&quot;);
latch.countDown();
};}.start();
System.out.println(&quot;等待 2 个子线程执行完毕...&quot;);
latch.await();
System.out.println(&quot; 2 个子线程已经执行完毕&quot;);
System.out.println(&quot;继续执行主线程&quot;);
}
</code></pre></div><h4 id="_4-1-15-2-cyclicbarrier-回环栅栏-等待至barrier状态再全部同时执行"><a href="#_4-1-15-2-cyclicbarrier-回环栅栏-等待至barrier状态再全部同时执行" class="header-anchor">#</a> 4.1.15.2. CyclicBarrier（回环栅栏-等待至barrier状态再全部同时执行）</h4> <p>字面意思回环栅栏，通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环
是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。我们暂且把这个状态就叫做
barrier，当调用await()方法之后，线程就处于barrier了。</p> <p>CyclicBarrier中最重要的方法就是await方法，它有 2 个重载版本：</p> <ol><li>public int await()：用来挂起当前线程，直至所有线程都到达barrier状态再同时执行后续任
务；</li> <li>public int await(long timeout, TimeUnit unit)：让这些线程等待至一定的时间，如果还有
线程没有到达barrier状态就直接让到达barrier的线程执行后续任务。</li></ol> <div class="language- extra-class"><pre class="language-text"><code>具体使用如下，另外CyclicBarrier是可以重用的。
public static void main(String[] args) {
int N = 4;
CyclicBarrier barrier = new CyclicBarrier(N);
for(int i=0;i\&lt;N;i++)
new Writer(barrier).start();
}
static class Writer extends Thread{
private CyclicBarrier cyclicBarrier;
public Writer(CyclicBarrier cyclicBarrier) {
this.cyclicBarrier = cyclicBarrier;
}
@Override
public void run() {
try {
Thread.sleep(5000); //以睡眠来模拟线程需要预定写入数据操作
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;写入数据完
毕，等待其他线程写入完毕&quot;);
cyclicBarrier.await();
} catch (InterruptedException e) {
e.printStackTrace();
}catch(BrokenBarrierException e){
e.printStackTrace();
}
System.out.println(&quot;所有线程写入完毕，继续处理其他任务，比如数据操作&quot;);
}
}
</code></pre></div><h4 id="_4-1-15-3-semaphore-信号量-控制同时访问的线程个数"><a href="#_4-1-15-3-semaphore-信号量-控制同时访问的线程个数" class="header-anchor">#</a> 4.1.15.3. Semaphore（信号量-控制同时访问的线程个数）</h4> <p>Semaphore翻译成字面意思为 信号量，Semaphore 可以控制同时访问的线程个数，通过
acquire() 获取一个许可，如果没有就等待，而 release() 释放一个许可。</p> <p>Semaphore类中比较重要的几个方法：</p> <ol><li>public void acquire(): 用来获取一个许可，若无许可能够获得，则会一直等待，直到获得许
可。</li> <li>public void acquire(int permits):获取permits个许可</li> <li>public void release() { } :释放许可。注意，在释放许可之前，必须先获获得许可。</li> <li>public void release(int permits) { }:释放permits个许可</li></ol> <p>上面 4 个方法都会被阻塞，如果想立即得到执行结果，可以使用下面几个方法</p> <ol><li>public boolean tryAcquire():尝试获取一个许可，若获取成功，则立即返回true，若获取失
败，则立即返回false</li> <li>public boolean tryAcquire(long timeout, TimeUnit unit):尝试获取一个许可，若在指定的
时间内获取成功，则立即返回true，否则则立即返回false</li> <li>public boolean tryAcquire(int permits):尝试获取permits个许可，若获取成功，则立即返
回true，若获取失败，则立即返回false</li> <li>public boolean tryAcquire(int permits, long timeout, TimeUnit unit): 尝试获取permits
个许可，若在指定的时间内获取成功，则立即返回true，否则则立即返回false</li> <li>还可以通过availablePermits()方法得到可用的许可数目。</li></ol> <p>例子：若一个工厂有 5 台机器，但是有 8 个工人，一台机器同时只能被一个工人使用，只有使用完
了，其他工人才能继续使用。那么我们就可以通过Semaphore来实现：
int N = 8; //工人数
Semaphore semaphore = new Semaphore(5); //机器数目
for(int i=0;i&lt;N;i++)
new Worker(i,semaphore).start();
}
static class Worker extends Thread{
private int num;
private Semaphore semaphore;
public Worker(int num,Semaphore semaphore){
this.num = num;
this.semaphore = semaphore;
}</p> <div class="language- extra-class"><pre class="language-text"><code>@Override
public void run() {
try {
semaphore.acquire();
System.out.println(&quot;工人&quot;+this.num+&quot;占用一个机器在生产...&quot;);
Thread.sleep(2000);
System.out.println(&quot;工人&quot;+this.num+&quot;释放出机器&quot;);
semaphore.release();
} catch (InterruptedException e) {
e.printStackTrace();
}
}
 CountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不
同；CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>执行；而CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时
执行；另外，CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。
 Semaphore其实和锁有点类似，它一般用于控制对某组资源的访问权限。
</code></pre></div><h3 id="_4-1-16-volatile-关键字的作用-变量可见性、禁止重排序"><a href="#_4-1-16-volatile-关键字的作用-变量可见性、禁止重排序" class="header-anchor">#</a> 4.1.16. volatile 关键字的作用（变量可见性、禁止重排序）</h3> <p>Java语言提供了一种稍弱的同步机制，即volatile变量，用来确保将变量的更新操作通知到其他
线程。volatile 变量具备两种特性，volatile变量不会被缓存在寄存器或者对其他处理器不可见的
地方，因此在读取volatile类型的变量时总会返回最新写入的值。</p> <h5 id="变量可见性"><a href="#变量可见性" class="header-anchor">#</a> 变量可见性</h5> <p>其一是保证该变量对所有线程可见，这里的可见性指的是当一个线程修改了变量的值，那么新的
值对于其他线程是可以立即获取的。</p> <h5 id="禁止重排序"><a href="#禁止重排序" class="header-anchor">#</a> 禁止重排序</h5> <p>volatile 禁止了指令重排。</p> <h5 id="比sychronized更轻量级的同步锁"><a href="#比sychronized更轻量级的同步锁" class="header-anchor">#</a> 比sychronized更轻量级的同步锁</h5> <p>在访问volatile变量时不会执行加锁操作，因此也就不会使执行线程阻塞，因此volatile变量是一</p> <p>种比sychronized关键字更轻量级的同步机制。volatile适合这种场景：一个变量被多个线程共</p> <h3 id="享-线程直接给这个变量赋值。"><a href="#享-线程直接给这个变量赋值。" class="header-anchor">#</a> 享，线程直接给这个变量赋值。</h3> <p>当对非 volatile 变量进行读写的时候，每个线程先从内存拷贝变量到CPU缓存中。如果计算机有
多个CPU，每个线程可能在不同的CPU上被处理，这意味着每个线程可以拷贝到不同的 CPU
cache 中。而声明变量是 volatile 的，JVM 保证了每次读变量都从内存中读，跳过 CPU cache
这一步。</p> <h5 id="适用场景"><a href="#适用场景" class="header-anchor">#</a> 适用场景</h5> <p>值得说明的是对volatile变量的单次读/写操作可以保证原子性的，如long和double类型变量，
但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。在某些场景下可以
代替Synchronized。但是,volatile的不能完全取代Synchronized的位置，只有在一些特殊的场</p> <p>景下，才能适用volatile。总的来说，必须同时满足下面两个条件才能保证在并发环境的线程安
全：
（ 1 ）对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean
flag = true）。
（ 2 ）该变量没有包含在具有其他变量的不变式中，也就是说，不同的volatile变量之间，不
能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。</p> <h3 id="_4-1-17-如何在两个线程之间共享数据"><a href="#_4-1-17-如何在两个线程之间共享数据" class="header-anchor">#</a> 4.1.17. 如何在两个线程之间共享数据</h3> <p>Java 里面进行多线程通信的主要方式就是共享内存的方式，共享内存主要的关注点有两个：可见
性和有序性原子性。Java内存模型（JMM）解决了可见性和有序性的问题，而锁解决了原子性的
问题，理想情况下我们希望做到“同步”和“互斥”。有以下常规实现方法：</p> <h5 id="将数据抽象成一个类-并将数据的操作作为这个类的方法"><a href="#将数据抽象成一个类-并将数据的操作作为这个类的方法" class="header-anchor">#</a> 将数据抽象成一个类，并将数据的操作作为这个类的方法</h5> <ol><li>将数据抽象成一个类，并将对这个数据的操作作为这个类的方法，这么设计可以和容易做到
同步，只要在方法上加”synchronized“
public class MyData {
private int j=0;
public synchronized void add(){
j++;
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j为：&quot;+j);
}
public synchronized void dec(){
j--;
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j为：&quot;+j);
}
public int getData(){
return j;
}
}
public class AddRunnable implements Runnable{
MyData data;
public AddRunnable(MyData data){
this.data= data;
}</li></ol> <div class="language- extra-class"><pre class="language-text"><code>public void run() {
data.add();
}
}
public class DecRunnable implements Runnable {
MyData data;
public DecRunnable(MyData data){
this.data = data;
}
public void run() {
data.dec();
}
}
public static void main(String[] args) {
MyData data = new MyData();
Runnable add = new AddRunnable(data);
Runnable dec = new DecRunnable(data);
for(int i=0;i\&lt;2;i++){
new Thread(add).start();
new Thread(dec).start();
}
</code></pre></div><h5 id="runnable对象作为一个类的内部类"><a href="#runnable对象作为一个类的内部类" class="header-anchor">#</a> Runnable对象作为一个类的内部类</h5> <ol start="2"><li>将Runnable对象作为一个类的内部类，共享数据作为这个类的成员变量，每个线程对共享数
据的操作方法也封装在外部类，以便实现对数据的各个操作的同步和互斥，作为内部类的各
个Runnable对象调用外部类的这些方法。
public class MyData {
private int j=0;
public synchronized void add(){
j++;
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j为：&quot;+j);
}
public synchronized void dec(){
j--;
System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j为：&quot;+j);
}
public int getData(){
return j;</li></ol> <div class="language- extra-class"><pre class="language-text"><code>}
}
public class TestThread {
public static void main(String[] args) {
final MyData data = new MyData();
for(int i=0;i\&lt;2;i++){
new Thread(new Runnable(){
public void run() {
data.add();
}
}).start();
new Thread(new Runnable(){
public void run() {
data.dec();
}
}).start();
}
}
}
</code></pre></div><h3 id="_4-1-18-threadlocal-作用-线程本地存储"><a href="#_4-1-18-threadlocal-作用-线程本地存储" class="header-anchor">#</a> 4.1.18. ThreadLocal 作用（线程本地存储）</h3> <p>ThreadLocal，很多地方叫做线程本地变量，也有些地方叫做线程本地存储，ThreadLocal的作用
是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或
者组件之间一些公共变量的传递的复杂度。</p> <h5 id="threadlocalmap-线程的一个属性"><a href="#threadlocalmap-线程的一个属性" class="header-anchor">#</a> ThreadLocalMap（线程的一个属性）</h5> <ol><li>每个线程中都有一个自己的ThreadLocalMap类对象，可以将线程自己的对象保持到其中，
各管各的，线程可以正确的访问到自己的对象。</li> <li>将一个共用的ThreadLocal 静态实例作为key，将不同对象的引用保存到不同线程的
ThreadLocalMap中，然后在线程执行的各处通过这个静态ThreadLocal实例的get()方法取
得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。</li> <li>ThreadLocalMap其实就是线程里面的一个属性，它在Thread类中定义</li></ol> <div class="language- extra-class"><pre class="language-text"><code>ThreadLocal.ThreadLocalMap threadLocals = null;
</code></pre></div><h5 id="使用场景"><a href="#使用场景" class="header-anchor">#</a> 使用场景</h5> <div class="language- extra-class"><pre class="language-text"><code>最常见的ThreadLocal使用场景为 用来解决 数据库连接、Session管理等。
private static final ThreadLocal threadSession = new ThreadLocal();
public static Session getSession() throws InfrastructureException {
Session s = (Session) threadSession.get();
try {
if (s == null) {
s = getSessionFactory().openSession();
threadSession.set(s);
}
} catch (HibernateException ex) {
throw new InfrastructureException(ex);
}
return s;
}
</code></pre></div><h3 id="_4-1-19-synchronized-和-reentrantlock-的区别"><a href="#_4-1-19-synchronized-和-reentrantlock-的区别" class="header-anchor">#</a> 4.1.19. synchronized 和 ReentrantLock 的区别</h3> <h4 id="_4-1-19-1-两者的共同点"><a href="#_4-1-19-1-两者的共同点" class="header-anchor">#</a> 4.1.19.1. 两者的共同点：</h4> <ol><li>都是用来协调多线程对共享对象、变量的访问</li> <li>都是可重入锁，同一线程可以多次获得同一个锁</li> <li>都保证了可见性和互斥性</li></ol> <h4 id="_4-1-19-2-两者的不同点"><a href="#_4-1-19-2-两者的不同点" class="header-anchor">#</a> 4.1.19.2. 两者的不同点：</h4> <ol><li>ReentrantLock显示的获得、释放锁，synchronized隐式获得释放锁</li> <li>ReentrantLock可响应中断、可轮回，synchronized是不可以响应中断的，为处理锁的
不可用性提供了更高的灵活性</li> <li>ReentrantLock是API级别的，synchronized是JVM级别的</li> <li>ReentrantLock可以实现公平锁</li> <li>ReentrantLock通过Condition可以绑定多个条件</li> <li>底层实现不一样， synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻
塞，采用的是乐观并发策略</li> <li>Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言
实现。</li> <li>synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，
因此使用Lock时需要在finally块中释放锁。</li> <li>Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，
等待的线程会一直等待下去，不能够响应中断。</li> <li>通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。</li> <li>Lock可以提高多个线程进行读操作的效率，既就是实现读写锁等。</li></ol> <h3 id="_4-1-20-concurrenthashmap-并发"><a href="#_4-1-20-concurrenthashmap-并发" class="header-anchor">#</a> 4.1.20. ConcurrentHashMap 并发</h3> <h4 id="_4-1-20-1-减小锁粒度"><a href="#_4-1-20-1-减小锁粒度" class="header-anchor">#</a> 4.1.20.1. 减小锁粒度</h4> <p>减小锁粒度是指缩小锁定对象的范围，从而减小锁冲突的可能性，从而提高系统的并发能力。减
小锁粒度是一种削弱多线程锁竞争的有效手段，这种技术典型的应用是ConcurrentHashMap(高
性能的HashMap)类的实现。对于HashMap而言，最重要的两个方法是get与set方法，如果我
们对整个HashMap加锁，可以得到线程安全的对象，但是加锁粒度太大。Segment的大小也被
称为ConcurrentHashMap的并发度。</p> <h4 id="_4-1-20-2-concurrenthashmap分段锁"><a href="#_4-1-20-2-concurrenthashmap分段锁" class="header-anchor">#</a> 4.1.20.2. ConcurrentHashMap分段锁</h4> <p>ConcurrentHashMap，它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下
一个ConcurrentHashMap被进一步细分为 16 个段，既就是锁的并发度。</p> <p>如果需要在ConcurrentHashMap中添加一个新的表项，并不是将整个HashMap加锁，而是首
先根据hashcode得到该表项应该存放在哪个段中，然后对该段加锁，并完成put操作。在多线程
环境中，如果多个线程同时进行put操作，只要被加入的表项不存放在同一个段中，则线程间可以
做到真正的并行。</p> <h5 id="concurrenthashmap是由segment数组结构和hashentry数组结构组成"><a href="#concurrenthashmap是由segment数组结构和hashentry数组结构组成" class="header-anchor">#</a> ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成</h5> <p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可
重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值
对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap
类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是
一个链表结构的元素， 每个Segment守护一个HashEntry数组里的元素,当对HashEntry数组的
数据进行修改时，必须首先获得它对应的Segment锁。</p> <h3 id="_4-1-21-java-中用到的线程调度"><a href="#_4-1-21-java-中用到的线程调度" class="header-anchor">#</a> 4.1.21. Java 中用到的线程调度</h3> <h4 id="_4-1-21-1-抢占式调度"><a href="#_4-1-21-1-抢占式调度" class="header-anchor">#</a> 4.1.21.1. 抢占式调度：</h4> <p>抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制，系统控制指的是在系统某种
运行机制下，可能每条线程都分同样的执行时间片，也可能是某些线程执行的时间片较长，甚至
某些线程得不到执行的时间片。在这种机制下，一个线程的堵塞不会导致整个进程堵塞。</p> <h4 id="_4-1-21-2-协同式调度"><a href="#_4-1-21-2-协同式调度" class="header-anchor">#</a> 4.1.21.2. 协同式调度：</h4> <p>协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行，这种模式就像接力赛一样，
一个人跑完自己的路程就把接力棒交接给下一个人，下个人继续往下跑。线程的执行时间由线程
本身控制，线程切换可以预知，不存在多线程同步问题，但它有一个致命弱点：如果一个线程编
写有问题，运行到一半就一直堵塞，那么可能导致整个系统崩溃。</p> <h4 id="_4-1-21-3-jvm的线程调度实现-抢占式调度"><a href="#_4-1-21-3-jvm的线程调度实现-抢占式调度" class="header-anchor">#</a> 4.1.21.3. JVM的线程调度实现（抢占式调度）</h4> <p>java使用的线程调使用抢占式调度，Java中线程会按优先级分配CPU时间片运行，且优先级越高
越优先执行，但优先级高并不代表能独自占用执行时间片，可能是优先级高得到越多的执行时间
片，反之，优先级低的分到的执行时间少但不会分配不到执行时间。</p> <h4 id="_4-1-21-4-线程让出cpu的情况"><a href="#_4-1-21-4-线程让出cpu的情况" class="header-anchor">#</a> 4.1.21.4. 线程让出cpu的情况：</h4> <ol><li>当前运行线程主动放弃CPU，JVM暂时放弃CPU操作（基于时间片轮转调度的JVM操作系
统不会让线程永久放弃CPU，或者说放弃本次时间片的执行权），例如调用yield()方法。</li> <li>当前运行线程因为某些原因进入阻塞状态，例如阻塞在I/O上。</li> <li>当前运行线程结束，即运行完run()方法里面的任务。</li></ol> <h3 id="_4-1-22-进程调度算法"><a href="#_4-1-22-进程调度算法" class="header-anchor">#</a> 4.1.22. 进程调度算法</h3> <h4 id="_4-1-22-1-优先调度算法"><a href="#_4-1-22-1-优先调度算法" class="header-anchor">#</a> 4.1.22.1. 优先调度算法</h4> <ol><li>先来先服务调度算法（FCFS）</li></ol> <p>当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队
列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采
用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，</p> <p>使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机，特点是：算法比较
简单，可以实现基本上的公平。</p> <ol start="2"><li>短作业(进程)优先调度算法</li></ol> <p>短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们
调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，
将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重
新调度。该算法未照顾紧迫型作业。</p> <h4 id="_4-1-22-2-高优先权优先调度算法"><a href="#_4-1-22-2-高优先权优先调度算法" class="header-anchor">#</a> 4.1.22.2. 高优先权优先调度算法</h4> <p>为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度
算法。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。
当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程。</p> <ol><li>非抢占式优先权算法</li></ol> <p>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下
去，直至完成；或因发生某事件使该进程放弃处理机时。这种调度算法主要用于批处理系统中；
也可用于某些对实时性要求不严的实时系统中。</p> <ol start="2"><li>抢占式优先权调度算法</li></ol> <p>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只
要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)
的执行，重新将处理机分配给新到的优先权最高的进程。显然，这种抢占式的优先权调度算法能
更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批
处理和分时系统中。</p> <p>2 ．高响应比优先调度算法</p> <p>在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行
得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时
间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的
变化规律可描述为：</p> <p>(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于
短作业。</p> <p>(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权
愈高，因而它实现的是先来先服务。</p> <p>(3) 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其
优先级便可升到很高，从而也可获得处理机。简言之，该算法既照顾了短作业，又考虑了作业到
达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在
利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。</p> <h4 id="_4-1-22-3-基于时间片的轮转调度算法"><a href="#_4-1-22-3-基于时间片的轮转调度算法" class="header-anchor">#</a> 4.1.22.3. 基于时间片的轮转调度算法</h4> <ol><li>时间片轮转法</li></ol> <p>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度
时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行
的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，
并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执
行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处
理机执行时间。</p> <ol start="2"><li>多级反馈队列调度算法</li></ol> <p>(1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二
个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各
不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的
时间片要比第一个队列的时间片长一倍，......，第i+1个队列的时间片要比第i个队列的时间片长
一倍。</p> <p>(2) 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当
轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时
尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果
它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，......，如此下去，当一个
长作业(进程)从第一队列依次降到第n队列后，在第n 队列便采取按时间片轮转的方式运行。</p> <p>(3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1 ～(i-1)队列均空时，
才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优
先权较高的队列(第 1 ～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即
由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。</p> <p>在多级反馈队列调度算法中，如果规定第一个队列的时间片略大于多数人机交互所需之处理时间
时，便能够较好的满足各种类型用户的需要。</p> <h3 id="_4-1-23-什么是-cas-比较并交换-乐观锁机制-锁自旋"><a href="#_4-1-23-什么是-cas-比较并交换-乐观锁机制-锁自旋" class="header-anchor">#</a> 4.1.23. 什么是 CAS （比较并交换-乐观锁机制-锁自旋）</h3> <h4 id="_4-1-23-1-概念及特性"><a href="#_4-1-23-1-概念及特性" class="header-anchor">#</a> 4.1.23.1. 概念及特性</h4> <p>CAS（Compare And Swap/Set）比较并交换，CAS 算法的过程是这样：它包含 3 个参数
CAS(V,E,N)。V表示要更新的变量(内存值)，E表示预期值(旧的)，N表示新值。当且仅当V值等</p> <p>于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当</p> <p>前线程什么都不做。最后，CAS返回当前V的真实值。
CAS操作是抱着乐观的态度进行的(乐观锁)，它总是认为自己可以成功完成操作。当多个线程同时</p> <p>使用CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂
起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，</p> <p>CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。</p> <h4 id="_4-1-23-2-原子包-java-util-concurrent-atomic-锁自旋"><a href="#_4-1-23-2-原子包-java-util-concurrent-atomic-锁自旋" class="header-anchor">#</a> 4.1.23.2. 原子包 java.util.concurrent.atomic（锁自旋）</h4> <p>JDK1.5的原子包：java.util.concurrent.atomic这个包里面提供了一组原子类。其基本的特性就</p> <p>是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个
线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等</p> <p>到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。</p> <p>相对于对于synchronized这种阻塞算法，CAS是非阻塞算法的一种常见实现。由于一般CPU切
换时间比CPU指令集操作更加长， 所以J.U.C在性能上有了很大的提升。如下代码：</p> <div class="language- extra-class"><pre class="language-text"><code>public class AtomicInteger extends Number implements java.io.Serializable {
private volatile int value;
public final int get() {
return value;
}
public final int getAndIncrement() {
for (;;) { //CAS自旋，一直尝试，直达成功
int current = get();
int next = current + 1;
if (compareAndSet(current, next))
return current;
}
}
public final boolean compareAndSet(int expect, int update) {
return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
}
}
</code></pre></div><p>getAndIncrement 采用了CAS 操作，每次从内存中读取数据然后将此数据和+1后的结果进行
CAS操作，如果成功就返回结果，否则重试直到成功为止。而compareAndSet利用JNI来完成
CPU指令的操作。</p> <h4 id="_4-1-23-3-aba问题"><a href="#_4-1-23-3-aba问题" class="header-anchor">#</a> 4.1.23.3. ABA问题</h4> <p>CAS会导致“ABA问题”。CAS算法实现一个重要前提需要取出内存中某时刻的数据，而在下时
刻比较并替换，那么在这个时间差类会导致数据的变化。</p> <p>比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且
two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操
作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过
程就是没有问题的。</p> <p>部分乐观锁的实现是通过版本号（version）的方式来解决ABA问题，乐观锁每次在执行数据的修
改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本
号执行+1操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现ABA 问
题，因为版本号只会增加不会减少。</p> <h3 id="_4-1-24-什么是-aqs-抽象的队列同步器"><a href="#_4-1-24-什么是-aqs-抽象的队列同步器" class="header-anchor">#</a> 4.1.24. 什么是 AQS （抽象的队列同步器）</h3> <p>AbstractQueuedSynchronizer类如其名，抽象的队列式的同步器，AQS定义了一套多线程访问
共享资源的同步器框架，许多同步类实现都依赖于它，如常用的
ReentrantLock/Semaphore/CountDownLatch。</p> <p>它维护了一个volatile int state（代表共享资源）和一个FIFO线程等待队列（多线程争用资源被
阻塞时会进入此队列）。这里volatile是核心关键词，具体volatile的语义，在此不述。state的
访问方式有三种:</p> <div class="language- extra-class"><pre class="language-text"><code>getState()
setState()
compareAndSetState()
</code></pre></div><p>AQS定义两种资源共享方式</p> <h5 id="exclusive独占资源-reentrantlock"><a href="#exclusive独占资源-reentrantlock" class="header-anchor">#</a> Exclusive独占资源-ReentrantLock</h5> <p>Exclusive（独占，只有一个线程能执行，如ReentrantLock）</p> <h5 id="share共享资源-semaphore-countdownlatch"><a href="#share共享资源-semaphore-countdownlatch" class="header-anchor">#</a> Share共享资源-Semaphore/CountDownLatch</h5> <p>Share（共享，多个线程可同时执行，如Semaphore/CountDownLatch）。</p> <p>AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现，AQS这里只定义了一个
接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS)之所以没有定义成
abstract，是因为独占模式下只用实现 tryAcquire-tryRelease，而共享模式下只用实现
tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模
式下的接口。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实
现共享资源state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/
唤醒出队等），AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法：</p> <p>1 ． isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
2 ． tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
3 ． tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
4 ． tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败； 0 表示成功，但没有剩余
可用资源；正数表示成功，且有剩余资源。
5 ． tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回
true，否则返回false。</p> <h5 id="同步器的实现是abs核心-state资源状态计数"><a href="#同步器的实现是abs核心-state资源状态计数" class="header-anchor">#</a> 同步器的实现是ABS核心（state资源状态计数）</h5> <p>同步器的实现是ABS核心，以ReentrantLock为例，state初始化为 0 ，表示未锁定状态。A线程
lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失
败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放
锁之前，A 线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，
获取多少次就要释放多么次，这样才能保证state是能回到零态的。</p> <p>以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与
线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state
会CAS减 1 。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程
就会从await()函数返回，继续后余动作。</p> <h5 id="reentrantreadwritelock实现独占和共享两种方式"><a href="#reentrantreadwritelock实现独占和共享两种方式" class="header-anchor">#</a> ReentrantReadWriteLock实现独占和共享两种方式</h5> <p>一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-
tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器
同时实现独占和共享两种方式，如ReentrantReadWriteLock。</p> <h2 id="_5-java-基础"><a href="#_5-java-基础" class="header-anchor">#</a> 5. JAVA 基础</h2> <h3 id="_5-1-1-java-异常分类及处理"><a href="#_5-1-1-java-异常分类及处理" class="header-anchor">#</a> 5.1.1. JAVA 异常分类及处理</h3> <h4 id="_5-1-1-1-概念"><a href="#_5-1-1-1-概念" class="header-anchor">#</a> 5.1.1.1. 概念</h4> <p>如果某个方法不能按照正常的途径完成任务，就可以通过另一种路径退出方法。在这种情况下
会抛出一个封装了错误信息的对象。此时，这个方法会立刻退出同时不返回任何值。另外，调用
这个方法的其他代码也无法继续执行，异常处理机制会将代码执行交给异常处理器。</p> <h4 id="_5-1-1-2-异常分类"><a href="#_5-1-1-2-异常分类" class="header-anchor">#</a> 5.1.1.2. 异常分类</h4> <p>Throwable是 Java 语言中所有错误或异常的超类。下一层分为Error和Exception</p> <h5 id="error"><a href="#error" class="header-anchor">#</a> Error</h5> <ol><li>Error类是指java运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果
出现了这样的错误，除了告知用户，剩下的就是尽力使程序安全的终止。</li></ol> <h5 id="exception-runtimeexception、checkedexception"><a href="#exception-runtimeexception、checkedexception" class="header-anchor">#</a> Exception（RuntimeException、CheckedException）</h5> <ol start="2"><li>Exception 又有两个分支，一个是运行时异常RuntimeException，一个是
CheckedException。</li></ol> <p><strong>RuntimeException</strong> 如：NullPointerException、ClassCastException；一个是检查异常
CheckedException，如I/O错误导致的IOException、SQLException。 RuntimeException是
那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 如果出现RuntimeException，那么一
定是程序员的错误.</p> <p><strong>检查异常CheckedException</strong> ：一般是外部错误，这种异常都发生在编译阶段，Java编译器会强
制程序去捕获此类异常，即会出现要求你把这段可能出现异常的程序进行try catch，该类异常一
般包括几个方面：</p> <ol><li>试图在文件尾部读取数据</li> <li>试图打开一个错误格式的URL</li> <li>试图根据给定的字符串查找class对象，而这个字符串表示的类并不存在</li></ol> <h4 id="_5-1-1-3-异常的处理方式"><a href="#_5-1-1-3-异常的处理方式" class="header-anchor">#</a> 5.1.1.3. 异常的处理方式</h4> <h5 id="遇到问题不进行具体处理-而是继续抛给调用者-throw-throws"><a href="#遇到问题不进行具体处理-而是继续抛给调用者-throw-throws" class="header-anchor">#</a> 遇到问题不进行具体处理，而是继续抛给调用者 （throw,throws）</h5> <p>抛出异常有三种形式，一是throw,一个throws，还有一种系统自动抛异常。</p> <div class="language- extra-class"><pre class="language-text"><code>public static void main(String[] args) {
String s = &quot;abc&quot;;
if(s.equals(&quot;abc&quot;)) {
throw new NumberFormatException();
} else {
System.out.println(s);
}
}
int div(int a,int b) throws Exception{
return a/b;}
</code></pre></div><h5 id="try-catch-捕获异常针对性处理方式"><a href="#try-catch-捕获异常针对性处理方式" class="header-anchor">#</a> try catch 捕获异常针对性处理方式</h5> <h4 id="_5-1-1-4-throw和throws的区别"><a href="#_5-1-1-4-throw和throws的区别" class="header-anchor">#</a> 5.1.1.4. Throw和throws的区别：</h4> <h5 id="位置不同"><a href="#位置不同" class="header-anchor">#</a> 位置不同</h5> <ol><li>throws用在函数上，后面跟的是异常类，可以跟多个；而throw用在函数内，后面跟的
是异常对象。</li></ol> <h5 id="功能不同"><a href="#功能不同" class="header-anchor">#</a> 功能不同：</h5> <ol start="2"><li><p>throws 用来声明异常，让调用者只知道该功能可能出现的问题，可以给出预先的处理方
式；throw抛出具体的问题对象，执行到throw，功能就已经结束了，跳转到调用者，并
将具体的问题对象抛给调用者。也就是说throw 语句独立存在时，下面不要定义其他语
句，因为执行不到。</p></li> <li><p>throws表示出现异常的一种可能性，并不一定会发生这些异常；throw则是抛出了异常，
执行throw则一定抛出了某种异常对象。</p></li> <li><p>两者都是消极处理异常的方式，只是抛出或者可能抛出异常，但是不会由函数去处理异
常，真正的处理异常由函数的上层调用处理。</p></li></ol> <h3 id="_5-1-2-java-反射"><a href="#_5-1-2-java-反射" class="header-anchor">#</a> 5.1.2. JAVA 反射</h3> <h4 id="_5-1-2-1-动态语言"><a href="#_5-1-2-1-动态语言" class="header-anchor">#</a> 5.1.2.1. 动态语言</h4> <p>动态语言，是指程序在运行时可以改变其结构：新的函数可以引进，已有的函数可以被删除等结
构上的变化。比如常见的JavaScript就是动态语言，除此之外Ruby,Python等也属于动态语言，
而C、C++则不属于动态语言。从反射角度说JAVA属于半动态语言。</p> <h4 id="_5-1-2-2-反射机制概念-运行状态中知道类所有的属性和方法"><a href="#_5-1-2-2-反射机制概念-运行状态中知道类所有的属性和方法" class="header-anchor">#</a> 5.1.2.2. 反射机制概念 （运行状态中知道类所有的属性和方法）</h4> <p>在Java中的反射机制是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；
并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方
法的功能成为Java语言的反射机制。</p> <h4 id="_5-1-2-3-反射的应用场合"><a href="#_5-1-2-3-反射的应用场合" class="header-anchor">#</a> 5.1.2.3. 反射的应用场合</h4> <h5 id="编译时类型和运行时类型"><a href="#编译时类型和运行时类型" class="header-anchor">#</a> 编译时类型和运行时类型</h5> <p>在Java程序中许多对象在运行是都会出现两种类型：编译时类型和运行时类型。 编译时的类型由
声明对象时实用的类型来决定，运行时的类型由实际赋值给对象的类型决定 。如：</p> <div class="language- extra-class"><pre class="language-text"><code>Person p=new Student();
</code></pre></div><p>其中编译时类型为Person，运行时类型为Student。</p> <h5 id="的编译时类型无法获取具体方法"><a href="#的编译时类型无法获取具体方法" class="header-anchor">#</a> 的编译时类型无法获取具体方法</h5> <p>程序在运行时还可能接收到外部传入的对象，该对象的编译时类型为Object,但是程序有需要调用
该对象的运行时类型的方法。为了解决这些问题，程序需要在运行时发现对象和类的真实信息。
然而，如果编译时根本无法预知该对象和类属于哪些类，程序只能依靠运行时信息来发现该对象
和类的真实信息，此时就必须使用到反射了。</p> <h4 id="_5-1-2-4-java反射api"><a href="#_5-1-2-4-java反射api" class="header-anchor">#</a> 5.1.2.4. Java反射API</h4> <h5 id="反射api用来生成jvm中的类、接口或则对象的信息。"><a href="#反射api用来生成jvm中的类、接口或则对象的信息。" class="header-anchor">#</a> 反射API用来生成JVM中的类、接口或则对象的信息。</h5> <ol><li>Class类：反射的核心类，可以获取类的属性，方法等信息。</li> <li>Field类：Java.lang.reflec包中的类，表示类的成员变量，可以用来获取和设置类之中的属性
值。</li> <li>Method类： Java.lang.reflec包中的类，表示类的方法，它可以用来获取类中的方法信息或
者执行方法。</li> <li>Constructor类： Java.lang.reflec包中的类，表示类的构造方法。</li></ol> <h4 id="_5-1-2-5-反射使用步骤-获取class对象、调用对象方法"><a href="#_5-1-2-5-反射使用步骤-获取class对象、调用对象方法" class="header-anchor">#</a> 5.1.2.5. 反射使用步骤（获取Class对象、调用对象方法）</h4> <ol><li>获取想要操作的类的Class对象，他是反射的核心，通过Class对象我们可以任意调用类的方
法。</li> <li>调用Class类中的方法，既就是反射的使用阶段。</li> <li>使用反射API来操作这些信息。</li></ol> <h4 id="_5-1-2-6-获取class对象的-3-种方法"><a href="#_5-1-2-6-获取class对象的-3-种方法" class="header-anchor">#</a> 5.1.2.6. 获取Class对象的 3 种方法</h4> <h5 id="调用某个对象的getclass-方法"><a href="#调用某个对象的getclass-方法" class="header-anchor">#</a> 调用某个对象的getClass()方法</h5> <div class="language- extra-class"><pre class="language-text"><code>Person p=new Person();
Class clazz=p.getClass();
</code></pre></div><h5 id="调用某个类的class属性来获取该类对应的class对象"><a href="#调用某个类的class属性来获取该类对应的class对象" class="header-anchor">#</a> 调用某个类的class属性来获取该类对应的Class对象</h5> <div class="language- extra-class"><pre class="language-text"><code>Class clazz=Person.class;
</code></pre></div><h5 id="使用class类中的forname-静态方法-最安全-性能最好"><a href="#使用class类中的forname-静态方法-最安全-性能最好" class="header-anchor">#</a> 使用Class类中的forName()静态方法(最安全/性能最好)</h5> <div class="language- extra-class"><pre class="language-text"><code>Class clazz=Class.forName(&quot;类的全路径&quot;); (最常用)
</code></pre></div><p>当我们获得了想要操作的类的Class对象后，可以通过Class类中的方法获取并查看该类中的方法
和属性。</p> <div class="language- extra-class"><pre class="language-text"><code>//获取Person类的Class对象
Class clazz=Class.forName(&quot;reflection.Person&quot;);
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>//获取Person类的所有方法信息
Method[] method=clazz.getDeclaredMethods();
for(Method m:method){
System.out.println(m.toString());
}
//获取Person类的所有成员属性信息
Field[] field=clazz.getDeclaredFields();
for(Field f:field){
System.out.println(f.toString());
}
//获取Person类的所有构造方法信息
Constructor[] constructor=clazz.getDeclaredConstructors();
for(Constructor c:constructor){
System.out.println(c.toString());
}
</code></pre></div><h4 id="_5-1-2-7-创建对象的两种方法"><a href="#_5-1-2-7-创建对象的两种方法" class="header-anchor">#</a> 5.1.2.7. 创建对象的两种方法</h4> <h5 id="class对象的newinstance"><a href="#class对象的newinstance" class="header-anchor">#</a> Class对象的newInstance()</h5> <ol><li>使用Class对象的newInstance()方法来创建该Class对象对应类的实例，但是这种方法要求
该Class对象对应的类有默认的空构造器。</li></ol> <h5 id="调用constructor对象的newinstance"><a href="#调用constructor对象的newinstance" class="header-anchor">#</a> 调用Constructor对象的newInstance()</h5> <ol start="2"><li>先使用Class对象获取指定的Constructor对象，再调用Constructor对象的newInstance()
方法来创建 Class对象对应类的实例,通过这种方法可以选定构造方法创建实例。
//获取Person类的Class对象
Class clazz=Class.forName(&quot;reflection.Person&quot;);
//使用.newInstane方法创建对象
Person p=(Person) clazz.newInstance();
//获取构造方法并创建对象
Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);
//创建对象并设置属性</li></ol> <div class="language- extra-class"><pre class="language-text"><code>Person p1=(Person) c.newInstance(&quot;李四&quot;,&quot;男&quot;,20);
</code></pre></div><h3 id="_5-1-3-java-注解"><a href="#_5-1-3-java-注解" class="header-anchor">#</a> 5.1.3. JAVA 注解</h3> <h4 id="_5-1-3-1-概念"><a href="#_5-1-3-1-概念" class="header-anchor">#</a> 5.1.3.1. 概念</h4> <p>Annotation（注解）是Java提供的一种对元程序中元素关联信息和元数据（metadata）的途径
和方法。Annatation(注解)是一个接口，程序可以通过反射来获取指定程序中元素的Annotation
对象，然后通过该Annotation对象来获取注解中的元数据信息。</p> <h4 id="_5-1-3-2-4-种标准元注解"><a href="#_5-1-3-2-4-种标准元注解" class="header-anchor">#</a> 5.1.3.2. 4 种标准元注解......................................................................................................................................</h4> <p>元注解的作用是负责注解其他注解。 Java5.0定义了 4 个标准的meta-annotation类型，它们被
用来提供对其它 annotation类型作说明。</p> <h5 id="target修饰的对象范围"><a href="#target修饰的对象范围" class="header-anchor">#</a> @Target修饰的对象范围</h5> <p>@Target说明了Annotation所修饰的对象范围： Annotation可被用于 packages、types（类、
接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数
和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了target可更加明晰
其修饰的目标</p> <h5 id="retention定义-被保留的时间长短"><a href="#retention定义-被保留的时间长短" class="header-anchor">#</a> @Retention定义 被保留的时间长短</h5> <p>Retention 定义了该Annotation被保留的时间长短：表示需要在什么级别保存注解信息，用于描
述注解的生命周期（即：被描述的注解在什么范围内有效），取值（RetentionPoicy）由：</p> <div class="language- extra-class"><pre class="language-text"><code> SOURCE:在源文件中有效（即源文件保留）
 CLASS:在class文件中有效（即class保留）
 RUNTIME:在运行时有效（即运行时保留）
</code></pre></div><h4 id="documented描述-javadoc"><a href="#documented描述-javadoc" class="header-anchor">#</a> @Documented描述-javadoc</h4> <p>@ Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因
此可以被例如javadoc此类的工具文档化。</p> <h4 id="inherited阐述了某个被标注的类型是被继承的"><a href="#inherited阐述了某个被标注的类型是被继承的" class="header-anchor">#</a> @Inherited阐述了某个被标注的类型是被继承的</h4> <p>@Inherited 元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一
个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该
class的子类。</p> <h4 id="_5-1-3-3-注解处理器"><a href="#_5-1-3-3-注解处理器" class="header-anchor">#</a> 5.1.3.3. 注解处理器.............................................................................................................................................</h4> <p>如果没有用来读取注解的方法和工作，那么注解也就不会比注释更有用处了。使用注解的过程中，
很重要的一部分就是创建于使用注解处理器。Java SE5扩展了反射机制的API，以帮助程序员快速
的构造自定义注解处理器。下面实现一个注解处理器。</p> <div class="language- extra-class"><pre class="language-text"><code>/1：*** 定义注解*/
@Target(ElementType.FIELD)
@Retention(RetentionPolicy.RUNTIME)
@Documented
public @interface FruitProvider {
/**供应商编号*/
public int id() default -1;
/*** 供应商名称*/
public String name() default &quot;&quot;；
</code></pre></div><p>/** * 供应商地址*/</p> <p>public String address() default &quot;&quot;;</p> <p>}</p> <p>// 2 ：注解使用</p> <p>public class Apple {</p> <p>@FruitProvider(id = 1, name = &quot;陕西红富士集团&quot;, address = &quot;陕西省西安市延安路&quot;)</p> <p>private String appleProvider;</p> <p>public void setAppleProvider(String appleProvider) {</p> <p>this.appleProvider = appleProvider;</p> <p>}</p> <p>public String getAppleProvider() {</p> <p>return appleProvider;</p> <p>}</p> <p>}</p> <p>/ 3 ：*********** 注解处理器 ***************/</p> <p>public class FruitInfoUtil {</p> <p>public static void getFruitInfo(Class&lt;?&gt; clazz) {</p> <p>String strFruitProvicer = &quot;供应商信息：&quot;;</p> <p>Field[] fields = clazz.getDeclaredFields();//通过反射获取处理注解</p> <p>for (Field field : fields) {</p> <p>if (field.isAnnotationPresent(FruitProvider.class)) {</p> <p>FruitProvider fruitProvider = (FruitProvider) field.getAnnotation(FruitProvider.class);</p> <div class="language- extra-class"><pre class="language-text"><code>//注解信息的处理地方
</code></pre></div><p>strFruitProvicer = &quot; 供应商编号：&quot; + fruitProvider.id() + &quot; 供应商名称：&quot;</p> <ul><li>fruitProvider.name() + &quot; 供应商地址：&quot;+ fruitProvider.address();</li></ul> <p>System.out.println(strFruitProvicer);</p> <p>}</p> <p>}</p> <p>}</p> <p>}</p> <div class="language- extra-class"><pre class="language-text"><code>public class FruitRun {
public static void main(String[] args) {
FruitInfoUtil.getFruitInfo(Apple.class);
/***********输出结果***************/
// 供应商编号： 1 供应商名称：陕西红富士集团 供应商地址：陕西省西安市延
}
}
</code></pre></div><h3 id="_5-1-4-java-内部类"><a href="#_5-1-4-java-内部类" class="header-anchor">#</a> 5.1.4. JAVA 内部类</h3> <p>Java 类中不仅可以定义变量和方法，还可以定义类，这样定义在类内部的类就被称为内部类。根
据定义的方式不同，内部类分为静态内部类，成员内部类，局部内部类，匿名内部类四种。</p> <h4 id="_5-1-4-1-静态内部类"><a href="#_5-1-4-1-静态内部类" class="header-anchor">#</a> 5.1.4.1. 静态内部类.............................................................................................................................................</h4> <p>定义在类内部的静态类，就是静态内部类。</p> <div class="language- extra-class"><pre class="language-text"><code>public class Out {
private static int a;
private int b;
public static class Inner {
public void print() {
System.out.println(a);
}
}
}
</code></pre></div><ol><li>静态内部类可以访问外部类所有的静态变量和方法，即使是private的也一样。</li> <li>静态内部类和一般类一致，可以定义静态变量、方法，构造方法等。</li> <li>其它类使用静态内部类需要使用“外部类.静态内部类”方式，如下所示：Out.Inner inner =
new Out.Inner();inner.print();</li> <li>Java集合类HashMap内部就有一个静态内部类Entry。Entry是HashMap存放元素的抽象，
HashMap内部维护Entry数组用了存放元素，但是Entry对使用者是透明的。像这种和外部
类关系密切的，且不依赖外部类实例的，都可以使用静态内部类。</li></ol> <h4 id="_5-1-4-2-成员内部类"><a href="#_5-1-4-2-成员内部类" class="header-anchor">#</a> 5.1.4.2. 成员内部类.............................................................................................................................................</h4> <p>定义在类内部的非静态类，就是成员内部类。成员内部类不能定义静态方法和变量（final修饰的
除外）。这是因为成员内部类是非静态的，类初始化的时候先初始化静态成员，如果允许成员内
部类定义静态变量，那么成员内部类的静态变量初始化顺序是有歧义的。</p> <div class="language- extra-class"><pre class="language-text"><code>public class Out {
private static int a;
private int b;
public class Inner {
public void print() {
System.out.println(a);
System.out.println(b);
}
}
}
</code></pre></div><h4 id="_5-1-4-3-局部内部类-定义在方法中的类"><a href="#_5-1-4-3-局部内部类-定义在方法中的类" class="header-anchor">#</a> 5.1.4.3. 局部内部类（定义在方法中的类）</h4> <p>定义在方法中的类，就是局部类。如果一个类只在某个方法中使用，则可以考虑使用局部类。</p> <div class="language- extra-class"><pre class="language-text"><code>public class Out {
private static int a;
private int b;
public void test(final int c) {
final int d = 1;
class Inner {
public void print() {
System.out.println(c);
}
}
}
}
</code></pre></div><h4 id="_5-1-4-4-匿名内部类-要继承一个父类或者实现一个接口、直接使用new来生成一个对象的引用"><a href="#_5-1-4-4-匿名内部类-要继承一个父类或者实现一个接口、直接使用new来生成一个对象的引用" class="header-anchor">#</a> 5.1.4.4. 匿名内部类（要继承一个父类或者实现一个接口、直接使用new来生成一个对象的引用）</h4> <p>匿名内部类我们必须要继承一个父类或者实现一个接口，当然也仅能只继承一个父类或者实现一
个接口。同时它也是没有class关键字，这是因为匿名内部类是直接使用new来生成一个对象的引
用。</p> <div class="language- extra-class"><pre class="language-text"><code>public abstract class Bird {
private String name;
public String getName() {
return name;
}
public void setName(String name) {
this.name = name;
}
public abstract int fly();
}
public class Test {
public void test(Bird bird){
System.out.println(bird.getName() + &quot;能够飞 &quot; + bird.fly() + &quot;米&quot;);
}
public static void main(String[] args) {
Test test = new Test();
test.test(new Bird() {
public int fly() {
return 10000;
}
public String getName() {
return &quot;大雁&quot;;
}
});
}
}
</code></pre></div><h3 id="_5-1-5-java-泛型"><a href="#_5-1-5-java-泛型" class="header-anchor">#</a> 5.1.5. JAVA 泛型</h3> <p>泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本
质是参数化类型，也就是说所操作的数据类型被指定为一个参数。比如我们要写一个排序方法，
能够对整型数组、字符串数组甚至其他任何类型的数组进行排序，我们就可以使用Java 泛型。</p> <h4 id="_5-1-5-1-泛型方法-e"><a href="#_5-1-5-1-泛型方法-e" class="header-anchor">#</a> 5.1.5.1. 泛型方法（&lt;E&gt;）</h4> <p>你可以写一个泛型方法，该方法在调用时可以接收不同类型的参数。根据传递给泛型方法的参数
类型，编译器适当地处理每一个方法调用。</p> <div class="language- extra-class"><pre class="language-text"><code>// 泛型方法 printArray
public static \&lt; E \&gt; void printArray( E[] inputArray )
{
for ( E element : inputArray ){
System.out.printf( &quot;%s &quot;, element );
}
}
</code></pre></div><ol><li>&lt;? extends T&gt;表示该通配符所代表的类型是T类型的子类。</li> <li>&lt;? super T&gt;表示该通配符所代表的类型是T类型的父类。</li></ol> <h4 id="_5-1-5-2-泛型类-t"><a href="#_5-1-5-2-泛型类-t" class="header-anchor">#</a> 5.1.5.2. 泛型类&lt;T&gt;</h4> <p>泛型类的声明和非泛型类的声明类似，除了在类名后面添加了类型参数声明部分。和泛型方法一
样，泛型类的类型参数声明部分也包含一个或多个类型参数，参数间用逗号隔开。一个泛型参数，
也被称为一个类型变量，是用于指定一个泛型类型名称的标识符。因为他们接受一个或多个参数，
这些类被称为参数化的类或参数化的类型。</p> <div class="language- extra-class"><pre class="language-text"><code>public class Box\&lt;T\&gt; {
private T t;
public void add(T t) {
this.t = t;
}
public T get() {
return t;
}
</code></pre></div><h4 id="_5-1-5-3-类型通配符"><a href="#_5-1-5-3-类型通配符" class="header-anchor">#</a> 5.1.5.3. 类型通配符?</h4> <div class="language- extra-class"><pre class="language-text"><code>类型通配符一般是使用?代替具体的类型参数。例如 List\&lt;?\&gt; 在逻辑上是
List\&lt;String\&gt;,List\&lt;Integer\&gt; 等所有List\&lt;具体类型实参\&gt;的父类。
</code></pre></div><h4 id="_5-1-5-4-类型擦除"><a href="#_5-1-5-4-类型擦除" class="header-anchor">#</a> 5.1.5.4. 类型擦除</h4> <div class="language- extra-class"><pre class="language-text"><code>Java中的泛型基本上都是在编译器这个层次来实现的。在生成的Java字节代码中是不包含泛
型中的类型信息的。使用泛型的时候加上的类型参数，会被编译器在编译的时候去掉。这个
过程就称为类型擦除。如在代码中定义的List\&lt;Object\&gt;和List\&lt;String\&gt;等类型，在编译之后
都会变成List。JVM看到的只是List，而由泛型附加的类型信息对JVM来说是不可见的。
类型擦除的基本过程也比较简单，首先是找到用来替换类型参数的具体类。这个具体类一般
是Object。如果指定了类型参数的上界的话，则使用这个上界。把代码中的类型参数都替换
成具体的类。
</code></pre></div><h3 id="_5-1-6-java-序列化-创建可复用的-java-对象"><a href="#_5-1-6-java-序列化-创建可复用的-java-对象" class="header-anchor">#</a> 5.1.6. JAVA 序列化 ( 创建可复用的 Java 对象 )</h3> <h5 id="保存-持久化-对象及其状态到内存或者磁盘"><a href="#保存-持久化-对象及其状态到内存或者磁盘" class="header-anchor">#</a> 保存(持久化)对象及其状态到内存或者磁盘</h5> <p>Java平台允许我们在内存中创建可复用的Java对象，但一般情况下，只有当JVM处于运行时，
这些对象才可能存在，即，这些对象的生命周期不会比JVM的生命周期更长。但在现实应用中，
就可能要求在JVM停止运行之后能够保存(持久化)指定的对象，并在将来重新读取被保存的对象。
Java对象序列化就能够帮助我们实现该功能。</p> <h5 id="序列化对象以字节数组保持-静态成员不保存"><a href="#序列化对象以字节数组保持-静态成员不保存" class="header-anchor">#</a> 序列化对象以字节数组保持-静态成员不保存</h5> <p>使用Java对象序列化，在保存对象时，会把其状态保存为一组字节，在未来，再将这些字节组装
成对象。必须注意地是，对象序列化保存的是对象的”状态”，即它的成员变量。由此可知，对
象序列化不会关注类中的静态变量。</p> <h5 id="序列化用户远程对象传输"><a href="#序列化用户远程对象传输" class="header-anchor">#</a> 序列化用户远程对象传输</h5> <p>除了在持久化对象时会用到对象序列化之外，当使用RMI(远程方法调用)，或在网络中传递对象时，
都会用到对象序列化。Java序列化API为处理对象序列化提供了一个标准机制，该API简单易用。</p> <h5 id="serializable实现序列化"><a href="#serializable实现序列化" class="header-anchor">#</a> Serializable实现序列化</h5> <p>在Java中，只要一个类实现了java.io.Serializable接口，那么它就可以被序列化。</p> <h5 id="objectoutputstream和objectinputstream对对象进行序列化及反序列化"><a href="#objectoutputstream和objectinputstream对对象进行序列化及反序列化" class="header-anchor">#</a> ObjectOutputStream和ObjectInputStream对对象进行序列化及反序列化...............................................</h5> <p>通过ObjectOutputStream和ObjectInputStream对对象进行序列化及反序列化。</p> <h5 id="writeobject-和-readobject自定义序列化策略"><a href="#writeobject-和-readobject自定义序列化策略" class="header-anchor">#</a> writeObject 和 readObject自定义序列化策略</h5> <p>在类中增加writeObject 和 readObject 方法可以实现自定义序列化策略。</p> <h5 id="序列化-id"><a href="#序列化-id" class="header-anchor">#</a> 序列化 ID.............................................................................................................................................................</h5> <p>虚拟机是否允许反序列化，不仅取决于类路径和功能代码是否一致，一个非常重要的一点是两个
类的序列化 ID 是否一致（就是 private static final long serialVersionUID）</p> <h5 id="序列化并不保存静态变量"><a href="#序列化并不保存静态变量" class="header-anchor">#</a> 序列化并不保存静态变量</h5> <h5 id="序列化子父类说明"><a href="#序列化子父类说明" class="header-anchor">#</a> 序列化子父类说明</h5> <p>要想将父类对象也序列化，就需要让父类也实现Serializable 接口。</p> <h5 id="transient-关键字阻止该变量被序列化到文件中"><a href="#transient-关键字阻止该变量被序列化到文件中" class="header-anchor">#</a> Transient 关键字阻止该变量被序列化到文件中</h5> <ol><li>在变量声明前加上Transient 关键字，可以阻止该变量被序列化到文件中，在被反序列
化后，transient 变量的值被设为初始值，如 int 型的是 0 ，对象型的是 null。</li> <li>服务器端给客户端发送序列化对象数据，对象中有一些数据是敏感的，比如密码字符串
等，希望对该密码字段在序列化时，进行加密，而客户端如果拥有解密的密钥，只有在
客户端进行反序列化时，才可以对密码进行读取，这样可以一定程度保证序列化对象的
数据安全。</li></ol> <h3 id="_5-1-7-java-复制"><a href="#_5-1-7-java-复制" class="header-anchor">#</a> 5 .1.7. JAVA 复制</h3> <p>将一个对象的引用复制给另外一个对象，一共有三种方式。第一种方式是直接赋值，第二种方式
是浅拷贝，第三种是深拷贝。所以大家知道了哈，这三种概念实际上都是为了拷贝对象。</p> <h4 id="_5-1-7-1-直接赋值复制"><a href="#_5-1-7-1-直接赋值复制" class="header-anchor">#</a> 5.1.7.1. 直接赋值复制</h4> <div class="language- extra-class"><pre class="language-text"><code>直接赋值。在Java中，A a1 = a2，我们需要理解的是这实际上复制的是引用，也就是
说a1和a2指向的是同一个对象。因此，当a1变化的时候，a2里面的成员变量也会跟
着变化。
</code></pre></div><h4 id="_5-1-7-2-浅复制-复制引用但不复制引用的对象"><a href="#_5-1-7-2-浅复制-复制引用但不复制引用的对象" class="header-anchor">#</a> 5.1.7.2. 浅复制（复制引用但不复制引用的对象）</h4> <div class="language- extra-class"><pre class="language-text"><code>创建一个新对象，然后将当前对象的非静态字段复制到该新对象，如果字段是值类型的，
那么对该字段执行复制；如果该字段是引用类型的话，则复制引用但不复制引用的对象。
因此，原始对象及其副本引用同一个对象。
class Resume implements Cloneable{
public Object clone() {
try {
return (Resume)super.clone();
} catch (Exception e) {
e.printStackTrace();
return null;
}
}
}
</code></pre></div><h4 id="_5-1-7-3-深复制-复制对象和其应用对象"><a href="#_5-1-7-3-深复制-复制对象和其应用对象" class="header-anchor">#</a> 5.1.7.3. 深复制（复制对象和其应用对象）</h4> <p>深拷贝不仅复制对象本身，而且复制对象包含的引用指向的所有对象。</p> <div class="language- extra-class"><pre class="language-text"><code>class Student implements Cloneable {
String name;
int age;
Professor p;
Student(String name, int age, Professor p) {
this.name = name;
this.age = age;
this.p = p;
}
public Object clone() {
Student o = null;
try {
o = (Student) super.clone();
} catch (CloneNotSupportedException e) {
System.out.println(e.toString());
}
o.p = (Professor) p.clone();
return o;
}
}
</code></pre></div><h4 id="_5-1-7-4-序列化-深clone一中实现"><a href="#_5-1-7-4-序列化-深clone一中实现" class="header-anchor">#</a> 5.1.7.4. 序列化（深clone一中实现）</h4> <div class="language- extra-class"><pre class="language-text"><code>在Java语言里深复制一个对象，常常可以先使对象实现Serializable接口，然后把对
象（实际上只是对象的一个拷贝）写到一个流里，再从流里读出来，便可以重建对象。
</code></pre></div><h2 id="_6-spring-原理"><a href="#_6-spring-原理" class="header-anchor">#</a> 6. SPRING 原理</h2> <p>它是一个全面的、企业应用开发一站式的解决方案，贯穿表现层、业务层、持久层。但是 Spring
仍然可以和其他的框架无缝整合。</p> <h3 id="_6-1-1-spring-特点"><a href="#_6-1-1-spring-特点" class="header-anchor">#</a> 6.1.1. Spring 特点</h3> <h4 id="_6-1-1-1-轻量级"><a href="#_6-1-1-1-轻量级" class="header-anchor">#</a> 6.1.1.1. 轻量级</h4> <h3 id="_6-1-1-2-控制反转"><a href="#_6-1-1-2-控制反转" class="header-anchor">#</a> 6.1.1.2. 控制反转</h3> <h3 id="_6-1-1-3-面向切面"><a href="#_6-1-1-3-面向切面" class="header-anchor">#</a> 6.1.1.3. 面向切面</h3> <h3 id="_6-1-1-4-容器"><a href="#_6-1-1-4-容器" class="header-anchor">#</a> 6.1.1.4. 容器</h3> <h3 id="_6-1-1-5-框架集合"><a href="#_6-1-1-5-框架集合" class="header-anchor">#</a> 6.1.1.5. 框架集合</h3> <h2 id="_6-1-2-spring-核心组件"><a href="#_6-1-2-spring-核心组件" class="header-anchor">#</a> 6.1.2. Spring 核心组件</h2> <h2 id="_6-1-3-spring-常用模块"><a href="#_6-1-3-spring-常用模块" class="header-anchor">#</a> 6.1.3. Spring 常用模块</h2> <h2 id="_6-1-4-spring-主要包"><a href="#_6-1-4-spring-主要包" class="header-anchor">#</a> 6.1.4. Spring 主要包</h2> <h2 id="_6-1-5-spring-常用注解"><a href="#_6-1-5-spring-常用注解" class="header-anchor">#</a> 6.1.5. Spring 常用注解</h2> <p>bean注入与装配的的方式有很多种，可以通过xml，get set方式，构造函数或者注解等。简单易
用的方式就是使用Spring的注解了，Spring提供了大量的注解方式。</p> <h2 id="_6-1-6-spring-第三方结合"><a href="#_6-1-6-spring-第三方结合" class="header-anchor">#</a> 6.1.6. Spring 第三方结合</h2> <h2 id="_6-1-7-spring-ioc-原理"><a href="#_6-1-7-spring-ioc-原理" class="header-anchor">#</a> 6.1.7. Spring IOC 原理</h2> <h3 id="_6-1-7-1-概念"><a href="#_6-1-7-1-概念" class="header-anchor">#</a> 6.1.7.1. 概念</h3> <p>Spring 通过一个配置文件描述 Bean 及 Bean 之间的依赖关系，利用 Java 语言的反射功能实例化
Bean 并建立 Bean 之间的依赖关系。 Spring 的 IoC 容器在完成这些底层工作的基础上，还提供
了 Bean 实例缓存、生命周期管理、 Bean 实例代理、事件发布、资源装载等高级服务。</p> <h3 id="_6-1-7-2-spring容器高层视图"><a href="#_6-1-7-2-spring容器高层视图" class="header-anchor">#</a> 6.1.7.2. Spring容器高层视图</h3> <p>Spring 启动时读取应用程序提供的Bean配置信息，并在Spring容器中生成一份相应的Bean配
置注册表，然后根据这张注册表实例化Bean，装配好Bean之间的依赖关系，为上层应用提供准
备就绪的运行环境。其中Bean缓存池为HashMap实现</p> <h3 id="_6-1-7-3-ioc容器实现"><a href="#_6-1-7-3-ioc容器实现" class="header-anchor">#</a> 6.1.7.3. IOC容器实现</h3> <h4 id="beanfactory-框架基础设施"><a href="#beanfactory-框架基础设施" class="header-anchor">#</a> BeanFactory-框架基础设施</h4> <div class="language- extra-class"><pre class="language-text"><code>BeanFactory 是 Spring 框架的基础设施，面向 Spring 本身；ApplicationContext 面向使用
Spring 框架的开发者，几乎所有的应用场合我们都直接使用 ApplicationContext 而非底层
的 BeanFactory。
</code></pre></div><h5 id="_1-1-1-1-1-beandefinitionregistry注册表"><a href="#_1-1-1-1-1-beandefinitionregistry注册表" class="header-anchor">#</a> 1.1..1.1.1 BeanDefinitionRegistry注册表.................................................................................................</h5> <ol><li>Spring 配置文件中每一个节点元素在 Spring 容器里都通过一个 BeanDefinition 对象表示，
它描述了 Bean 的配置信息。而 BeanDefinitionRegistry 接口提供了向容器手工注册
BeanDefinition 对象的方法。</li></ol> <h5 id="_1-1-1-1-2-beanfactory-顶层接口"><a href="#_1-1-1-1-2-beanfactory-顶层接口" class="header-anchor">#</a> 1.1..1.1.2 BeanFactory 顶层接口</h5> <ol start="2"><li>位于类结构树的顶端 ，它最主要的方法就是 getBean(String beanName)，该方法从容器中
返回特定名称的 Bean，BeanFactory 的功能通过其他的接口得到不断扩展：</li></ol> <h5 id="_1-1-1-1-3-listablebeanfactory"><a href="#_1-1-1-1-3-listablebeanfactory" class="header-anchor">#</a> 1.1..1.1.3 ListableBeanFactory</h5> <ol start="3"><li>该接口定义了访问容器中 Bean 基本信息的若干方法，如查看 Bean 的个数、获取某一类型
Bean 的配置名、查看容器中是否包括某一 Bean 等方法；</li></ol> <h5 id="_1-1-1-1-4-hierarchicalbeanfactory父子级联"><a href="#_1-1-1-1-4-hierarchicalbeanfactory父子级联" class="header-anchor">#</a> 1.1..1.1.4 HierarchicalBeanFactory父子级联..........................................................................................</h5> <ol start="4"><li>父子级联 IoC 容器的接口，子容器可以通过接口方法访问父容器； 通过
HierarchicalBeanFactory 接口， Spring 的 IoC 容器可以建立父子层级关联的容器体系，子
容器可以访问父容器中的 Bean，但父容器不能访问子容器的 Bean。Spring 使用父子容器实
现了很多功能，比如在 Spring MVC 中，展现层 Bean 位于一个子容器中，而业务层和持久
层的 Bean 位于父容器中。这样，展现层 Bean 就可以引用业务层和持久层的 Bean，而业务
层和持久层的 Bean 则看不到展现层的 Bean。</li></ol> <h5 id="_1-1-1-1-5-configurablebeanfactory"><a href="#_1-1-1-1-5-configurablebeanfactory" class="header-anchor">#</a> 1.1..1.1.5 ConfigurableBeanFactory</h5> <ol start="5"><li>是一个重要的接口，增强了 IoC 容器的可定制性，它定义了设置类装载器、属性编辑器、容
器初始化后置处理器等方法；</li></ol> <h5 id="_1-1-1-1-6-autowirecapablebeanfactory自动装配"><a href="#_1-1-1-1-6-autowirecapablebeanfactory自动装配" class="header-anchor">#</a> 1.1..1.1.6 AutowireCapableBeanFactory自动装配</h5> <ol start="6"><li>定义了将容器中的 Bean 按某种规则（如按名字匹配、按类型匹配等）进行自动装配的方法；</li></ol> <h5 id="_1-1-1-1-7-singletonbeanregistry运行期间注册单例bean"><a href="#_1-1-1-1-7-singletonbeanregistry运行期间注册单例bean" class="header-anchor">#</a> 1.1..1.1. 7 SingletonBeanRegistry运行期间注册单例Bean</h5> <ol start="7"><li>定义了允许在运行期间向容器注册单实例 Bean 的方法；对于单实例（ singleton）的 Bean
来说，BeanFactory会缓存 Bean 实例，所以第二次使用 getBean() 获取 Bean 时将直接从
IoC 容器的缓存中获取 Bean 实例。Spring 在 DefaultSingletonBeanRegistry 类中提供了一
个用于缓存单实例 Bean 的缓存器，它是一个用HashMap 实现的缓存器，单实例的 Bean 以
beanName 为键保存在这个HashMap 中。</li></ol> <h5 id="_1-1-1-1-8-依赖日志框框"><a href="#_1-1-1-1-8-依赖日志框框" class="header-anchor">#</a> 1.1..1.1.8 依赖日志框框</h5> <ol start="8"><li>在初始化 BeanFactory 时，必须为其提供一种日志框架，比如使用Log4J， 即在类路径下提
供 Log4J 配置文件，这样启动 Spring 容器才不会报错。</li></ol> <h4 id="applicationcontext面向开发应用"><a href="#applicationcontext面向开发应用" class="header-anchor">#</a> ApplicationContext面向开发应用</h4> <p>ApplicationContext 由 BeanFactory 派生而来，提供了更多面向实际应用的功能。
ApplicationContext 继承了 HierarchicalBeanFactory 和 ListableBeanFactory 接口，在此基础
上，还通过多个其他的接口扩展了 BeanFactory 的功能：</p> <ol><li><p>ClassPathXmlApplicationContext：默认从类路径加载配置文件</p></li> <li><p>FileSystemXmlApplicationContext：默认从文件系统中装载配置文件</p></li> <li><p>ApplicationEventPublisher：让容器拥有发布应用上下文事件的功能，包括容器启动事
件、关闭事件等。</p></li> <li><p>MessageSource：为应用提供 i18n 国际化消息访问的功能；</p></li> <li><p>ResourcePatternResolver ： 所 有 ApplicationContext 实现类都实现了类似于
PathMatchingResourcePatternResolver 的功能，可以通过带前缀的 Ant 风格的资源文
件路径装载 Spring 的配置文件。</p></li> <li><p>LifeCycle：该接口是 Spring 2.0 加入的，该接口提供了 start()和 stop()两个方法，主要
用于控制异步处理过程。在具体使用时，该接口同时被 ApplicationContext 实现及具体
Bean 实现， ApplicationContext 会将 start/stop 的信息传递给容器中所有实现了该接
口的 Bean，以达到管理和控制 JMX、任务调度等目的。</p></li> <li><p>ConfigurableApplicationContext 扩展于 ApplicationContext，它新增加了两个主要
的方法： refresh()和 close()，让 ApplicationContext 具有启动、刷新和关闭应用上下
文的能力。在应用上下文关闭的情况下调用 refresh()即可启动应用上下文，在已经启动
的状态下，调用 refresh()则清除缓存并重新装载配置信息，而调用close()则可关闭应用
上下文。</p></li></ol> <h4 id="webapplication体系架构"><a href="#webapplication体系架构" class="header-anchor">#</a> WebApplication体系架构</h4> <div class="language- extra-class"><pre class="language-text"><code>WebApplicationContext 是专门为 Web 应用准备的，它允许从相对于 Web 根目录的
路径中装载配置文件完成初始化工作。从WebApplicationContext 中可以获得
ServletContext 的引用，整个 Web 应用上下文对象将作为属性放置到 ServletContext
中，以便 Web 应用环境可以访问 Spring 应用上下文。
</code></pre></div><h3 id="_6-1-7-4-spring-bean-作用域"><a href="#_6-1-7-4-spring-bean-作用域" class="header-anchor">#</a> 6.1.7.4. Spring Bean 作用域</h3> <p>Spring 3中为 Bean定义了 5 中作用域，分别为 singleton（单例）、prototype（原型）、
request、session和global session， 5 种作用域说明如下：</p> <h4 id="singleton-单例模式-多线程下不安全"><a href="#singleton-单例模式-多线程下不安全" class="header-anchor">#</a> singleton：单例模式（多线程下不安全）</h4> <ol><li>singleton：单例模式，Spring IoC 容器中只会存在一个共享的Bean实例，无论有多少个
Bean 引用它，始终指向同一对象。该模式在多线程下是不安全的。Singleton作用域是
Spring中的缺省作用域，也可以显示的将Bean定义为singleton模式，配置为：
&lt;bean id=&quot;userDao&quot; class=&quot;com.ioc.UserDaoImpl&quot; scope=&quot;singleton&quot;/&gt;</li></ol> <h4 id="prototype-原型模式每次使用时创建"><a href="#prototype-原型模式每次使用时创建" class="header-anchor">#</a> prototype:原型模式每次使用时创建</h4> <ol start="2"><li>prototype:原型模式，每次通过Spring容器获取prototype定义的bean时，容器都将创建
一个新的Bean实例，每个Bean实例都有自己的属性和状态，而singleton全局只有一个对
象。根据经验，对有状态的bean使用prototype作用域，而对无状态的bean使用singleton
作用域。</li></ol> <h4 id="request-一次request一个实例"><a href="#request-一次request一个实例" class="header-anchor">#</a> Request：一次request一个实例</h4> <ol start="3"><li>request：在一次Http请求中，容器会返回该Bean的同一实例。而对不同的Http请求则会
产生新的Bean，而且该bean仅在当前Http Request内有效,当前Http请求结束，该bean
实例也将会被销毁。</li></ol> <p>&lt;bean id=&quot;loginAction&quot; class=&quot;com.cnblogs.Login&quot; scope=&quot;request&quot;/&gt;</p> <h4 id="session"><a href="#session" class="header-anchor">#</a> session</h4> <ol start="4"><li>session：在一次Http Session中，容器会返回该Bean的同一实例。而对不同的Session请
求则会创建新的实例，该bean实例仅在当前Session内有效。同Http请求相同，每一次
session请求创建新的实例，而不同的实例之间不共享属性，且实例仅在自己的session请求
内有效，请求结束，则实例将被销毁。
&lt;bean id=&quot;userPreference&quot; class=&quot;com.ioc.UserPreference&quot; scope=&quot;session&quot;/&gt;</li></ol> <h4 id="global-session"><a href="#global-session" class="header-anchor">#</a> global Session</h4> <ol start="5"><li>global Session：在一个全局的Http Session中，容器会返回该Bean的同一个实例，仅在
使用portlet context时有效。</li></ol> <h3 id="_6-1-7-5-spring-bean-生命周期"><a href="#_6-1-7-5-spring-bean-生命周期" class="header-anchor">#</a> 6.1.7.5. Spring Bean 生命周期</h3> <h4 id="实例化"><a href="#实例化" class="header-anchor">#</a> 实例化</h4> <ol><li>实例化一个Bean，也就是我们常说的new。</li></ol> <h4 id="ioc依赖注入"><a href="#ioc依赖注入" class="header-anchor">#</a> IOC依赖注入</h4> <ol start="2"><li>按照Spring上下文对实例化的Bean进行配置，也就是IOC注入。</li></ol> <h4 id="setbeanname实现"><a href="#setbeanname实现" class="header-anchor">#</a> setBeanName实现</h4> <ol start="3"><li>如果这个Bean已经实现了BeanNameAware接口，会调用它实现的setBeanName(String)
方法，此处传递的就是Spring配置文件中Bean的id值</li></ol> <h4 id="beanfactoryaware实现"><a href="#beanfactoryaware实现" class="header-anchor">#</a> BeanFactoryAware实现</h4> <ol start="4"><li>如果这个Bean已经实现了BeanFactoryAware接口，会调用它实现的 setBeanFactory，
setBeanFactory(BeanFactory)传递的是Spring工厂自身（可以用这个方式来获取其它Bean，
只需在Spring配置文件中配置一个普通的Bean就可以）。</li></ol> <h4 id="applicationcontextaware实现"><a href="#applicationcontextaware实现" class="header-anchor">#</a> ApplicationContextAware实现.........................................................................................................................</h4> <ol start="5"><li>如果这个Bean已经实现了ApplicationContextAware接口，会调用
setApplicationContext(ApplicationContext)方法，传入Spring上下文（同样这个方式也
可以实现步骤 4 的内容，但比 4 更好，因为ApplicationContext是BeanFactory的子接
口，有更多的实现方法）</li></ol> <h4 id="postprocessbeforeinitialization接口实现-初始化预处理"><a href="#postprocessbeforeinitialization接口实现-初始化预处理" class="header-anchor">#</a> postProcessBeforeInitialization接口实现-初始化预处理</h4> <ol start="6"><li>如果这个Bean关联了BeanPostProcessor接口，将会调用
postProcessBeforeInitialization(Object obj, String s)方法，BeanPostProcessor经常被用
作是Bean内容的更改，并且由于这个是在Bean初始化结束时调用那个的方法，也可以被应
用于内存或缓存技术。</li></ol> <h4 id="init-method"><a href="#init-method" class="header-anchor">#</a> init-method</h4> <ol start="7"><li>如果Bean在Spring配置文件中配置了init-method属性会自动调用其配置的初始化方法。</li></ol> <h4 id="postprocessafterinitialization"><a href="#postprocessafterinitialization" class="header-anchor">#</a> postProcessAfterInitialization</h4> <ol start="8"><li>如果这个Bean关联了BeanPostProcessor接口，将会调用
postProcessAfterInitialization(Object obj, String s)方法。
注：以上工作完成以后就可以应用这个Bean了，那这个Bean是一个Singleton的，所以一
般情况下我们调用同一个id的Bean会是在内容地址相同的实例，当然在Spring配置文件中
也可以配置非Singleton。</li></ol> <h4 id="destroy过期自动清理阶段"><a href="#destroy过期自动清理阶段" class="header-anchor">#</a> Destroy过期自动清理阶段</h4> <ol start="9"><li>当Bean不再需要时，会经过清理阶段，如果Bean实现了DisposableBean这个接口，会调
用那个其实现的destroy()方法；</li></ol> <h4 id="destroy-method自配置清理"><a href="#destroy-method自配置清理" class="header-anchor">#</a> destroy-method自配置清理</h4> <ol start="10"><li><p>最后，如果这个Bean的Spring配置中配置了destroy-method属性，会自动调用其配置的
销毁方法。</p></li> <li><p>bean 标签有两个重要的属性（init-method和destroy-method）。用它们你可以自己定制
初始化和注销方法。它们也有相应的注解（@PostConstruct和@PreDestroy）。</p></li></ol> <p>&lt;bean id=&quot;&quot; class=&quot;&quot; init-method=&quot;初始化方法&quot; destroy-method=&quot;销毁方法&quot;&gt;</p> <h3 id="_6-1-7-6-spring-依赖注入四种方式"><a href="#_6-1-7-6-spring-依赖注入四种方式" class="header-anchor">#</a> 6.1.7.6. Spring 依赖注入四种方式</h3> <h4 id="构造器注入"><a href="#构造器注入" class="header-anchor">#</a> 构造器注入</h4> <div class="language- extra-class"><pre class="language-text"><code>/*带参数，方便利用构造器进行注入*/
public CatDaoImpl(String message){
this. message = message;
}
\&lt;bean id=&quot;CatDaoImpl&quot; class=&quot;com.CatDaoImpl&quot;\&gt;
\&lt;constructor-arg value=&quot; message &quot;\&gt;\&lt;/constructor-arg\&gt;
\&lt;/bean\&gt;
</code></pre></div><h4 id="setter方法注入"><a href="#setter方法注入" class="header-anchor">#</a> setter方法注入</h4> <div class="language- extra-class"><pre class="language-text"><code>public class Id {
private int id;
public int getId() { return id; }
public void setId(int id) { this.id = id; }
}
\&lt;bean id=&quot;id&quot; class=&quot;com.id &quot;\&gt; \&lt;property name=&quot;id&quot; value=&quot;123&quot;\&gt;\&lt;/property\&gt; \&lt;/bean\&gt;
</code></pre></div><h4 id="静态工厂注入"><a href="#静态工厂注入" class="header-anchor">#</a> 静态工厂注入</h4> <p>静态工厂顾名思义，就是通过调用静态工厂的方法来获取自己需要的对象，为了让spring管理所
有对象，我们不能直接通过&quot;工程类.静态方法()&quot;来获取对象，而是依然通过spring注入的形式获
取：</p> <div class="language- extra-class"><pre class="language-text"><code>public class DaoFactory { //静态工厂
public static final FactoryDao getStaticFactoryDaoImpl(){
return new StaticFacotryDaoImpl();
}
}
public class SpringAction {
private FactoryDao staticFactoryDao; //注入对象
//注入对象的set方法
public void setStaticFactoryDao(FactoryDao staticFactoryDao) {
this.staticFactoryDao = staticFactoryDao;
}
}
//factory-method=&quot;getStaticFactoryDaoImpl&quot;指定调用哪个工厂方法
\&lt;bean name=&quot;springAction&quot; class=&quot; SpringAction&quot; \&gt;
\&lt;!--使用静态工厂的方法注入对象,对应下面的配置文件--\&gt;
\&lt;property name=&quot;staticFactoryDao&quot; ref=&quot;staticFactoryDao&quot;\&gt;\&lt;/property\&gt;
\&lt;/bean\&gt;
\&lt;!--此处获取对象的方式是从工厂类中获取静态方法--\&gt;
\&lt;bean name=&quot;staticFactoryDao&quot; class=&quot;DaoFactory&quot;
factory-method=&quot;getStaticFactoryDaoImpl&quot;\&gt;\&lt;/bean\&gt;
</code></pre></div><h4 id="实例工厂"><a href="#实例工厂" class="header-anchor">#</a> 实例工厂</h4> <p>实例工厂的意思是获取对象实例的方法不是静态的，所以你需要首先new工厂类，再调用普通的
实例方法：</p> <div class="language- extra-class"><pre class="language-text"><code>public class DaoFactory { //实例工厂
public FactoryDao getFactoryDaoImpl(){
return new FactoryDaoImpl();
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>}
}
public class SpringAction {
private FactoryDao factoryDao; //注入对象
public void setFactoryDao(FactoryDao factoryDao) {
this.factoryDao = factoryDao;
}
}
\&lt;bean name=&quot;springAction&quot; class=&quot;SpringAction&quot;\&gt;
\&lt;!--使用实例工厂的方法注入对象,对应下面的配置文件--\&gt;
\&lt;property name=&quot;factoryDao&quot; ref=&quot;factoryDao&quot;\&gt;\&lt;/property\&gt;
\&lt;/bean\&gt;
\&lt;!--此处获取对象的方式是从工厂类中获取实例方法--\&gt;
\&lt;bean name=&quot;daoFactory&quot; class=&quot;com.DaoFactory&quot;\&gt;\&lt;/bean\&gt;
\&lt;bean name=&quot;factoryDao&quot; factory-bean=&quot;daoFactory&quot;
factory-method=&quot;getFactoryDaoImpl&quot;\&gt;\&lt;/bean\&gt;
</code></pre></div><h3 id="_6-1-7-7-5-种不同方式的自动装配"><a href="#_6-1-7-7-5-种不同方式的自动装配" class="header-anchor">#</a> 6.1.7.7. 5 种不同方式的自动装配</h3> <p>Spring装配包括手动装配和自动装配，手动装配是有基于xml装配、构造方法、setter方法等</p> <p>自动装配有五种自动装配的方式，可以用来指导Spring容器用自动装配方式来进行依赖注入。</p> <ol><li>no：默认的方式是不进行自动装配，通过显式设置ref 属性来进行装配。</li> <li>byName：通过参数名 自动装配，Spring容器在配置文件中发现bean的autowire属性被设
置成byname，之后容器试图匹配、装配和该bean的属性具有相同名字的bean。</li> <li>byType：通过参数类型自动装配，Spring容器在配置文件中发现bean的autowire属性被
设置成byType，之后容器试图匹配、装配和该bean的属性具有相同类型的bean。如果有多
个bean符合条件，则抛出错误。</li> <li>constructor：这个方式类似于byType， 但是要提供给构造器参数，如果没有确定的带参数
的构造器参数类型，将会抛出异常。</li> <li>autodetect：首先尝试使用constructor来自动装配，如果无法工作，则使用byType方式。</li></ol> <h2 id="_6-1-8-spring-apo-原理"><a href="#_6-1-8-spring-apo-原理" class="header-anchor">#</a> 6.1.8. Spring APO 原理</h2> <h3 id="_6-1-8-1-概念"><a href="#_6-1-8-1-概念" class="header-anchor">#</a> 6.1.8.1. 概念</h3> <p>&quot;横切&quot;的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，
并将其命名为&quot;Aspect&quot;，即切面。所谓&quot;切面&quot;，简单说就是那些与业务无关，却为业务模块所共
同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未
来的可操作性和可维护性。</p> <p>使用&quot;横切&quot;技术，AOP 把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流
程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生
在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统
中的各种关注点，将核心关注点和横切关注点分离开来。</p> <p>AOP主要应用场景有：</p> <ol><li>Authentication 权限</li> <li>Caching 缓存</li> <li>Context passing 内容传递</li> <li>Error handling 错误处理</li> <li>Lazy loading 懒加载</li> <li>Debugging 调试</li> <li>logging, tracing, profiling and monitoring 记录跟踪 优化 校准</li> <li>Performance optimization 性能优化</li> <li>Persistence 持久化</li> <li>Resource pooling 资源池</li> <li>Synchronization 同步</li> <li>Transactions 事务</li></ol> <h3 id="_6-1-8-2-aop核心概念"><a href="#_6-1-8-2-aop核心概念" class="header-anchor">#</a> 6.1.8.2. AOP核心概念</h3> <p>1 、切面（aspect）：类是对物体特征的抽象，切面就是对横切关注点的抽象</p> <p>2 、横切关注点：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点。</p> <p>3 、连接点（joinpoint）：被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring
中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器。</p> <p>4 、切入点（pointcut）：对连接点进行拦截的定义</p> <p>5 、通知（advice）：所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、
异常、最终、环绕通知五类。</p> <p>6 、目标对象：代理的目标对象</p> <p>7 、织入（weave）：将切面应用到目标对象并导致代理对象创建的过程</p> <p>8 、引入（introduction）：在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法
或字段。</p> <p>参考：https://segmentfault.com/a/1190000007469968</p> <h3 id="_6-1-8-1-aop两种代理方式"><a href="#_6-1-8-1-aop两种代理方式" class="header-anchor">#</a> 6.1.8.1. AOP两种代理方式</h3> <p>Spring 提供了两种方式来生成代理对象: JDKProxy 和 Cglib，具体使用哪种方式生成由
AopProxyFactory根据AdvisedSupport对象的配置来决定。默认的策略是如果目标类是接口，
则使用JDK动态代理技术，否则使用Cglib来生成代理。</p> <h4 id="jdk动态接口代理"><a href="#jdk动态接口代理" class="header-anchor">#</a> JDK动态接口代理</h4> <ol><li>JDK动态代理主要涉及到java.lang.reflect包中的两个类：Proxy和InvocationHandler。
InvocationHandler是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类
的代码，动态将横切逻辑和业务逻辑编制在一起。Proxy利用 InvocationHandler 动态创建
一个符合某一接口的实例，生成目标类的代理对象。</li></ol> <h4 id="cglib动态代理"><a href="#cglib动态代理" class="header-anchor">#</a> CGLib动态代理</h4> <ol start="2"><li>：CGLib全称为Code Generation Library，是一个强大的高性能，高质量的代码生成类库，
可以在运行期扩展Java类与实现Java接口，CGLib封装了asm，可以再运行期动态生成新
的class。和JDK动态代理相比较：JDK创建代理有一个限制，就是只能为接口创建代理实例，
而对于没有通过接口定义业务方法的类，则可以通过CGLib创建动态代理。</li></ol> <h3 id="_6-1-8-2-实现原理"><a href="#_6-1-8-2-实现原理" class="header-anchor">#</a> 6.1.8.2. 实现原理</h3> <div class="language- extra-class"><pre class="language-text"><code>@Aspect
public class TransactionDemo {
@Pointcut(value=&quot;execution(* com.yangxin.core.service.*.*.*(..))&quot;)
public void point(){
}
@Before(value=&quot;point()&quot;)
public void before(){
System.out.println(&quot;transaction begin&quot;);
}
@AfterReturning(value = &quot;point()&quot;)
public void after(){
System.out.println(&quot;transaction commit&quot;);
}
@Around(&quot;point()&quot;)
public void around(ProceedingJoinPoint joinPoint) throws Throwable{
System.out.println(&quot;transaction begin&quot;);
joinPoint.proceed();
System.out.println(&quot;transaction commit&quot;);
}
</code></pre></div><h3 id="-2"><a href="#-2" class="header-anchor">#</a> }</h3> <h2 id="_6-1-9-spring-mvc-原理"><a href="#_6-1-9-spring-mvc-原理" class="header-anchor">#</a> 6.1.9. Spring MVC 原理</h2> <p>Spring的模型-视图-控制器（MVC）框架是围绕一个DispatcherServlet来设计的，这个Servlet
会把请求分发给各个处理器，并支持可配置的处理器映射、视图渲染、本地化、时区与主题渲染
等，甚至还能支持文件上传。</p> <h3 id="_6-1-9-1-mvc流程"><a href="#_6-1-9-1-mvc流程" class="header-anchor">#</a> 6.1.9.1. MVC流程</h3> <h4 id="http请求到dispatcherservlet"><a href="#http请求到dispatcherservlet" class="header-anchor">#</a> Http请求到DispatcherServlet</h4> <div class="language- extra-class"><pre class="language-text"><code>(1) 客户端请求提交到DispatcherServlet。
</code></pre></div><h4 id="handlermapping寻找处理器"><a href="#handlermapping寻找处理器" class="header-anchor">#</a> HandlerMapping寻找处理器</h4> <div class="language- extra-class"><pre class="language-text"><code>(2) 由 DispatcherServlet 控制器查询一个或多个HandlerMapping，找到处理请求的
Controller。
</code></pre></div><h4 id="调用处理器controller"><a href="#调用处理器controller" class="header-anchor">#</a> 调用处理器Controller</h4> <div class="language- extra-class"><pre class="language-text"><code>(3) DispatcherServlet将请求提交到Controller。
</code></pre></div><h5 id="controller调用业务逻辑处理后-返回modelandview"><a href="#controller调用业务逻辑处理后-返回modelandview" class="header-anchor">#</a> Controller调用业务逻辑处理后，返回ModelAndView</h5> <p>(4)(5)调用业务处理和返回结果：Controller调用业务逻辑处理后，返回ModelAndView。</p> <h5 id="dispatcherservlet查询modelandview"><a href="#dispatcherservlet查询modelandview" class="header-anchor">#</a> DispatcherServlet查询ModelAndView</h5> <p>(6)(7)处理视图映射并返回模型： DispatcherServlet查询一个或多个ViewResoler视图解析器，
找到ModelAndView指定的视图。</p> <h5 id="modelandview反馈浏览器http"><a href="#modelandview反馈浏览器http" class="header-anchor">#</a> ModelAndView反馈浏览器HTTP</h5> <p>(8) Http响应：视图负责将结果显示到客户端。</p> <h4 id="_6-1-9-1-mvc常用注解"><a href="#_6-1-9-1-mvc常用注解" class="header-anchor">#</a> 6.1.9.1. MVC常用注解</h4> <h3 id="_6-1-10-spring-boot-原理"><a href="#_6-1-10-spring-boot-原理" class="header-anchor">#</a> 6.1.10. Spring Boot 原理</h3> <p>Spring Boot是由Pivotal团队提供的全新框架，其设计目的是用来简化新Spring应用的初始搭
建以及开发过程。该框架使用了特定的方式来进行配置，从而使开发人员不再需要定义样板化的
配置。通过这种方式，Spring Boot 致力于在蓬勃发展的快速应用开发领域(rapid application
development)成为领导者。其特点如下：</p> <h4 id="_1-创建独立的spring应用程序"><a href="#_1-创建独立的spring应用程序" class="header-anchor">#</a> 1. 创建独立的Spring应用程序</h4> <h4 id="_2-嵌入的tomcat-无需部署war文件"><a href="#_2-嵌入的tomcat-无需部署war文件" class="header-anchor">#</a> 2. 嵌入的Tomcat，无需部署WAR文件</h4> <h4 id="_3-简化maven配置"><a href="#_3-简化maven配置" class="header-anchor">#</a> 3. 简化Maven配置</h4> <h4 id="_4-自动配置spring"><a href="#_4-自动配置spring" class="header-anchor">#</a> 4. 自动配置Spring</h4> <h4 id="_5-提供生产就绪型功能-如指标-健康检查和外部配置"><a href="#_5-提供生产就绪型功能-如指标-健康检查和外部配置" class="header-anchor">#</a> 5. 提供生产就绪型功能，如指标，健康检查和外部配置</h4> <h4 id="_6-绝对没有代码生成和对xml没有要求配置-1"><a href="#_6-绝对没有代码生成和对xml没有要求配置-1" class="header-anchor">#</a> 6. 绝对没有代码生成和对XML没有要求配置 [1]</h4> <h3 id="_6-1-11-jpa-原理"><a href="#_6-1-11-jpa-原理" class="header-anchor">#</a> 6.1.11. JPA 原理</h3> <h4 id="_6-1-11-1-事务"><a href="#_6-1-11-1-事务" class="header-anchor">#</a> 6.1.11.1. 事务</h4> <p>事务是计算机应用中不可或缺的组件模型，它保证了用户操作的原子性 ( Atomicity )、一致性
( Consistency )、隔离性 ( Isolation ) 和持久性 ( Durabilily )。</p> <h4 id="_6-1-11-2-本地事务"><a href="#_6-1-11-2-本地事务" class="header-anchor">#</a> 6.1.11.2. 本地事务</h4> <p>紧密依赖于底层资源管理器（例如数据库连接 )，事务处理局限在当前事务资源内。此种事务处理
方式不存在对应用服务器的依赖，因而部署灵活却无法支持多数据源的分布式事务。在数据库连
接中使用本地事务示例如下：</p> <div class="language- extra-class"><pre class="language-text"><code>public void transferAccount() {
Connection conn = null;
Statement stmt = null;
try{
conn = getDataSource().getConnection();
// 将自动提交设置为 false，若设置为 true 则数据库将会把每一次数据更新认定为一个事务并自动提交
conn.setAutoCommit(false);
stmt = conn.createStatement();
// 将 A 账户中的金额减少 500
stmt.execute(&quot;update t_account set amount = amount - 50 0 where account_id = 'A'&quot;);
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>// 将 B 账户中的金额增加 500
stmt.execute(&quot;update t_account set amount = amount + 500 where account_id = 'B'&quot;);
// 提交事务
conn.commit();
// 事务提交：转账的两步操作同时成功
} catch(SQLException sqle){
// 发生异常，回滚在本事务中的操做
conn.rollback();
// 事务回滚：转账的两步操作完全撤销
stmt.close();
conn.close();
}
}
</code></pre></div><h4 id="_6-1-11-1-分布式事务"><a href="#_6-1-11-1-分布式事务" class="header-anchor">#</a> 6.1.11.1. 分布式事务</h4> <p>Java 事务编程接口（JTA：Java Transaction API）和 Java 事务服务 (JTS；Java Transaction
Service) 为 J2EE 平台提供了分布式事务服务。分布式事务（Distributed Transaction）包括事务
管理器（Transaction Manager）和一个或多个支持 XA 协议的资源管理器 ( Resource
Manager )。我们可以将资源管理器看做任意类型的持久化数据存储；事务管理器承担着所有事务
参与单元的协调与控制。</p> <div class="language- extra-class"><pre class="language-text"><code>public void transferAccount() {
UserTransaction userTx = null;
Connection connA = null; Statement stmtA = null;
Connection connB = null; Statement stmtB = null;
try{
// 获得 Transaction 管理对象
userTx = (UserTransaction)getContext().lookup(&quot;java:comp/UserTransaction&quot;);
connA = getDataSourceA().getConnection();// 从数据库 A 中取得数据库连接
connB = getDataSourceB().getConnection();// 从数据库 B 中取得数据库连接
userTx.begin(); // 启动事务
stmtA = connA.createStatement();// 将 A 账户中的金额减少 500
stmtA.execute(&quot;update t_account set amount = amount - 500 where account_id = 'A'&quot;);
// 将 B 账户中的金额增加 500
stmtB = connB.createStatement();
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>stmtB.execute(&quot;update t_account set amount = amount + 500 where account_id = 'B'&quot;);
userTx.commit();// 提交事务
// 事务提交：转账的两步操作同时成功（数据库 A 和数据库 B 中的数据被同时更新）
} catch(SQLException sqle){
// 发生异常，回滚在本事务中的操纵
userTx.rollback();// 事务回滚：数据库 A 和数据库 B 中的数据更新被同时撤销
} catch(Exception ne){ }
}
</code></pre></div><h4 id="_6-1-11-1-两阶段提交"><a href="#_6-1-11-1-两阶段提交" class="header-anchor">#</a> 6.1.11.1. 两阶段提交</h4> <p>两阶段提交主要保证了分布式事务的原子性：即所有结点要么全做要么全不做，所谓的两个阶段
是指：第一阶段：准备阶段；第二阶段：提交阶段。</p> <h5 id="_1-准备阶段"><a href="#_1-准备阶段" class="header-anchor">#</a> 1 准备阶段</h5> <p>事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回
失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一
种“万事俱备，只欠东风”的状态。</p> <h5 id="_2-提交阶段"><a href="#_2-提交阶段" class="header-anchor">#</a> 2 提交阶段：</h5> <p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，
发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过
程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p> <p>将提交分成两阶段进行的目的很明确，就是尽可能晚地提交事务，让事务在提交前尽可能地完成
所有能完成的工作。</p> <h3 id="_6-1-12-mybatis-缓存"><a href="#_6-1-12-mybatis-缓存" class="header-anchor">#</a> 6.1.12. Mybatis 缓存</h3> <p>Mybatis中有一级缓存和二级缓存，默认情况下一级缓存是开启的，而且是不能关闭的。一级缓存
是指SqlSession级别的缓存，当在同一个SqlSession中进行相同的SQL语句查询时，第二次以
后的查询不会从数据库查询，而是直接从缓存中获取，一级缓存最多缓存 1024 条SQL。二级缓存
是指可以跨SqlSession 的缓存。是mapper 级别的缓存，对于mapper级别的缓存不同的
sqlsession是可以共享的。</p> <h4 id="_6-1-12-1-mybatis的一级缓存原理-sqlsession级别"><a href="#_6-1-12-1-mybatis的一级缓存原理-sqlsession级别" class="header-anchor">#</a> 6.1.12.1. Mybatis的一级缓存原理（sqlsession级别）</h4> <p>第一次发出一个查询sql，sql查询结果写入sqlsession的一级缓存中，缓存使用的数据结构是一
个map。
key：MapperID+offset+limit+Sql+所有的入参</p> <p>value：用户信息</p> <p>同一个sqlsession再次发出相同的sql，就从缓存中取出数据。如果两次中间出现commit操作
（修改、添加、删除），本 sqlsession中的一级缓存区域全部清空，下次再去缓存中查询不到所
以要从数据库查询，从数据库查询到再写入缓存。</p> <h4 id="_6-1-12-2-二级缓存原理-mapper基本"><a href="#_6-1-12-2-二级缓存原理-mapper基本" class="header-anchor">#</a> 6.1.12.2. 二级缓存原理（mapper基本）</h4> <p>二级缓存的范围是mapper级别（mapper同一个命名空间），mapper以命名空间为单位创建缓
存数据结构，结构是map。mybatis的二级缓存是通过CacheExecutor实现的。CacheExecutor</p> <p>其实是Executor 的代理对象。所有的查询操作，在CacheExecutor中都会先匹配缓存中是否存
在，不存在则查询数据库。
key：MapperID+offset+limit+Sql+所有的入参</p> <h5 id="具体使用需要配置"><a href="#具体使用需要配置" class="header-anchor">#</a> 具体使用需要配置：</h5> <ol><li>Mybatis全局配置中启用二级缓存配置</li> <li>在对应的Mapper.xml中配置cache节点</li> <li>在对应的select查询节点中添加useCache=true</li></ol> <h3 id="_6-1-13-tomcat-架构"><a href="#_6-1-13-tomcat-架构" class="header-anchor">#</a> 6.1.13. Tomcat 架构</h3> <p><a href="http://www.importnew.com/21112.html" target="_blank" rel="noopener noreferrer">http://www.importnew.com/21112.html<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="_7-微服务"><a href="#_7-微服务" class="header-anchor">#</a> 7. 微服务</h2> <h3 id="_7-1-1-服务注册发现"><a href="#_7-1-1-服务注册发现" class="header-anchor">#</a> 7.1.1. 服务注册发现</h3> <p>服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记
簿交待自己的地址信息。服务的依赖方直接向登记簿要Service Provider地址就行了。当下用于服
务注册的工具非常多ZooKeeper，Consul，Etcd, 还有Netflix家的eureka等。服务注册有两种
形式：客户端注册和第三方注册。</p> <h4 id="_7-1-1-1-客户端注册-zookeeper"><a href="#_7-1-1-1-客户端注册-zookeeper" class="header-anchor">#</a> 7.1.1.1. 客户端注册（zookeeper）</h4> <p>客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身，当服务下
线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做，也可以由注册中心
负责（这个过程叫探活）。这种方式的缺点是注册工作与服务耦合在一起，不同语言都要实现一
套注册逻辑。</p> <h4 id="_7-1-1-2-第三方注册-独立的服务registrar"><a href="#_7-1-1-2-第三方注册-独立的服务registrar" class="header-anchor">#</a> 7.1.1.2. 第三方注册（独立的服务Registrar）</h4> <p>第三方注册由一个独立的服务Registrar负责注册与注销。当服务启动后以某种方式通知Registrar，
然后Registrar负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳，当服务不
可用时，向注册中心注销服务。这种方式的缺点是Registrar必须是一个高可用的系统，否则注册
工作没法进展。</p> <h4 id="_7-1-1-3-客户端发现"><a href="#_7-1-1-3-客户端发现" class="header-anchor">#</a> 7.1.1.3. 客户端发现.............................................................................................................................................</h4> <p>客户端发现是指客户端负责查询可用服务地址，以及负载均衡的工作。这种方式最方便直接，而
且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个，非常直接。缺点也在于多
语言时的重复工作，每个语言实现相同的逻辑。</p> <h4 id="_7-1-1-4-服务端发现"><a href="#_7-1-1-4-服务端发现" class="header-anchor">#</a> 7.1.1.4. 服务端发现.............................................................................................................................................</h4> <p>服务端发现需要额外的Router服务，请求先打到Router，然后Router负责查询服务与负载均衡。
这种方式虽然没有客户端发现的缺点，但是它的缺点是保证Router的高可用。</p> <h4 id="_7-1-1-5-consul"><a href="#_7-1-1-5-consul" class="header-anchor">#</a> 7.1.1.5. Consul</h4> <h4 id="_7-1-1-6-eureka"><a href="#_7-1-1-6-eureka" class="header-anchor">#</a> 7.1.1.6. Eureka</h4> <h4 id="_7-1-1-7-smartstack"><a href="#_7-1-1-7-smartstack" class="header-anchor">#</a> 7.1.1.7. SmartStack</h4> <h4 id="_7-1-1-8-etcd"><a href="#_7-1-1-8-etcd" class="header-anchor">#</a> 7.1.1.8. Etcd</h4> <h3 id="_7-1-2-api-网关"><a href="#_7-1-2-api-网关" class="header-anchor">#</a> 7.1.2. API 网关</h3> <p>API Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的
Facade模式很像。API Gateway封装内部系统的架构，并且提供API给各个客户端。它还可能有
其他功能，如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。下图展示了一
个适应当前架构的API Gateway。</p> <p>API Gateway负责请求转发、合成和协议转换。所有来自客户端的请求都要先经过API Gateway，
然后路由这些请求到对应的微服务。API Gateway将经常通过调用多个微服务来处理一个请求以
及聚合多个服务的结果。它可以在web 协议与内部使用的非Web 友好型协议间进行转换，如
HTTP协议、WebSocket协议。</p> <h4 id="_7-1-2-1-请求转发"><a href="#_7-1-2-1-请求转发" class="header-anchor">#</a> 7.1.2.1. 请求转发</h4> <p>服务转发主要是对客户端的请求安装微服务的负载转发到不同的服务上</p> <h4 id="_7-1-2-2-响应合并"><a href="#_7-1-2-2-响应合并" class="header-anchor">#</a> 7.1.2.2. 响应合并</h4> <p>把业务上需要调用多个服务接口才能完成的工作合并成一次调用对外统一提供服务。</p> <h4 id="_7-1-2-3-协议转换"><a href="#_7-1-2-3-协议转换" class="header-anchor">#</a> 7.1.2.3. 协议转换</h4> <h3 id="重点是支持soap-jms-rest间的协议转换。"><a href="#重点是支持soap-jms-rest间的协议转换。" class="header-anchor">#</a> 重点是支持SOAP，JMS，Rest间的协议转换。</h3> <h4 id="_7-1-2-4-数据转换"><a href="#_7-1-2-4-数据转换" class="header-anchor">#</a> 7.1.2.4. 数据转换</h4> <p>重点是支持XML和Json之间的报文格式转换能力（可选）</p> <h4 id="_7-1-2-5-安全认证"><a href="#_7-1-2-5-安全认证" class="header-anchor">#</a> 7.1.2.5. 安全认证</h4> <ol><li>基于Token的客户端访问控制和安全策略</li> <li>传输数据和报文加密，到服务端解密，需要在客户端有独立的SDK代理包</li> <li>基于Https的传输加密，客户端和服务端数字证书支持</li> <li>基于OAuth2.0的服务安全认证(授权码，客户端，密码模式等）</li></ol> <h3 id="_7-1-3-配置中心"><a href="#_7-1-3-配置中心" class="header-anchor">#</a> 7.1.3. 配置中心</h3> <p>配置中心一般用作系统的参数配置，它需要满足如下几个要求：高效获取、实时感知、分布式访
问。</p> <h4 id="_7-1-3-1-zookeeper配置中心"><a href="#_7-1-3-1-zookeeper配置中心" class="header-anchor">#</a> 7.1.3.1. zookeeper配置中心</h4> <p>实现的架构图如下所示，采取数据加载到内存方式解决高效获取的问题，借助zookeeper的节点
监听机制来实现实时感知。</p> <h4 id="_7-1-3-2-配置中心数据分类"><a href="#_7-1-3-2-配置中心数据分类" class="header-anchor">#</a> 7.1.3.2. 配置中心数据分类</h4> <h3 id="_7-1-4-事件调度-kafka"><a href="#_7-1-4-事件调度-kafka" class="header-anchor">#</a> 7.1.4. 事件调度（ kafka ）</h3> <p>消息服务和事件的统一调度，常用用kafka ，activemq等。</p> <h3 id="_7-1-5-服务跟踪-starter-sleuth"><a href="#_7-1-5-服务跟踪-starter-sleuth" class="header-anchor">#</a> 7.1.5. 服务跟踪（starter-sleuth）</h3> <p>随着微服务数量不断增长，需要跟踪一个请求从一个微服务到下一个微服务的传播过程， Spring
Cloud Sleuth 正是解决这个问题，它在日志中引入唯一ID，以保证微服务调用之间的一致性，这
样你就能跟踪某个请求是如何从一个微服务传递到下一个。</p> <ol><li>为了实现请求跟踪，当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求
创建一个唯一的跟踪标识，同时在分布式系统内部流转的时候，框架始终保持传递该唯一标
识，直到返回给请求方为止，这个唯一标识就是前文中提到的Trace ID。通过Trace ID的记
录，我们就能将所有请求过程日志关联起来。</li> <li>为了统计各处理单元的时间延迟，当请求达到各个服务组件时，或是处理逻辑到达某个状态
时，也通过一个唯一标识来标记它的开始、具体过程以及结束，该标识就是我们前文中提到
的Span ID，对于每个Span来说，它必须有开始和结束两个节点，通过记录开始Span和结
束Span的时间戳，就能统计出该Span的时间延迟，除了时间戳记录之外，它还可以包含一
些其他元数据，比如：事件名称、请求信息等。</li> <li>在快速入门示例中，我们轻松实现了日志级别的跟踪信息接入，这完全归功于spring-cloud-
starter-sleuth 组件的实现。在 Spring Boot应用中，通过在工程中引入 spring-cloud-
starter-sleuth依赖之后， 它会自动的为当前应用构建起各通信通道的跟踪机制，比如：
 通过诸如RabbitMQ、Kafka（或者其他任何Spring Cloud Stream绑定器实现的消息
中间件）传递的请求。
 通过Zuul代理传递的请求。
 通过RestTemplate发起的请求。</li></ol> <h3 id="_7-1-6-服务熔断-hystrix"><a href="#_7-1-6-服务熔断-hystrix" class="header-anchor">#</a> 7.1.6. 服务熔断（ Hystrix ）</h3> <p>在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个
系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不
可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。</p> <p>熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到
许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序
不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU
时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经
修正，应用程序会再次尝试调用操作。</p> <h4 id="_7-1-6-1-hystrix断路器机制"><a href="#_7-1-6-1-hystrix断路器机制" class="header-anchor">#</a> 7.1.6.1. Hystrix断路器机制</h4> <p>断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会
切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态
一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况,
如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器
就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效
请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力。</p> <h3 id="_7-1-7-api-管理"><a href="#_7-1-7-api-管理" class="header-anchor">#</a> 7.1.7. API 管理</h3> <p>SwaggerAPI 管理工具。</p> <h2 id="_8-netty-与-rpc"><a href="#_8-netty-与-rpc" class="header-anchor">#</a> 8. NETTY 与 RPC</h2> <h3 id="_8-1-1-netty-原理"><a href="#_8-1-1-netty-原理" class="header-anchor">#</a> 8.1.1. Netty 原理</h3> <p>Netty是一个高性能、异步事件驱动的NIO框架，基于JAVA NIO提供的API实现。它提供了对
TCP、UDP和文件传输的支持，作为一个异步NIO框架，Netty的所有IO操作都是异步非阻塞
的，通过Future-Listener机制，用户可以方便的主动获取或者通过通知机制获得IO操作结果。</p> <h3 id="_8-1-2-netty-高性能"><a href="#_8-1-2-netty-高性能" class="header-anchor">#</a> 8.1.2. Netty 高性能</h3> <p>在IO编程过程中，当需要同时处理多个客户端接入请求时，可以利用多线程或者IO多路复用技术
进行处理。IO多路复用技术通过把多个IO的阻塞复用到同一个select的阻塞上，从而使得系统在
单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型比，I/O 多路复用的
最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程
的运行，降低了系统的维护工作量，节省了系统资源。</p> <p>与Socket类和ServerSocket类相对应，NIO也提供了SocketChannel和ServerSocketChannel
两种不同的套接字通道实现。</p> <h4 id="_8-1-2-1-多路复用通讯方式"><a href="#_8-1-2-1-多路复用通讯方式" class="header-anchor">#</a> 8.1.2.1. 多路复用通讯方式</h4> <p>Netty架构按照Reactor模式设计和实现，它的服务端通信序列图如下：</p> <p>客户端通信序列图如下：</p> <p>Netty的IO线程NioEventLoop由于聚合了多路复用器Selector，可以同时并发处理成百上千个
客户端Channel，由于读写操作都是非阻塞的，这就可以充分提升IO线程的运行效率，避免由于
频繁IO阻塞导致的线程挂起。</p> <h4 id="_8-1-2-1-异步通讯nio"><a href="#_8-1-2-1-异步通讯nio" class="header-anchor">#</a> 8.1.2.1. 异步通讯NIO</h4> <p>由于Netty采用了异步通信模式，一个IO线程可以并发处理N个客户端连接和读写操作，这从根
本上解决了传统同步阻塞IO一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极
大的提升。</p> <h4 id="_8-1-2-2-零拷贝-direct-buffers使用堆外直接内存"><a href="#_8-1-2-2-零拷贝-direct-buffers使用堆外直接内存" class="header-anchor">#</a> 8.1.2.2. 零拷贝（DIRECT BUFFERS使用堆外直接内存）</h4> <ol><li>Netty的接收和发送ByteBuffer采用DIRECT BUFFERS，使用堆外直接内存进行Socket读写，
不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行Socket读写，
JVM会将堆内存Buffer拷贝一份到直接内存中，然后才写入Socket中。相比于堆外直接内存，
消息在发送过程中多了一次缓冲区的内存拷贝。</li> <li>Netty提供了组合Buffer对象，可以聚合多个ByteBuffer对象，用户可以像操作一个Buffer那样
方便的对组合Buffer进行操作，避免了传统通过内存拷贝的方式将几个小Buffer合并成一个大的
Buffer。</li> <li>Netty的文件传输采用了transferTo方法，它可以直接将文件缓冲区的数据发送到目标Channel，
避免了传统通过循环write方式导致的内存拷贝问题</li></ol> <h4 id="_8-1-2-3-内存池-基于内存池的缓冲区重用机制"><a href="#_8-1-2-3-内存池-基于内存池的缓冲区重用机制" class="header-anchor">#</a> 8.1.2.3. 内存池（基于内存池的缓冲区重用机制）</h4> <p>随着JVM虚拟机和JIT即时编译技术的发展，对象的分配和回收是个非常轻量级的工作。但是对于缓
冲区Buffer，情况却稍有不同，特别是对于堆外直接内存的分配和回收，是一件耗时的操作。为了尽
量重用缓冲区，Netty提供了基于内存池的缓冲区重用机制。</p> <h4 id="_8-1-2-4-高效的reactor线程模型"><a href="#_8-1-2-4-高效的reactor线程模型" class="header-anchor">#</a> 8.1.2.4. 高效的Reactor线程模型</h4> <p>常用的Reactor线程模型有三种，Reactor单线程模型, Reactor多线程模型, 主从Reactor多线程模
型。</p> <h5 id="reactor单线程模型"><a href="#reactor单线程模型" class="header-anchor">#</a> Reactor单线程模型</h5> <p>Reactor单线程模型，指的是所有的IO操作都在同一个NIO线程上面完成，NIO线程的职责如下：</p> <ol><li><p>作为NIO服务端，接收客户端的TCP连接；</p></li> <li><p>作为NIO客户端，向服务端发起TCP连接；</p></li> <li><p>读取通信对端的请求或者应答消息；</p></li> <li><p>向通信对端发送消息请求或者应答消息。</p></li></ol> <p>由于Reactor模式使用的是异步非阻塞IO，所有的IO操作都不会导致阻塞，理论上一个线程可以独
立处理所有IO相关的操作。从架构层面看，一个NIO线程确实可以完成其承担的职责。例如，通过
Acceptor接收客户端的TCP连接请求消息，链路建立成功之后，通过Dispatch将对应的ByteBuffer
派发到指定的Handler上进行消息解码。用户Handler可以通过NIO线程将消息发送给客户端。</p> <h5 id="reactor多线程模型"><a href="#reactor多线程模型" class="header-anchor">#</a> Reactor多线程模型</h5> <div class="language- extra-class"><pre class="language-text"><code>Rector多线程模型与单线程模型最大的区别就是有一组NIO线程处理IO操作。 有专门一个
NIO线程-Acceptor线程用于监听服务端，接收客户端的TCP连接请求； 网络IO操作-读、写
等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N
个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送；
</code></pre></div><h5 id="主从reactor多线程模型"><a href="#主从reactor多线程模型" class="header-anchor">#</a> 主从Reactor多线程模型</h5> <div class="language- extra-class"><pre class="language-text"><code>服务端用于接收客户端连接的不再是个 1 个单独的NIO线程，而是一个独立的NIO线程池。
Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的
SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责
SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全
认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负
责后续的IO操作。
</code></pre></div><h4 id="_8-1-2-5-无锁设计、线程绑定"><a href="#_8-1-2-5-无锁设计、线程绑定" class="header-anchor">#</a> 8.1.2.5. 无锁设计、线程绑定</h4> <p>Netty采用了串行无锁化设计，在IO线程内部进行串行操作，避免多线程竞争导致的性能下降。
表面上看，串行化设计似乎CPU利用率不高，并发程度不够。但是，通过调整NIO线程池的线程
参数，可以同时启动多个串行化的线程并行运行，这种局部无锁化的串行线程设计相比一个队列-
多个工作线程模型性能更优。</p> <div class="language- extra-class"><pre class="language-text"><code>Netty的NioEventLoop读取到消息之后，直接调用ChannelPipeline的
fireChannelRead(Object msg)，只要用户不主动切换线程，一直会由NioEventLoop调用
到用户的Handler，期间不进行线程切换，这种串行化处理方式避免了多线程操作导致的锁
的竞争，从性能角度看是最优的。
</code></pre></div><h4 id="_8-1-2-6-高性能的序列化框架"><a href="#_8-1-2-6-高性能的序列化框架" class="header-anchor">#</a> 8.1.2.6. 高性能的序列化框架</h4> <p>Netty默认提供了对Google Protobuf的支持，通过扩展Netty的编解码接口，用户可以实现其它的
高性能序列化框架，例如Thrift的压缩二进制编解码框架。</p> <ol><li>SO_RCVBUF和SO_SNDBUF：通常建议值为128K或者 2 56K。</li></ol> <h5 id="小包封大包-防止网络阻塞"><a href="#小包封大包-防止网络阻塞" class="header-anchor">#</a> 小包封大包，防止网络阻塞</h5> <ol start="2"><li>SO_TCPNODELAY：NAGLE算法通过将缓冲区内的小封包自动相连，组成较大的封包，阻止大量
小封包的发送阻塞网络，从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算
法。</li></ol> <h5 id="软中断hash值和cpu绑定"><a href="#软中断hash值和cpu绑定" class="header-anchor">#</a> 软中断Hash值和CPU绑定.............................................................................................................................</h5> <ol start="3"><li>软中断：开启RPS后可以实现软中断，提升网络吞吐量。RPS根据数据包的源地址，目的地址以
及目的和源端口，计算出一个hash值，然后根据这个hash值来选择软中断运行的cpu，从上层
来看，也就是说将每个连接和cpu绑定，并通过这个hash值，来均衡软中断在多个cpu上，提升
网络并行处理性能。</li></ol> <h3 id="_8-1-3-netty-rpc-实现"><a href="#_8-1-3-netty-rpc-实现" class="header-anchor">#</a> 8.1.3. Netty RPC 实现</h3> <h4 id="_8-1-3-1-概念"><a href="#_8-1-3-1-概念" class="header-anchor">#</a> 8.1.3.1. 概念</h4> <p>RPC，即 Remote Procedure Call（远程过程调用），调用远程计算机上的服务，就像调用本地服务一
样。RPC可以很好的解耦系统，如WebService就是一种基于Http协议的RPC。这个RPC整体框架
如下：</p> <h4 id="_8-1-3-2-关键技术"><a href="#_8-1-3-2-关键技术" class="header-anchor">#</a> 8.1.3.2. 关键技术</h4> <ol><li>服务发布与订阅：服务端使用Zookeeper注册服务地址，客户端从Zookeeper获取可用的服务
地址。</li> <li>通信：使用Netty作为通信框架。</li> <li>Spring：使用Spring配置服务，加载Bean，扫描注解。</li> <li>动态代理：客户端使用代理模式透明化服务调用。</li> <li>消息编解码：使用Protostuff序列化和反序列化消息。</li></ol> <h4 id="_8-1-3-3-核心流程"><a href="#_8-1-3-3-核心流程" class="header-anchor">#</a> 8.1.3.3. 核心流程</h4> <ol><li><p>服务消费方（client）调用以本地调用方式调用服务；</p></li> <li><p>client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；</p></li> <li><p>client stub找到服务地址，并将消息发送到服务端；</p></li> <li><p>server stub收到消息后进行解码；</p></li> <li><p>server stub根据解码结果调用本地的服务；</p></li> <li><p>本地服务执行并将结果返回给server stub；</p></li> <li><p>server stub将返回结果打包成消息并发送至消费方；</p></li> <li><p>client stub接收到消息，并进行解码；</p></li> <li><p>服务消费方得到最终结果。
RPC的目标就是要2~8这些步骤都封装起来，让用户对这些细节透明。JAVA一般使用动态代
理方式实现远程调用。</p></li></ol> <h4 id="_8-1-3-1-消息编解码"><a href="#_8-1-3-1-消息编解码" class="header-anchor">#</a> 8.1.3.1. 消息编解码.............................................................................................................................................</h4> <h5 id="息数据结构-接口名称-方法名-参数类型和参数值-超时时间-requestid"><a href="#息数据结构-接口名称-方法名-参数类型和参数值-超时时间-requestid" class="header-anchor">#</a> 息数据结构（接口名称+方法名+参数类型和参数值+超时时间+ requestID）</h5> <p>客户端的请求消息结构一般需要包括以下内容：</p> <ol><li>接口名称：在我们的例子里接口名是“HelloWorldService”，如果不传，服务端就不知道调用哪
个接口了；</li> <li>方法名：一个接口内可能有很多方法，如果不传方法名服务端也就不知道调用哪个方法；</li> <li>参数类型和参数值：参数类型有很多，比如有bool、int、long、double、string、map、list，
甚至如struct（class）；以及相应的参数值；</li> <li>超时时间：</li> <li>requestID，标识唯一请求id，在下面一节会详细描述requestID的用处。</li> <li>服务端返回的消息 ： 一般包括以下内容。返回值+状态code+requestID</li></ol> <h5 id="序列化"><a href="#序列化" class="header-anchor">#</a> 序列化</h5> <div class="language- extra-class"><pre class="language-text"><code>目前互联网公司广泛使用Protobuf、Thrift、Avro等成熟的序列化解决方案来搭建RPC框架，这
些都是久经考验的解决方案。
</code></pre></div><h4 id="_8-1-3-1-通讯过程"><a href="#_8-1-3-1-通讯过程" class="header-anchor">#</a> 8.1.3.1. 通讯过程</h4> <h5 id="核心问题-线程暂停、消息乱序"><a href="#核心问题-线程暂停、消息乱序" class="header-anchor">#</a> 核心问题(线程暂停、消息乱序)</h5> <div class="language- extra-class"><pre class="language-text"><code>如果使用netty的话，一般会用channel.writeAndFlush()方法来发送消息二进制串，这个方
法调用后对于整个远程调用(从发出请求到接收到结果)来说是一个异步的，即对于当前线程来说，
将请求发送出来后，线程就可以往后执行了，至于服务端的结果，是服务端处理完成后，再以消息
的形式发送给客户端的。于是这里出现以下两个问题：
</code></pre></div><ol><li>怎么让当前线程“暂停”，等结果回来后，再向后执行？</li> <li>如果有多个线程同时进行远程方法调用，这时建立在client server之间的socket连接上
会有很多双方发送的消息传递，前后顺序也可能是随机的，server处理完结果后，将结
果消息发送给client，client收到很多消息，怎么知道哪个消息结果是原先哪个线程调用
的？如下图所示，线程A和线程B同时向client socket发送请求requestA和requestB，
socket先后将requestB和requestA发送至server，而server可能将responseB先返
回，尽管requestB 请求到达时间更晚。我们需要一种机制保证responseA 丢给
ThreadA，responseB丢给ThreadB。</li></ol> <h5 id="通讯流程"><a href="#通讯流程" class="header-anchor">#</a> 通讯流程</h5> <h5 id="requestid生成-atomiclong"><a href="#requestid生成-atomiclong" class="header-anchor">#</a> requestID生成-AtomicLong</h5> <ol><li>client线程每次通过socket调用一次远程接口前，生成一个唯一的ID，即requestID
（requestID必需保证在一个Socket连接里面是唯一的），一般常常使用AtomicLong
从 0 开始累计数字生成唯一ID；</li></ol> <h5 id="存放回调对象callback到全局concurrenthashmap"><a href="#存放回调对象callback到全局concurrenthashmap" class="header-anchor">#</a> 存放回调对象callback到全局ConcurrentHashMap</h5> <ol start="2"><li>将处理结果的回调对象callback，存放到全局ConcurrentHashMap 里面
put(requestID, callback)；</li></ol> <h5 id="synchronized获取回调对象callback的锁并自旋wait"><a href="#synchronized获取回调对象callback的锁并自旋wait" class="header-anchor">#</a> synchronized获取回调对象callback的锁并自旋wait</h5> <ol start="3"><li>当线程调用channel.writeAndFlush()发送消息后，紧接着执行callback的get()方法试
图获取远程返回的结果。在get()内部，则使用synchronized获取回调对象callback的
锁，再先检测是否已经获取到结果，如果没有，然后调用callback的wait()方法，释放
callback上的锁，让当前线程处于等待状态。</li></ol> <h5 id="监听消息的线程收到消息-找到callback上的锁并唤醒"><a href="#监听消息的线程收到消息-找到callback上的锁并唤醒" class="header-anchor">#</a> 监听消息的线程收到消息，找到callback上的锁并唤醒</h5> <ol start="4"><li>服务端接收到请求并处理后，将response结果（此结果中包含了前面的requestID）发
送给客户端，客户端 socket连接上专门监听消息的线程收到消息，分析结果，取到
requestID，再从前面的ConcurrentHashMap 里面get(requestID)，从而找到
callback对象，再用 synchronized获取callback 上的锁，将方法调用结果设置到
callback对象里，再调用callback.notifyAll()唤醒前面处于等待状态的线程。</li></ol> <div class="language- extra-class"><pre class="language-text"><code>public Object get() {
synchronized (this) { // 旋锁
while (true) { // 是否有结果了
If （!isDone）{
wait(); //没结果释放锁，让当前线程处于等待状态
}else{//获取数据并处理
}
}
}
}
private void setDone(Response res) {
this.res = res;
isDone = true;
synchronized (this) { //获取锁，因为前面wait()已经释放了callback的锁了
notifyAll(); // 唤醒处于等待的线程
}
}
</code></pre></div><h3 id="_8-1-4-rmi-实现方式"><a href="#_8-1-4-rmi-实现方式" class="header-anchor">#</a> 8.1.4. RMI 实现方式</h3> <p>Java远程方法调用，即Java RMI（Java Remote Method Invocation）是Java编程语言里，一种用
于实现远程过程调用的应用程序编程接口。它使客户机上运行的程序可以调用远程服务器上的对象。远
程方法调用特性使Java编程人员能够在网络环境中分布操作。RMI全部的宗旨就是尽可能简化远程接
口对象的使用。</p> <h4 id="_8-1-4-1-实现步骤"><a href="#_8-1-4-1-实现步骤" class="header-anchor">#</a> 8.1.4.1. 实现步骤</h4> <ol><li><p>编写远程服务接口，该接口必须继承 java.rmi.Remote 接口，方法必须抛出
java.rmi.RemoteException 异常；</p></li> <li><p>编写远程接口实现类，该实现类必须继承 java.rmi.server.UnicastRemoteObject 类；</p></li> <li><p>运行RMI编译器（rmic），创建客户端 stub 类和服务端 skeleton 类;</p></li> <li><p>启动一个RMI注册表，以便驻留这些服务;</p></li> <li><p>在RMI注册表中注册服务；</p></li> <li><p>客户端查找远程对象，并调用远程方法；
1 ：创建远程接口，继承java.rmi.Remote接口
public interface GreetService extends java.rmi.Remote {
String sayHello(String name) throws RemoteException;
}
2 ：实现远程接口，继承 java.rmi.server.UnicastRemoteObject类
public class GreetServiceImpl extends java.rmi.server.UnicastRemoteObject
implements GreetService {
private static final long serialVersionUID = 3434060152387200042L;
public GreetServiceImpl() throws RemoteException {
super();
}
@Override
public String sayHello(String name) throws RemoteException {
return &quot;Hello &quot; + name;
}
}
3 ：生成Stub和Skeleton;
4 ：执行rmiregistry命令注册服务
5 ：启动服务
LocateRegistry.createRegistry(1098);
Naming.bind(&quot;rmi://10.108.1.138:1098/GreetService&quot;, new GreetServiceImpl());
6.客户端调用
GreetService greetService = (GreetService)
Naming.lookup(&quot;rmi://10.108.1.138:1098/GreetService&quot;);
System.out.println(greetService.sayHello(&quot;Jobs&quot;));</p></li></ol> <h3 id="_8-1-5-protoclol-buffer"><a href="#_8-1-5-protoclol-buffer" class="header-anchor">#</a> 8.1.5. Protoclol Buffer</h3> <p>protocol buffer是google的一个开源项目,它是用于结构化数据串行化的灵活、高效、自动的方法，
例如XML，不过它比xml更小、更快、也更简单。你可以定义自己的数据结构，然后使用代码生成器
生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。</p> <h4 id="_8-1-5-1-特点"><a href="#_8-1-5-1-特点" class="header-anchor">#</a> 8.1.5.1. 特点</h4> <p>Protocol Buffer的序列化 &amp; 反序列化简单 &amp; 速度快的原因是：</p> <ol><li>编码 / 解码 方式简单（只需要简单的数学运算 = 位移等等）</li> <li>采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成</li></ol> <p>Protocol Buffer的数据压缩效果好（即序列化后的数据量体积小）的原因是：</p> <ol><li>a. 采用了独特的编码方式，如Varint、Zigzag编码方式等等</li> <li>b. 采用T - L - V 的数据存储方式：减少了分隔符的使用 &amp; 数据存储得紧凑</li></ol> <h3 id="_8-1-6-thrift"><a href="#_8-1-6-thrift" class="header-anchor">#</a> 8.1.6. Thrift</h3> <p>Apache Thrift 是 Facebook 实现的一种高效的、支持多种编程语言的远程服务调用的框架。本文将从
Java 开发人员角度详细介绍 Apache Thrift 的架构、开发和部署，并且针对不同的传输协议和服务类
型给出相应的 Java 实例，同时详细介绍 Thrift 异步客户端的实现，最后提出使用 Thrift 需要注意的事
项。</p> <p>目前流行的服务调用方式有很多种，例如基于 SOAP 消息格式的 Web Service，基于 JSON 消息格式
的 RESTful 服务等。其中所用到的数据传输方式包括 XML，JSON 等，然而 XML 相对体积太大，传输
效率低，JSON 体积较小，新颖，但还不够完善。本文将介绍由 Facebook 开发的远程服务调用框架
Apache Thrift，它采用接口描述语言定义并创建服务，支持可扩展的跨语言服务开发，所包含的代码
生成引擎可以在多种语言中，如 C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa,
Smalltalk 等创建高效的、无缝的服务，其传输数据采用二进制格式，相对 XML 和 JSON 体积更小，
对于高并发、大数据量和多语言的环境更有优势。本文将详细介绍 Thrift 的使用，并且提供丰富的实例
代码加以解释说明，帮助使用者快速构建服务。</p> <p>为什么要Thrift：</p> <p>1 、多语言开发的需要 2 、性能问题</p> <h2 id="_9-网络"><a href="#_9-网络" class="header-anchor">#</a> 9. 网络</h2> <h3 id="_9-1-1-网络-7-层架构"><a href="#_9-1-1-网络-7-层架构" class="header-anchor">#</a> 9.1.1. 网络 7 层架构</h3> <p>7 层模型主要包括：</p> <ol><li>物理层：主要定义物理设备标准，如网线的接口类型、光纤的接口类型、各种传输介质的传输速率
等。它的主要作用是传输比特流（就是由 1 、 0 转化为电流强弱来进行传输,到达目的地后在转化为
1 、 0 ，也就是我们常说的模数转换与数模转换）。这一层的数据叫做比特。</li> <li>数据链路层：主要将从物理层接收的数据进行MAC地址（网卡的地址）的封装与解封装。常把这
一层的数据叫做帧。在这一层工作的设备是交换机，数据通过交换机来传输。</li> <li>网络层：主要将从下层接收到的数据进行IP地址（例192.168.0.1)的封装与解封装。在这一层工
作的设备是路由器，常把这一层的数据叫做数据包。</li> <li>传输层：定义了一些传输数据的协议和端口号（WWW端口 80 等），如：TCP（传输控制协议，
传输效率低，可靠性强，用于传输可靠性要求高，数据量大的数据），UDP（用户数据报协议，
与TCP特性恰恰相反，用于传输可靠性要求不高，数据量小的数据，如QQ聊天数据就是通过这
种方式传输的）。 主要是将从下层接收的数据进行分段进行传输，到达目的地址后在进行重组。
常常把这一层数据叫做段。</li> <li>会话层：通过传输层（端口号：传输端口与接收端口）建立数据传输的通路。主要在你的系统之间
发起会话或或者接受会话请求（设备之间需要互相认识可以是IP也可以是MAC或者是主机名）</li> <li>表示层：主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等（也就是把计算机能够
识别的东西转换成人能够能识别的东西（如图片、声音等））</li> <li>应用层 主要是一些终端的应用，比如说FTP（各种文件下载），WEB（IE浏览），QQ之类的（你
就把它理解成我们在电脑屏幕上可以看到的东西．就 是终端应用）。</li></ol> <h3 id="_9-1-2-tcp-ip-原理"><a href="#_9-1-2-tcp-ip-原理" class="header-anchor">#</a> 9.1.2. TCP/IP 原理</h3> <div class="language- extra-class"><pre class="language-text"><code>TCP/IP协议不是TCP和IP这两个协议的合称，而是指因特网整个TCP/IP协议族。从协议分层
模型方面来讲，TCP/IP由四个层次组成：网络接口层、网络层、传输层、应用层。
</code></pre></div><h4 id="_9-1-2-1-网络访问层-network-access-layer"><a href="#_9-1-2-1-网络访问层-network-access-layer" class="header-anchor">#</a> 9.1.2.1. 网络访问层(Network Access Layer)</h4> <ol><li>网络访问层(Network Access Layer)在TCP/IP参考模型中并没有详细描述，只是指出主机
必须使用某种协议与网络相连。</li></ol> <h4 id="_9-1-2-2-网络层-internet-layer"><a href="#_9-1-2-2-网络层-internet-layer" class="header-anchor">#</a> 9.1.2.2. 网络层(Internet Layer)</h4> <ol start="2"><li>网络层(Internet Layer)是整个体系结构的关键部分，其功能是使主机可以把分组发往任何网
络，并使分组独立地传向目标。这些分组可能经由不同的网络，到达的顺序和发送的顺序也
可能不同。高层如果需要顺序收发，那么就必须自行处理对分组的排序。互联网层使用因特
网协议(IP，Internet Protocol)。</li></ol> <h4 id="_9-1-2-3-传输层-tramsport-layer-tcp-udp"><a href="#_9-1-2-3-传输层-tramsport-layer-tcp-udp" class="header-anchor">#</a> 9.1.2.3. 传输层(Tramsport Layer-TCP/UDP)</h4> <ol start="3"><li>传输层(Tramsport Layer)使源端和目的端机器上的对等实体可以进行会话。在这一层定义了
两个端到端的协议：传输控制协议(TCP，Transmission Control Protocol)和用户数据报协
议(UDP，User Datagram Protocol)。TCP是面向连接的协议，它提供可靠的报文传输和对
上层应用的连接服务。为此，除了基本的数据传输外，它还有可靠性保证、流量控制、多路
复用、优先权和安全性控制等功能。UDP是面向无连接的不可靠传输的协议，主要用于不需
要TCP的排序和流量控制等功能的应用程序。</li></ol> <h4 id="_9-1-2-4-应用层-application-layer"><a href="#_9-1-2-4-应用层-application-layer" class="header-anchor">#</a> 9.1.2.4. 应用层(Application Layer)....................................................................................................................</h4> <ol start="4"><li>应用层(Application Layer)包含所有的高层协议，包括：虚拟终端协议(TELNET，
TELecommunications NETwork)、文件传输协议(FTP，File Transfer Protocol)、电子邮件
传输协议(SMTP，Simple Mail Transfer Protocol)、域名服务(DNS，Domain Name</li></ol> <div class="language- extra-class"><pre class="language-text"><code>Service)、网上新闻传输协议(NNTP，Net News Transfer Protocol)和超文本传送协议
(HTTP，HyperText Transfer Protocol)等。
</code></pre></div><h3 id="_9-1-3-tcp-三次握手-四次挥手"><a href="#_9-1-3-tcp-三次握手-四次挥手" class="header-anchor">#</a> 9.1.3. TCP 三次握手 / 四次挥手</h3> <p>TCP在传输之前会进行三次沟通，一般称为“三次握手”，传完数据断开的时候要进行四次沟通，一般
称为“四次挥手”。</p> <h4 id="_9-1-3-1-数据包说明"><a href="#_9-1-3-1-数据包说明" class="header-anchor">#</a> 9.1.3.1. 数据包说明.............................................................................................................................................</h4> <ol><li><p>源端口号（ 16 位）：它（连同源主机 IP 地址）标识源主机的一个应用进程。</p></li> <li><p>目的端口号（ 16 位）：它（连同目的主机 IP 地址）标识目的主机的一个应用进程。这两个值
加上 IP 报头中的源主机 IP 地址和目的主机 IP 地址唯一确定一个 TCP 连接。</p></li> <li><p>顺序号seq（ 32 位）：用来标识从 TCP 源端向 TCP 目的端发送的数据字节流，它表示在这个
报文段中的第一个数据字节的顺序号。如果将字节流看作在两个应用程序间的单向流动，则
TCP 用顺序号对每个字节进行计数。序号是 32bit 的无符号数，序号到达 2 的 32 次方 － 1 后
又从 0 开始。当建立一个新的连接时， SYN 标志变 1 ，顺序号字段包含由这个主机选择的该
连接的初始顺序号 ISN （ Initial Sequence Number ）。</p></li> <li><p>确认号ack（ 32 位）：包含发送确认的一端所期望收到的下一个顺序号。因此，确认序号应当
是上次已成功收到数据字节顺序号加 1 。只有 ACK 标志为 1 时确认序号字段才有效。 TCP 为
应用层提供全双工服务，这意味数据能在两个方向上独立地进行传输。因此，连接的每一端必
须保持每个方向上的传输数据顺序号。</p></li> <li><p>TCP 报头长度（ 4 位）：给出报头中 32bit 字的数目，它实际上指明数据从哪里开始。需要这
个值是因为任选字段的长度是可变的。这个字段占 4bit ，因此 TCP 最多有 60 字节的首部。然
而，没有任选字段，正常的长度是 20 字节。</p></li> <li><p>保留位（ 6 位）：保留给将来使用，目前必须置为 0 。</p></li> <li><p>控制位（ control flags ， 6 位）：在 TCP 报头中有 6 个标志比特，它们中的多个可同时被设
置为 1 。依次为：
 URG ：为 1 表示紧急指针有效，为 0 则忽略紧急指针值。
 ACK ：为 1 表示确认号有效，为 0 表示报文中不包含确认信息，忽略确认号字段。
 PSH ：为 1 表示是带有 PUSH 标志的数据，指示接收方应该尽快将这个报文段交给应用层
而不用等待缓冲区装满。
 RST ：用于复位由于主机崩溃或其他原因而出现错误的连接。它还可以用于拒绝非法的报
文段和拒绝连接请求。一般情况下，如果收到一个 RST 为 1 的报文，那么一定发生了某些
问题。
 SYN ：同步序号，为 1 表示连接请求，用于建立连接和使顺序号同步（ synchronize ）。
 FIN ：用于释放连接，为 1 表示发送方已经没有数据发送了，即关闭本方数据流。</p></li> <li><p>窗口大小（ 16 位）：数据字节数，表示从确认号开始，本报文的源方可以接收的字节数，即源
方接收窗口大小。窗口大小是一个 16bit 字段，因而窗口大小最大为 65535 字节。</p></li> <li><p>校验和（ 16 位）：此校验和是对整个的 TCP 报文段，包括 TCP 头部和 TCP 数据，以 16 位字
进行计算所得。这是一个强制性的字段，一定是由发送端计算和存储，并由接收端进行验证。</p></li> <li><p>紧急指针（ 16 位）：只有当 URG 标志置 1 时紧急指针才有效。TCP 的紧急方式是发送端向另
一端发送紧急数据的一种方式。</p></li> <li><p>选项：最常见的可选字段是最长报文大小，又称为 MSS(Maximum Segment Size) 。每个连
接方通常都在通信的第一个报文段（为建立连接而设置 SYN 标志的那个段）中指明这个选项，
它指明本端所能接收的最大长度的报文段。选项长度不一定是 32 位字的整数倍，所以要加填充
位，使得报头长度成为整字数。</p></li> <li><p>数据： TCP 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报
文段仅有 TCP 首部。如果一方没有数据要发送，也使用没有任何数据的首部来确认收到的数
据。在处理超时的许多情况中，也会发送不带任何数据的报文段。</p></li></ol> <h4 id="_9-1-3-2-三次握手"><a href="#_9-1-3-2-三次握手" class="header-anchor">#</a> 9.1.3.2. 三次握手</h4> <p>第一次握手：主机A发送位码为syn＝1,随机产生seq number=1234567的数据包到服务器，主机B
由SYN=1知道，A要求建立联机；</p> <p>第二次握手：主机B 收到请求后要确认联机信息，向A 发送ack number=(主机A 的
seq+1),syn=1,ack=1,随机产生seq=7654321的包</p> <p>第三次握手：主机A收到后检查ack number是否正确，即第一次发送的seq number+1,以及位码
ack是否为 1 ，若正确，主机A会再发送ack number=(主机B的seq+1),ack=1，主机B收到后确认</p> <p>seq值与ack=1则连接建立成功。</p> <h4 id="_9-1-3-3-四次挥手"><a href="#_9-1-3-3-四次挥手" class="header-anchor">#</a> 9.1.3.3. 四次挥手</h4> <p>TCP建立连接要进行三次握手，而断开连接要进行四次。这是由于TCP的半关闭造成的。因为TCP连
接是全双工的(即数据可在两个方向上同时传递)所以进行关闭时每个方向上都要单独进行关闭。这个单
方向的关闭就叫半关闭。当一方完成它的数据发送任务，就发送一个FIN来向另一方通告将要终止这个
方向的连接。</p> <p>1 ） 关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户到服务器的数据传送，
然后等待服务器的确认。其中终止标志位FIN=1，序列号seq=u</p> <p>2 ） 服务器收到这个FIN，它发回一个ACK，确认号ack为收到的序号加 1 。</p> <p>3 ） 关闭服务器到客户端的连接：也是发送一个FIN给客户端。</p> <p>4 ） 客户段收到FIN后，并发回一个ACK报文确认，并将确认序号seq设置为收到序号加 1 。</p> <p>首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。</p> <div class="language- extra-class"><pre class="language-text"><code>主机A发送FIN后，进入终止等待状态， 服务器B收到主机A连接释放报文段后，就立即
给主机A发送确认，然后服务器B就进入close-wait状态，此时TCP服务器进程就通知高
层应用进程，因而从A到B的连接就释放了。此时是“半关闭”状态。即A不可以发送给
B，但是B可以发送给A。此时，若B没有数据报要发送给A了，其应用进程就通知TCP释
放连接，然后发送给A连接释放报文段，并等待确认。A发送确认后，进入time-wait，注
意，此时TCP连接还没有释放掉，然后经过时间等待计时器设置的2MSL后，A才进入到
close状态。
</code></pre></div><h3 id="_9-1-4-http-原理"><a href="#_9-1-4-http-原理" class="header-anchor">#</a> 9.1.4. HTTP 原理</h3> <p>HTTP是一个无状态的协议。无状态是指客户机（Web浏览器）和服务器之间不需要建立持久的连接，
这意味着当一个客户端向服务器端发出请求，然后服务器返回响应(response)，连接就被关闭了，在服
务器端不保留连接的有关信息.HTTP遵循请求(Request)/应答(Response)模型。客户机（浏览器）向
服务器发送请求，服务器处理请求并返回适当的应答。所有HTTP连接都被构造成一套请求和应答。</p> <h4 id="_9-1-4-1-传输流程"><a href="#_9-1-4-1-传输流程" class="header-anchor">#</a> 9.1.4.1. 传输流程</h4> <h5 id="_1-地址解析"><a href="#_1-地址解析" class="header-anchor">#</a> 1 ：地址解析</h5> <p>如用客户端浏览器请求这个页面：http://localhost.com:8080/index.htm 从中分解出协议名、主机名、
端口、对象路径等部分，对于我们的这个地址，解析得到的结果如下：</p> <p>协议名：http</p> <p>主机名：localhost.com</p> <p>端口： 8080</p> <p>对象路径：/index.htm</p> <p>在这一步，需要域名系统DNS解析域名localhost.com,得主机的IP地址。</p> <h5 id="_2-封装http请求数据包"><a href="#_2-封装http请求数据包" class="header-anchor">#</a> 2 ：封装HTTP请求数据包</h5> <div class="language- extra-class"><pre class="language-text"><code>把以上部分结合本机自己的信息，封装成一个HTTP请求数据包
</code></pre></div><h5 id="_3-封装成tcp包并建立连接"><a href="#_3-封装成tcp包并建立连接" class="header-anchor">#</a> 3 ：封装成TCP包并建立连接</h5> <p>封装成TCP包，建立TCP连接（TCP的三次握手）</p> <h5 id="_4-客户机发送请求命"><a href="#_4-客户机发送请求命" class="header-anchor">#</a> 4 ：客户机发送请求命</h5> <p>4 ）客户机发送请求命令：建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资
源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可内容。</p> <h5 id="_5-服务器响应"><a href="#_5-服务器响应" class="header-anchor">#</a> 5 ：服务器响应....................................................................................................................................................</h5> <p>服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或
错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。</p> <h5 id="_6-服务器关闭tcp连接"><a href="#_6-服务器关闭tcp连接" class="header-anchor">#</a> 6 ：服务器关闭TCP连接</h5> <p>服务器关闭TCP连接：一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连
接，然后如果浏览器或者服务器在其头信息加入了这行代码Connection:keep-alive，TCP连接在发送
后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求
建立新连接所需的时间，还节约了网络带宽。</p> <h4 id="_9-1-4-2-http状态"><a href="#_9-1-4-2-http状态" class="header-anchor">#</a> 9.1.4.2. HTTP状态</h4> <div class="language- extra-class"><pre class="language-text"><code>状态码 原因短语
消息响应
100 Continue(继续)
101 Switching Protocol(切换协议)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>成功响应
200 OK(成功)
201 Created(已创建)
202 Accepted(已创建)
203 Non-Authoritative Information(未授权信息)
204 No Content(无内容)
205 Reset Content(重置内容)
206 Partial Content(部分内容)
重定向
300 Multiple Choice(多种选择)
301 Moved Permanently(永久移动)
302 Found(临时移动)
303 See Other(查看其他位置)
304 Not Modified(未修改)
305 Use Proxy(使用代理)
306 unused(未使用)
307 Temporary Redirect(临时重定向)
308 Permanent Redirect(永久重定向)
客户端错误
400 Bad Request(错误请求)
401 Unauthorized(未授权)
402 Payment Required(需要付款)
403 Forbidden(禁止访问)
404 Not Found(未找到)
405 Method Not Allowed(不允许使用该方法)
406 Not Acceptable(无法接受)
407 Proxy Authentication Required(要求代理身份验证)
408 Request Timeout(请求超时)
409 Conflict(冲突)
410 Gone(已失效)
411 Length Required(需要内容长度头)
412 Precondition Failed(预处理失败)
413 Request Entity Too Large(请求实体过长)
414 Request-URI Too Long(请求网址过长)
415 Unsupported Media Type(媒体类型不支持)
416 Requested Range Not Satisfiable(请求范围不合要求)
417 Expectation Failed(预期结果失败)
服务器端错误
500 Internal Server Error(内部服务器错误)
501 Implemented(未实现)
502 Bad Gateway(网关错误)
503 Service Unavailable(服务不可用)
504 Gateway Timeout (网关超时)
505 HTTP Version Not Supported(HTTP版本不受支持)
</code></pre></div><h4 id="_9-1-4-3-https"><a href="#_9-1-4-3-https" class="header-anchor">#</a> 9.1.4.3. HTTPS</h4> <p>HTTPS（全称：Hypertext Transfer Protocol over Secure Socket Layer），是以安全为目标的
HTTP通道，简单讲是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL。其所用
的端口号是 443 。 过程大致如下：</p> <h5 id="建立连接获取证书"><a href="#建立连接获取证书" class="header-anchor">#</a> 建立连接获取证书</h5> <div class="language- extra-class"><pre class="language-text"><code>1 ） SSL客户端通过TCP和服务器建立连接之后（ 443 端口），并且在一般的tcp连接协商（握
手）过程中请求证书。即客户端发出一个消息给服务器，这个消息里面包含了自己可实现的算
法列表和其它一些需要的消息，SSL的服务器端会回应一个数据包，这里面确定了这次通信所
需要的算法，然后服务器向客户端返回证书。（证书里面包含了服务器信息：域名。申请证书
的公司，公共秘钥）。
</code></pre></div><h5 id="证书验证"><a href="#证书验证" class="header-anchor">#</a> 证书验证</h5> <div class="language- extra-class"><pre class="language-text"><code>2 ） Client在收到服务器返回的证书后，判断签发这个证书的公共签发机构，并使用这个机构的公
共秘钥确认签名是否有效，客户端还会确保证书中列出的域名就是它正在连接的域名。
</code></pre></div><h5 id="数据加密和传输"><a href="#数据加密和传输" class="header-anchor">#</a> 数据加密和传输</h5> <p>3 ） 如果确认证书有效，那么生成对称秘钥并使用服务器的公共秘钥进行加密。然后发送给服务
器，服务器使用它的私钥对它进行解密，这样两台计算机可以开始进行对称加密进行通信。</p> <h3 id="_9-1-5-cdn-原理"><a href="#_9-1-5-cdn-原理" class="header-anchor">#</a> 9.1.5. CDN 原理</h3> <p>CND一般包含分发服务系统、负载均衡系统和管理系统</p> <h4 id="_9-1-5-1-分发服务系统"><a href="#_9-1-5-1-分发服务系统" class="header-anchor">#</a> 9.1.5.1. 分发服务系统</h4> <p>其基本的工作单元就是各个Cache服务器。负责直接响应用户请求，将内容快速分发到用户；同时还
负责内容更新，保证和源站内容的同步。</p> <p>根据内容类型和服务种类的不同，分发服务系统分为多个子服务系统，如：网页加速服务、流媒体加速
服务、应用加速服务等。每个子服务系统都是一个分布式的服务集群，由功能类似、地域接近的分布部
署的Cache集群组成。
在承担内容同步、更新和响应用户请求之外，分发服务系统还需要向上层的管理调度系统反馈各个
Cache设备的健康状况、响应情况、内容缓存状况等，以便管理调度系统能够根据设定的策略决定由
哪个Cache设备来响应用户的请求。</p> <h4 id="_9-1-5-2-负载均衡系统"><a href="#_9-1-5-2-负载均衡系统" class="header-anchor">#</a> 9.1.5.2. 负载均衡系统：</h4> <p>负载均衡系统是整个CDN系统的中枢。负责对所有的用户请求进行调度，确定提供给用户的最终访问
地址。
使用分级实现。最基本的两极调度体系包括全局负载均衡（GSLB）和本地负载均衡（SLB）。
GSLB根据用户地址和用户请求的内容，主要根据就近性原则，确定向用户服务的节点。一般通过DNS
解析或者应用层重定向（Http 3XX重定向）的方式实现。
SLB主要负责节点内部的负载均衡。当用户请求从GSLB调度到SLB时，SLB会根据节点内各个
Cache设备的工作状况和内容分布情况等对用户请求重定向。SLB的实现有四层调度（LVS）、七层调
度（Nginx）和链路负载调度等。</p> <h4 id="_9-1-5-3-管理系统"><a href="#_9-1-5-3-管理系统" class="header-anchor">#</a> 9.1.5.3. 管理系统：.............................................................................................................................................</h4> <p>分为运营管理和网络管理子系统。
网络管理系统实现对CDN系统的设备管理、拓扑管理、链路监控和故障管理，为管理员提供对全网资
源的可视化的集中管理，通常用web方式实现。
运营管理是对CDN系统的业务管理，负责处理业务层面的与外界系统交互所必须的一些收集、整理、
交付工作。包括用户管理、产品管理、计费管理、统计分析等。</p> <h2 id="_10-日志"><a href="#_10-日志" class="header-anchor">#</a> 10. 日志</h2> <h3 id="_10-1-1-slf4j"><a href="#_10-1-1-slf4j" class="header-anchor">#</a> 10.1.1. Slf4j</h3> <p>slf4j的全称是Simple Loging Facade For Java，即它仅仅是一个为Java程序提供日志输出的统一接
口，并不是一个具体的日志实现方案，就比如JDBC一样，只是一种规则而已。所以单独的slf4j是不
能工作的，必须搭配其他具体的日志实现方案，比如apache的org.apache.log4j.Logger，jdk自带
的java.util.logging.Logger等。</p> <h3 id="_10-1-2-log4j"><a href="#_10-1-2-log4j" class="header-anchor">#</a> 10.1.2. Log4j</h3> <p>Log4j是Apache的一个开源项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、
文件、GUI组件，甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控
制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。
Log4j由三个重要的组成构成：日志记录器(Loggers)，输出端(Appenders)和日志格式化器(Layout)。</p> <p>1.Logger：控制要启用或禁用哪些日志记录语句，并对日志信息进行级别限制</p> <p>2.Appenders : 指定了日志将打印到控制台还是文件中</p> <p>3.Layout : 控制日志信息的显示格式</p> <p>Log4j中将要输出的Log信息定义了 5 种级别，依次为DEBUG、INFO、WARN、ERROR和FATAL，
当输出时，只有级别高过配置中规定的 级别的信息才能真正的输出，这样就很方便的来配置不同情况
下要输出的内容，而不需要更改代码。</p> <h3 id="_10-1-3-logback"><a href="#_10-1-3-logback" class="header-anchor">#</a> 10.1.3. LogBack</h3> <p>简单地说，Logback 是一个 Java 领域的日志框架。它被认为是 Log4J 的继承人。</p> <p>Logback 主要由三个模块组成：logback-core，logback-classic。logback-access</p> <p>logback-core 是其它模块的基础设施，其它模块基于它构建，显然，logback-core 提供了一些关键的
通用机制。</p> <p>logback-classic 的地位和作用等同于 Log4J，它也被认为是 Log4J 的一个改进版，并且它实现了简单
日志门面 SLF4J；</p> <p>logback-access 主要作为一个与 Servlet 容器交互的模块，比如说 tomcat 或者 jetty，提供一些与
HTTP 访问相关的功能。</p> <h4 id="_10-1-3-1-logback优点"><a href="#_10-1-3-1-logback优点" class="header-anchor">#</a> 10.1.3.1. Logback优点</h4> <p> 同样的代码路径，Logback 执行更快
 更充分的测试
 原生实现了 SLF4J API（Log4J 还需要有一个中间转换层）
 内容更丰富的文档
 支持 XML 或者 Groovy 方式配置
 配置文件自动热加载</p> <p> 从 IO 错误中优雅恢复
 自动删除日志归档
 自动压缩日志成为归档文件
 支持 Prudent 模式，使多个 JVM 进程能记录同一个日志文件
 支持配置文件中加入条件判断来适应不同的环境
 更强大的过滤器
 支持 SiftingAppender（可筛选 Appender）
 异常栈信息带有包信息</p> <h3 id="_10-1-4-elk"><a href="#_10-1-4-elk" class="header-anchor">#</a> 10.1.4. ELK</h3> <p>ELK 是软件集合 Elasticsearch、Logstash、Kibana 的简称，由这三个软件及其相关的组件可以打
造大规模日志实时处理系统。</p> <p> Elasticsearch 是一个基于 Lucene 的、支持全文索引的分布式存储和索引引擎，主要负责将
日志索引并存储起来，方便业务方检索查询。
 Logstash 是一个日志收集、过滤、转发的中间件，主要负责将各条业务线的各类日志统一收
集、过滤后，转发给 Elasticsearch 进行下一步处理。
 Kibana 是一个可视化工具，主要负责查询 Elasticsearch 的数据并以可视化的方式展现给业
务方，比如各类饼图、直方图、区域图等。</p> <h2 id="_11-zookeeper"><a href="#_11-zookeeper" class="header-anchor">#</a> 11. ZOOKEEPER</h2> <h3 id="_11-1-1-zookeeper-概念"><a href="#_11-1-1-zookeeper-概念" class="header-anchor">#</a> 11.1.1. Zookeeper 概念</h3> <p>Zookeeper是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。
Zookeeper提供了一个类似于Linux文件系统的树形结构（可认为是轻量级的内存文件系统，但
只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与
通知机制。</p> <h3 id="_11-1-1-zookeeper-角色"><a href="#_11-1-1-zookeeper-角色" class="header-anchor">#</a> 11.1.1. Zookeeper 角色</h3> <p>Zookeeper集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种</p> <h4 id="_11-1-1-1-leader"><a href="#_11-1-1-1-leader" class="header-anchor">#</a> 11.1.1.1. Leader</h4> <ol><li>一个Zookeeper集群同一时间只会有一个实际工作的Leader，它会发起并维护与各Follwer
及Observer间的心跳。</li> <li>所有的写操作必须要通过Leader完成再由Leader将写操作广播给其它服务器。只要有超过
半数节点（不包括observeer节点）写入成功，该写请求就会被提交（类 2PC 协议）。</li></ol> <h4 id="_11-1-1-2-follower"><a href="#_11-1-1-2-follower" class="header-anchor">#</a> 11.1.1.2. Follower</h4> <ol><li>一个Zookeeper集群可能同时存在多个Follower，它会响应Leader的心跳，</li> <li>Follower可直接处理并返回客户端的读请求，同时会将写请求转发给Leader处理，</li> <li>并且负责在Leader处理写请求时对请求进行投票。</li></ol> <h4 id="_11-1-1-3-observer"><a href="#_11-1-1-3-observer" class="header-anchor">#</a> 11.1.1.3. Observer</h4> <p>角色与Follower类似，但是无投票权。Zookeeper需保证高可用和强一致性，为了支持更多的客
户端，需要增加更多Server；Server增多，投票阶段延迟增大，影响性能；引入Observer，
Observer不参与投票； Observers接受客户端的连接，并将写请求转发给leader节点； 加入更
多Observer节点，提高伸缩性，同时不影响吞吐率。</p> <h4 id="_11-1-1-1-zab协议"><a href="#_11-1-1-1-zab协议" class="header-anchor">#</a> 11.1.1.1. ZAB协议</h4> <h5 id="事务编号-zxid-事务请求计数器-epoch"><a href="#事务编号-zxid-事务请求计数器-epoch" class="header-anchor">#</a> 事务编号 Zxid（事务请求计数器+ epoch）</h5> <p>在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议） 协议的事务编号 Zxid
设计中，Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每
一个事务请求，计数器加 1 ；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新
的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的ZXID，并从中读取
epoch 值，然后加 1 ，以此作为新的 epoch，并将低 32 位从 0 开始计数。</p> <p>Zxid（Transaction id）类似于RDBMS中的事务ID，用于标识一次更新操作的Proposal（提议）
ID。为了保证顺序性，该zkid必须单调递增。</p> <h5 id="epoch"><a href="#epoch" class="header-anchor">#</a> epoch</h5> <p>epoch：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所
以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1 。这样就算旧的 leader 崩溃
恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。</p> <h5 id="zab协议有两种模式-恢复模式-选主-、广播模式-同步"><a href="#zab协议有两种模式-恢复模式-选主-、广播模式-同步" class="header-anchor">#</a> Zab协议有两种模式-恢复模式（选主）、广播模式（同步）</h5> <p>Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导
者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和leader的状
态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。</p> <h5 id="zab协议-4-阶段"><a href="#zab协议-4-阶段" class="header-anchor">#</a> ZAB协议 4 阶段</h5> <h5 id="leader-election-选举阶段-选出准leader"><a href="#leader-election-选举阶段-选出准leader" class="header-anchor">#</a> Leader election（选举阶段-选出准Leader）</h5> <ol><li>Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数
节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成
为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。</li></ol> <h5 id="discovery-发现阶段-接受提议、生成epoch、接受epoch"><a href="#discovery-发现阶段-接受提议、生成epoch、接受epoch" class="header-anchor">#</a> Discovery（发现阶段-接受提议、生成epoch、接受epoch）</h5> <ol start="2"><li>Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers
最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且
准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch
一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f
在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。</li></ol> <h5 id="synchronization-同步阶段-同步follower副本"><a href="#synchronization-同步阶段-同步follower副本" class="header-anchor">#</a> Synchronization（同步阶段-同步follower副本）</h5> <ol start="3"><li>Synchronization（同步阶段）：同步阶段主要是利用 leader 前一阶段获得的最新提议历史，
同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。
follower 只会接收 zxid 比自己的 lastZxid 大的提议。</li></ol> <h5 id="broadcast-广播阶段-leader消息广播"><a href="#broadcast-广播阶段-leader消息广播" class="header-anchor">#</a> Broadcast（广播阶段-leader消息广播）</h5> <ol start="4"><li>Broadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，
并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。</li></ol> <p>ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就
可以了。</p> <h5 id="zab协议java实现-fle-发现阶段和同步合并为-recovery-phase-恢复阶段"><a href="#zab协议java实现-fle-发现阶段和同步合并为-recovery-phase-恢复阶段" class="header-anchor">#</a> ZAB协议JAVA实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段））</h5> <p>协议的 Java 版本实现跟上面的定义有些不同，选举阶段使用的是 Fast Leader Election（FLE），
它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader，这样就省去了
发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase（恢复阶段）。所
以，ZAB 的实现只有三个阶段：Fast Leader Election；Recovery Phase；Broadcast Phase。</p> <h4 id="_11-1-1-2-投票机制"><a href="#_11-1-1-2-投票机制" class="header-anchor">#</a> 11.1.1.2. 投票机制</h4> <p>每个sever首先给自己投票，然后用自己的选票和其他sever选票对比，权重大的胜出，使用权
重较大的更新自身选票箱。具体选举过程如下：</p> <ol><li>每个Server启动以后都询问其它的Server它要投票给谁。对于其他server的询问，
server每次根据自己的状态都回复自己推荐的leader的id和上一次处理事务的zxid（系
统启动时每个server都会推荐自己）</li> <li>收到所有Server回复以后，就计算出zxid最大的哪个Server，并将这个Server相关信
息设置成下一次要投票的Server。</li> <li>计算这过程中获得票数最多的的sever为获胜者，如果获胜者的票数超过半数，则改
server被选为leader。否则，继续这个过程，直到leader被选举出来</li> <li>leader就会开始等待server连接</li> <li>Follower连接leader，将最大的zxid发送给leader</li> <li>Leader根据follower的zxid确定同步点，至此选举阶段完成。</li> <li>选举阶段完成Leader同步后通知follower 已经成为uptodate状态</li> <li>Follower收到uptodate消息后，又可以重新接受client的请求进行服务了</li></ol> <p>目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们
的选择举过程如下：</p> <ol><li>服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反
馈信息，服务器 1 的状态一直属于Looking。</li> <li>服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号
大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是
LOOKING。</li> <li>服务器 3 启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器 3 的编
号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器
1,2成为小弟。</li> <li>服务器 4 启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器 4 的
编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。</li> <li>服务器 5 启动，后面的逻辑同服务器 4 成为小弟。</li></ol> <h3 id="_11-1-2-zookeeper-工作原理-原子广播"><a href="#_11-1-2-zookeeper-工作原理-原子广播" class="header-anchor">#</a> 11.1.2. Zookeeper 工作原理（原子广播）</h3> <ol><li>Zookeeper的核心是原子广播，这个机制保证了各个server之间的同步。实现这个机制
的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式和广播模式。</li> <li>当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多
数server的完成了和leader的状态同步以后，恢复模式就结束了。</li> <li>状态同步保证了leader和server具有相同的系统状态</li> <li>一旦leader已经和多数的follower进行了状态同步后，他就可以开始广播消息了，即进
入广播状态。这时候当一个server加入zookeeper服务中，它会在恢复模式下启动，发
现leader，并和leader进行状态同步。待到同步结束，它也参与消息广播。Zookeeper
服务一直维持在Broadcast状态，直到leader崩溃了或者leader失去了大部分的
followers支持。</li> <li>广播模式需要保证proposal被按顺序处理，因此zk采用了递增的事务id号(zxid)来保
证。所有的提议(proposal)都在被提出的时候加上了zxid。</li> <li>实现中zxid是一个 64 为的数字，它高 32 位是epoch用来标识leader关系是否改变，
每次一个leader被选出来，它都会有一个新的epoch。低 32 位是个递增计数。</li> <li>当leader崩溃或者leader失去大多数的follower，这时候zk进入恢复模式，恢复模式
需要重新选举出一个新的leader，让所有的server都恢复到一个正确的状态。</li></ol> <h3 id="_11-1-3-znode-有四种形式的目录节点"><a href="#_11-1-3-znode-有四种形式的目录节点" class="header-anchor">#</a> 11.1.3. Znode 有四种形式的目录节点</h3> <ol><li>PERSISTENT：持久的节点。</li> <li>EPHEMERAL：暂时的节点。</li> <li>PERSISTENT_SEQUENTIAL：持久化顺序编号目录节点。</li> <li>EPHEMERAL_SEQUENTIAL：暂时化顺序编号目录节点。</li></ol> <h2 id="_12-kafka"><a href="#_12-kafka" class="header-anchor">#</a> 12. KAFKA</h2> <h3 id="_12-1-1-kafka-概念"><a href="#_12-1-1-kafka-概念" class="header-anchor">#</a> 12.1.1. Kafka 概念</h3> <p>Kafka是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由LinkedIn公司开发，使用
Scala语言编写，目前是Apache的开源项目。</p> <ol><li>broker：Kafka服务器，负责消息存储和转发</li> <li>topic：消息类别，Kafka按照topic来分类消息</li> <li>partition：topic 的分区，一个topic 可以包含多个partition，topic 消息保存在各个
partition上</li> <li>offset：消息在日志中的位置，可以理解是消息在partition 上的偏移量，也是代表该消息的
唯一序号</li> <li>Producer：消息生产者</li> <li>Consumer：消息消费者</li> <li>Consumer Group：消费者分组，每个Consumer必须属于一个group</li> <li>Zookeeper：保存着集群broker、topic、partition等meta数据；另外，还负责broker故
障发现，partition leader选举，负载均衡等功能</li></ol> <h3 id="_12-1-2-kafka-数据存储设计"><a href="#_12-1-2-kafka-数据存储设计" class="header-anchor">#</a> 12.1.2. Kafka 数据存储设计</h3> <h4 id="_12-1-2-1-partition的数据文件-offset-messagesize-data"><a href="#_12-1-2-1-partition的数据文件-offset-messagesize-data" class="header-anchor">#</a> 12.1.2.1. partition的数据文件（offset，MessageSize，data）</h4> <p>partition中的每条Message包含了以下三个属性：offset，MessageSize，data，其中offset表
示Message在这个partition中的偏移量，offset不是该Message在partition数据文件中的实</p> <p>际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message，可以认为offset是
partition中Message的id；MessageSize表示消息内容data的大小；data为Message的具
体内容。</p> <h4 id="_12-1-2-2-数据文件分段segment-顺序读写、分段命令、二分查找"><a href="#_12-1-2-2-数据文件分段segment-顺序读写、分段命令、二分查找" class="header-anchor">#</a> 12.1.2.2. 数据文件分段segment（顺序读写、分段命令、二分查找）</h4> <p>partition物理上由多个segment文件组成，每个segment大小相等，顺序读写。每个segment
数据文件以该段中最小的offset命名，文件扩展名为.log。这样在查找指定offset的Message的
时候，用二分查找就可以定位到该Message在哪个segment数据文件中。</p> <h4 id="_12-1-2-3-数据文件索引-分段索引、稀疏存储"><a href="#_12-1-2-3-数据文件索引-分段索引、稀疏存储" class="header-anchor">#</a> 12.1.2.3. 数据文件索引（分段索引、稀疏存储）</h4> <p>Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩
展名为.index。index文件中并没有为数据文件中的每条Message建立索引，而是采用了稀疏存
储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以
将索引文件保留在内存中。</p> <h3 id="_12-1-3-生产者设计"><a href="#_12-1-3-生产者设计" class="header-anchor">#</a> 12.1.3. 生产者设计</h3> <h4 id="_12-1-3-1-负载均衡-partition会均衡分布到不同broker上"><a href="#_12-1-3-1-负载均衡-partition会均衡分布到不同broker上" class="header-anchor">#</a> 12.1.3.1. 负载均衡（partition会均衡分布到不同broker上）</h4> <p>由于消息topic由多个partition组成，且partition会均衡分布到不同broker上，因此，为了有
效利用broker集群的性能，提高消息的吞吐量，producer可以通过随机或者hash等方式，将消
息平均发送到多个partition上，以实现负载均衡。</p> <h4 id="_12-1-3-2-批量发送"><a href="#_12-1-3-2-批量发送" class="header-anchor">#</a> 12.1.3.2. 批量发送</h4> <p>是提高消息吞吐量重要的方式，Producer端可以在内存中合并多条消息后，以一次请求的方式发
送了批量的消息给broker，从而大大减少broker存储消息的IO操作次数。但也一定程度上影响
了消息的实时性，相当于以时延代价，换取更好的吞吐量。</p> <h4 id="_12-1-3-3-压缩-gzip或snappy"><a href="#_12-1-3-3-压缩-gzip或snappy" class="header-anchor">#</a> 12.1.3.3. 压缩（GZIP或Snappy）</h4> <p>Producer端可以通过GZIP或Snappy格式对消息集合进行压缩。Producer端进行压缩之后，在
Consumer 端需进行解压。压缩的好处就是减少传输的数据量，减轻对网络传输的压力，在对大
数据处理上，瓶颈往往体现在网络上而不是CPU（压缩和解压会耗掉部分CPU资源）。</p> <h3 id="_12-1-1-消费者设计"><a href="#_12-1-1-消费者设计" class="header-anchor">#</a> 12.1.1. 消费者设计</h3> <h4 id="_12-1-1-1-consumer-group"><a href="#_12-1-1-1-consumer-group" class="header-anchor">#</a> 12.1.1.1. Consumer Group</h4> <p>同一Consumer Group中的多个Consumer实例，不同时消费同一个partition，等效于队列模
式。partition内消息是有序的，Consumer通过pull方式消费消息。Kafka不删除已消费的消息</p> <p>对于partition，顺序读写磁盘数据，以时间复杂度O(1)方式提供消息持久化能力。</p> <h2 id="_13-rabbitmq"><a href="#_13-rabbitmq" class="header-anchor">#</a> 13. RABBITMQ</h2> <h3 id="_13-1-1-概念"><a href="#_13-1-1-概念" class="header-anchor">#</a> 13.1.1. 概念</h3> <p>RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。</p> <p>AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为
面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言
等条件的限制。</p> <p>RabbitMQ 最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可
用性等方面表现不俗。具体特点包括：</p> <ol><li>可靠性（Reliability）：RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布
确认。</li> <li>灵活的路由（Flexible Routing）：在消息进入队列之前，通过 Exchange 来路由消息的。对
于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路
由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。</li> <li>消息集群（Clustering）：多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。</li> <li>高可用（Highly Available Queues）：队列可以在集群中的机器上进行镜像，使得在部分节
点出问题的情况下队列仍然可用。</li> <li>多种协议（Multi-protocol）：RabbitMQ 支持多种消息队列协议，比如 STOMP、MQTT
等等。</li> <li>多语言客户端（Many Clients）：RabbitMQ 几乎支持所有常用语言，比如 Java、.NET、
Ruby 等等。</li> <li>管理界面（Management UI）:RabbitMQ 提供了一个易用的用户界面，使得用户可以监控
和管理消息 Broker 的许多方面。</li> <li>跟踪机制（Tracing）:如果消息异常，RabbitMQ 提供了消息跟踪机制，使用者可以找出发生
了什么。</li> <li>插件机制（Plugin System）:RabbitMQ 提供了许多插件，来从多方面进行扩展，也可以编
写自己的插件。</li></ol> <h3 id="_13-1-2-rabbitmq-架构"><a href="#_13-1-2-rabbitmq-架构" class="header-anchor">#</a> 13.1.2. RabbitMQ 架构</h3> <h4 id="_13-1-2-1-message"><a href="#_13-1-2-1-message" class="header-anchor">#</a> 13.1.2.1. Message</h4> <div class="language- extra-class"><pre class="language-text"><code>消息，消息是不具名的，它由消息头和消息体组成。消息体是不透明的，而消息头则由一系
列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其他消息的优
先权）、delivery-mode（指出该消息可能需要持久性存储）等。
</code></pre></div><h4 id="_13-1-2-2-publisher"><a href="#_13-1-2-2-publisher" class="header-anchor">#</a> 13.1.2.2. Publisher</h4> <ol><li>消息的生产者，也是一个向交换器发布消息的客户端应用程序。</li></ol> <h4 id="_13-1-2-3-exchange-将消息路由给队列"><a href="#_13-1-2-3-exchange-将消息路由给队列" class="header-anchor">#</a> 13.1.2.3. Exchange（将消息路由给队列 ）</h4> <ol start="2"><li>交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。</li></ol> <h4 id="_13-1-2-4-binding-消息队列和交换器之间的关联"><a href="#_13-1-2-4-binding-消息队列和交换器之间的关联" class="header-anchor">#</a> 13.1.2.4. Binding（消息队列和交换器之间的关联）</h4> <ol start="3"><li>绑定，用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连
接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。</li></ol> <h4 id="_13-1-2-5-queue"><a href="#_13-1-2-5-queue" class="header-anchor">#</a> 13.1.2.5. Queue</h4> <ol start="4"><li>消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息
可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。</li></ol> <h4 id="_13-1-2-6-connection"><a href="#_13-1-2-6-connection" class="header-anchor">#</a> 13.1.2.6. Connection</h4> <ol start="5"><li>网络连接，比如一个TCP连接。</li></ol> <h4 id="_13-1-2-7-channel"><a href="#_13-1-2-7-channel" class="header-anchor">#</a> 13.1.2.7. Channel</h4> <ol start="6"><li>信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的 TCP连接内地虚
拟连接，AMQP 命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这
些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销，所
以引入了信道的概念，以复用一条 TCP 连接。</li></ol> <h4 id="_13-1-2-8-consumer"><a href="#_13-1-2-8-consumer" class="header-anchor">#</a> 13.1.2.8. Consumer</h4> <ol start="7"><li>消息的消费者，表示一个从消息队列中取得消息的客户端应用程序。</li></ol> <h4 id="_13-1-2-9-virtual-host"><a href="#_13-1-2-9-virtual-host" class="header-anchor">#</a> 13.1.2.9. Virtual Host</h4> <ol start="8"><li>虚拟主机，表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密
环境的独立服务器域。</li></ol> <h4 id="_13-1-2-10-broker"><a href="#_13-1-2-10-broker" class="header-anchor">#</a> 13.1.2.10. Broker</h4> <ol start="9"><li>表示消息队列服务器实体。</li></ol> <h3 id="_13-1-3-exchange-类型"><a href="#_13-1-3-exchange-类型" class="header-anchor">#</a> 13.1.3. Exchange 类型</h3> <p>Exchange分发消息时根据类型的不同分发策略有区别，目前共四种类型：direct、fanout、
topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键，此外 headers 交换器和
direct 交换器完全一致，但性能差很多，目前几乎用不到了，所以直接看另外三种类型：</p> <h4 id="_13-1-3-1-direct键-routing-key-分布"><a href="#_13-1-3-1-direct键-routing-key-分布" class="header-anchor">#</a> 13.1.3.1. Direct键（routing key）分布：</h4> <ol><li>Direct：消息中的路由键（routing key）如果和 Binding 中的 binding key 一致，
交换器就将消息发到对应的队列中。它是完全匹配、单播的模式。</li></ol> <h4 id="_13-1-3-2-fanout-广播分发"><a href="#_13-1-3-2-fanout-广播分发" class="header-anchor">#</a> 13.1.3.2. Fanout（广播分发）</h4> <ol start="2"><li>Fanout：每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。很像子
网广播，每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快
的。</li></ol> <h4 id="_13-1-3-3-topic-交换器-模式匹配"><a href="#_13-1-3-3-topic-交换器-模式匹配" class="header-anchor">#</a> 13.1.3.3. topic 交换器（模式匹配）</h4> <ol start="3"><li>topic 交换器：topic 交换器通过模式匹配分配消息的路由键属性，将路由键和某个模
式进行匹配，此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成
单词，这些单词之间用点隔开。它同样也会识别两个通配符：符号“#”和符号
“”。#匹配 0 个或多个单词，匹配不多不少一个单词。</li></ol> <h2 id="_14-hbase"><a href="#_14-hbase" class="header-anchor">#</a> 14. HBASE</h2> <h3 id="_14-1-1-概念"><a href="#_14-1-1-概念" class="header-anchor">#</a> 14.1.1. 概念</h3> <p>base是分布式、面向列的开源数据库（其实准确的说是面向列族）。HDFS为Hbase提供可靠的
底层数据存储服务，MapReduce为Hbase提供高性能的计算能力，Zookeeper为Hbase提供
稳定服务和Failover机制，因此我们说Hbase是一个通过大量廉价的机器解决海量数据的高速存
储和读取的分布式数据库解决方案。</p> <h3 id="_14-1-2-列式存储"><a href="#_14-1-2-列式存储" class="header-anchor">#</a> 14.1.2. 列式存储</h3> <p>列方式所带来的重要好处之一就是，由于查询中的选择规则是通过列来定义的，因此整个数据库
是自动索引化的。</p> <p>这里的列式存储其实说的是列族存储，Hbase是根据列族来存储数据的。列族下面可以有非常多
的列，列族在创建表的时候就必须指定。为了加深对Hbase列族的理解，下面是一个简单的关系
型数据库的表和Hbase数据库的表：</p> <h3 id="_14-1-3-hbase-核心概念"><a href="#_14-1-3-hbase-核心概念" class="header-anchor">#</a> 14.1.3. Hbase 核心概念</h3> <h4 id="_14-1-3-1-column-family列族"><a href="#_14-1-3-1-column-family列族" class="header-anchor">#</a> 14.1.3.1. Column Family列族</h4> <p>Column Family又叫列族，Hbase通过列族划分数据的存储，列族下面可以包含任意多的列，实
现灵活的数据存取。Hbase 表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须
指定具体的列是一样的。Hbase的列族不是越多越好，官方推荐的是列族最好小于或者等于 3 。我
们使用的场景一般是 1 个列族。</p> <h4 id="_14-1-3-2-rowkey-rowkey查询-rowkey范围扫描-全表扫描"><a href="#_14-1-3-2-rowkey-rowkey查询-rowkey范围扫描-全表扫描" class="header-anchor">#</a> 14.1.3.2. Rowkey（Rowkey查询，Rowkey范围扫描，全表扫描）</h4> <p>Rowkey的概念和mysql中的主键是完全一样的，Hbase使用Rowkey来唯一的区分某一行的数
据。Hbase只支持 3 中查询方式：基于Rowkey的单行查询，基于Rowkey的范围扫描，全表扫
描。</p> <h4 id="_14-1-3-3-region分区"><a href="#_14-1-3-3-region分区" class="header-anchor">#</a> 14.1.3.3. Region分区</h4> <p> <strong>Region</strong> ：Region的概念和关系型数据库的分区或者分片差不多。Hbase会将一个大表的数
据基于Rowkey的不同范围分配到不通的Region中，每个Region负责一定范围的数据访问
和存储。这样即使是一张巨大的表，由于被切割到不通的region，访问起来的时延也很低。</p> <h4 id="_14-1-3-4-timestamp多版本"><a href="#_14-1-3-4-timestamp多版本" class="header-anchor">#</a> 14.1.3.4. TimeStamp多版本</h4> <p> TimeStamp是实现Hbase多版本的关键。在Hbase中使用不同的timestame来标识相同
rowkey行对应的不通版本的数据。在写入数据的时候，如果用户没有指定对应的
timestamp，Hbase会自动添加一个timestamp，timestamp和服务器时间保持一致。在
Hbase中，相同rowkey的数据按照timestamp倒序排列。默认查询的是最新的版本，用户
可同指定timestamp的值来读取旧版本的数据。</p> <h3 id="_14-1-4-hbase-核心架构"><a href="#_14-1-4-hbase-核心架构" class="header-anchor">#</a> 14.1.4. Hbase 核心架构</h3> <div class="language- extra-class"><pre class="language-text"><code>Hbase是由Client、Zookeeper、Master、HRegionServer、HDFS等几个组建组成。
</code></pre></div><h4 id="_14-1-4-1-client"><a href="#_14-1-4-1-client" class="header-anchor">#</a> 14.1.4.1. Client：</h4> <div class="language- extra-class"><pre class="language-text"><code> Client包含了访问Hbase的接口，另外Client还维护了对应的cache来加速Hbase的
访问，比如cache的.META.元数据的信息。
</code></pre></div><h4 id="_14-1-4-2-zookeeper"><a href="#_14-1-4-2-zookeeper" class="header-anchor">#</a> 14.1.4.2. Zookeeper：....................................................................................................................................</h4> <div class="language- extra-class"><pre class="language-text"><code> Hbase通过Zookeeper来做master的高可用、RegionServer的监控、元数据的入口
以及集群配置的维护等工作。具体工作如下：
</code></pre></div><ol><li>通过Zoopkeeper来保证集群中只有 1 个master在运行，如果master异
常，会通过竞争机制产生新的master提供服务</li> <li>通过Zoopkeeper来监控RegionServer的状态，当RegionSevrer有异常的
时候，通过回调的形式通知Master RegionServer上下限的信息</li> <li>通过Zoopkeeper存储元数据的统一入口地址。</li></ol> <h4 id="_14-1-4-3-hmaster"><a href="#_14-1-4-3-hmaster" class="header-anchor">#</a> 14.1.4.3. Hmaster</h4> <p> master节点的主要职责如下：</p> <ol><li>为RegionServer分配Region</li> <li>维护整个集群的负载均衡</li> <li>维护集群的元数据信息发现失效的Region，并将失效的Region分配到正常
RegionServer上当RegionSever失效的时候，协调对应Hlog的拆分</li></ol> <h4 id="_14-1-4-4-hregionserver"><a href="#_14-1-4-4-hregionserver" class="header-anchor">#</a> 14.1.4.4. HregionServer</h4> <p> HregionServer直接对接用户的读写请求，是真正的“干活”的节点。它的功能概括如
下：</p> <ol><li><p>管理master为其分配的Region</p></li> <li><p>处理来自客户端的读写请求</p></li> <li><p>负责和底层HDFS的交互，存储数据到HDFS</p></li> <li><p>负责Region变大以后的拆分</p></li> <li><p>负责Storefile的合并工作</p></li></ol> <h4 id="_14-1-4-5-region寻址方式-通过zookeeper-meta"><a href="#_14-1-4-5-region寻址方式-通过zookeeper-meta" class="header-anchor">#</a> 14.1.4.5. Region寻址方式（通过zookeeper .META）</h4> <div class="language- extra-class"><pre class="language-text"><code>第 1 步：Client请求ZK获取.META.所在的RegionServer的地址。
第 2 步：Client请求.META.所在的RegionServer获取访问数据所在的RegionServer地
址，client会将.META.的相关信息cache下来，以便下一次快速访问。
第 3 步：Client请求数据所在的RegionServer，获取所需要的数据。
</code></pre></div><h4 id="_14-1-4-6-hdfs"><a href="#_14-1-4-6-hdfs" class="header-anchor">#</a> 14.1.4.6. HDFS</h4> <p> HDFS为Hbase提供最终的底层数据存储服务，同时为Hbase提供高可用（Hlog存储在
HDFS）的支持。</p> <h3 id="_14-1-5-hbase-的写逻辑"><a href="#_14-1-5-hbase-的写逻辑" class="header-anchor">#</a> 14.1.5. Hbase 的写逻辑</h3> <h4 id="_14-1-5-1-hbase的写入流程"><a href="#_14-1-5-1-hbase的写入流程" class="header-anchor">#</a> 14.1.5.1. Hbase的写入流程</h4> <div class="language- extra-class"><pre class="language-text"><code>从上图可以看出氛围 3 步骤：
</code></pre></div><h5 id="获取regionserver"><a href="#获取regionserver" class="header-anchor">#</a> 获取RegionServer</h5> <div class="language- extra-class"><pre class="language-text"><code>第 1 步：Client获取数据写入的Region所在的RegionServer
</code></pre></div><h5 id="请求写hlog"><a href="#请求写hlog" class="header-anchor">#</a> 请求写Hlog</h5> <div class="language- extra-class"><pre class="language-text"><code>第 2 步：请求写Hlog, Hlog存储在HDFS，当RegionServer出现异常，需要使用Hlog来
恢复数据。
</code></pre></div><h5 id="请求写memstore"><a href="#请求写memstore" class="header-anchor">#</a> 请求写MemStore</h5> <div class="language- extra-class"><pre class="language-text"><code>第 3 步：请求写MemStore,只有当写Hlog和写MemStore都成功了才算请求写入完成。
MemStore后续会逐渐刷到HDFS中。
</code></pre></div><h4 id="_14-1-5-2-memstore刷盘"><a href="#_14-1-5-2-memstore刷盘" class="header-anchor">#</a> 14.1.5.2. MemStore刷盘</h4> <div class="language- extra-class"><pre class="language-text"><code>为了提高Hbase的写入性能，当写请求写入MemStore后，不会立即刷盘。而是会等到一
定的时候进行刷盘的操作。具体是哪些场景会触发刷盘的操作呢？总结成如下的几个场景：
</code></pre></div><h5 id="全局内存控制"><a href="#全局内存控制" class="header-anchor">#</a> 全局内存控制</h5> <ol><li>这个全局的参数是控制内存整体的使用情况，当所有memstore占整个heap的最大比
例的时候，会触发刷盘的操作。这个参数是
hbase.regionserver.global.memstore.upperLimit，默认为整个heap内存的40%。
但这并不意味着全局内存触发的刷盘操作会将所有的MemStore都进行输盘，而是通过
另外一个参数hbase.regionserver.global.memstore.lowerLimit来控制，默认是整个
heap内存的35%。当flush到所有memstore占整个heap内存的比率为35%的时
候，就停止刷盘。这么做主要是为了减少刷盘对业务带来的影响，实现平滑系统负载的
目的。</li></ol> <h5 id="memstore达到上限"><a href="#memstore达到上限" class="header-anchor">#</a> MemStore达到上限...........................................................................................................................................</h5> <ol start="2"><li>当MemStore的大小达到hbase.hregion.memstore.flush.size大小的时候会触发刷
盘，默认128M大小</li></ol> <h5 id="regionserver的hlog数量达到上限"><a href="#regionserver的hlog数量达到上限" class="header-anchor">#</a> RegionServer的Hlog数量达到上限</h5> <ol start="3"><li>前面说到Hlog为了保证Hbase数据的一致性，那么如果Hlog太多的话，会导致故障
恢复的时间太长，因此Hbase会对Hlog的最大个数做限制。当达到Hlog的最大个数
的时候，会强制刷盘。这个参数是hase.regionserver.max.logs，默认是 32 个。</li></ol> <h5 id="手工触发"><a href="#手工触发" class="header-anchor">#</a> 手工触发</h5> <ol start="4"><li>可以通过hbase shell或者java api手工触发flush的操作。</li></ol> <h5 id="关闭regionserver触发"><a href="#关闭regionserver触发" class="header-anchor">#</a> 关闭RegionServer触发</h5> <ol start="5"><li>在正常关闭RegionServer会触发刷盘的操作，全部数据刷盘后就不需要再使用Hlog恢
复数据。</li></ol> <h5 id="region使用hlog恢复完数据后触发"><a href="#region使用hlog恢复完数据后触发" class="header-anchor">#</a> Region使用HLOG恢复完数据后触发............................................................................................................</h5> <ol start="6"><li>：当RegionServer出现故障的时候，其上面的Region会迁移到其他正常的
RegionServer上，在恢复完Region的数据后，会触发刷盘，当刷盘完成后才会提供给
业务访问。</li></ol> <h3 id="_14-1-6-hbase-vs-cassandra"><a href="#_14-1-6-hbase-vs-cassandra" class="header-anchor">#</a> 14.1.6. HBase vs Cassandra</h3> <p><strong>HBase Cassandra</strong>
语言 Java Java
出发点 BigTable BigTable and Dynamo
License Apache Apache
Protocol HTTP/REST (also Thrift) Custom, binary (Thrift)
数据分布 表划分为多个region存在不同region
server上</p> <div class="language- extra-class"><pre class="language-text"><code>改进的一致性哈希（虚拟节点）
</code></pre></div><p>存储目标 大文件 小文件
一致性 强一致性 最终一致性，Quorum NRW策略
架构 master/slave p2p
高可用性 NameNode是HDFS的单点故障点 P2P和去中心化设计，不会出现单点故障
伸缩性 Region Server扩容，通过将自身发布到
Master，Master均匀分布Region</p> <div class="language- extra-class"><pre class="language-text"><code>扩容需在Hash Ring上多个节点间调整数据分布
</code></pre></div><p>读写性能 数据读写定位可能要通过最多 6 次的网
络RPC，性能较低。</p> <div class="language- extra-class"><pre class="language-text"><code>数据读写定位非常快
</code></pre></div><p>数据冲突处理 乐观并发控制（optimistic concurrency
control）</p> <div class="language- extra-class"><pre class="language-text"><code>向量时钟
</code></pre></div><p>临时故障处理 Region Server宕机，重做HLog 数据回传机制：某节点宕机，hash到该节点的新数据自
动路由到下一节点做 hinted handoff，源节点恢复后，推
送回源节点。
永久故障恢复 Region Server恢复，master重新给其
分配region</p> <p>Merkle 哈希树，通过Gossip协议同步Merkle Tree，维
护集群节点间的数据一致性
成员通信及错误检测 Zookeeper 基于Gossip
CAP 1 ，强一致性， 0 数据丢失。 2 ，可用性
低。 3 ，扩容方便。</p> <div class="language- extra-class"><pre class="language-text"><code>1 ，弱一致性，数据可能丢失。 2 ，可用性高。 3 ，扩容方
便。
</code></pre></div><h2 id="_15-mongodb"><a href="#_15-mongodb" class="header-anchor">#</a> 15. MONGODB</h2> <h3 id="_15-1-1-概念"><a href="#_15-1-1-概念" class="header-anchor">#</a> 15.1.1. 概念</h3> <div class="language- extra-class"><pre class="language-text"><code>MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情
况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能
数据存储解决方案。
MongoDB 将数据存储为一个文档，数据结构由键值(key=\&gt;value)对组成。MongoDB 文档类似
于 JSON 对象。字段值可以包含其他文档，数组及文档数组。
</code></pre></div><h3 id="_15-1-2-特点"><a href="#_15-1-2-特点" class="header-anchor">#</a> 15.1.2. 特点</h3> <p>x MongoDB 是一个面向文档存储的数据库，操作起来比较简单和容易。</p> <p>x 你可以在MongoDB记录中设置任何属性的索引 (如：FirstName=&quot;Sameer&quot;,Address=&quot;8 Ga
ndhi Road&quot;)来实现更快的排序。</p> <p>x 你可以通过本地或者网络创建数据镜像，这使得MongoDB有更强的扩展性。</p> <p>x 如果负载的增加（需要更多的存储空间和更强的处理能力） ，它可以分布在计算机网络中的其
他节点上这就是所谓的分片。</p> <p>x Mongo支持丰富的查询表达式。查询指令使用JSON形式的标记，可轻易查询文档中内嵌的
对象及数组。</p> <p>x MongoDb 使用update()命令可以实现替换完成的文档（数据）或者一些指定的数据字段 。</p> <p>x Mongodb中的Map/reduce主要是用来对数据进行批量处理和聚合操作。</p> <p>x Map和Reduce。Map函数调用emit(key,value)遍历集合中所有的记录，将key与value传
给Reduce函数进行处理。</p> <p>x Map函数和Reduce函数是使用Javascript编写的，并可以通过db.runCommand或mapre
duce命令来执行MapReduce操作。</p> <p>x GridFS是MongoDB中的一个内置功能，可以用于存放大量小文件。</p> <p>x MongoDB允许在服务端执行脚本，可以用Javascript编写某个函数，直接在服务端执行，也
可以把函数的定义存储在服务端，下次直接调用即可。</p> <h2 id="_16-cassandra"><a href="#_16-cassandra" class="header-anchor">#</a> 16. CASSANDRA</h2> <h3 id="_16-1-1-概念"><a href="#_16-1-1-概念" class="header-anchor">#</a> 16.1.1. 概念</h3> <p>Apache Cassandra是高度可扩展的，高性能的分布式NoSQL数据库。 Cassandra旨在处理许
多商品服务器上的大量数据，提供高可用性而无需担心单点故障。</p> <p>Cassandra 具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上，
以获得高可用性，而无需担心单点故障。</p> <h3 id="_16-1-2-数据模型"><a href="#_16-1-2-数据模型" class="header-anchor">#</a> 16.1.2. 数据模型</h3> <h4 id="key-space-对应sql数据库中的database"><a href="#key-space-对应sql数据库中的database" class="header-anchor">#</a> Key Space（对应SQL数据库中的database）</h4> <ol><li>一个Key Space中可包含若干个CF，如同SQL数据库中一个database可包含多个table</li></ol> <h4 id="key-对应sql数据库中的主键"><a href="#key-对应sql数据库中的主键" class="header-anchor">#</a> Key（对应SQL数据库中的主键）</h4> <ol start="2"><li>在Cassandra中，每一行数据记录是以key/value的形式存储的，其中key是唯一标识。</li></ol> <h4 id="column-对应sql数据库中的列"><a href="#column-对应sql数据库中的列" class="header-anchor">#</a> column（对应SQL数据库中的列）</h4> <ol start="3"><li>Cassandra中每个key/value对中的value又称为column，它是一个三元组，即：name，
value和timestamp，其中name需要是唯一的。</li></ol> <h4 id="super-column-sql数据库不支持"><a href="#super-column-sql数据库不支持" class="header-anchor">#</a> super column（SQL数据库不支持）</h4> <ol start="4"><li>cassandra允许key/value中的value是一个map(key/value_list)，即某个column有多个
子列。</li></ol> <h4 id="standard-column-family-相对应sql数据库中的table"><a href="#standard-column-family-相对应sql数据库中的table" class="header-anchor">#</a> Standard Column Family（相对应SQL数据库中的table）</h4> <ol start="5"><li>每个CF由一系列row组成，每个row包含一个key以及其对应的若干column。</li></ol> <h4 id="super-column-family-sql数据库不支持"><a href="#super-column-family-sql数据库不支持" class="header-anchor">#</a> Super Column Family（SQL数据库不支持）</h4> <ol start="6"><li>每个SCF由一系列row组成，每个row包含一个key以及其对应的若干super column。</li></ol> <h3 id="_16-1-3-cassandra-一致-hash-和虚拟节点"><a href="#_16-1-3-cassandra-一致-hash-和虚拟节点" class="header-anchor">#</a> 16.1.3. Cassandra 一致 Hash 和虚拟节点</h3> <h4 id="一致性hash-多米诺down机"><a href="#一致性hash-多米诺down机" class="header-anchor">#</a> 一致性Hash（多米诺down机）</h4> <p>为每个节点分配一个token，根据这个token值来决定节点在集群中的位置以及这个节点所存储
的数据范围。</p> <h4 id="虚拟节点-down机多节点托管"><a href="#虚拟节点-down机多节点托管" class="header-anchor">#</a> 虚拟节点（down机多节点托管）</h4> <p>由于这种方式会造成数据分布不均的问题，在Cassandra1.2以后采用了虚拟节点的思想：不需要
为每个节点分配token，把圆环分成更多部分，让每个节点负责多个部分的数据，这样一个节点移
除后，它所负责的多个token会托管给多个节点处理，这种思想解决了数据分布不均的问题。</p> <p>如图所示，上面部分是标准一致性哈希，每个节点负责圆环中连续的一段，如果Node2 突然
down掉，Node2负责的数据托管给Node1，即Node1负责EFAB四段，如果Node1里面有</p> <p>很多热点用户产生的数据导致Node1已经有点撑不住了，恰巧B也是热点用户产生的数据，这样
一来Node1可能会接着down机，Node1down机，Node6还hold住吗？</p> <p>下面部分是虚拟节点实现，每个节点不再负责连续部分，且圆环被分为更多的部分。如果 Node2
突然down掉，Node2负责的数据不全是托管给Node1，而是托管给多个节点。而且也保持了一</p> <p>致性哈希的特点。</p> <h3 id="_16-1-4-gossip-协议"><a href="#_16-1-4-gossip-协议" class="header-anchor">#</a> 16.1.4. Gossip 协议</h3> <p>Gossip算法如其名，灵感来自办公室八卦，只要一个人八卦一下，在有限的时间内所有的人都
会知道该八卦的信息，这种方式也与病毒传播类似，因此Gossip有众多的别名“闲话算法”、
“疫情传播算法”、“病毒感染算法”、“谣言传播算法”。 Gossip的特点：在一个有界网络中，
每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一
致。因为Gossip不要求节点知道所有其他节点，因此又具有去中心化的特点，节点之间完全对等，
不需要任何的中心节点。实际上Gossip可以用于众多能接受“最终一致性”的领域：失败检测、
路由同步、Pub/Sub、动态负载均衡。</p> <h4 id="gossip节点的通信方式及收敛性"><a href="#gossip节点的通信方式及收敛性" class="header-anchor">#</a> Gossip节点的通信方式及收敛性</h4> <h5 id="gossip两个节点-a、b-之间存在三种通信方式-push、pull、push-pull"><a href="#gossip两个节点-a、b-之间存在三种通信方式-push、pull、push-pull" class="header-anchor">#</a> Gossip两个节点（A、B）之间存在三种通信方式（push、pull、push&amp;pull）</h5> <ol><li>push: A节点将数据(key,value,version)及对应的版本号推送给B节点，B节点更新A中比自
己新的数据。</li> <li>pull：A仅将数据key,version推送给B，B将本地比A新的数据（Key,value,version）推送
给A，A更新本地。</li> <li>push/pull：与pull类似，只是多了一步，A再将本地比B新的数据推送给B，B更新本地。</li></ol> <p>如果把两个节点数据同步一次定义为一个周期，则在一个周期内，push需通信 1 次，pull需 2 次，
push/pull则需 3 次，从效果上来讲，push/pull最好，理论上一个周期内可以使两个节点完全一
致。直观上也感觉，push/pull的收敛速度是最快的。</p> <h5 id="gossip的协议和seed-list-防止集群分列"><a href="#gossip的协议和seed-list-防止集群分列" class="header-anchor">#</a> gossip的协议和seed list（防止集群分列）</h5> <p>cassandra使用称为gossip的协议来发现加入C集群中的其他节点的位置和状态信息。gossip进
程每秒都在进行，并与至多三个节点交换状态信息。节点交换他们自己和所知道的信息，于是所
有的节点很快就能学习到整个集群中的其他节点的信息。gossip信息有一个相关的版本号，于是
在一次gossip信息交换中，旧的信息会被新的信息覆盖重写。要阻止分区进行gossip交流，那么
在集群中的所有节点中使用相同的seed list，种子节点的指定除了启动起gossip进程外，没有其
他的目的。种子节点不是一个单点故障，他们在集群操作中也没有其他的特殊目的，除了引导节
点以外</p> <h3 id="_16-1-5-数据复制"><a href="#_16-1-5-数据复制" class="header-anchor">#</a> 16.1.5. 数据复制</h3> <h4 id="partitioners-计算primary-key-token的hash函数"><a href="#partitioners-计算primary-key-token的hash函数" class="header-anchor">#</a> Partitioners（计算primary key token的hash函数）</h4> <p>在Cassandra中，table的每行由唯一的primarykey标识，partitioner实际上为一hash函数用
以计算primary key的token。Cassandra依据这个token值在集群中放置对应的行</p> <h4 id="两种可用的复制策略"><a href="#两种可用的复制策略" class="header-anchor">#</a> 两种可用的复制策略：</h4> <h5 id="simplestrategy-仅用于单数据中心"><a href="#simplestrategy-仅用于单数据中心" class="header-anchor">#</a> SimpleStrategy：仅用于单数据中心，</h5> <p>将第一个replica放在由partitioner确定的节点中，其余的replicas放在上述节点顺时针方向的
后续节点中。</p> <h5 id="networktopologystrategy-可用于较复杂的多数据中心。"><a href="#networktopologystrategy-可用于较复杂的多数据中心。" class="header-anchor">#</a> NetworkTopologyStrategy：可用于较复杂的多数据中心。</h5> <h5 id="可以指定在每个数据中心分别存储多少份replicas。"><a href="#可以指定在每个数据中心分别存储多少份replicas。" class="header-anchor">#</a> 可以指定在每个数据中心分别存储多少份replicas。</h5> <p>复制策略在创建keyspace时指定，如</p> <p>CREATE KEYSPACE Excelsior WITH REPLICATION = { 'class' :
'SimpleStrategy','replication_factor' : 3 };</p> <p>CREATE KEYSPACE Excalibur WITH REPLICATION = {'class' :'NetworkTopologyStrategy',
'dc1' : 3, 'dc2' : 2};</p> <h3 id="_16-1-6-数据写请求和协调者"><a href="#_16-1-6-数据写请求和协调者" class="header-anchor">#</a> 16.1.6. 数据写请求和协调者</h3> <h4 id="协调者-coordinator"><a href="#协调者-coordinator" class="header-anchor">#</a> 协调者(coordinator)</h4> <p>协调者(coordinator)将write请求发送到拥有对应row的所有replica节点，只要节点可用便获取
并执行写请求。写一致性级别(write consistency level)确定要有多少个replica节点必须返回成功
的确认信息。成功意味着数据被正确写入了commit log和memtable。</p> <p>其中dc1、dc2这些数据中心名称要与snitch中配置的名称一致.上面的拓扑策略表示在dc1配置
3 个副本,在dc2配置 2 个副本</p> <h3 id="_16-1-7-数据读请求和后台修复"><a href="#_16-1-7-数据读请求和后台修复" class="header-anchor">#</a> 16.1.7. 数据读请求和后台修复</h3> <ol><li>协调者首先与一致性级别确定的所有replica联系，被联系的节点返回请求的数据。</li> <li>若多个节点被联系，则来自各replica的row会在内存中作比较，若不一致，则协调者使用含
最新数据的replica向client返回结果。那么比较操作过程中只需要传递时间戳就可以,因为要
比较的只是哪个副本数据是最新的。</li> <li>协调者在后台联系和比较来自其余拥有对应row的replica 的数据，若不一致，会向过时的
replica发写请求用最新的数据进行更新read repair。</li></ol> <h3 id="_16-1-8-数据存储-commitlog、memtable、sstable"><a href="#_16-1-8-数据存储-commitlog、memtable、sstable" class="header-anchor">#</a> 16.1.8. 数据存储（CommitLog、MemTable、SSTable）</h3> <p>写请求分别到CommitLog和MemTable, 并且MemTable的数据会刷写到磁盘SSTable上. 除
了写数据,还有索引也会保存到磁盘上.</p> <p>先将数据写到磁盘中的commitlog，同时追加到中内存中的数据结构memtable 。这个时候就会
返回客户端状态，memtable 内容超出指定容量后会被放进将被刷入磁盘的队列
(memtable_flush_queue_size配置队列长度)。若将被刷入磁盘的数据超出了队列长度，将内存
数据刷进磁盘中的SSTable,之后commit log被清空。</p> <h4 id="sstable文件构成-bloomfilter、index、data、static"><a href="#sstable文件构成-bloomfilter、index、data、static" class="header-anchor">#</a> SSTable文件构成（BloomFilter、index、data、static）</h4> <p>SSTable 文件有fileer（判断数据key是否存在，这里使用了BloomFilter提高效率），index（寻
找对应column值所在data文件位置）文件，data（存储真实数据）文件，static（存储和统计
column和row大小）文件。</p> <h3 id="_16-1-9-二级索引-对要索引的-value-摘要-生成-rowkey"><a href="#_16-1-9-二级索引-对要索引的-value-摘要-生成-rowkey" class="header-anchor">#</a> 16.1.9. 二级索引（对要索引的 value 摘要，生成 RowKey ）</h3> <p>在Cassandra中，数据都是以Key-value的形式保存的。</p> <p>KeysIndex所创建的二级索引也被保存在一张ColumnFamily中。在插入数据时，对需要进行索</p> <p>引的value进行摘要，生成独一无二的key，将其作为RowKey保存在索引的ColumnFamily中；
同时在RowKey上添加一个Column，将插入数据的RowKey作为name域的值，value域则赋</p> <p>空值，timestamp域则赋为插入数据的时间戳。</p> <p>如果有相同的value被索引了，则会在索引 ColumnFamily中相同的RowKey 后再添加新的</p> <p>Column。如果有新的value被索引，则会在索引ColumnFamily中添加新的RowKey以及对应
新的Column。</p> <p>当对value进行查询时，只需计算该 value的RowKey，在索引ColumnFamily 中的查找该
RowKey，对其Columns进行遍历就能得到该value所有数据的RowKey。</p> <h3 id="_16-1-10-数据读写"><a href="#_16-1-10-数据读写" class="header-anchor">#</a> 16.1.10. 数据读写</h3> <h4 id="数据写入和更新-数据追加"><a href="#数据写入和更新-数据追加" class="header-anchor">#</a> 数据写入和更新（数据追加）</h4> <p>Cassandra 的设计思路与这些系统不同，无论是 insert 还是 remove 操作，都是在已有的数据后</p> <p>面进行追加，而不修改已有的数据。这种设计称为 Log structured 存储，顾名思义就是系统中的
数据是以日志的形式存在的，所以只会将新的数据追加到已有数据的后面。Log structured 存储</p> <p>系统有两个主要优点：</p> <h5 id="数据的写和删除效率极高"><a href="#数据的写和删除效率极高" class="header-anchor">#</a> 数据的写和删除效率极高</h5> <div class="language- extra-class"><pre class="language-text"><code>x 传统的存储系统需要更新元信息和数据，因此磁盘的磁头需要反复移动，这是一个比较耗时
的操作，而 Log structured 的系统则是顺序写，可以充分利用文件系统的 cache，所以效率
很高。
</code></pre></div><h5 id="错误恢复简单"><a href="#错误恢复简单" class="header-anchor">#</a> 错误恢复简单</h5> <div class="language- extra-class"><pre class="language-text"><code>x 由于数据本身就是以日志形式保存，老的数据不会被覆盖，所以在设计 journal 的时候不需
要考虑 undo，简化了错误恢复。
</code></pre></div><h5 id="读的复杂度高"><a href="#读的复杂度高" class="header-anchor">#</a> 读的复杂度高</h5> <div class="language- extra-class"><pre class="language-text"><code>x 但是，Log structured 的存储系统也引入了一个重要的问题：读的复杂度和性能。理论上
说，读操作需要从后往前扫描数据，以找到某个记录的最新版本。相比传统的存储系统，这
是比较耗时的。
</code></pre></div><p>参考：https://blog.csdn.net/fs1360472174/article/details/55005335</p> <h4 id="数据删除-column-的墓碑"><a href="#数据删除-column-的墓碑" class="header-anchor">#</a> 数据删除（column 的墓碑）</h4> <p>如果一次删除操作在一个节点上失败了（总共 3 个节点，副本为 3 ， RF=3).整个删除操作仍然被
认为成功的（因为有两个节点应答成功，使用CL.QUORUM一致性）。接下来如果读发生在该节
点上就会变的不明确，因为结果返回是空，还是返回数据，没有办法确定哪一种是正确的。</p> <p>Cassandra 总是认为返回数据是对的，那就会发生删除的数据又出现了的事情，这些数据可以叫”
僵尸”，并且他们的表现是不可预见的。</p> <h5 id="墓碑"><a href="#墓碑" class="header-anchor">#</a> 墓碑......................................................................................................................................................................</h5> <p>删除一个 column 其实只是插入一个关于这个 column 的墓碑（tombstone），并不直接删除原
有的 column。该墓碑被作为对该 CF 的一次修改记录在 Memtable 和 SSTable 中。墓碑的内容
是删除请求被执行的时间，该时间是接受客户端请求的存储节点在执行该请求时的本地时间
（local delete time），称为本地删除时间。需要注意区分本地删除时间和时间戳，每个 CF 修改
记录都有一个时间戳，这个时间戳可以理解为该 column 的修改时间，是由客户端给定的。</p> <h5 id="垃圾回收compaction"><a href="#垃圾回收compaction" class="header-anchor">#</a> 垃圾回收compaction</h5> <p>由于被删除的 column 并不会立即被从磁盘中删除，所以系统占用的磁盘空间会越来越大，这就
需要有一种垃圾回收的机制，定期删除被标记了墓碑的 column。垃圾回收是在 compaction 的过
程中完成的。</p> <h5 id="数据读取-memtable-sstables"><a href="#数据读取-memtable-sstables" class="header-anchor">#</a> 数据读取（memtable+SStables）</h5> <p>为了满足读cassandra读取的数据是memtable中的数据和SStables中数据的合并结果。读取
SSTables 中的数据就是查找到具体的哪些的SSTables 以及数据在这些SSTables 中的偏移量
(SSTables是按主键排序后的数据块)。首先如果row cache enable了话，会检测缓存。缓存命中
直接返回数据，没有则查找Bloom filter，查找可能的SSTable。然后有一层Partition key cache，
找partition key的位置。如果有根据找到的partition去压缩偏移量映射表找具体的数据块。如果
缓存没有，则要经过Partition summary,Partition index去找partition key。然后经过压缩偏移
量映射表找具体的数据块。</p> <ol><li>检查 memtable</li> <li>如果enabled了,检查row cache</li> <li>检查Bloom filter</li> <li>如果enable了,检查partition key 缓存</li> <li>如果在partition key缓存中找到了partition key,直接去compression offset 命中，如果没
有，检查 partition summary</li> <li>根据compression offset map找到数据位置</li> <li>从磁盘的SSTable中取出数据</li></ol> <h4 id="行缓存和键缓存请求流程图"><a href="#行缓存和键缓存请求流程图" class="header-anchor">#</a> 行缓存和键缓存请求流程图</h4> <p><strong>MemTable：</strong> 如果memtable有目标分区数据，这个数据会被读出来并且和从SSTables中读出
来的数据进行合并。SSTable的数据访问如下面所示的步骤。</p> <h5 id="row-cache-sstables中频繁被访问的数据"><a href="#row-cache-sstables中频繁被访问的数据" class="header-anchor">#</a> Row Cache（SSTables中频繁被访问的数据）</h5> <p>在Cassandra2.2+，它们被存储在堆外内存，使用全新的实现避免造成垃圾回收对JVM造成压力。
存在在row cache 的子集数据可以在特定的一段时间内配置一定大小的内存。row cache使用
LRU(least-recently-userd)进行回收在申请内存。存储在row cache中的数据是SSTables中频繁
被访问的数据。存储到row cache中后，数据就可以被后续的查询访问。row cache不是写更新。
如果写某行了，这行的缓存就会失效，并且不会被继续缓存，直到这行被读到。类似的，如果一
个partition更新了，整个partition的cache都会被移除，但目标的数据在row cache中找不到，
就会去检查Bloom filter。</p> <h5 id="bloom-filter-查找数据可能对应的sstable"><a href="#bloom-filter-查找数据可能对应的sstable" class="header-anchor">#</a> Bloom Filter（查找数据可能对应的SSTable）</h5> <p>首先，Cassandra检查Bloom filter去发现哪个SSTables中有可能有请求的分区数据。Bloom
filter是存储在堆外内存。每个SSTable都有一个关联的Bloom filter。一个Bloom filter可以建
立一个SSTable没有包含的特定的分区数据。同样也可以找到分区数据存在SSTable中的可能性。
它可以加速查找partition key的查找过程。然而，因为Bloom filter是一个概率函数，所以可能
会得到错误的结果，并不是所有的SSTables 都可以被Bloom filter识别出是否有数据。如果
Bloom filter不能够查找到SSTable，Cassandra会检查partition key cache。Bloom filter 大小
增长很适宜，每 10 亿数据1~2GB。在极端情况下，可以一个分区一行。都可以很轻松的将数十
亿的entries存储在单个机器上。Bloom filter是可以调节的，如果你愿意用内存来换取性能。</p> <h5 id="partition-key-cache-查找数据可能对应的partition-key"><a href="#partition-key-cache-查找数据可能对应的partition-key" class="header-anchor">#</a> Partition Key Cache（查找数据可能对应的Partition key）</h5> <p>partition key 缓存如果开启了，将partition index存储在堆外内存。key cache使用一小块可配
置大小的内存。在读的过程中，每个”hit”保存一个检索。如果在key cache中找到了partition
key。就直接到compression offset map中招对应的块。partition key cache热启动后工作的更
好，相比较冷启动，有很大的性能提升。如果一个节点上的内存非常受限制，可能的话，需要限
制保存在key cache中的partition key数目。如果一个在key cache中没有找到partition key。
就会去partition summary中去找。partition key cache 大小是可以配置的，意义就是存储在key
cache中的partition keys数目。</p> <h5 id="partition-summary-内存中存储一些partition-index的样本"><a href="#partition-summary-内存中存储一些partition-index的样本" class="header-anchor">#</a> Partition Summary（内存中存储一些partition index的样本）</h5> <p>partition summary 是存储在堆外内存的结构，存储一些partition index 的样本。如果一个
partition index包含所有的partition keys。鉴于一个partition summary从每X个keys中取
样，然后将每X个key map到index 文件中。例如，如果一个partition summary设置了20keys
进行取样。它就会存储 SSTable file 开始的一个key,20th 个key，以此类推。尽管并不知道
partition key 的具体位置，partition summary 可以缩短找到partition 数据位置。当找到了
partition key值可能的范围后，就会去找partition index。通过配置取样频率，你可以用内存来
换取性能，当partition summary包含的数据越多，使用的内存越多。可以通过表定义的index
interval属性来改变样本频率。固定大小的内存可以通过index_summary_capacity_in_mb属性
来设置，默认是堆大小的5%。</p> <h5 id="partition-index-磁盘中"><a href="#partition-index-磁盘中" class="header-anchor">#</a> Partition Index（磁盘中）</h5> <p>partition index 驻扎在磁盘中，索引所有partition keys和偏移量的映射。如果partition
summary 已经查到partition keys的范围，现在的检索就是根据这个范围值来检索目标partition
key。需要进行单次检索和顺序读。根据找到的信息。然后去compression offset map中去找磁
盘中有这个数据的块。如果partition index必须要被检索，则需要检索两次磁盘去找到目标数据。</p> <h5 id="compression-offset-map-磁盘中"><a href="#compression-offset-map-磁盘中" class="header-anchor">#</a> Compression offset map（磁盘中）</h5> <p>compression offset map存储磁盘数据准确位置的指针。存储在堆外内存，可以被partition key
cache或者partition index访问。一旦compression offset map识别出来磁盘中的数据位置，
就会从正确的SStable(s)中取出数据。查询就会收到结果集。</p> <h2 id="_17-设计模式"><a href="#_17-设计模式" class="header-anchor">#</a> 17. 设计模式</h2> <h3 id="_17-1-1-设计原则"><a href="#_17-1-1-设计原则" class="header-anchor">#</a> 17.1.1. 设计原则</h3> <h3 id="_17-1-2-工厂方法模式"><a href="#_17-1-2-工厂方法模式" class="header-anchor">#</a> 17.1.2. 工厂方法模式</h3> <h3 id="_17-1-3-抽象工厂模式"><a href="#_17-1-3-抽象工厂模式" class="header-anchor">#</a> 17.1.3. 抽象工厂模式</h3> <h3 id="_17-1-4-单例模式"><a href="#_17-1-4-单例模式" class="header-anchor">#</a> 17.1.4. 单例模式</h3> <h3 id="_17-1-5-建造者模式"><a href="#_17-1-5-建造者模式" class="header-anchor">#</a> 17.1.5. 建造者模式</h3> <h3 id="_17-1-6-原型模式"><a href="#_17-1-6-原型模式" class="header-anchor">#</a> 17.1.6. 原型模式</h3> <h3 id="_17-1-7-适配器模式"><a href="#_17-1-7-适配器模式" class="header-anchor">#</a> 17.1.7. 适配器模式</h3> <h3 id="_17-1-8-装饰器模式"><a href="#_17-1-8-装饰器模式" class="header-anchor">#</a> 17.1.8. 装饰器模式</h3> <h3 id="_17-1-9-代理模式"><a href="#_17-1-9-代理模式" class="header-anchor">#</a> 17.1.9. 代理模式</h3> <h3 id="_17-1-10-外观模式"><a href="#_17-1-10-外观模式" class="header-anchor">#</a> 17.1.10. 外观模式</h3> <h3 id="_17-1-11-桥接模式"><a href="#_17-1-11-桥接模式" class="header-anchor">#</a> 17.1.11. 桥接模式</h3> <h3 id="_17-1-12-组合模式"><a href="#_17-1-12-组合模式" class="header-anchor">#</a> 17.1.12. 组合模式</h3> <h3 id="_17-1-13-享元模式"><a href="#_17-1-13-享元模式" class="header-anchor">#</a> 17.1.13. 享元模式</h3> <h3 id="_17-1-14-策略模式"><a href="#_17-1-14-策略模式" class="header-anchor">#</a> 17.1.14. 策略模式</h3> <h3 id="_17-1-15-模板方法模式"><a href="#_17-1-15-模板方法模式" class="header-anchor">#</a> 17.1.15. 模板方法模式</h3> <h3 id="_17-1-16-观察者模式"><a href="#_17-1-16-观察者模式" class="header-anchor">#</a> 17.1.16. 观察者模式</h3> <h3 id="_17-1-17-迭代子模式"><a href="#_17-1-17-迭代子模式" class="header-anchor">#</a> 17.1.17. 迭代子模式</h3> <h3 id="_17-1-18-责任链模式"><a href="#_17-1-18-责任链模式" class="header-anchor">#</a> 17.1.18. 责任链模式</h3> <h3 id="_17-1-19-命令模式"><a href="#_17-1-19-命令模式" class="header-anchor">#</a> 17.1.19. 命令模式</h3> <h3 id="_1-7-1-20-备忘录模式"><a href="#_1-7-1-20-备忘录模式" class="header-anchor">#</a> 1 7.1.20. 备忘录模式</h3> <h3 id="_17-1-21-状态模式"><a href="#_17-1-21-状态模式" class="header-anchor">#</a> 17.1.21. 状态模式</h3> <h3 id="_17-1-22-访问者模式"><a href="#_17-1-22-访问者模式" class="header-anchor">#</a> 17.1.22. 访问者模式</h3> <h3 id="_17-1-23-中介者模式"><a href="#_17-1-23-中介者模式" class="header-anchor">#</a> 17.1.23. 中介者模式</h3> <h3 id="_17-1-24-解释器模式"><a href="#_17-1-24-解释器模式" class="header-anchor">#</a> 17.1.24. 解释器模式</h3> <h2 id="_18-负载均衡"><a href="#_18-负载均衡" class="header-anchor">#</a> 18. 负载均衡</h2> <p>负载均衡 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带
宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。</p> <h3 id="_18-1-1-四层负载均衡-vs-七层负载均衡"><a href="#_18-1-1-四层负载均衡-vs-七层负载均衡" class="header-anchor">#</a> 18.1.1. 四层负载均衡 vs 七层负载均衡</h3> <h4 id="_18-1-1-1-四层负载均衡-目标地址和端口交换"><a href="#_18-1-1-1-四层负载均衡-目标地址和端口交换" class="header-anchor">#</a> 18.1.1.1. 四层负载均衡（目标地址和端口交换）</h4> <p>主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择
的内部服务器。</p> <p>以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选
择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务
器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类
似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在
转发报文的同时可能还会对报文原来的源地址进行修改。实现四层负载均衡的软件有：</p> <h5 id="f5-硬件负载均衡器-功能很好-但是成本很高。"><a href="#f5-硬件负载均衡器-功能很好-但是成本很高。" class="header-anchor">#</a> F5：硬件负载均衡器，功能很好，但是成本很高。</h5> <h5 id="lvs-重量级的四层负载软件。"><a href="#lvs-重量级的四层负载软件。" class="header-anchor">#</a> lvs：重量级的四层负载软件。</h5> <h5 id="nginx-轻量级的四层负载软件-带缓存功能-正则表达式较灵活。"><a href="#nginx-轻量级的四层负载软件-带缓存功能-正则表达式较灵活。" class="header-anchor">#</a> nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活。</h5> <h5 id="haproxy-模拟四层转发-较灵活。"><a href="#haproxy-模拟四层转发-较灵活。" class="header-anchor">#</a> haproxy：模拟四层转发，较灵活。</h5> <h4 id="_18-1-1-2-七层负载均衡-内容交换"><a href="#_18-1-1-2-七层负载均衡-内容交换" class="header-anchor">#</a> 18.1.1.2. 七层负载均衡（内容交换）</h4> <p>所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，
再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。</p> <p>七层应用负载的好处，是使得整个网络更智能化。例如访问一个网站的用户流量，可以通过七层
的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可
以转发到特定的文字服务器并可以使用压缩技术。实现七层负载均衡的软件有：</p> <h5 id="haproxy-天生负载均衡技能-全面支持七层代理-会话保持-标记-路径转移"><a href="#haproxy-天生负载均衡技能-全面支持七层代理-会话保持-标记-路径转移" class="header-anchor">#</a> haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；</h5> <h5 id="nginx-只在http协议和mail协议上功能比较好-性能与haproxy差不多"><a href="#nginx-只在http协议和mail协议上功能比较好-性能与haproxy差不多" class="header-anchor">#</a> nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；</h5> <h5 id="apache-功能较差"><a href="#apache-功能较差" class="header-anchor">#</a> apache：功能较差</h5> <h5 id="mysql-proxy-功能尚可。"><a href="#mysql-proxy-功能尚可。" class="header-anchor">#</a> Mysql proxy：功能尚可。</h5> <h3 id="_18-1-2-负载均衡算法-策略"><a href="#_18-1-2-负载均衡算法-策略" class="header-anchor">#</a> 18.1.2. 负载均衡算法 / 策略</h3> <h4 id="_18-1-2-1-轮循均衡-round-robin"><a href="#_18-1-2-1-轮循均衡-round-robin" class="header-anchor">#</a> 18.1.2.1. 轮循均衡（Round Robin）</h4> <p>每一次来自网络的请求轮流分配给内部中的服务器，从 1 至N然后重新开始。此种均衡算法适合
于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。</p> <h4 id="_18-1-2-2-权重轮循均衡-weighted-round-robin"><a href="#_18-1-2-2-权重轮循均衡-weighted-round-robin" class="header-anchor">#</a> 18.1.2.2. 权重轮循均衡（Weighted Round Robin）</h4> <p>根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请
求。例如：服务器A的权值被设计成 1 ，B的权值是 3 ，C的权值是 6 ，则服务器A、B、C将分
别接受到10%、 30 ％、 60 ％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用
率，避免低性能的服务器负载过重。</p> <h4 id="_18-1-2-3-随机均衡-random"><a href="#_18-1-2-3-随机均衡-random" class="header-anchor">#</a> 18.1.2.3. 随机均衡（Random）</h4> <p>把来自网络的请求随机分配给内部中的多个服务器。</p> <h4 id="_18-1-2-4-权重随机均衡-weighted-random"><a href="#_18-1-2-4-权重随机均衡-weighted-random" class="header-anchor">#</a> 18.1.2.4. 权重随机均衡（Weighted Random）</h4> <div class="language- extra-class"><pre class="language-text"><code>此种均衡算法类似于权重轮循算法，不过在处理请求分担时是个随机选择的过程。
</code></pre></div><h4 id="_18-1-2-5-响应速度均衡-response-time探测时间"><a href="#_18-1-2-5-响应速度均衡-response-time探测时间" class="header-anchor">#</a> 18.1.2.5. 响应速度均衡（Response Time探测时间）</h4> <p>负载均衡设备对内部各服务器发出一个探测请求（例如Ping），然后根据内部中各服务器对探测
请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映
服务器的当前运行状态，但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时
间，而不是客户端与服务器间的最快响应时间。</p> <h4 id="_18-1-2-6-最少连接数均衡-least-connection"><a href="#_18-1-2-6-最少连接数均衡-least-connection" class="header-anchor">#</a> 18.1.2.6. 最少连接数均衡（Least Connection）</h4> <p>最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在
处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡
更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。</p> <h4 id="_18-1-2-7-处理能力均衡-cpu、内存"><a href="#_18-1-2-7-处理能力均衡-cpu、内存" class="header-anchor">#</a> 18.1.2.7. 处理能力均衡（CPU、内存）</h4> <p>此种均衡算法将把服务请求分配给内部中处理负荷（根据服务器CPU型号、CPU数量、内存大小
及当前连接数等换算而成）最轻的服务器，由于考虑到了内部服务器的处理能力及当前网络运行
状况，所以此种均衡算法相对来说更加精确，尤其适合运用到第七层（应用层）负载均衡的情况
下。</p> <h4 id="_18-1-2-8-dns响应均衡-flash-dns"><a href="#_18-1-2-8-dns响应均衡-flash-dns" class="header-anchor">#</a> 18.1.2.8. DNS响应均衡（Flash DNS）</h4> <p>在此均衡算法下，分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求，并在
同一时间内把此域名解析成各自相对应服务器的IP地址并返回给客户端，则客户端将以最先收到
的域名解析IP地址来继续请求服务，而忽略其它的IP地址响应。在种均衡策略适合应用在全局负
载均衡的情况下，对本地负载均衡是没有意义的。</p> <h4 id="_18-1-2-9-哈希算法"><a href="#_18-1-2-9-哈希算法" class="header-anchor">#</a> 18.1.2.9. 哈希算法</h4> <p>一致性哈希一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往
该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。</p> <h4 id="_18-1-2-10-ip地址散列-保证客户端服务器对应关系稳定"><a href="#_18-1-2-10-ip地址散列-保证客户端服务器对应关系稳定" class="header-anchor">#</a> 18.1.2.10. IP地址散列（保证客户端服务器对应关系稳定）</h4> <p>通过管理发送方IP和目的地IP地址的散列，将来自同一发送方的分组(或发送至同一目的地的分
组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信
时，该算法能够以流(会话)为单位，保证来自相同客户端的通信能够一直在同一服务器中进行处
理。</p> <h4 id="_18-1-2-11-url散列"><a href="#_18-1-2-11-url散列" class="header-anchor">#</a> 18.1.2.11. URL散列</h4> <p>通过管理客户端请求URL信息的散列，将发送至相同URL的请求转发至同一服务器的算法。</p> <h3 id="_18-1-3-lvs"><a href="#_18-1-3-lvs" class="header-anchor">#</a> 18.1.3. LVS</h3> <h4 id="_18-1-3-1-lvs原理"><a href="#_18-1-3-1-lvs原理" class="header-anchor">#</a> 18.1.3.1. LVS原理</h4> <h5 id="ipvs"><a href="#ipvs" class="header-anchor">#</a> IPVS</h5> <p>LVS 的 IP 负载均衡技术是通过 IPVS 模块来实现的，IPVS 是 LVS集群系统的核心软件，它的主要
作用是：安装在 Director Server 上，同时在 Director Server上虚拟出一个IP 地址，用户必须通
过这个虚拟的 IP 地址访问服务器。这个虚拟 IP 一般称为 LVS 的VIP，即 Virtual IP。访问的请求
首先经过 VIP 到达负载调度器，然后由负载调度器从Real Server 列表中选取一个服务节点响应用
户的请求。 在用户的请求到达负载调度器后，调度器如何将请求发送到提供服务的 Real Server 节
点，而 Real Server节点如何返回数据给用户，是 IPVS 实现的重点技术。</p> <p>ipvs ： 工作于内核空间，主要用于使用户定义的策略生效</p> <p>ipvsadm : 工作于用户空间，主要用于用户定义和管理集群服务的工具</p> <p>ipvs工作于内核空间的INPUT链上，当收到用户请求某集群服务时，经过PREROUTING链，经
检查本机路由表，送往INPUT链；在进入netfilter的INPUT链时，ipvs强行将请求报文通过
ipvsadm定义的集群服务策略的路径改为FORWORD链，将报文转发至后端真实提供服务的主机。</p> <h4 id="_18-1-3-1-lvs-nat-模式"><a href="#_18-1-3-1-lvs-nat-模式" class="header-anchor">#</a> 18.1.3.1. LVS NAT 模式</h4> <p>①.客户端将请求发往前端的负载均衡器，请求报文源地址是CIP(客户端IP),后面统称为CIP)，目
标地址为VIP(负载均衡器前端地址，后面统称为VIP)。</p> <p>②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将客户端请求报文的目
标地址改为了后端服务器的RIP地址并将报文根据算法发送出去。</p> <p>③.报文送到Real Server后，由于报文的目标地址是自己，所以会响应该请求，并将响应报文返还
给LVS。</p> <p>④.然后lvs将此报文的源地址修改为本机并发送给客户端。</p> <p>注意：在NAT模式中，Real Server的网关必须指向LVS，否则报文无法送达客户端</p> <p><strong>特点：</strong></p> <p>1 、NAT 技术将请求的报文和响应的报文都需要通过 LB 进行地址改写，因此网站访问量比较大的
时候 LB 负载均衡调度器有比较大的瓶颈，一般要求最多之能 10 - 20 台节点</p> <p>2 、只需要在 LB 上配置一个公网 IP 地址就可以了。</p> <p>3 、每台内部的 realserver 服务器的网关地址必须是调度器 LB 的内网地址。</p> <p>4 、NAT 模式支持对 IP 地址和端口进行转换。即用户请求的端口和真实服务器的端口可以不一致。</p> <p><strong>优点：</strong></p> <p>集群中的物理服务器可以使用任何支持TCP/IP操作系统，只有负载均衡器需要一个合法的IP地
址。</p> <p><strong>缺点：</strong></p> <p>扩展性有限。当服务器节点（普通PC服务器）增长过多时,负载均衡器将成为整个系统的瓶颈，因
为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时，大量的数据包都交汇
在负载均衡器那，速度就会变慢！</p> <h4 id="_18-1-3-2-lvs-dr-模式-局域网改写mac地址"><a href="#_18-1-3-2-lvs-dr-模式-局域网改写mac地址" class="header-anchor">#</a> 18.1.3.2. LVS DR 模式（局域网改写mac地址）</h4> <p>①.客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。</p> <p>②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将客户端请求报文的源
MAC地址改为自己DIP的MAC地址，目标MAC改为了RIP的MAC地址，并将此包发送给RS。</p> <p>③.RS发现请求报文中的目的MAC是自己，就会将次报文接收下来，处理完请求报文后，将响应
报文通过lo接口送给eth0网卡直接发送给客户端。</p> <p>注意：需要设置lo接口的VIP不能响应本地网络内的arp请求。</p> <p><strong>总结：</strong></p> <p>1 、通过在调度器 LB 上修改数据包的目的 MAC 地址实现转发。注意源地址仍然是 CIP，目的地址
仍然是 VIP 地址。</p> <p>2 、请求的报文经过调度器，而 RS 响应处理后的报文无需经过调度器 LB，因此并发访问量大时使
用效率很高（和 NAT 模式比）</p> <p>3 、因为 DR 模式是通过 MAC 地址改写机制实现转发，因此所有 RS 节点和调度器 LB 只能在一个
局域网里面</p> <p>4 、RS 主机需要绑定 VIP 地址在 LO 接口（掩码 32 位）上，并且需要配置 ARP 抑制。</p> <p>5 、RS 节点的默认网关不需要配置成 LB，而是直接配置为上级路由的网关，能让 RS 直接出网就
可以。</p> <p>6 、由于 DR 模式的调度器仅做 MAC 地址的改写，所以调度器 LB 就不能改写目标端口，那么 RS
服务器就得使用和 VIP 相同的端口提供服务。</p> <p>7 、直接对外的业务比如WEB等，RS 的IP最好是使用公网IP。对外的服务，比如数据库等最好
使用内网IP。</p> <p><strong>优点：</strong></p> <p>和TUN（隧道模式）一样，负载均衡器也只是分发请求，应答包通过单独的路由方法返回给客户
端。与VS-TUN相比，VS-DR这种实现方式不需要隧道结构，因此可以使用大多数操作系统做为
物理服务器。</p> <p>DR 模式的效率很高，但是配置稍微复杂一点，因此对于访问量不是特别大的公司可以用
haproxy/nginx取代。日 1000 - 2000W PV或者并发请求 1 万一下都可以考虑用haproxy/nginx。</p> <p><strong>缺点：</strong></p> <p>所有 RS 节点和调度器 LB 只能在一个局域网里面</p> <h4 id="_18-1-3-3-lvs-tun-模式-ip封装、跨网段"><a href="#_18-1-3-3-lvs-tun-模式-ip封装、跨网段" class="header-anchor">#</a> 18.1.3.3. LVS TUN 模式（IP封装、跨网段）</h4> <p>①.客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。</p> <p>②.负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将在客户端请求报文的
首部再封装一层IP报文,将源地址改为DIP，目标地址改为RIP,并将此包发送给RS。</p> <p>③.RS收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层IP首部的目标地址是自己
lo接口上的VIP，所以会处理次请求报文，并将响应报文通过lo接口送给eth0网卡直接发送给客
户端。</p> <p>注意：需要设置lo接口的VIP不能在共网上出现。</p> <p><strong>总结：</strong></p> <p>1.TUNNEL 模式必须在所有的 realserver 机器上面绑定 VIP 的 IP 地址</p> <p>2.TUNNEL 模式的 vip ------&gt;realserver 的包通信通过 TUNNEL 模式，不管是内网和外网都能通
信，所以不需要 lvs vip 跟 realserver 在同一个网段内。</p> <p>3.TUNNEL 模式 realserver 会把 packet 直接发给 client 不会给 lvs 了</p> <p>4.TUNNEL 模式走的隧道模式，所以运维起来比较难，所以一般不用。</p> <p><strong>优点：</strong></p> <p>负载均衡器只负责将请求包分发给后端节点服务器，而RS将应答包直接发给用户。所以，减少了
负载均衡器的大量数据流动，负载均衡器不再是系统的瓶颈，就能处理很巨大的请求量，这种方
式，一台负载均衡器能够为很多RS进行分发。而且跑在公网上就能进行不同地域的分发。</p> <p><strong>缺点：</strong></p> <p>隧道模式的RS 节点需要合法IP，这种方式需要所有的服务器支持”IP Tunneling”(IP
Encapsulation)协议，服务器可能只局限在部分Linux系统上。</p> <h4 id="_18-1-3-4-lvs-fullnat模式"><a href="#_18-1-3-4-lvs-fullnat模式" class="header-anchor">#</a> 18.1.3.4. LVS FULLNAT模式</h4> <p>无论是 DR 还是 NAT 模式，不可避免的都有一个问题：LVS 和 RS 必须在同一个 VLAN 下，否则
LVS 无法作为 RS 的网关。这引发的两个问题是：</p> <p>1 、同一个 VLAN 的限制导致运维不方便，跨 VLAN 的 RS 无法接入。</p> <p>2 、LVS 的水平扩展受到制约。当 RS 水平扩容时，总有一天其上的单点 LVS 会成为瓶颈。</p> <p>Full-NAT 由此而生，解决的是 LVS 和 RS 跨 VLAN 的问题，而跨 VLAN 问题解决后，LVS 和 RS
不再存在 VLAN 上的从属关系，可以做到多个 LVS 对应多个 RS，解决水平扩容的问题。</p> <p>Full-NAT 相比 NAT 的主要改进是，在 SNAT/DNAT 的基础上，加上另一种转换，转换过程如下：</p> <ol><li>在包从 LVS 转到 RS 的过程中，源地址从客户端 IP 被替换成了 LVS 的内网 IP。内网 IP 之间
可以通过多个交换机跨 VLAN 通信。目标地址从VIP修改为RS IP.</li> <li>当 RS 处理完接受到的包，处理完成后返回时，将目标地址修改为LVS ip，原地址修改为RS
IP，最终将这个包返回给 LVS 的内网 IP，这一步也不受限于 VLAN。</li> <li>LVS 收到包后，在 NAT 模式修改源地址的基础上，再把 RS 发来的包中的目标地址从 LVS 内
网 IP 改为客户端的 IP,并将原地址修改为VIP。</li></ol> <p>Full-NAT 主要的思想是把网关和其下机器的通信，改为了普通的网络通信，从而解决了跨 VLAN
的问题。采用这种方式，LVS 和 RS 的部署在 VLAN 上将不再有任何限制，大大提高了运维部署的
便利性。</p> <p><strong>总结</strong></p> <ol><li>FULL NAT 模式不需要 LBIP 和 realserver ip 在同一个网段；</li> <li>full nat 因为要更新 sorce ip 所以性能正常比 nat 模式下降 10%</li></ol> <h3 id="_18-1-4-keepalive"><a href="#_18-1-4-keepalive" class="header-anchor">#</a> 18.1.4. Keepalive</h3> <p>keepalive起初是为LVS设计的，专门用来监控lvs各个服务节点的状态，后来加入了vrrp的功
能，因此除了lvs，也可以作为其他服务（nginx，haproxy）的高可用软件。VRRP 是virtual
router redundancy protocal（虚拟路由器冗余协议）的缩写。VRRP的出现就是为了解决静态路
由出现的单点故障，它能够保证网络可以不间断的稳定的运行。所以keepalive一方面具有LVS
cluster node healthcheck功能，另一方面也具有LVS director failover。</p> <h3 id="_18-1-5-nginx-反向代理负载均衡"><a href="#_18-1-5-nginx-反向代理负载均衡" class="header-anchor">#</a> 18.1.5. Nginx 反向代理负载均衡</h3> <p>普通的负载均衡软件，如LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节
点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户；而反向代理就不一</p> <p>样了，反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，
最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代
理服务器，而非真实的网站访问用户。</p> <h4 id="_18-1-5-1-upstream-module和健康检测"><a href="#_18-1-5-1-upstream-module和健康检测" class="header-anchor">#</a> 18.1.5.1. upstream_module和健康检测</h4> <p>ngx_http_upstream_module是负载均衡模块，可以实现网站的负载均衡功能即节点的健康检
查，upstream模块允许Nginx定义一组或多组节点服务器组，使用时可通过 proxy_pass 代理方
式把网站的请求发送到事先定义好的对应 Upstream组 的名字上。
<strong>upstream模块
内参数</strong></p> <div class="language- extra-class"><pre class="language-text"><code>参数说明
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>weight 服务器权重^
max_fails Nginx尝试连接后端主机失败的此时，这是值是配合^ proxy_next_upstream、
fastcgi_next_upstream和memcached_next_upstream这三个参数来使用的。当Nginx
接收后端服务器返回这三个参数定义的状态码时，会将这个请求转发给正常工作的的后端服
务器。如 404 、 503 、503,max_files=1
fail_timeout max_fails 和^ fail_timeout 一般会关联使用，如果某台server在^ fail_timeout 时间内出现了^
max_fails 次连接失败，那么Nginx会认为其已经挂掉，从而在 fail_timeout 时间内不再去
请求它，fail_timeout默认是 10s，max_fails默认是 1 ，即默认情况只要是发生错误就认为
服务器挂了，如果将max_fails设置为 0 ，则表示取消这项检查
backup 表示当前server是备用服务器，只有其它非backup后端服务器都挂掉了或很忙才会分配请
求给它
down 标志服务器永远不可用，可配合ip_hash使用^
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>upstream lvsServer{
server 191.168.1.11 weight=5 ;
server 191.168.1.22:82;
server example.com:8080 max_fails=2 fail_timeout=10s backup;
#域名的话需要解析的哦，内网记得hosts
</code></pre></div><h3 id="-3"><a href="#-3" class="header-anchor">#</a> }</h3> <h4 id="_18-1-5-1-proxy-pass请求转发"><a href="#_18-1-5-1-proxy-pass请求转发" class="header-anchor">#</a> 18.1.5.1. proxy_pass请求转发</h4> <p>proxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，
在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到服务匹配URI的
请求通过proyx_pass抛给定义好的upstream节点池。</p> <div class="language- extra-class"><pre class="language-text"><code>location /download/ {
proxy_pass http://download/vedio/;
}
#这是前端代理节点的设置
</code></pre></div><p>#交给后端upstream为download的节点
<strong>proxy模块参数 说明</strong>
proxy_next_upstream 什么情况下将请求传递到下一个upstream
proxy_limite_rate 限制从后端服务器读取响应的速率
proyx_set_header 设置http请求header传给后端服务器节点，如：可实现让代
理后端的服务器节点获取访问客户端的这是ip
client_body_buffer_size 客户端请求主体缓冲区大小
proxy_connect_timeout 代理与后端节点服务器连接的超时时间
proxy_send_timeout 后端节点数据回传的超时时间
proxy_read_timeout 设置Nginx从代理的后端服务器获取信息的时间，表示连接成
功建立后，Nginx等待后端服务器的响应时间
proxy_buffer_size 设置缓冲区大小
proxy_buffers 设置缓冲区的数量和大小
proyx_busy_buffers_size 用于设置系统很忙时可以使用的proxy_buffers大小，推荐为
proxy_buffers*2
proxy_temp_file_write_size 指定proxy缓存临时文件的大小</p> <h3 id="_18-1-6-haproxy"><a href="#_18-1-6-haproxy" class="header-anchor">#</a> 18.1.6. HAProxy</h3> <h2 id="_19-数据库"><a href="#_19-数据库" class="header-anchor">#</a> 19. 数据库</h2> <h3 id="_19-1-1-存储引擎"><a href="#_19-1-1-存储引擎" class="header-anchor">#</a> 19.1.1. 存储引擎</h3> <h4 id="_19-1-1-1-概念"><a href="#_19-1-1-1-概念" class="header-anchor">#</a> 19.1.1.1. 概念</h4> <p>数据库存储引擎是数据库底层软件组织，数据库管理系统（DBMS）使用数据引擎进行创建、查询、
更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同
的存储引擎，还可以 获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引
擎。存储引擎主要有： 1. MyIsam , 2. InnoDB, 3. Memory, 4. Archive, 5. Federated 。</p> <h4 id="_19-1-1-2-innodb-b-树"><a href="#_19-1-1-2-innodb-b-树" class="header-anchor">#</a> 19.1.1.2. InnoDB（B+树）</h4> <p>InnoDB 底层存储结构为B+树， B树的每个节点对应innodb的一个page，page大小是固定的，
一般设为16k。其中非叶子节点只有键值，叶子节点包含完成数据。</p> <p>适用场景：</p> <p>1 ）经常更新的表，适合处理多重并发的更新请求。</p> <p>2 ）支持事务。</p> <p>3 ）可以从灾难中恢复（通过bin-log日志等）。</p> <p>4 ）外键约束。只有他支持外键。</p> <p>5 ）支持自动增加列属性auto_increment。</p> <h4 id="_19-1-1-3-tokudb-fractal-tree-节点带数据"><a href="#_19-1-1-3-tokudb-fractal-tree-节点带数据" class="header-anchor">#</a> 19.1.1.3. TokuDB（Fractal Tree-节点带数据）</h4> <p>TokuDB 底层存储结构为Fractal Tree,Fractal Tree的结构与B+树有些类似, 在Fractal Tree
中，每一个child指针除了需要指向一个child节点外，还会带有一个Message Buffer ，这个
Message Buffer 是一个FIFO的队列，用来缓存更新操作。</p> <p>例如，一次插入操作只需要落在某节点的Message Buffer就可以马上返回了，并不需要搜索到叶
子节点。这些缓存的更新会在查询时或后台异步合并应用到对应的节点中。</p> <p>TokuDB在线添加索引，不影响读写操作, 非常快的写入性能， Fractal-tree在事务实现上有优
势。 他主要适用于访问频率不高的数据或历史数据归档。</p> <h4 id="_19-1-1-4-myiasm"><a href="#_19-1-1-4-myiasm" class="header-anchor">#</a> 19.1.1.4. MyIASM</h4> <p>MyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，
因此当INSERT(插入)或UPDATE(更新)数据时即写操作需要锁定整个表，效率便会低一些。</p> <p>ISAM执行读取操作的速度很快，而且不占用大量的内存和存储资源。在设计之初就预想数据组织
成有固定长度的记录，按顺序存储的。---ISAM是一种静态索引结构。</p> <p>缺点是它不 支持事务处理。</p> <h4 id="_19-1-1-5-memory"><a href="#_19-1-1-5-memory" class="header-anchor">#</a> 19.1.1.5. Memory</h4> <p>Memory（也叫HEAP）堆内存：使用存在内存中的内容来创建表。每个MEMORY表只实际对应
一个磁盘文件。MEMORY类型的表访问非常得快，因为它的数据是放在内存中的，并且默认使用
HASH索引。但是一旦服务关闭，表中的数据就会丢失掉。 Memory同时支持散列索引和B树索
引，B树索引可以使用部分查询和通配查询，也可以使用&lt;,&gt;和&gt;=等操作符方便数据挖掘，散列索
引相等的比较快但是对于范围的比较慢很多。</p> <h3 id="_19-1-2-索引"><a href="#_19-1-2-索引" class="header-anchor">#</a> 19.1.2. 索引</h3> <p>索引（Index）是帮助 MySQL高效获取数据的数据结构。常见的查询算法,顺序查找,二分查找,二
叉排序树查找,哈希散列法,分块查找,平衡多路搜索树B树（B-tree）</p> <h4 id="_19-1-2-1-常见索引原则有"><a href="#_19-1-2-1-常见索引原则有" class="header-anchor">#</a> 19.1.2.1. 常见索引原则有</h4> <h5 id="_1-选择唯一性索引"><a href="#_1-选择唯一性索引" class="header-anchor">#</a> 1.选择唯一性索引</h5> <p>1 ． 唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。</p> <h5 id="_2-为经常需要排序、分组和联合操作的字段建立索引"><a href="#_2-为经常需要排序、分组和联合操作的字段建立索引" class="header-anchor">#</a> 2.为经常需要排序、分组和联合操作的字段建立索引：</h5> <h5 id="_3-为常作为查询条件的字段建立索引。"><a href="#_3-为常作为查询条件的字段建立索引。" class="header-anchor">#</a> 3 ．为常作为查询条件的字段建立索引。</h5> <h5 id="_4-限制索引的数目"><a href="#_4-限制索引的数目" class="header-anchor">#</a> 4 ．限制索引的数目：</h5> <p>越多的索引，会使更新表变得很浪费时间。</p> <h5 id="尽量使用数据量少的索引"><a href="#尽量使用数据量少的索引" class="header-anchor">#</a> 尽量使用数据量少的索引</h5> <p>6 ． 如果索引的值很长，那么查询的速度会受到影响。</p> <h5 id="尽量使用前缀来索引"><a href="#尽量使用前缀来索引" class="header-anchor">#</a> 尽量使用前缀来索引</h5> <p>7 ． 如果索引字段的值很长，最好使用值的前缀来索引。</p> <h5 id="_7-删除不再使用或者很少使用的索引"><a href="#_7-删除不再使用或者很少使用的索引" class="header-anchor">#</a> 7 ．删除不再使用或者很少使用的索引</h5> <h5 id="_8-最左前缀匹配原则-非常重要的原则。"><a href="#_8-最左前缀匹配原则-非常重要的原则。" class="header-anchor">#</a> 8 最左前缀匹配原则，非常重要的原则。</h5> <h5 id="_10-尽量选择区分度高的列作为索引"><a href="#_10-尽量选择区分度高的列作为索引" class="header-anchor">#</a> 10 尽量选择区分度高的列作为索引</h5> <p>区分度的公式是表示字段不重复的比例</p> <h5 id="_11-索引列不能参与计算-保持列-干净-带函数的查询不参与索引。"><a href="#_11-索引列不能参与计算-保持列-干净-带函数的查询不参与索引。" class="header-anchor">#</a> 11 .索引列不能参与计算，保持列“干净”：带函数的查询不参与索引。</h5> <h5 id="_12-尽量的扩展索引-不要新建索引。"><a href="#_12-尽量的扩展索引-不要新建索引。" class="header-anchor">#</a> 12 .尽量的扩展索引，不要新建索引。</h5> <h3 id="_19-1-3-数据库三范式"><a href="#_19-1-3-数据库三范式" class="header-anchor">#</a> 19.1.3. 数据库三范式</h3> <p>范式是具有最小冗余的表结构。 3 范式具体如下：</p> <h4 id="_19-1-3-1-第一范式-1st-nf-列都是不可再分"><a href="#_19-1-3-1-第一范式-1st-nf-列都是不可再分" class="header-anchor">#</a> 19.1.3.1. 第一范式(1st NF －列都是不可再分)</h4> <p>第一范式的目标是确保每列的原子性:如果每列都是不可再分的最小数据单元（也称为最小的原子
单元），则满足第一范式（1NF）</p> <h4 id="_19-1-3-2-第二范式-2nd-nf-每个表只描述一件事情"><a href="#_19-1-3-2-第二范式-2nd-nf-每个表只描述一件事情" class="header-anchor">#</a> 19.1.3.2. 第二范式(2nd NF－每个表只描述一件事情)</h4> <p>首先满足第一范式，并且表中非主键列不存在对主键的部分依赖。 第二范式要求每个表只描述一
件事情。</p> <h4 id="_19-1-3-3-第三范式-3rd-nf-不存在对非主键列的传递依赖"><a href="#_19-1-3-3-第三范式-3rd-nf-不存在对非主键列的传递依赖" class="header-anchor">#</a> 19.1.3.3. 第三范式(3rd NF－ 不存在对非主键列的传递依赖)</h4> <p>第三范式定义是，满足第二范式，并且表中的列不存在对非主键列的传递依赖。除了主键订单编
号外，顾客姓名依赖于非主键顾客编号。</p> <h3 id="_19-1-4-数据库是事务"><a href="#_19-1-4-数据库是事务" class="header-anchor">#</a> 19.1.4. 数据库是事务</h3> <p>事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作，这些操作作为一个整体一起向
系统提交，要么都执行、要么都不执行 。事务是一个不可分割的工作逻辑单元</p> <p>事务必须具备以下四个属性，简称ACID 属性：</p> <h5 id="原子性-atomicity"><a href="#原子性-atomicity" class="header-anchor">#</a> 原子性（Atomicity）</h5> <ol><li>事务是一个完整的操作。事务的各步操作是不可分的（原子的）；要么都执行，要么都不执
行。</li></ol> <h5 id="一致性-consistency"><a href="#一致性-consistency" class="header-anchor">#</a> 一致性（Consistency）</h5> <ol start="2"><li>当事务完成时，数据必须处于一致状态。</li></ol> <h5 id="隔离性-isolation"><a href="#隔离性-isolation" class="header-anchor">#</a> 隔离性（Isolation）</h5> <ol start="3"><li>对数据进行修改的所有并发事务是彼此隔离的，这表明事务必须是独立的，它不应以任何方
式依赖于或影响其他事务。</li></ol> <h5 id="永久性-durability"><a href="#永久性-durability" class="header-anchor">#</a> 永久性（Durability）</h5> <ol start="4"><li>事务完成后，它对数据库的修改被永久保持，事务日志能够保持事务的永久性。</li></ol> <h3 id="_19-1-5-存储过程-特定功能的-sql-语句集"><a href="#_19-1-5-存储过程-特定功能的-sql-语句集" class="header-anchor">#</a> 19.1.5. 存储过程 ( 特定功能的 SQL 语句集 )</h3> <p>一组为了完成特定功能的SQL 语句集，存储在数据库中，经过第一次编译后再次调用不需要再次
编译，用户通过指定存储过程的名字并给出参数（如果该存储过程带有参数）来执行它。存储过
程是数据库中的一个重要对象。</p> <h4 id="存储过程优化思路"><a href="#存储过程优化思路" class="header-anchor">#</a> 存储过程优化思路：</h4> <ol><li>尽量利用一些sql语句来替代一些小循环，例如聚合函数，求平均函数等。</li> <li>中间结果存放于临时表，加索引。</li> <li>少使用游标。sql是个集合语言，对于集合运算具有较高性能。而cursors是过程运算。比如
对一个 100 万行的数据进行查询。游标需要读表 100 万次，而不使用游标则只需要少量几次
读取。</li> <li>事务越短越好。sqlserver支持并发操作。如果事务过多过长，或者隔离级别过高，都会造成
并发操作的阻塞，死锁。导致查询极慢，cpu占用率极地。</li> <li>使用try-catch处理错误异常。</li> <li>查找语句尽量不要放在循环内。</li></ol> <h3 id="_19-1-6-触发器-一段能自动执行的程序"><a href="#_19-1-6-触发器-一段能自动执行的程序" class="header-anchor">#</a> 19.1.6. 触发器 ( 一段能自动执行的程序 )</h3> <p>触发器是一段能自动执行的程序，是一种特殊的存储过程，触发器和普通的存储过程的区别是：
触发器是当对某一个表进行操作时触发。诸如：update、insert、delete这些操作的时候，系统
会自动调用执行该表上对应的触发器。SQL Server 2005中触发器可以分为两类：DML触发器和
DDL 触发器，其中DDL触发器它们会影响多种数据定义语言语句而激发，这些语句有create、
alter、drop语句。</p> <h3 id="_19-1-7-数据库并发策略"><a href="#_19-1-7-数据库并发策略" class="header-anchor">#</a> 19.1.7. 数据库并发策略</h3> <p>并发控制一般采用三种方法，分别是乐观锁和悲观锁以及时间戳。</p> <h4 id="_19-1-7-1-乐观锁"><a href="#_19-1-7-1-乐观锁" class="header-anchor">#</a> 19.1.7.1. 乐观锁</h4> <p>乐观锁认为一个用户读数据的时候，别人不会去写自己所读的数据；悲观锁就刚好相反，觉得自
己读数据库的时候，别人可能刚好在写自己刚读的数据，其实就是持一种比较保守的态度；时间
戳就是不加锁，通过时间戳来控制并发出现的问题。</p> <h4 id="_19-1-7-2-悲观锁"><a href="#_19-1-7-2-悲观锁" class="header-anchor">#</a> 19.1.7.2. 悲观锁</h4> <p>悲观锁就是在读取数据的时候，为了不让别人修改自己读取的数据，就会先对自己读取的数据加
锁，只有自己把数据读完了，才允许别人修改那部分数据，或者反过来说，就是自己修改某条数
据的时候，不允许别人读取该数据，只有等自己的整个事务提交了，才释放自己加上的锁，才允
许其他用户访问那部分数据。</p> <h4 id="_19-1-7-3-时间戳"><a href="#_19-1-7-3-时间戳" class="header-anchor">#</a> 19.1.7.3. 时间戳</h4> <p>时间戳就是在数据库表中单独加一列时间戳，比如“TimeStamp”，每次读出来的时候，把该字
段也读出来，当写回去的时候，把该字段加 1 ，提交之前 ，跟数据库的该字段比较一次，如果比数
据库的值大的话，就允许保存，否则不允许保存，这种处理方法虽然不使用数据库系统提供的锁
机制，但是这种方法可以大大提高数据库处理的并发量，</p> <p>以上悲观锁所说的加“锁”，其实分为几种锁，分别是：排它锁（写锁）和共享锁（读锁）。</p> <h3 id="_19-1-8-数据库锁"><a href="#_19-1-8-数据库锁" class="header-anchor">#</a> 19.1.8. 数据库锁</h3> <h4 id="_19-1-8-1-行级锁"><a href="#_19-1-8-1-行级锁" class="header-anchor">#</a> 19.1.8.1. 行级锁</h4> <p>行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时，Oracle会自动应用行级锁：</p> <ol><li>INSERT、UPDATE、DELETE、SELECT ... FOR UPDATE [OF columns] [WAIT n | NOWAIT];</li> <li>SELECT ... FOR UPDATE语句允许用户一次锁定多条记录进行更新</li> <li>使用COMMIT或ROLLBACK语句释放锁。</li></ol> <h4 id="_19-1-8-2-表级锁"><a href="#_19-1-8-2-表级锁" class="header-anchor">#</a> 19.1.8.2. 表级锁</h4> <p>表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使
用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁
（排他锁）。</p> <h4 id="_19-1-8-1-页级锁"><a href="#_19-1-8-1-页级锁" class="header-anchor">#</a> 19.1.8.1. 页级锁</h4> <p>页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级
冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁</p> <h3 id="_19-1-9-基于-redis-分布式锁"><a href="#_19-1-9-基于-redis-分布式锁" class="header-anchor">#</a> 19.1.9. 基于 Redis 分布式锁</h3> <ol><li><p>获取锁的时候，使用setnx（SETNX key val：当且仅当key不存在时，set一个key
为val的字符串，返回 1 ；若key存在，则什么都不做，返回 0 ）加锁，锁的value
值为一个随机生成的UUID，在释放锁的时候进行判断。并使用expire命令为锁添
加一个超时时间，超过该时间则自动释放锁。</p></li> <li><p>获取锁的时候调用setnx，如果返回 0 ，则该锁正在被别人使用，返回 1 则成功获取
锁。 还设置一个获取的超时时间，若超过这个时间则放弃获取锁。</p></li> <li><p>释放锁的时候，通过UUID判断是不是该锁，若是该锁，则执行delete进行锁释放。</p></li></ol> <h3 id="_19-1-10-分区分表"><a href="#_19-1-10-分区分表" class="header-anchor">#</a> 19.1.10. 分区分表</h3> <p>分库分表有垂直切分和水平切分两种。</p> <h5 id="垂直切分-按照功能模块"><a href="#垂直切分-按照功能模块" class="header-anchor">#</a> 垂直切分(按照功能模块)</h5> <p> 将表按照功能模块、关系密切程度划分出来，部署到不同的库上。例如，我们会建立定义数
据库workDB、商品数据库payDB、用户数据库userDB、日志数据库logDB等，分别用于
存储项目数据定义表、商品定义表、用户数据表、日志数据表等。</p> <h5 id="水平切分-按照规则划分存储"><a href="#水平切分-按照规则划分存储" class="header-anchor">#</a> 水平切分(按照规则划分存储)</h5> <p> 当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，例如userID散列，进行
划分，然后存储到多个结构相同的表，和不同的库上。</p> <h3 id="_19-1-11-两阶段提交协议"><a href="#_19-1-11-两阶段提交协议" class="header-anchor">#</a> 19.1.11. 两阶段提交协议</h3> <p>分布式事务是指会涉及到操作多个数据库的事务,在分布式系统中，各个节点之间在物理上相互独
立，通过网络进行沟通和协调。</p> <p>XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件
用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。</p> <p>二阶段提交(Two-phaseCommit)是指，在计算机网络以及数据库领域内，为了使基于分布式系统
架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常，二阶段提
交也被称为是一种协议(Protocol))。在分布式系统中，每个节点虽然可以知晓自己的操作时成功
或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事
务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并
最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，
二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者
的反馈情报决定各参与者是否要提交操作还是中止操作。</p> <h4 id="_19-1-11-1-准备阶段"><a href="#_19-1-11-1-准备阶段" class="header-anchor">#</a> 19.1.11.1. 准备阶段</h4> <p>事务协调者(事务管理器)给每个参与者(资源管理器)发送Prepare消息，每个参与者要么直接返回
失败(如权限验证失败)，要么在本地执行事务，写本地的redo和undo日志，但不提交，到达一
种“万事俱备，只欠东风”的状态。</p> <h4 id="_19-1-11-2-提交阶段"><a href="#_19-1-11-2-提交阶段" class="header-anchor">#</a> 19.1.11.2. 提交阶段</h4> <p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，
发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过
程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p> <h4 id="_19-1-11-3-缺点"><a href="#_19-1-11-3-缺点" class="header-anchor">#</a> 19.1.11.3. 缺点</h4> <h5 id="同步阻塞问题"><a href="#同步阻塞问题" class="header-anchor">#</a> 同步阻塞问题</h5> <div class="language- extra-class"><pre class="language-text"><code>1 、 执行过程中，所有参与节点都是事务阻塞型的。
</code></pre></div><h5 id="单点故障"><a href="#单点故障" class="header-anchor">#</a> 单点故障</h5> <div class="language- extra-class"><pre class="language-text"><code>2 、 由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。
</code></pre></div><h5 id="数据不一致-脑裂问题"><a href="#数据不一致-脑裂问题" class="header-anchor">#</a> 数据不一致（脑裂问题）</h5> <div class="language- extra-class"><pre class="language-text"><code>3 、 在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异
常或者在发送commit 请求过程中协调者发生了故障，导致只有一部分参与者接受到了
commit请求。于是整个分布式系统便出现了数据部一致性的现象(脑裂现象)。
</code></pre></div><h5 id="二阶段无法解决的问题-数据状态不确定"><a href="#二阶段无法解决的问题-数据状态不确定" class="header-anchor">#</a> 二阶段无法解决的问题（数据状态不确定）</h5> <div class="language- extra-class"><pre class="language-text"><code>4 、 协调者再发出commit消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那
么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道
事务是否被已经提交。
</code></pre></div><h3 id="_19-1-12-三阶段提交协议"><a href="#_19-1-12-三阶段提交协议" class="header-anchor">#</a> 19.1.12. 三阶段提交协议</h3> <p>三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit
protocol），是二阶段提交（2PC）的改进版本。</p> <p>与两阶段提交不同的是，三阶段提交有两个改动点。</p> <p>1 、引入超时机制。同时在协调者和参与者中都引入超时机制。</p> <p>2 、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是
一致的。也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段
提交就有CanCommit、PreCommit、DoCommit三个阶段。</p> <h4 id="_19-1-12-1-cancommit阶段"><a href="#_19-1-12-1-cancommit阶段" class="header-anchor">#</a> 19.1.12.1. CanCommit阶段</h4> <p>协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。</p> <h4 id="_19-1-12-2-precommit阶段"><a href="#_19-1-12-2-precommit阶段" class="header-anchor">#</a> 19.1.12.2. PreCommit阶段</h4> <p>协调者根据参与者的反应情况来决定是否可以继续进行，有以下两种可能。假如协调者从所有的
参与者获得的反馈都是Yes响应，那么就会执行事务的预执行假如有任何一个参与者向协调者发送
了No响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。</p> <h4 id="_19-1-12-3-docommit阶段"><a href="#_19-1-12-3-docommit阶段" class="header-anchor">#</a> 19.1.12.3. doCommit阶段</h4> <p>该阶段进行真正的事务提交，主要包含1.协调这发送提交请求 2.参与者提交事务 3.参与者响应反
馈（ 事务提交完之后，向协调者发送Ack响应。）4.协调者确定完成事务。</p> <h3 id="_19-1-13-柔性事务"><a href="#_19-1-13-柔性事务" class="header-anchor">#</a> 19.1.13. 柔性事务</h3> <h4 id="_19-1-13-1-柔性事务"><a href="#_19-1-13-1-柔性事务" class="header-anchor">#</a> 19.1.13.1. 柔性事务</h4> <p>在电商领域等互联网场景下，传统的事务在数据库性能和处理能力上都暴露出了瓶颈。在分布式
领域基于CAP理论以及BASE理论，有人就提出了 柔性事务 的概念。CAP（一致性、可用性、分
区容忍性）理论大家都理解很多次了，这里不再叙述。说一下BASE理论，它是在CAP理论的基
础之上的延伸。包括 基本可用（Basically Available）、柔性状态（Soft State）、最终一致性
（Eventual Consistency）。</p> <p>通常所说的柔性事务分为：两阶段型、补偿型、异步确保型、最大努力通知型几种。</p> <h5 id="两阶段型"><a href="#两阶段型" class="header-anchor">#</a> 两阶段型</h5> <div class="language- extra-class"><pre class="language-text"><code>1 、 就是分布式事务两阶段提交，对应技术上的XA、JTA/JTS。这是分布式环境下事务处理的
典型模式。
</code></pre></div><h5 id="补偿型"><a href="#补偿型" class="header-anchor">#</a> 补偿型</h5> <div class="language- extra-class"><pre class="language-text"><code>2 、 TCC型事务（Try/Confirm/Cancel）可以归为补偿型。
</code></pre></div><p>WS-BusinessActivity提供了一种基于补偿的long-running的事务处理模型。服务器A发起事务，
服务器B参与事务，服务器A的事务如果执行顺利，那么事务A就先行提交，如果事务B也执行
顺利，则事务B也提交，整个事务就算完成。但是如果事务B执行失败，事务B本身回滚，这时
事务A已经被提交，所以需要执行一个补偿操作，将已经提交的事务A执行的操作作反操作，恢
复到未执行前事务A的状态。这样的SAGA事务模型，是牺牲了一定的隔离性和一致性的，但是
提高了long-running事务的可用性。</p> <h5 id="异步确保型"><a href="#异步确保型" class="header-anchor">#</a> 异步确保型</h5> <div class="language- extra-class"><pre class="language-text"><code>3 、 通过将一系列同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步
阻塞操作的影响。
</code></pre></div><h5 id="最大努力通知型-多次尝试"><a href="#最大努力通知型-多次尝试" class="header-anchor">#</a> 最大努力通知型（多次尝试）</h5> <div class="language- extra-class"><pre class="language-text"><code>4 、 这是分布式事务中要求最低的一种, 也可以通过消息中间件实现, 与前面异步确保型操作不
同的一点是, 在消息由MQ Server投递到消费者之后, 允许在达到最大重试次数之后正常
结束事务。
</code></pre></div><h3 id="_19-1-14-cap"><a href="#_19-1-14-cap" class="header-anchor">#</a> 19.1.14. CAP</h3> <p>CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability
（可用性）、Partition tolerance（分区容错性），三者不可得兼。</p> <h4 id="一致性-c"><a href="#一致性-c" class="header-anchor">#</a> 一致性（C）：</h4> <ol><li>在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份
最新的数据副本）</li></ol> <h4 id="可用性-a"><a href="#可用性-a" class="header-anchor">#</a> 可用性（A）：</h4> <ol start="2"><li>在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备
高可用性）</li></ol> <h4 id="分区容忍性-p"><a href="#分区容忍性-p" class="header-anchor">#</a> 分区容忍性（P）：</h4> <ol start="3"><li>以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，
就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。</li></ol> <h2 id="_20-一致性算法"><a href="#_20-一致性算法" class="header-anchor">#</a> 20. 一致性算法</h2> <h3 id="_20-1-1-paxos"><a href="#_20-1-1-paxos" class="header-anchor">#</a> 20.1.1. Paxos</h3> <p>Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。一个典型的场景是，
在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点执行相同的操作序列，那么
他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列，需要在每一条指令上执
行一个“一致性算法”以保证每个节点看到的指令一致。zookeeper 使用的zab算法是该算法的
一个实现。 在Paxos算法中，有三种角色：Proposer，Acceptor，Learners</p> <h4 id="paxos三种角色-proposer-acceptor-learners"><a href="#paxos三种角色-proposer-acceptor-learners" class="header-anchor">#</a> Paxos三种角色：Proposer，Acceptor，Learners</h4> <h5 id="proposer"><a href="#proposer" class="header-anchor">#</a> Proposer：</h5> <p>只要Proposer发的提案被半数以上Acceptor接受，Proposer就认为该提案里的value被选定
了。</p> <h5 id="acceptor"><a href="#acceptor" class="header-anchor">#</a> Acceptor：</h5> <p>只要Acceptor接受了某个提案，Acceptor就认为该提案里的value被选定了。</p> <h5 id="learner"><a href="#learner" class="header-anchor">#</a> Learner：</h5> <p>Acceptor告诉Learner哪个value被选定，Learner就认为那个value被选定。</p> <h4 id="paxos算法分为两个阶段。具体如下"><a href="#paxos算法分为两个阶段。具体如下" class="header-anchor">#</a> Paxos算法分为两个阶段。具体如下：</h4> <h5 id="阶段一-准leader确定"><a href="#阶段一-准leader确定" class="header-anchor">#</a> 阶段一（准leader确定 ）：</h5> <p>(a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。</p> <p>(b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的
所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响
应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。</p> <h5 id="阶段二-leader确认"><a href="#阶段二-leader确认" class="header-anchor">#</a> 阶段二（leader确认）：</h5> <p>(a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它
就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中
编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。</p> <p>(b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号
大于N的Prepare请求做出过响应，它就接受该提案。</p> <h3 id="_20-1-2-zab"><a href="#_20-1-2-zab" class="header-anchor">#</a> 20.1.2. Zab</h3> <p>ZAB( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议）协议包括两种基本的模
式：崩溃恢复和消息广播</p> <ol><li>当整个服务框架在启动过程中，或是当Leader服务器出现网络中断崩溃退出与重启等异常情
况时，ZAB就会进入恢复模式并选举产生新的Leader服务器。</li> <li>当选举产生了新的Leader服务器，同时集群中已经有过半的机器与该Leader服务器完成了
状态同步之后，ZAB协议就会退出崩溃恢复模式，进入消息广播模式。</li> <li>当有新的服务器加入到集群中去，如果此时集群中已经存在一个Leader服务器在负责进行消
息广播，那么新加入的服务器会自动进入数据恢复模式，找到Leader服务器，并与其进行数
据同步，然后一起参与到消息广播流程中去。</li></ol> <p>以上其实大致经历了三个步骤：</p> <h5 id="_1-崩溃恢复-主要就是leader选举过程"><a href="#_1-崩溃恢复-主要就是leader选举过程" class="header-anchor">#</a> 1.崩溃恢复：主要就是Leader选举过程</h5> <h5 id="_2-数据同步-leader服务器与其他服务器进行数据同步"><a href="#_2-数据同步-leader服务器与其他服务器进行数据同步" class="header-anchor">#</a> 2.数据同步：Leader服务器与其他服务器进行数据同步</h5> <h5 id="_3-消息广播-leader服务器将数据发送给其他服务器"><a href="#_3-消息广播-leader服务器将数据发送给其他服务器" class="header-anchor">#</a> 3.消息广播：Leader服务器将数据发送给其他服务器</h5> <p>说明：zookeeper章节对该协议有详细描述。</p> <h3 id="_20-1-3-raft"><a href="#_20-1-3-raft" class="header-anchor">#</a> 20.1.3. Raft</h3> <p>与Paxos不同Raft强调的是易懂（Understandability），Raft和Paxos一样只要保证n/2+1节
点正常就能够提供服务；raft 把算法流程分为三个子问题：选举（Leader election）、日志复制
（Log replication）、安全性（Safety）三个子问题。</p> <h4 id="_20-1-3-1-角色"><a href="#_20-1-3-1-角色" class="header-anchor">#</a> 20.1.3.1. 角色</h4> <p>Raft把集群中的节点分为三种状态：Leader、 Follower 、Candidate，理所当然每种状态负
责的任务也是不一样的，Raft运行时提供服务的时候只存在Leader与Follower两种状态；</p> <h5 id="leader-领导者-日志管理"><a href="#leader-领导者-日志管理" class="header-anchor">#</a> Leader（领导者-日志管理）</h5> <div class="language- extra-class"><pre class="language-text"><code>负责日志的同步管理，处理来自客户端的请求，与Follower保持这heartBeat的联系；
</code></pre></div><h5 id="follower-追随者-日志同步"><a href="#follower-追随者-日志同步" class="header-anchor">#</a> Follower（追随者-日志同步）</h5> <p>刚启动时所有节点为Follower状态，响应Leader的日志同步请求，响应Candidate的请求，
把请求到Follower的事务转发给Leader；</p> <h5 id="candidate-候选者-负责选票"><a href="#candidate-候选者-负责选票" class="header-anchor">#</a> Candidate（候选者-负责选票）</h5> <p>负责选举投票，Raft 刚启动时由一个节点从Follower 转为Candidate 发起选举，选举出
Leader后从Candidate转为Leader状态；</p> <h4 id="_20-1-3-2-term-任期"><a href="#_20-1-3-2-term-任期" class="header-anchor">#</a> 20.1.3.2. Term（任期）</h4> <p>在Raft中使用了一个可以理解为周期（第几届、任期）的概念，用Term作为一个周期，每
个Term都是一个连续递增的编号，每一轮选举都是一个Term周期，在一个Term中只能产生一
个Leader；当某节点收到的请求中Term比当前Term小时则拒绝该请求。</p> <h4 id="_20-1-3-3-选举-election"><a href="#_20-1-3-3-选举-election" class="header-anchor">#</a> 20.1.3.3. 选举（Election）</h4> <h5 id="选举定时器"><a href="#选举定时器" class="header-anchor">#</a> 选举定时器</h5> <p>Raft 的选举由定时器来触发，每个节点的选举定时器时间都是不一样的，开始时状态都为
Follower某个节点定时器触发选举后Term递增，状态由Follower转为Candidate，向其他节点
发起RequestVote RPC请求，这时候有三种可能的情况发生：</p> <p>1 ：该RequestVote请求接收到n/2+1（过半数）个节点的投票，从Candidate转为Leader，
向其他节点发送heartBeat以保持Leader的正常运转。</p> <p>2 ：在此期间如果收到其他节点发送过来的AppendEntries RPC请求，如该节点的Term大
则当前节点转为Follower，否则保持Candidate拒绝该请求。</p> <p>3 ：Election timeout发生则Term递增，重新发起选举</p> <p>在一个Term期间每个节点只能投票一次，所以当有多个 Candidate存在时就会出现每个
Candidate发起的选举都存在接收到的投票数都不过半的问题，这时每个Candidate都将Term
递增、重启定时器并重新发起选举，由于每个节点中定时器的时间都是随机的，所以就不会多次
存在有多个Candidate同时发起投票的问题。</p> <p>在Raft中当接收到客户端的日志（事务请求）后先把该日志追加到本地的Log中，然后通过
heartbeat把该Entry同步给其他Follower，Follower接收到日志后记录日志然后向Leader发送
ACK，当Leader收到大多数（n/2+1）Follower的ACK信息后将该日志设置为已提交并追加到
本地磁盘中，通知客户端并在下个heartbeat中Leader将通知所有的Follower将该日志存储在
自己的本地磁盘中。</p> <h4 id="_20-1-3-4-安全性-safety"><a href="#_20-1-3-4-安全性-safety" class="header-anchor">#</a> 20.1.3.4. 安全性（Safety）</h4> <p>安全性是用于保证每个节点都执行相同序列的安全机制如当某个Follower在当前Leader commit
Log时变得不可用了，稍后可能该Follower又会倍选举为Leader，这时新Leader可能会用新的
Log覆盖先前已committed的Log，这就是导致节点执行不同序列；Safety就是用于保证选举出
来的Leader一定包含先前 commited Log的机制；</p> <p>选举安全性（Election Safety）：每个Term只能选举出一个Leader</p> <p>Leader完整性（Leader Completeness）：这里所说的完整性是指Leader日志的完整性，
Raft在选举阶段就使用Term的判断用于保证完整性：当请求投票的该Candidate的Term较大
或Term相同Index更大则投票，该节点将容易变成leader。</p> <h4 id="_20-1-3-5-raft协议和zab协议区别"><a href="#_20-1-3-5-raft协议和zab协议区别" class="header-anchor">#</a> 20.1.3.5. raft协议和zab协议区别</h4> <p><strong>相同点</strong></p> <p> 采用quorum来确定整个系统的一致性,这个quorum一般实现是集群中半数以上的服务器,
 zookeeper里还提供了带权重的quorum实现.
 都由leader来发起写操作.
 都采用心跳检测存活性</p> <p> leader election都采用先到先得的投票方式</p> <p><strong>不同点</strong></p> <p> zab用的是epoch和count的组合来唯一表示一个值, 而raft用的是term和index
 zab的follower在投票给一个leader之前必须和leader的日志达成一致,而raft的follower
则简单地说是谁的term高就投票给谁
 raft协议的心跳是从leader到follower, 而zab协议则相反
 raft协议数据只有单向地从leader到follower(成为leader的条件之一就是拥有最新的log),</p> <p>而zab协议在discovery阶段, 一个prospective leader需要将自己的log更新为quorum里面
最新的log,然后才好在synchronization阶段将quorum里的其他机器的log都同步到一致.</p> <h3 id="_20-1-4-nwr"><a href="#_20-1-4-nwr" class="header-anchor">#</a> 20.1.4. NWR</h3> <h5 id="n-在分布式存储系统中-有多少份备份数据"><a href="#n-在分布式存储系统中-有多少份备份数据" class="header-anchor">#</a> N：在分布式存储系统中，有多少份备份数据</h5> <h5 id="w-代表一次成功的更新操作要求至少有w份数据写入成功"><a href="#w-代表一次成功的更新操作要求至少有w份数据写入成功" class="header-anchor">#</a> W：代表一次成功的更新操作要求至少有w份数据写入成功</h5> <h5 id="r-代表一次成功的读数据操作要求至少有r份数据成功读取"><a href="#r-代表一次成功的读数据操作要求至少有r份数据成功读取" class="header-anchor">#</a> R： 代表一次成功的读数据操作要求至少有R份数据成功读取</h5> <p>NWR值的不同组合会产生不同的一致性效果，当W+R&gt;N的时候，整个系统对于客户端来讲能保
证强一致性。而如果R+W&lt;=N，则无法保证数据的强一致性。以常见的N=3、W=2、R=2为例：</p> <p>N=3，表示，任何一个对象都必须有三个副本（Replica），W=2 表示，对数据的修改操作
（Write）只需要在 3 个Replica中的 2 个上面完成就返回，R=2表示，从三个对象中要读取到 2
个数据对象，才能返回。</p> <h3 id="_20-1-5-gossip"><a href="#_20-1-5-gossip" class="header-anchor">#</a> 20.1.5. Gossip</h3> <p>Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵
就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机</p> <p>地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可
能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的
状态都是一致的，当然这也是疫情传播的特点。</p> <h3 id="_20-1-6-一致性-hash"><a href="#_20-1-6-一致性-hash" class="header-anchor">#</a> 20.1.6. 一致性 Hash</h3> <p>一致性哈希算法(Consistent Hashing Algorithm)是一种分布式算法，常用于负载均衡。
Memcached client也选择这种算法，解决将key-value均匀分配到众多Memcached server上
的问题。它可以取代传统的取模操作，解决了取模操作无法应对增删Memcached Server的问题
(增删server会导致同一个key,在get操作时分配不到数据真正存储的server，命中率会急剧下
降)。</p> <h4 id="_20-1-6-1-一致性hash特性"><a href="#_20-1-6-1-一致性hash特性" class="header-anchor">#</a> 20.1.6.1. 一致性Hash特性</h4> <p> 平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得
所有的缓冲空间都得到利用。
 单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，
又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓
冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。容易看到，上面的简单求余算法
hash(object)%N 难以满足单调性要求。
 平滑性(Smoothness)：平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致
的。</p> <h4 id="_20-1-6-2-一致性hash原理"><a href="#_20-1-6-2-一致性hash原理" class="header-anchor">#</a> 20.1.6.2. 一致性Hash原理</h4> <h5 id="_1-建构环形hash-空间"><a href="#_1-建构环形hash-空间" class="header-anchor">#</a> 1.建构环形hash 空间：</h5> <ol><li>考虑通常的 hash 算法都是将 value 映射到一个 32 为的 key 值，也即是 0~2^32- 1 次方的
数值空间；我们可以将这个空间想象成一个首（ 0 ）尾（ 2^32- 1 ）相接的圆环。</li></ol> <h5 id="_2-把需要缓存的内容-对象-映射到hash-空间"><a href="#_2-把需要缓存的内容-对象-映射到hash-空间" class="header-anchor">#</a> 2.把需要缓存的内容(对象)映射到hash 空间</h5> <ol start="2"><li>接下来考虑 4 个对象 object1~object4 ，通过 hash 函数计算出的 hash 值 key 在环上的分
布</li></ol> <h5 id="_3-把服务器-节点-映射到hash-空间"><a href="#_3-把服务器-节点-映射到hash-空间" class="header-anchor">#</a> 3.把服务器(节点)映射到hash 空间</h5> <ol start="3"><li>Consistent hashing 的基本思想就是将对象和 cache 都映射到同一个 hash 数值空间中，并
且使用相同的 hash算法。一般的方法可以使用 服务器(节点) 机器的 IP 地址或者机器名作为
hash输入。</li></ol> <h5 id="_4-把对象映射到服务节点"><a href="#_4-把对象映射到服务节点" class="header-anchor">#</a> 4.把对象映射到服务节点</h5> <ol start="4"><li>现在服务节点和对象都已经通过同一个 hash 算法映射到 hash 数值空间中了，首先确定对象
hash值在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位
到的服务器。</li></ol> <h5 id="考察cache-的变动"><a href="#考察cache-的变动" class="header-anchor">#</a> 考察cache 的变动</h5> <ol start="5"><li>通过 hash 然后求余的方法带来的最大问题就在于不能满足单调性，当 cache 有所变动时，
cache会失效。
<strong>5.1 移除 cache</strong> ：考虑假设 cache B 挂掉了，根据上面讲到的映射方法，这时受影响的将仅是
那些沿 cache B 逆时针遍历直到下一个 cache （ cache C ）之间的对象。</li></ol> <p><strong>5.2 添加 cache</strong> ：再考虑添加一台新的 cache D 的情况，这时受影响的将仅是那些沿 cache
D 逆时针遍历直到下一个 cache 之间的对象，将这些对象重新映射到 cache D 上即可。</p> <h5 id="虚拟节点"><a href="#虚拟节点" class="header-anchor">#</a> 虚拟节点</h5> <p>hash 算法并不是保证绝对的平衡，如果 cache 较少的话，对象并不能被均匀的映射到 cache 上，
为了解决这种情况， consistent hashing 引入了“虚拟节点”的概念，它可以如下定义：</p> <p>虚拟节点（ virtual node ）是实际节点在 hash 空间的复制品（ replica ），一实际个节点对应了
若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以 hash
值排列。</p> <p>仍以仅部署 cache A 和 cache C 的情况为例。现在我们引入虚拟节点，并设置“复制个数”为 2 ，
这就意味着一共会存在 4 个“虚拟节点”， cache A1, cache A2 代表了 cache A； cache C1,
cache C2 代表了 cache C 。此时，对象到“虚拟节点”的映射关系为：</p> <p>objec1-&gt;cache A2 ； objec2-&gt;cache A1 ； objec3-&gt;cache C1 ； objec4-&gt;cache C2 ；</p> <p>因此对象 object1 和 object2 都被映射到了 cache A 上，而 object3 和 object4 映射到了 cache
C 上；平衡性有了很大提高。</p> <p>引入“虚拟节点”后，映射关系就从 { 对象 - &gt; 节点 } 转换到了 { 对象 - &gt; 虚拟节点 } 。查询物体所
在 cache 时的映射关系如下图 所示。</p> <h2 id="_21-java-算法"><a href="#_21-java-算法" class="header-anchor">#</a> 21. JAVA 算法</h2> <h3 id="_21-1-1-二分查找"><a href="#_21-1-1-二分查找" class="header-anchor">#</a> 21.1.1. 二分查找</h3> <p>又叫折半查找，要求待查找的序列有序。每次取中间位置的值与待查关键字比较，如果中间位置
的值比待查关键字大，则在前半部分循环这个查找的过程，如果中间位置的值比待查关键字小，
则在后半部分循环这个查找的过程。直到查找到了为止，否则序列中没有待查的关键字。</p> <div class="language- extra-class"><pre class="language-text"><code>public static int biSearch(int []array,int a){
int lo=0;
int hi=array.length-1;
int mid;
while(lo\&lt;=hi){
mid=(lo+hi)/2;//中间位置
if(array[mid]==a){
return mid+1;
}else if(array[mid]\&lt;a){ //向右查找
lo=mid+1;
}else{ //向左查找
hi=mid-1;
}
}
return -1;
}
</code></pre></div><h3 id="_21-1-2-冒泡排序算法"><a href="#_21-1-2-冒泡排序算法" class="header-anchor">#</a> 21.1.2. 冒泡排序算法</h3> <p>（ 1 ）比较前后相邻的二个数据，如果前面数据大于后面的数据，就将这二个数据交换。</p> <p>（ 2 ）这样对数组的第 0 个数据到N- 1 个数据进行一次遍历后，最大的一个数据就“沉”到数组第
N- 1 个位置。</p> <p>（ 3 ）N=N- 1 ，如果N不为 0 就重复前面二步，否则排序完成。</p> <div class="language- extra-class"><pre class="language-text"><code>public static void bubbleSort1(int [] a, int n){
int i, j;
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>for(i=0; i\&lt;n; i++){//表示n次排序过程。
for(j=1; j\&lt;n-i; j++){
if(a[j-1] \&gt; a[j]){//前面的数字大于后面的数字就交换
//交换a[j-1]和a[j]
int temp;
temp = a[j-1];
a[j-1] = a[j];
a[j]=temp;
}
}
}
}
</code></pre></div><h3 id="_21-1-3-插入排序算法"><a href="#_21-1-3-插入排序算法" class="header-anchor">#</a> 21.1.3. 插入排序算法</h3> <p>通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应的位置并插入。
插入排序非常类似于整扑克牌。在开始摸牌时，左手是空的，牌面朝下放在桌上。接着，一次从
桌上摸起一张牌，并将它插入到左手一把牌中的正确位置上。为了找到这张牌的正确位置，要将
它与手中已有的牌从右到左地进行比较。无论什么时候，左手中的牌都是排好序的。</p> <p>如果输入数组已经是排好序的话，插入排序出现最佳情况，其运行时间是输入规模的一个线性函
数。如果输入数组是逆序排列的，将出现最坏情况。平均情况与最坏情况一样，其时间代价是(n2)。</p> <div class="language- extra-class"><pre class="language-text"><code>public void sort(int arr[])
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>{
for(int i =1; i\&lt;arr.length;i++)
{
//插入的数
int insertVal = arr[i];
//被插入的位置(准备和前一个数比较)
int index = i-1;
//如果插入的数比被插入的数小
while(index\&gt;=0&amp;&amp;insertVal\&lt;arr[index])
{
//将把arr[index] 向后移动
arr[index+1]=arr[index];
//让index向前移动
index--;
}
//把插入的数放入合适位置
arr[index+1]=insertVal;
}
}
</code></pre></div><h3 id="_21-1-4-快速排序算法"><a href="#_21-1-4-快速排序算法" class="header-anchor">#</a> 21.1.4. 快速排序算法</h3> <p>快速排序的原理：选择一个关键值作为基准值。比基准值小的都在左边序列（一般是无序的），
比基准值大的都在右边（一般是无序的）。一般选择序列的第一个元素。</p> <p>一次循环：从后往前比较，用基准值和最后一个值比较，如果比基准值小的交换位置，如果没有
继续比较下一个，直到找到第一个比基准值小的值才交换。找到这个值之后，又从前往后开始比
较，如果有比基准值大的，交换位置，如果没有继续比较下一个，直到找到第一个比基准值大的
值才交换。直到从前往后的比较索引&gt;从后往前比较的索引，结束第一次循环，此时，对于基准值
来说，左右两边就是有序的了。</p> <div class="language- extra-class"><pre class="language-text"><code>public void sort(int[] a,int low,int high){
int start = low;
int end = high;
</code></pre></div><p>int key = a[low];</p> <p>while(end&gt;start){</p> <p>//从后往前比较</p> <p>while(end&gt;start&amp;&amp;a[end]&gt;=key)</p> <p>//如果没有比关键值小的，比较下一个，直到有比关键值小的交换位置，然后又从前往后比较</p> <p>end--;</p> <p>if(a[end]&lt;=key){</p> <p>int temp = a[end];</p> <p>a[end] = a[start];</p> <p>a[start] = temp;</p> <p>}</p> <p>//从前往后比较</p> <p>while(end&gt;start&amp;&amp;a[start]&lt;=key)</p> <p>//如果没有比关键值大的，比较下一个，直到有比关键值大的交换位置</p> <p>start++;</p> <p>if(a[start]&gt;=key){</p> <p>int temp = a[start];</p> <p>a[start] = a[end];</p> <p>a[end] = temp;</p> <p>}</p> <p>//此时第一次循环比较结束，关键值的位置已经确定了。左边的值都比关键值小，右边的
值都比关键值大，但是两边的顺序还有可能是不一样的，进行下面的递归调用</p> <p>}</p> <p>//递归</p> <p>if(start&gt;low) sort(a,low,start-1);//左边序列。第一个索引位置到关键值索引- 1</p> <p>if(end&lt;high) sort(a,end+1,high);//右边序列。从关键值索引+1到最后一个</p> <p>}</p> <p>}</p> <h3 id="_21-1-1-希尔排序算法"><a href="#_21-1-1-希尔排序算法" class="header-anchor">#</a> 21.1.1. 希尔排序算法</h3> <p>基本思想：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列
中的记录“基本有序”时，再对全体记录进行依次直接插入排序。</p> <ol><li>操作方法：
选择一个增量序列t1，t2，...，tk，其中ti&gt;tj，tk=1；</li> <li>按增量序列个数k，对序列进行k 趟排序；</li> <li>每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进
行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长
度。</li></ol> <div class="language- extra-class"><pre class="language-text"><code>private void shellSort(int[] a) {
int dk = a.length/2;
while( dk \&gt;= 1 ){
ShellInsertSort(a, dk);
dk = dk/2;
}
}
private void ShellInsertSort(int[] a, int dk) {
//类似插入排序，只是插入排序增量是 1 ，这里增量是dk,把 1 换成dk就可以了
for(int i=dk;i\&lt;a.length;i++){
if(a[i]\&lt;a[i-dk]){
int j;
int x=a[i];//x为待插入元素
a[i]=a[i-dk];
for(j=i-dk; j\&gt;=0 &amp;&amp; x\&lt;a[j];j=j-dk){
//通过循环，逐个后移一位找到要插入的位置。
a[j+dk]=a[j];
}
a[j+dk]=x;//插入
}
}
}
</code></pre></div><h3 id="_21-1-2-归并排序算法"><a href="#_21-1-2-归并排序算法" class="header-anchor">#</a> 21.1.2. 归并排序算法</h3> <p>归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列
分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。</p> <p>public class MergeSortTest {</p> <p>public static void main(String[] args) {</p> <p>int[] data = new int[] { 5, 3, 6, 2, 1, 9, 4, 8, 7 };</p> <p>print(data);</p> <p>mergeSort(data);</p> <p>System.out.println(&quot;排序后的数组：&quot;);</p> <p>print(data);</p> <p>}</p> <p>public static void mergeSort(int[] data) {</p> <p>sort(data, 0, data.length - 1);</p> <p>}</p> <p>public static void sort(int[] data, int left, int right) {</p> <p>if (left &gt;= right)</p> <p>return;</p> <p>// 找出中间索引</p> <p>int center = (left + right) / 2;</p> <p>// 对左边数组进行递归</p> <p>sort(data, left, center);</p> <p>// 对右边数组进行递归</p> <p>sort(data, center + 1, right);</p> <p>// 合并</p> <p>merge(data, left, center, right);</p> <p>print(data);</p> <p>}</p> <p>/**</p> <ul><li><p>将两个数组进行归并，归并前面 2 个数组已有序，归并后依然有序</p></li> <li></li> <li><p>@param data</p></li> <li><p>数组对象</p></li> <li><p>@param left</p></li> <li><p>左数组的第一个元素的索引</p></li> <li><p>@param center</p></li> <li><p>左数组的最后一个元素的索引，center+1是右数组第一个元素的索引</p></li> <li><p>@param right</p></li> <li><p>右数组最后一个元素的索引</p></li></ul> <p>*/</p> <p>public static void merge(int[] data, int left, int center, int right) {</p> <p>// 临时数组</p> <p>int[] tmpArr = new int[data.length];</p> <p>// 右数组第一个元素索引</p> <p>int mid = center + 1;</p> <p>// third 记录临时数组的索引</p> <p>int third = left;</p> <p>// 缓存左数组第一个元素的索引</p> <p>int tmp = left;</p> <p>while (left &lt;= center &amp;&amp; mid &lt;= right) {</p> <p>// 从两个数组中取出最小的放入临时数组</p> <p>if (data[left] &lt;= data[mid]) {</p> <p>tmpArr[third++] = data[left++];</p> <p>} else {</p> <p>tmpArr[third++] = data[mid++];</p> <p>}</p> <p>}</p> <p>// 剩余部分依次放入临时数组（实际上两个while只会执行其中一个）</p> <p>while (mid &lt;= right) {</p> <p>tmpArr[third++] = data[mid++];</p> <div class="language- extra-class"><pre class="language-text"><code>}
while (left \&lt;= center) {
tmpArr[third++] = data[left++];
}
// 将临时数组中的内容拷贝回原数组中
// （原left-right范围的内容被复制回原数组）
while (tmp \&lt;= right) {
data[tmp] = tmpArr[tmp++];
}
}
public static void print(int[] data) {
for (int i = 0; i \&lt; data.length; i++) {
System.out.print(data[i] + &quot;\t&quot;);
}
System.out.println();
}
}
</code></pre></div><h3 id="_21-1-3-桶排序算法"><a href="#_21-1-3-桶排序算法" class="header-anchor">#</a> 21.1.3. 桶排序算法</h3> <p>桶排序的基本思想是： 把数组 arr 划分为n个大小相同子区间（桶），每个子区间各自排序，最
后合并 。计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里只有一个元素的情况。</p> <p>1.找出待排序数组中的最大值max、最小值min</p> <p>2.我们使用 动态数组ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为(max-
min)/arr.length+1</p> <p>3.遍历数组 arr，计算每个元素 arr[i] 放的桶</p> <p>4.每个桶各自排序
public static void bucketSort(int[] arr){</p> <div class="language- extra-class"><pre class="language-text"><code>int max = Integer.MIN_VALUE;
int min = Integer.MAX_VALUE;
for(int i = 0; i \&lt; arr.length; i++){
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>max = Math.max(max, arr[i]);
min = Math.min(min, arr[i]);
}
//创建桶
int bucketNum = (max - min) / arr.length + 1;
ArrayList\&lt;ArrayList\&lt;Integer\&gt;\&gt; bucketArr = new ArrayList\&lt;\&gt;(bucketNum);
for(int i = 0; i \&lt; bucketNum; i++){
bucketArr.add(new ArrayList\&lt;Integer\&gt;());
}
//将每个元素放入桶
for(int i = 0; i \&lt; arr.length; i++){
int num = (arr[i] - min) / (arr.length);
bucketArr.get(num).add(arr[i]);
}
//对每个桶进行排序
for(int i = 0; i \&lt; bucketArr.size(); i++){
Collections.sort(bucketArr.get(i));
}
}
</code></pre></div><h3 id="_21-1-4-基数排序算法"><a href="#_21-1-4-基数排序算法" class="header-anchor">#</a> 21.1.4. 基数排序算法</h3> <p>将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位
开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序
列。
public class radixSort {
inta[]={49,38,65,97,76,13,27,49,78,34,12,64,5,4,62,99,98,54,101,56,17,18,23,34,15,35,2
5,53,51};
public radixSort(){
sort(a);
for(inti=0;i&lt;a.length;i++){
System.out.println(a[i]);
}
}
public void sort(int[] array){
//首先确定排序的趟数;
int max=array[0];
for(inti=1;i&lt;array.length;i++){
if(array[i]&gt;max){</p> <p>max=array[i];
}
}
int time=0;
//判断位数;
while(max&gt;0){
max/=10;
time++;
}
//建立 10 个队列;
List&lt;ArrayList&gt; queue=newArrayList&lt;ArrayList&gt;();
for(int i=0;i&lt;10;i++){
ArrayList&lt;Integer&gt;queue1=new ArrayList&lt;Integer&gt;();
queue.add(queue1);
}
//进行time次分配和收集;
for(int i=0;i&lt;time;i++){
//分配数组元素;
for(intj=0;j&lt;array.length;j++){
//得到数字的第time+1位数;
int x=array[j]%(int)Math.pow(10,i+1)/(int)Math.pow(10, i);
ArrayList&lt;Integer&gt;queue2=queue.get(x);
queue2.add(array[j]);
queue.set(x, queue2);
}
int count=0;//元素计数器;
//收集队列元素;
for(int k=0;k&lt;10;k++){
while(queue.get(k).size()&gt;0){
ArrayList&lt;Integer&gt;queue3=queue.get(k);
array[count]=queue3.get(0);
queue3.remove(0);
count++;
}
}
}
}
}</p> <h3 id="_21-1-5-剪枝算法"><a href="#_21-1-5-剪枝算法" class="header-anchor">#</a> 21.1.5. 剪枝算法</h3> <p>在搜索算法中优化中，剪枝，就是通过某种判断，避免一些不必要的遍历过程，形象的说，就是
剪去了搜索树中的某些“枝条”，故称剪枝。应用剪枝优化的核心问题是设计剪枝判断方法，即
确定哪些枝条应当舍弃，哪些枝条应当保留的方法。</p> <h3 id="_21-1-6-回溯算法"><a href="#_21-1-6-回溯算法" class="header-anchor">#</a> 21.1.6. 回溯算法</h3> <p>回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现
已不满足求解条件时，就“回溯”返回，尝试别的路径。</p> <h3 id="_21-1-7-最短路径算法"><a href="#_21-1-7-最短路径算法" class="header-anchor">#</a> 21.1.7. 最短路径算法</h3> <p>从某顶点出发，沿图的边到达另一顶点所经过的路径中，各边上权值之和最小的一条路径叫做最
短路径。解决最短路的问题有以下算法，Dijkstra算法，Bellman-Ford算法，Floyd算法和SPFA
算法等。</p> <h3 id="_21-1-8-最大子数组算法"><a href="#_21-1-8-最大子数组算法" class="header-anchor">#</a> 21.1.8. 最大子数组算法</h3> <h3 id="_21-1-9-最长公共子序算法"><a href="#_21-1-9-最长公共子序算法" class="header-anchor">#</a> 21.1.9. 最长公共子序算法</h3> <h3 id="_21-1-10-最小生成树算法"><a href="#_21-1-10-最小生成树算法" class="header-anchor">#</a> 21.1.10. 最小生成树算法</h3> <p>现在假设有一个很实际的问题：我们要在n个城市中建立一个通信网络，则连通这n个城市需要
布置n- 1 一条通信线路，这个时候我们需要考虑如何在成本最低的情况下建立这个通信网？</p> <p>于是我们就可以引入连通图来解决我们遇到的问题，n个城市就是图上的n个顶点，然后，边表示
两个城市的通信线路，每条边上的权重就是我们搭建这条线路所需要的成本，所以现在我们有n个
顶点的连通网可以建立不同的生成树，每一颗生成树都可以作为一个通信网，当我们构造这个连
通网所花的成本最小时，搭建该连通网的生成树，就称为最小生成树。</p> <p>构造最小生成树有很多算法，但是他们都是利用了最小生成树的同一种性质：MST性质（假设
N=(V,{E})是一个连通网，U是顶点集V的一个非空子集，如果（u，v）是一条具有最小权值的边，
其中u属于U，v属于V-U，则必定存在一颗包含边（u，v）的最小生成树），下面就介绍两种使
用MST性质生成最小生成树的算法：普里姆算法和克鲁斯卡尔算法。</p> <h2 id="_22-数据结构"><a href="#_22-数据结构" class="header-anchor">#</a> 22. 数据结构</h2> <h3 id="_22-1-1-栈-stack"><a href="#_22-1-1-栈-stack" class="header-anchor">#</a> 22.1.1. 栈（ stack ）</h3> <p>栈（stack）是限制插入和删除只能在一个位置上进行的表，该位置是表的末端，叫做栈顶
（top）。它是后进先出（LIFO）的。对栈的基本操作只有push（进栈）和pop（出栈）两种，
前者相当于插入，后者相当于删除最后的元素。</p> <h3 id="_22-1-2-队列-queue"><a href="#_22-1-2-队列-queue" class="header-anchor">#</a> 22.1.2. 队列（ queue ）</h3> <p>队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的
后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为
队尾，进行删除操作的端称为队头。</p> <h3 id="_22-1-3-链表-link"><a href="#_22-1-3-链表-link" class="header-anchor">#</a> 22.1.3. 链表（ Link ）</h3> <p>链表是一种数据结构，和数组同级。比如，Java 中我们使用的ArrayList，其实现原理是数组。而
LinkedList的实现原理就是链表了。链表在进行循环遍历时效率不高，但是插入和删除时优势明显。</p> <h3 id="_22-1-4-散列表-hash-table"><a href="#_22-1-4-散列表-hash-table" class="header-anchor">#</a> 22.1.4. 散列表（ Hash Table ）</h3> <p>散列表（Hash table，也叫哈希表）是一种查找算法，与链表、树等算法不同的是，散列表算法
在查找时不需要进行一系列和关键字（关键字是数据元素中某个数据项的值，用以标识一个数据
元素）的比较操作。</p> <p>散列表算法希望能尽量做到不经过任何比较，通过一次存取就能得到所查找的数据元素，因而必
须要在数据元素的存储位置和它的关键字（可用key表示）之间建立一个确定的对应关系，使每个
关键字和散列表中一个唯一的存储位置相对应。因此在查找时，只要根据这个对应关系找到给定
关键字在散列表中的位置即可。这种对应关系被称为散列函数(可用h(key)表示)。</p> <p>用的构造散列函数的方法有：</p> <div class="language- extra-class"><pre class="language-text"><code>（ 1 ）直接定址法： 取关键字或关键字的某个线性函数值为散列地址。
即：h(key) = key 或 h(key) = a * key + b，其中a和b为常数。
</code></pre></div><p>（ 2 ）数字分析法</p> <p>（ 3 ）平方取值法： 取关键字平方后的中间几位为散列地址。</p> <p>（ 4 ）折叠法：将关键字分割成位数相同的几部分，然后取这几部分的叠加和作为散列地址。</p> <p>（ 5 ）除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址，
即：h(key) = key MOD p p ≤ m
（ 6 ）随机数法：选择一个随机函数，取关键字的随机函数值为它的散列地址，
即：h(key) = random(key)</p> <h3 id="_22-1-5-排序二叉树"><a href="#_22-1-5-排序二叉树" class="header-anchor">#</a> 22.1.5. 排序二叉树</h3> <p>首先如果普通二叉树每个节点满足：左子树所有节点值小于它的根节点值，且右子树所有节点值
大于它的根节点值，则这样的二叉树就是排序二叉树。</p> <h4 id="_22-1-5-1-插入操作"><a href="#_22-1-5-1-插入操作" class="header-anchor">#</a> 22.1.5.1. 插入操作</h4> <p>首先要从根节点开始往下找到自己要插入的位置（即新节点的父节点）；具体流程是：新节点与
当前节点比较，如果相同则表示已经存在且不能再重复插入；如果小于当前节点，则到左子树中</p> <p>寻找，如果左子树为空则当前节点为要找的父节点，新节点插入到当前节点的左子树即可；如果
大于当前节点，则到右子树中寻找，如果右子树为空则当前节点为要找的父节点，新节点插入到
当前节点的右子树即可。</p> <h4 id="_22-1-5-2-删除操作"><a href="#_22-1-5-2-删除操作" class="header-anchor">#</a> 22.1.5.2. 删除操作</h4> <p>删除操作主要分为三种情况，即要删除的节点无子节点，要删除的节点只有一个子节点，要删除
的节点有两个子节点。</p> <ol><li>对于要删除的节点无子节点可以直接删除，即让其父节点将该子节点置空即可。</li> <li>对于要删除的节点只有一个子节点，则替换要删除的节点为其子节点。</li> <li>对于要删除的节点有两个子节点，则首先找该节点的替换节点（即右子树中最小的节点），
接着替换要删除的节点为替换节点，然后删除替换节点。</li></ol> <h4 id="_22-1-5-3-查询操作"><a href="#_22-1-5-3-查询操作" class="header-anchor">#</a> 22.1.5.3. 查询操作</h4> <div class="language- extra-class"><pre class="language-text"><code>查找操作的主要流程为：先和根节点比较，如果相同就返回，如果小于根节点则到左子树中
递归查找，如果大于根节点则到右子树中递归查找。因此在排序二叉树中可以很容易获取最
大（最右最深子节点）和最小（最左最深子节点）值。
</code></pre></div><h3 id="_22-1-6-红黑树"><a href="#_22-1-6-红黑树" class="header-anchor">#</a> 22.1.6. 红黑树</h3> <p>R-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每
个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。</p> <h4 id="_22-1-6-1-红黑树的特性"><a href="#_22-1-6-1-红黑树的特性" class="header-anchor">#</a> 22.1.6.1. 红黑树的特性</h4> <p>（ 1 ）每个节点或者是黑色，或者是红色。</p> <p>（ 2 ）根节点是黑色。</p> <p>（ 3 ）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]</p> <p>（ 4 ）如果一个节点是红色的，则它的子节点必须是黑色的。</p> <p>（ 5 ）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</p> <h4 id="_22-1-6-1-左旋"><a href="#_22-1-6-1-左旋" class="header-anchor">#</a> 22.1.6.1. 左旋</h4> <p>对x进行左旋，意味着，将“x的右孩子”设为“x的父亲节点”；即，将 x变成了一个左节点(x
成了为z的左孩子)！。 因此，左旋中的“左”，意味着“被旋转的节点将变成一个左节点”。</p> <div class="language- extra-class"><pre class="language-text"><code>LEFT-ROTATE(T, x)
y ← right[x] // 前提：这里假设x的右孩子为y。下面开始正式操作
right[x] ← left[y] // 将 “y的左孩子” 设为 “x的右孩子”，即 将β设为x的右孩子
p[left[y]] ← x // 将 “x” 设为 “y的左孩子的父亲”，即 将β的父亲设为x
p[y] ← p[x] // 将 “x的父亲” 设为 “y的父亲”
if p[x] = nil[T]
then root[T] ← y // 情况 1 ：如果 “x的父亲” 是空节点，则将y设为根节点
else if x = left[p[x]]
then left[p[x]] ← y // 情况 2 ：如果 x是它父节点的左孩子，则将y设为“x的父节点
的左孩子”
else right[p[x]] ← y // 情况 3 ：(x是它父节点的右孩子) 将y设为“x的父节点的右孩
子”
left[y] ← x // 将 “x” 设为 “y的左孩子”
p[x] ← y // 将 “x的父节点” 设为 “y”
</code></pre></div><h4 id="_22-1-6-1-右旋"><a href="#_22-1-6-1-右旋" class="header-anchor">#</a> 22.1.6.1. 右旋</h4> <p>对x进行右旋，意味着，将“x的左孩子”设为“x的父亲节点”；即，将 x变成了一个右节点(x
成了为y的右孩子)！ 因此，右旋中的“右”，意味着“被旋转的节点将变成一个右节点”。</p> <div class="language- extra-class"><pre class="language-text"><code>RIGHT-ROTATE(T, y)
x ← left[y] // 前提：这里假设y的左孩子为x。下面开始正式操作
left[y] ← right[x] // 将 “x的右孩子” 设为 “y的左孩子”，即 将β设为y的左孩子
p[right[x]] ← y // 将 “y” 设为 “x的右孩子的父亲”，即 将β的父亲设为y
p[x] ← p[y] // 将 “y的父亲” 设为 “x的父亲”
if p[y] = nil[T]
then root[T] ← x // 情况 1 ：如果 “y的父亲” 是空节点，则将x设为根节点
else if y = right[p[y]]
then right[p[y]] ← x // 情况 2 ：如果 y是它父节点的右孩子，则将x设为“y的父节
点的左孩子”
else left[p[y]] ← x // 情况 3 ：(y是它父节点的左孩子) 将x设为“y的父节点的左孩
子”
right[x] ← y // 将 “y” 设为 “x的右孩子”
p[y] ← x // 将 “y的父节点” 设为 “x”
</code></pre></div><h4 id="_22-1-6-1-添加"><a href="#_22-1-6-1-添加" class="header-anchor">#</a> 22.1.6.1. 添加</h4> <p>第一步: 将红黑树当作一颗二叉查找树，将节点插入。</p> <p>第二步：将插入的节点着色为&quot;红色&quot;。</p> <p>根据被插入节点的父节点的情况，可以将&quot;当节点z被着色为红色节点，并插入二叉树&quot;划分为三
种情况来处理。</p> <p>① 情况说明：被插入的节点是根节点。</p> <p>处理方法：直接把此节点涂为黑色。</p> <p>② 情况说明：被插入的节点的父节点是黑色。</p> <p>处理方法：什么也不需要做。节点被插入后，仍然是红黑树。</p> <p>③ 情况说明：被插入的节点的父节点是红色。这种情况下，被插入节点是一定存在非空祖父节点
的；进一步的讲，被插入节点也一定存在叔叔节点(即使叔叔节点为空，我们也视之为存在，空节
点本身就是黑色节点)。理解这点之后，我们依据&quot;叔叔节点的情况&quot;，将这种情况进一步划分为 3
种情况(Case)。</p> <p>第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。</p> <h4 id="_22-1-6-2-删除"><a href="#_22-1-6-2-删除" class="header-anchor">#</a> 22.1.6.2. 删除</h4> <p>第一步：将红黑树当作一颗二叉查找树，将节点删除。</p> <p>这和&quot;删除常规二叉查找树中删除节点的方法是一样的&quot;。分 3 种情况：</p> <p>① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。</p> <p>② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。</p> <p>③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给
“该节点的内容”；之后，删除“它的后继节点”。</p> <p>第二步：通过&quot;旋转和重新着色&quot;等一系列来修正该树，使之重新成为一棵红黑树。</p> <p>因为&quot;第一步&quot;中删除节点之后，可能会违背红黑树的特性。所以需要通过&quot;旋转和重新着色&quot;来修正
该树，使之重新成为一棵红黑树。</p> <p>选择重着色 3 种情况。</p> <p>① 情况说明：x是“红+黑”节点。</p> <p>处理方法：直接把x设为黑色，结束。此时红黑树性质全部恢复。</p> <p>② 情况说明：x是“黑+黑”节点，且x是根。</p> <p>处理方法：什么都不做，结束。此时红黑树性质全部恢复。</p> <p>③ 情况说明：x是“黑+黑”节点，且x不是根。</p> <p>处理方法：这种情况又可以划分为 4 种子情况。这 4 种子情况如下表所示：</p> <p>参考：https://www.jianshu.com/p/038585421b73</p> <p>代码实现：https://www.cnblogs.com/skywang12345/p/3624343.html</p> <h3 id="_22-1-7-b-tree"><a href="#_22-1-7-b-tree" class="header-anchor">#</a> 22.1.7. B-TREE</h3> <p>B-tree又叫平衡多路查找树。一棵m阶的B-tree (m叉树)的特性如下（其中ceil(x)是一个取上限
的函数）：</p> <ol><li>树中每个结点至多有m个孩子；</li> <li>除根结点和叶子结点外，其它每个结点至少有有ceil(m / 2)个孩子；</li> <li>若根结点不是叶子结点，则至少有 2 个孩子（特殊情况：没有孩子的根结点，即根结点为叶子
结点，整棵树只有一个根节点）；</li> <li>所有叶子结点都出现在同一层，叶子结点不包含任何关键字信息(可以看做是外部结点或查询
失败的结点，实际上这些结点不存在，指向这些结点的指针都为null)；</li> <li>每个非终端结点中包含有n个关键字信息： (n，P0，K1，P1，K2，P2，......，Kn，Pn)。其
中：</li></ol> <p>a) Ki (i=1...n)为关键字，且关键字按顺序排序K(i-1)&lt; Ki。</p> <p>b) Pi为指向子树根的接点，且指针P(i-1)指向子树种所有结点的关键字均小于Ki，但都大于K(i-
1)。</p> <p>c) 关键字的个数n必须满足： ceil(m / 2)-1 &lt;= n &lt;= m- 1 。</p> <p>一棵m阶的B+tree和m阶的B-tree的差异在于：</p> <p>1.有n棵子树的结点中含有n个关键字； (B-tree是n棵子树有n- 1 个关键字)</p> <p>2.所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本
身依关键字的大小自小而大的顺序链接。 (B-tree的叶子节点并没有包括全部需要查找的信息)</p> <p>3.所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。
(B-tree的非终节点也包含需要查找的有效信息)</p> <p>参考：https://www.jianshu.com/p/1ed61b4cca12</p> <h3 id="_22-1-8-位图"><a href="#_22-1-8-位图" class="header-anchor">#</a> 22.1.8. 位图</h3> <p>位图的原理就是用一个bit来标识一个数字是否存在，采用一个bit来存储一个数据，所以这样可
以大大的节省空间。 bitmap是很常用的数据结构，比如用于Bloom Filter中；用于无重复整数的
排序等等。bitmap通常基于数组来实现，数组中每个元素可以看成是一系列二进制数，所有元素
组成更大的二进制集合。</p> <p>https://www.cnblogs.com/polly333/p/4760275.html</p> <h2 id="_23-加密算法"><a href="#_23-加密算法" class="header-anchor">#</a> 23. 加密算法</h2> <h3 id="_23-1-1-aes"><a href="#_23-1-1-aes" class="header-anchor">#</a> 23.1.1. AES</h3> <p>高级加密标准(AES,Advanced Encryption Standard)为最常见的对称加密算法(微信小程序加密传
输就是用这个加密算法的)。对称加密算法也就是加密和解密用相同的密钥，具体的加密流程如下
图：</p> <h3 id="_23-1-2-rsa"><a href="#_23-1-2-rsa" class="header-anchor">#</a> 23.1.2. RSA</h3> <p>RSA加密算法是一种典型的非对称加密算法，它基于大数的因式分解数学难题，它也是应用最广
泛的非对称加密算法。</p> <p>非对称加密是通过两个密钥（公钥-私钥）来实现对数据的加密和解密的。公钥用于加密，私钥用
于解密。</p> <h3 id="_23-1-3-crc"><a href="#_23-1-3-crc" class="header-anchor">#</a> 23.1.3. CRC............................................................................................................................................</h3> <p>循环冗余校验(Cyclic Redundancy Check, CRC)是一种根据网络数据包或电脑文件等数据产生简
短固定位数校验码的一种散列函数，主要用来检测或校验数据传输或者保存后可能出现的错误。
它是利用除法及余数的原理来作错误侦测的。</p> <h3 id="_23-1-4-md5"><a href="#_23-1-4-md5" class="header-anchor">#</a> 23.1.4. MD5</h3> <p>MD5 常常作为文件的签名出现，我们在下载文件的时候，常常会看到文件页面上附带一个扩展
名为.MD5的文本或者一行字符，这行字符就是就是把整个文件当作原数据通过MD5计算后的值，
我们下载文件后，可以用检查文件MD5信息的软件对下载到的文件在进行一次计算。两次结果对
比就可以确保下载到文件的准确性。 另一种常见用途就是网站敏感信息加密，比如用户名密码，
支付签名等等。随着 https技术的普及，现在的网站广泛采用前台明文传输到后台，MD5加密
（使用偏移量）的方式保护敏感数据保护站点和数据安全。</p> <h2 id="_24-分布式缓存"><a href="#_24-分布式缓存" class="header-anchor">#</a> 24. 分布式缓存</h2> <h3 id="_24-1-1-缓存雪崩"><a href="#_24-1-1-缓存雪崩" class="header-anchor">#</a> 24.1.1. 缓存雪崩</h3> <p>缓存雪崩我们可以简单的理解为：由于原有缓存失效，新缓存未到期间所有原本应该访问缓存的请求都
去查询数据库了，而对数据库CPU 和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列
连锁反应，造成整个系统崩溃。一般有三种处理办法：</p> <ol><li>一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。</li> <li>给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓
存。</li> <li>为key设置不同的缓存失效时间。</li></ol> <h3 id="_24-1-2-缓存穿透"><a href="#_24-1-2-缓存穿透" class="header-anchor">#</a> 24.1.2. 缓存穿透</h3> <p>缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在
缓存中找不到，每次都要去数据库再查询一遍，然后返回空（相当于进行了两次无用的查询）。这样请
求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题。</p> <p>有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈
希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存
储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空（不管是数据不
存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。
通过这个直接设置的默认值存放到缓存，这样第二次到缓冲中获取就有值了，而不会继续访问数据库。</p> <h3 id="_24-1-3-缓存预热"><a href="#_24-1-3-缓存预热" class="header-anchor">#</a> 24.1.3. 缓存预热</h3> <p>缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，
先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！</p> <h3 id="_24-1-4-缓存更新"><a href="#_24-1-4-缓存更新" class="header-anchor">#</a> 24.1.4. 缓存更新</h3> <p>缓存更新除了缓存服务器自带的缓存失效策略之外（Redis默认的有 6 中策略可供选择），我们还可以
根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：</p> <p>（ 1 ）定时去清理过期的缓存；</p> <p>（ 2 ）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数
据并更新缓存。</p> <h3 id="_24-1-5-缓存降级"><a href="#_24-1-5-缓存降级" class="header-anchor">#</a> 24.1.5. 缓存降级</h3> <p>当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然
需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开
关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的
（如加入购物车、结算）。</p> <h2 id="_25-hadoop"><a href="#_25-hadoop" class="header-anchor">#</a> 25. HADOOP</h2> <h3 id="_25-1-1-概念"><a href="#_25-1-1-概念" class="header-anchor">#</a> 25.1.1. 概念</h3> <p>就是一个大数据解决方案。它提供了一套分布式系统基础架构。 核心内容包含hdfs 和
mapreduce。hadoop2.0以后引入yarn.</p> <p>hdfs是提供数据存储的，mapreduce是方便数据计算的。</p> <ol><li>hdfs 又对应namenode 和 datanode. namenode 负责保存元数据的基本信息，
datanode直接存放数据本身；</li> <li>mapreduce对应jobtracker和tasktracker. jobtracker负责分发任务，tasktracker负
责执行具体任务；</li> <li>对应到master/slave架构，namenode和jobtracker就应该对应到master, datanode
和tasktracker就应该对应到slave.</li></ol> <h3 id="_25-1-2-hdfs"><a href="#_25-1-2-hdfs" class="header-anchor">#</a> 25.1.2. HDFS</h3> <h4 id="_25-1-2-1-client"><a href="#_25-1-2-1-client" class="header-anchor">#</a> 25.1.2.1. Client</h4> <p>Client（代表用 户） 通过与 NameNode 和 DataNode 交互访问 HDFS 中 的文件。 Client提供
了一个类似 POSIX 的文件系统接口供用户调用。</p> <h4 id="_25-1-2-2-namenode"><a href="#_25-1-2-2-namenode" class="header-anchor">#</a> 25.1.2.2. NameNode</h4> <p>整个Hadoop 集群中只有一个 NameNode。 它是整个系统的“ 总管”， 负责管理 HDFS的目
录树和相关的文件元数据信息。 这些信息是以“ fsimage”（ HDFS 元数据镜像文件）和
“ editlog”（HDFS 文件改动日志）两个文件形式存放在本地磁盘，当 HDFS 重启时重新构造出
来的。此外， NameNode 还负责监控各个 DataNode 的健康状态， 一旦发现某个DataNode 宕
掉，则将该 DataNode 移出 HDFS 并重新备份其上面的数据。</p> <h4 id="_25-1-2-3-secondary-namenode"><a href="#_25-1-2-3-secondary-namenode" class="header-anchor">#</a> 25.1.2.3. Secondary NameNode</h4> <p>Secondary NameNode 最重要的任务并不是为 NameNode 元数据进行热备份， 而是定期合并
fsimage 和 edits 日志， 并传输给 NameNode。 这里需要注意的是，为了减小 NameNode压
力， NameNode 自己并不会合并fsimage 和 edits， 并将文件存储到磁盘上， 而是交由
Secondary NameNode 完成。</p> <h4 id="_25-1-2-4-datanode"><a href="#_25-1-2-4-datanode" class="header-anchor">#</a> 25.1.2.4. DataNode.........................................................................................................................................</h4> <p>一般而言， 每个 Slave 节点上安装一个 DataNode， 它负责实际的数据存储， 并将数据信息定期
汇报给 NameNode。 DataNode 以固定大小的 block 为基本单位组织文件内容， 默认情况下
block 大小为 64MB。 当用户上传一个大的文件到 HDFS 上时， 该文件会被切分成若干个 block，
分别存储到不同的 DataNode ； 同时，为了保证数据可靠， 会将同一个block以流水线方式写到</p> <p>若干个（默认是 3 ，该参数可配置）不同的 DataNode 上。 这种文件切割后存储的过程是对用户
透明的。</p> <h3 id="_25-1-3-mapreduce"><a href="#_25-1-3-mapreduce" class="header-anchor">#</a> 25.1.3. MapReduce</h3> <p>同 HDFS 一样，Hadoop MapReduce 也采用了 Master/Slave（M/S）架构，具体如图所示。它
主要由以下几个组件组成：Client、JobTracker、TaskTracker 和 Task。 下面分别对这几个组件
进行介绍。</p> <h4 id="_25-1-3-1-client"><a href="#_25-1-3-1-client" class="header-anchor">#</a> 25.1.3.1. Client</h4> <p>用户编写的 MapReduce 程序通过 Client 提交到 JobTracker 端； 同时， 用户可通过 Client 提
供的一些接口查看作业运行状态。 在 Hadoop 内部用“作业”（Job） 表示 MapReduce 程序。
一个MapReduce 程序可对应若干个作业，而每个作业会被分解成若干个 Map/Reduce 任务
（Task）。</p> <h4 id="_25-1-3-2-jobtracker"><a href="#_25-1-3-2-jobtracker" class="header-anchor">#</a> 25.1.3.2. JobTracker</h4> <p>JobTracker 主要负责资源监控和作业调度。JobTracker监控所有TaskTracker与作业的健康状况，
一旦发现失败情况后，其会将相应的任务转移到其他节点；同时JobTracker 会跟踪任务的执行进
度、资源使用量等信息，并将这些信息告诉任务调度器，而调度器会在资源出现空闲时，选择合
适的任务使用这些资源。在 Hadoop 中，任务调度器是一个可插拔的模块，用户可以根据自己的
需要设计相应的调度器。</p> <h4 id="_25-1-3-3-tasktracker"><a href="#_25-1-3-3-tasktracker" class="header-anchor">#</a> 25.1.3.3. TaskTracker</h4> <p>TaskTracker 会周期性地通过 Heartbeat 将本节点上资源的使用情况和任务的运行进度汇报给
JobTracker， 同时接收 JobTracker 发送过来的命令并执行相应的操作（如启动新任务、 杀死任
务等）。TaskTracker 使用“slot” 等量划分本节点上的资源量。“slot” 代表计算资源（CPU、
内存等）。一个 Task 获取到一个slot 后才有机会运行，而Hadoop 调度器的作用就是将各个
TaskTracker 上的空闲 slot 分配给 Task 使用。 slot 分为 Map slot 和 Reduce slot 两种，分别供
MapTask 和 Reduce Task 使用。 TaskTracker 通过 slot 数目（可配置参数）限定 Task 的并发
度。</p> <h4 id="_25-1-3-4-task"><a href="#_25-1-3-4-task" class="header-anchor">#</a> 25.1.3.4. Task</h4> <p>Task 分为 Map Task 和 Reduce Task 两种， 均由 TaskTracker 启动。 HDFS 以固定大小的 block
为基本单位存储数据， 而对于 MapReduce 而言， 其处理单位是 split。split 与 block 的对应关
系如图所示。 split 是一个逻辑概念， 它只包含一些元数据信息， 比如数据起始位置、数据长度、
数据所在节点等。它的划分方法完全由用户自己决定。 但需要注意的是，split 的多少决定了 Map
Task 的数目 ，因为每个 split 会交由一个 Map Task 处理。</p> <p>Map Task 执行过程如图所示。 由该图可知，Map Task 先将对应的 split 迭代解析成一个个
key/value 对，依次调用用户自定义的 map() 函数进行处理，最终将临时结果存放到本地磁盘上，
其中临时数据被分成若干个 partition，每个 partition 将被一个Reduce Task 处理。</p> <h4 id="_25-1-3-5-reduce-task-执行过程"><a href="#_25-1-3-5-reduce-task-执行过程" class="header-anchor">#</a> 25.1.3.5. Reduce Task 执行过程</h4> <p>该过程分为三个阶段</p> <ol><li>从远程节点上读取MapTask中间结果（称为“Shuffle 阶段”）；</li> <li>按照key对key/value对进行排序（称为“ Sort 阶段”）；</li> <li>依次读取&lt;key, value list&gt;，调用用户自定义的 reduce() 函数处理，并将最终结果存到 HDFS
上（称为“ Reduce 阶段”）。</li></ol> <h3 id="_25-1-4-hadoop-mapreduce-作业的生命周期"><a href="#_25-1-4-hadoop-mapreduce-作业的生命周期" class="header-anchor">#</a> 25.1.4. Hadoop MapReduce 作业的生命周期</h3> <h5 id="_1-作业提交与初始化"><a href="#_1-作业提交与初始化" class="header-anchor">#</a> 1.作业提交与初始化...........................................................................................................................................</h5> <ol><li>用户提交作业后， 首先由 JobClient 实例将作业相关信息， 比如将程序 jar 包、作业配置文
件、 分片元信息文件等上传到分布式文件系统（ 一般为HDFS）上，其中，分片元信息文件
记录了每个输入分片的逻辑位置信息。 然后 JobClient 通过 RPC 通知 JobTracker。
JobTracker 收到新作业提交请求后， 由 作业调度模块对作业进行初始化：为作业创建一个
JobInProgress 对象以跟踪作业运行状况， 而 JobInProgress 则会为每个Task 创建一个
TaskInProgress 对象以跟踪每个任务的运行状态， TaskInProgress 可能需要管理多个
“ Task 运行尝试”（ 称为“ Task Attempt”）。</li></ol> <h5 id="_2-任务调度与监控。"><a href="#_2-任务调度与监控。" class="header-anchor">#</a> 2.任务调度与监控。...........................................................................................................................................</h5> <ol start="2"><li>前面提到，任务调度和监控的功能均由 JobTracker 完成。TaskTracker 周期性地通过
Heartbeat 向 JobTracker 汇报本节点的资源使用 情况， 一旦出 现空闲资源， JobTracker
会按照一定的策略选择一个合适的任务使用该空闲资源， 这由任务调度器完成。 任务调度器
是一个可插拔的独立模块， 且为双层架构， 即首先选择作业， 然后从该作业中选择任务， 其
中，选择任务时需要重点考虑数据本地性。 此外，JobTracker 跟踪作业的整个运行过程，并
为作业的成功运行提供全方位的保障。 首先， 当 TaskTracker 或者Task 失败时， 转移计算
任务 ； 其次， 当某个 Task 执行进度远落后于同一作业的其他 Task 时，为之启动一个相同
Task， 并选取计算快的 Task 结果作为最终结果。</li></ol> <h5 id="_3-任务运行环境准备"><a href="#_3-任务运行环境准备" class="header-anchor">#</a> 3.任务运行环境准备...........................................................................................................................................</h5> <ol start="3"><li>运行环境准备包括 JVM 启动和资源隔 离， 均由TaskTracker 实现。 TaskTracker 为每个
Task 启动一个独立的 JVM 以避免不同 Task 在运行过程中相互影响 ； 同时，TaskTracker 使
用了操作系统进程实现资源隔离以防止 Task 滥用资源。</li></ol> <h5 id="_4-任务执行"><a href="#_4-任务执行" class="header-anchor">#</a> 4.任务执行</h5> <ol start="4"><li>TaskTracker 为 Task 准备好运行环境后， 便会启动 Task。 在运行过程中， 每个 Task 的最
新进度首先由 Task 通过 RPC 汇报给 TaskTracker， 再由 TaskTracker汇报给 JobTracker。</li></ol> <h5 id="_5-作业完成。"><a href="#_5-作业完成。" class="header-anchor">#</a> 5.作业完成。</h5> <ol start="5"><li>待所有 Task 执行完毕后， 整个作业执行成功。</li></ol> <h2 id="_26-spark"><a href="#_26-spark" class="header-anchor">#</a> 26. SPARK</h2> <h3 id="_26-1-1-概念"><a href="#_26-1-1-概念" class="header-anchor">#</a> 26.1.1. 概念</h3> <p>Spark提供了一个全面、统一的框架用于管理各种有着不同性质（文本数据、图表数据等）的数据
集和数据源（批量数据或实时的流数据）的大数据处理的需求。</p> <h3 id="_26-1-2-核心架构"><a href="#_26-1-2-核心架构" class="header-anchor">#</a> 26.1.2. 核心架构</h3> <h5 id="spark-core"><a href="#spark-core" class="header-anchor">#</a> Spark Core</h5> <p>包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都
是构建在RDD和Spark Core之上的</p> <h5 id="spark-sql"><a href="#spark-sql" class="header-anchor">#</a> Spark SQL</h5> <p>提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个
数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。</p> <h5 id="spark-streaming"><a href="#spark-streaming" class="header-anchor">#</a> Spark Streaming</h5> <p>对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据</p> <h5 id="mllib"><a href="#mllib" class="header-anchor">#</a> Mllib</h5> <p>一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，
比如分类、回归等需要对大量数据集进行迭代的操作。</p> <h5 id="graphx"><a href="#graphx" class="header-anchor">#</a> GraphX</h5> <p>控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、
创建子图、访问路径上所有顶点的操作</p> <h3 id="_26-1-3-核心组件"><a href="#_26-1-3-核心组件" class="header-anchor">#</a> 26.1.3. 核心组件</h3> <h5 id="cluster-manager-制整个集群-监控worker"><a href="#cluster-manager-制整个集群-监控worker" class="header-anchor">#</a> Cluster Manager-制整个集群，监控worker</h5> <p>在standalone模式中即为Master主节点，控制整个集群，监控worker。在YARN模式中为资
源管理器</p> <h5 id="worker节点-负责控制计算节点"><a href="#worker节点-负责控制计算节点" class="header-anchor">#</a> Worker节点-负责控制计算节点</h5> <p>从节点，负责控制计算节点，启动Executor或者Driver。</p> <h5 id="driver-运行application-的main-函数"><a href="#driver-运行application-的main-函数" class="header-anchor">#</a> Driver： 运行Application 的main()函数.........................................................................................................</h5> <h5 id="executor-执行器-是为某个application运行在worker-node上的一个进程"><a href="#executor-执行器-是为某个application运行在worker-node上的一个进程" class="header-anchor">#</a> Executor：执行器，是为某个Application运行在worker node上的一个进程</h5> <h3 id="_26-1-4-spark-编程模型"><a href="#_26-1-4-spark-编程模型" class="header-anchor">#</a> 26.1.4. SPARK 编程模型</h3> <p>Spark 应用程序从编写到提交、执行、输出的整个过程如图所示，图中描述的步骤如下：</p> <ol><li>用户使用SparkContext提供的API（常用的有textFile、sequenceFile、runJob、stop等）
编写Driver application程序。此外SQLContext、HiveContext及StreamingContext对
SparkContext进行封装，并提供了SQL、Hive及流式计算相关的API。</li> <li>使用SparkContext提交的用户应用程序，首先会使用BlockManager和BroadcastManager
将任务的Hadoop配置进行广播。然后由DAGScheduler将任务转换为RDD并组织成DAG，
DAG还将被划分为不同的Stage。最后由TaskScheduler借助ActorSystem将任务提交给
集群管理器（Cluster Manager）。</li> <li>集群管理器（ClusterManager）给任务分配资源，即将具体任务分配到Worker上，Worker
创建Executor来处理任务的运行。Standalone、YARN、Mesos、EC2等都可以作为Spark
的集群管理器。</li></ol> <h3 id="_26-1-5-spark-计算模型"><a href="#_26-1-5-spark-计算模型" class="header-anchor">#</a> 26.1.5. SPARK 计算模型</h3> <p>RDD可以看做是对各种数据计算模型的统一抽象，Spark的计算过程主要是RDD的迭代计算过
程。RDD的迭代计算过程非常类似于管道。分区数量取决于partition数量的设定，每个分区的数
据只会在一个Task中计算。所有分区可以在多个机器节点的Executor上并行执行。</p> <h3 id="_26-1-6-spark-运行流程"><a href="#_26-1-6-spark-运行流程" class="header-anchor">#</a> 26.1.6. SPARK 运行流程</h3> <h5 id="_1-构建spark-application的运行环境-启动sparkcontext"><a href="#_1-构建spark-application的运行环境-启动sparkcontext" class="header-anchor">#</a> 1. 构建Spark Application的运行环境，启动SparkContext</h5> <p><strong><em>2. SparkContext</em></strong> 向资源管理器（可以是 <strong><em>Standalone</em></strong> ， <strong><em>Mesos</em></strong> ， <strong><em>Yarn</em></strong> ）申请运行 <strong><em>Executor</em></strong> 资源，
并启动 <strong><em>StandaloneExecutorbackend</em></strong> ，</p> <h5 id="_3-executor向sparkcontext申请task"><a href="#_3-executor向sparkcontext申请task" class="header-anchor">#</a> 3. Executor向SparkContext申请Task</h5> <h5 id="_4-sparkcontext将应用程序分发给executor"><a href="#_4-sparkcontext将应用程序分发给executor" class="header-anchor">#</a> 4. SparkContext将应用程序分发给Executor</h5> <p><strong><em>5. SparkContext</em></strong> 构建成 <strong><em>DAG</em></strong> 图，将 <strong><em>DAG</em></strong> 图分解成 <strong><em>Stage</em></strong> 、将 <strong><em>Taskset</em></strong> 发送给 <strong><em>Task Scheduler</em></strong> ，
最后由 <strong><em>Task Scheduler</em></strong> 将 <strong><em>Task</em></strong> 发送给 <strong><em>Executor</em></strong> 运行</p> <h5 id="_6-task在executor上运行-运行完释放所有资源"><a href="#_6-task在executor上运行-运行完释放所有资源" class="header-anchor">#</a> 6. Task在Executor上运行，运行完释放所有资源...................................................................................</h5> <h3 id="_26-1-7-spark-rdd-流程"><a href="#_26-1-7-spark-rdd-流程" class="header-anchor">#</a> 26.1.7. SPARK RDD 流程</h3> <ol><li>创建RDD对象</li> <li>DAGScheduler模块介入运算，计算RDD之间的依赖关系，RDD之间的依赖关系就形成了
DAG</li> <li>每一个Job被分为多个Stage。划分Stage的一个主要依据是当前计算因子的输入是否是确
定的，如果是则将其分在同一个Stage，避免多个Stage之间的消息传递开销</li></ol> <h3 id="_26-1-8-spark-rdd"><a href="#_26-1-8-spark-rdd" class="header-anchor">#</a> 26.1.8. SPARK RDD</h3> <h4 id="_1-rdd的创建方式"><a href="#_1-rdd的创建方式" class="header-anchor">#</a> （ 1 ）RDD的创建方式...........................................................................................................................................</h4> <p>1 ）从Hadoop文件系统（或与Hadoop兼容的其他持久化存储系统，如Hive、Cassandra、
HBase）输入（例如HDFS）创建。</p> <p>2 ）从父RDD转换得到新RDD。</p> <p>3 ）通过parallelize或makeRDD将单机数据创建为分布式RDD。</p> <h4 id="_2-rdd的两种操作算子-转换-transformation-与行动-action"><a href="#_2-rdd的两种操作算子-转换-transformation-与行动-action" class="header-anchor">#</a> （ 2 ）RDD的两种操作算子（转换（Transformation）与行动（Action））</h4> <p>对于RDD可以有两种操作算子：转换（Transformation）与行动（Action）。</p> <div class="language- extra-class"><pre class="language-text"><code>1 ） 转换（Transformation）：Transformation操作是延迟计算的，也就是说从一个RDD转
换生成另一个RDD的转换操作不是马上执行，需要等到有Action操作的时候才会真正触
发运算。
</code></pre></div><p>2 ）行动（Action）：Action算子会触发Spark提交作业（Job），并将数据输出Spark系统。</p> <h2 id="_27-storm"><a href="#_27-storm" class="header-anchor">#</a> 27. STORM</h2> <h3 id="_27-1-1-概念"><a href="#_27-1-1-概念" class="header-anchor">#</a> 27.1.1. 概念</h3> <p>Storm是一个免费并开源的分布式实时计算系统。利用Storm可以很容易做到可靠地处理无限的
数据流，像Hadoop批量处理大数据一样，Storm可以实时处理数据。</p> <h3 id="_27-1-1-集群架构"><a href="#_27-1-1-集群架构" class="header-anchor">#</a> 27.1.1. 集群架构</h3> <h4 id="_27-1-1-1-nimbus-master-代码分发给supervisor"><a href="#_27-1-1-1-nimbus-master-代码分发给supervisor" class="header-anchor">#</a> 27.1.1.1. Nimbus（master-代码分发给Supervisor）</h4> <p>Storm集群的Master节点，负责分发用户代码，指派给具体的Supervisor节点上的Worker节
点，去运行Topology对应的组件（Spout/Bolt）的Task。</p> <h4 id="_27-1-1-2-supervisor-slave-管理worker进程的启动和终止"><a href="#_27-1-1-2-supervisor-slave-管理worker进程的启动和终止" class="header-anchor">#</a> 27.1.1.2. Supervisor（slave-管理Worker进程的启动和终止）</h4> <p>Storm集群的从节点，负责管理运行在Supervisor节点上的每一个Worker进程的启动和终止。
通过Storm的配置文件中的supervisor.slots.ports配置项，可以指定在一个Supervisor上最大
允许多少个Slot，每个Slot通过端口号来唯一标识，一个端口号对应一个Worker进程（如果该
Worker进程被启动）。</p> <h4 id="_27-1-1-3-worker-具体处理组件逻辑的进程"><a href="#_27-1-1-3-worker-具体处理组件逻辑的进程" class="header-anchor">#</a> 27.1.1.3. Worker（具体处理组件逻辑的进程）</h4> <p>运行具体处理组件逻辑的进程。Worker运行的任务类型只有两种，一种是Spout任务，一种是
Bolt任务。</p> <h4 id="_27-1-1-4-task"><a href="#_27-1-1-4-task" class="header-anchor">#</a> 27.1.1.4. Task</h4> <p>worker中每一个spout/bolt的线程称为一个task. 在storm0.8之后，task不再与物理线程对应，
不同spout/bolt的task可能会共享一个物理线程，该线程称为executor。</p> <h4 id="_27-1-1-5-zookeeper"><a href="#_27-1-1-5-zookeeper" class="header-anchor">#</a> 27.1.1.5. ZooKeeper</h4> <p>用来协调Nimbus 和Supervisor，如果 Supervisor因故障出现问题而无法运行 Topology，
Nimbus会第一时间感知到，并重新分配Topology到其它可用的Supervisor上运行</p> <h3 id="_27-1-2-编程模型-spout-tuple-bolt"><a href="#_27-1-2-编程模型-spout-tuple-bolt" class="header-anchor">#</a> 27.1.2. 编程模型（spout-&gt;tuple-&gt;bolt）</h3> <p>strom在运行中可分为spout与bolt两个组件，其中，数据源从spout开始，数据以tuple的方
式发送到bolt，多个bolt可以串连起来，一个bolt也可以接入多个spot/bolt.运行时原理如下图：</p> <h4 id="_27-1-2-1-topology"><a href="#_27-1-2-1-topology" class="header-anchor">#</a> 27.1.2.1. Topology</h4> <p>Storm中运行的一个实时应用程序的名称。将 Spout、 Bolt整合起来的拓扑图。定义了 Spout和
Bolt的结合关系、并发数量、配置等等。</p> <h4 id="_27-1-2-2-spout"><a href="#_27-1-2-2-spout" class="header-anchor">#</a> 27.1.2.2. Spout..................................................................................................................................................</h4> <p>在一个topology中获取源数据流的组件。通常情况下spout会从外部数据源中读取数据，然后转
换为topology内部的源数据。</p> <h4 id="_27-1-2-3-bolt"><a href="#_27-1-2-3-bolt" class="header-anchor">#</a> 27.1.2.3. Bolt</h4> <p>接受数据然后执行处理的组件,用户可以在其中执行自己想要的操作。</p> <h4 id="_27-1-2-4-tuple"><a href="#_27-1-2-4-tuple" class="header-anchor">#</a> 27.1.2.4. Tuple</h4> <p>一次消息传递的基本单元，理解为一组消息就是一个Tuple。</p> <h4 id="_27-1-2-5-stream"><a href="#_27-1-2-5-stream" class="header-anchor">#</a> 27.1.2.5. Stream</h4> <p>Tuple的集合。表示数据的流向。</p> <h3 id="_27-1-3-topology-运行"><a href="#_27-1-3-topology-运行" class="header-anchor">#</a> 27.1.3. Topology 运行</h3> <p>在Storm中,一个实时应用的计算任务被打包作为Topology发布，这同Hadoop MapReduce</p> <p>任务相似。但是有一点不同的是:在Hadoop中，MapReduce任务最终会执行完成后结束；而在
Storm中，Topology任务一旦提交后永远不会结束，除非你显示去停止任务。计算任务</p> <p>Topology是由不同的Spouts和Bolts，通过数据流（Stream）连接起来的图｡一个Storm在集
群上运行一个Topology时，主要通过以下 3 个实体来完成Topology的执行工作：</p> <h5 id="_1-worker-进程-2-executor-线程-3-task"><a href="#_1-worker-进程-2-executor-线程-3-task" class="header-anchor">#</a> (1). Worker（进程） (2). Executor（线程） (3). Task</h5> <h4 id="_27-1-3-1-worker-1-个worker进程执行的是-1-个topology的子集"><a href="#_27-1-3-1-worker-1-个worker进程执行的是-1-个topology的子集" class="header-anchor">#</a> 27.1.3.1. Worker( 1 个worker进程执行的是 1 个topology的子集)</h4> <p>1 个worker进程执行的是 1 个topology的子集（注：不会出现 1 个worker为多个topology</p> <p>服务）。 1 个worker进程会启动 1 个或多个executor线程来执行 1 个topology的
component(spout或bolt)。因此， 1 个运行中的topology就是由集群中多台物理机上的多个</p> <p>worker进程组成的。</p> <h4 id="_27-1-3-2-executor-executor是-1-个被worker进程启动的单独线程"><a href="#_27-1-3-2-executor-executor是-1-个被worker进程启动的单独线程" class="header-anchor">#</a> 27.1.3.2. Executor(executor是 1 个被worker进程启动的单独线程)</h4> <p>executor是 1 个被worker进程启动的单独线程。每个executor只会运行 1 个topology的 1 个</p> <p>component(spout或bolt)的task（注：task可以是 1 个或多个，storm默认是 1 个
component只生成 1 个task，executor线程里会在每次循环里顺序调用所有task实例）。</p> <h4 id="_27-1-3-3-task-最终运行spout或bolt中代码的单元"><a href="#_27-1-3-3-task-最终运行spout或bolt中代码的单元" class="header-anchor">#</a> 27.1.3.3. Task(最终运行spout或bolt中代码的单元)</h4> <p>是最终运行spout或bolt中代码的单元（注： 1 个task即为spout或bolt的 1 个实例，</p> <p>executor线程在执行期间会调用该task的nextTuple或execute方法）。topology启动后， 1
个component(spout或bolt)的task数目是固定不变的，但该component使用的executor线</p> <p>程数可以动态调整（例如： 1 个executor线程可以执行该component的 1 个或多个task实
例）。这意味着，对于 1 个component存在这样的条件：#threads&lt;=#tasks（即：线程数小于</p> <p>等于task数目）。默认情况下task的数目等于executor线程数目，即 1 个executor线程只运
行 1 个task。</p> <h3 id="_27-1-4-storm-streaming-grouping"><a href="#_27-1-4-storm-streaming-grouping" class="header-anchor">#</a> 27.1.4. Storm Streaming Grouping</h3> <p>Storm中最重要的抽象，应该就是Stream grouping了，它能够控制Spot/Bolt对应的Task以
什么样的方式来分发Tuple，将Tuple发射到目的Spot/Bolt对应的Task.</p> <p>目前，Storm Streaming Grouping支持如下几种类型：</p> <h4 id="_27-1-4-1-huffle-grouping"><a href="#_27-1-4-1-huffle-grouping" class="header-anchor">#</a> 27.1.4.1. huffle Grouping</h4> <p>随机分组，尽量均匀分布到下游Bolt中将流分组定义为混排。这种混排分组意味着来自Spout的
输入将混排，或随机分发给此Bolt中的任务。shuffle grouping对各个task的tuple分配的比</p> <p>较均匀。</p> <h4 id="_27-1-4-2-fields-grouping"><a href="#_27-1-4-2-fields-grouping" class="header-anchor">#</a> 27.1.4.2. Fields Grouping</h4> <p>按字段分组，按数据中field值进行分组；相同field值的Tuple被发送到相同的Task这种
grouping机制保证相同field值的tuple会去同一个task。</p> <h4 id="_27-1-4-3-all-grouping-广播"><a href="#_27-1-4-3-all-grouping-广播" class="header-anchor">#</a> 27.1.4.3. All grouping ：广播</h4> <p>广播发送， 对于每一个tuple将会复制到每一个bolt中处理。</p> <h4 id="_27-1-4-4-global-grouping"><a href="#_27-1-4-4-global-grouping" class="header-anchor">#</a> 27.1.4.4. Global grouping</h4> <p>全局分组，Tuple被分配到一个Bolt中的一个Task，实现事务性的Topology。Stream中的所</p> <p>有的tuple都会发送给同一个bolt任务处理，所有的tuple将会发送给拥有最小task_id的bolt
任务处理。</p> <h4 id="_27-1-4-5-none-grouping-不分组"><a href="#_27-1-4-5-none-grouping-不分组" class="header-anchor">#</a> 27.1.4.5. None grouping ：不分组</h4> <p>不关注并行处理负载均衡策略时使用该方式，目前等同于shuffle grouping,另外storm将会把
bolt任务和他的上游提供数据的任务安排在同一个线程下。</p> <h4 id="_27-1-4-6-direct-grouping-直接分组-指定分组"><a href="#_27-1-4-6-direct-grouping-直接分组-指定分组" class="header-anchor">#</a> 27.1.4.6. Direct grouping ：直接分组 指定分组</h4> <p>由tuple的发射单元直接决定tuple将发射给那个bolt，一般情况下是由接收tuple的bolt决定</p> <p>接收哪个bolt发射的Tuple。这是一种比较特别的分组方法，用这种分组意味着消息的发送者指
定由消息接收者的哪个task处理这个消息。 只有被声明为Direct Stream的消息流可以声明这种</p> <p>分组方法。而且这种消息tuple必须使用emitDirect方法来发射。消息处理者可以通过
TopologyContext来获取处理它的消息的taskid (OutputCollector.emit方法也会返回</p> <p>taskid)。</p> <h2 id="_28-yarn"><a href="#_28-yarn" class="header-anchor">#</a> 28. YARN</h2> <h3 id="_28-1-1-概念"><a href="#_28-1-1-概念" class="header-anchor">#</a> 28.1.1. 概念</h3> <p>YARN 是一个资源管理、任务调度的框架，主要包含三大模块：ResourceManager（RM）、
NodeManager（NM）、ApplicationMaster（AM）。其中，ResourceManager 负责所有资
源的监控、分配和管理；ApplicationMaster 负责每一个具体应用程序的调度和协调；
NodeManager负责每一个节点的维护。对于所有的applications，RM拥有绝对的控制权和对资
源的分配权。而每个AM则会和RM协商资源，同时和NodeManager通信来执行和监控task。
几个模块之间的关系如图所示。</p> <h3 id="_28-1-2-resourcemanager"><a href="#_28-1-2-resourcemanager" class="header-anchor">#</a> 28.1.2. ResourceManager</h3> <ol><li>ResourceManager负责整个集群的资源管理和分配，是一个全局的资源管理系统。</li> <li>NodeManager以心跳的方式向ResourceManager汇报资源使用情况（目前主要是CPU和
内存的使用情况）。RM只接受NM的资源回报信息，对于具体的资源处理则交给NM自己
处理。</li> <li>YARN Scheduler根据application的请求为其分配资源，不负责application job的监控、
追踪、运行状态反馈、启动等工作。</li></ol> <h3 id="_28-1-3-nodemanager"><a href="#_28-1-3-nodemanager" class="header-anchor">#</a> 28.1.3. NodeManager</h3> <ol><li><p>NodeManager是每个节点上的资源和任务管理器，它是管理这台机器的代理，负责该节点
程序的运行，以及该节点资源的管理和监控。YARN集群每个节点都运行一个NodeManager。</p></li> <li><p>NodeManager 定时向ResourceManager 汇报本节点资源（CPU、内存）的使用情况和
Container的运行状态。当ResourceManager宕机时NodeManager自动连接RM备用节
点。</p></li> <li><p>NodeManager接收并处理来自ApplicationMaster的Container启动、停止等各种请求。</p></li></ol> <h3 id="_28-1-4-applicationmaster"><a href="#_28-1-4-applicationmaster" class="header-anchor">#</a> 28.1.4. ApplicationMaster</h3> <p>用户提交的每个应用程序均包含一个ApplicationMaster，它可以运行在ResourceManager以外
的机器上。</p> <ol><li>负责与RM调度器协商以获取资源（用Container表示）。</li> <li>将得到的任务进一步分配给内部的任务(资源的二次分配)。</li> <li>与NM通信以启动/停止任务。</li> <li>监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。</li> <li>当前YARN自带了两个ApplicationMaster实现，一个是用于演示AM编写方法的实例程序
DistributedShell，它可以申请一定数目的Container以并行运行一个Shell命令或者Shell
脚本；另一个是运行MapReduce应用程序的AM—MRAppMaster。</li></ol> <p>注：RM只负责监控AM，并在AM运行失败时候启动它。RM不负责AM内部任务的容错，任务
的容错由AM完成。</p> <h3 id="_28-1-5-yarn运行流程"><a href="#_28-1-5-yarn运行流程" class="header-anchor">#</a> 28.1.5. YARN运行流程</h3> <ol><li>client向RM提交应用程序，其中包括启动该应用的ApplicationMaster的必须信息，例如
ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。</li> <li>ResourceManager启动一个container用于运行ApplicationMaster。</li> <li>启动中的ApplicationMaster向ResourceManager注册自己，启动成功后与RM保持心跳。</li> <li>ApplicationMaster向ResourceManager发送请求，申请相应数目的container。</li> <li>ResourceManager 返回ApplicationMaster 的申请的containers 信息。申请成功的
container，由ApplicationMaster进行初始化。container的启动信息初始化后，AM与对
应的NodeManager通信，要求NM启动container。AM与NM保持心跳，从而对NM上
运行的任务进行监控和管理。</li> <li>container运行期间，ApplicationMaster对container进行监控。container通过RPC协议
向对应的AM汇报自己的进度和状态等信息。</li> <li>应用运行期间，client直接与AM通信获取应用的状态、进度更新等信息。</li> <li>应用运行结束后，ApplicationMaster 向ResourceManager 注销自己，并允许属于它的
container被收回。</li></ol> <h2 id="_29-机器学习"><a href="#_29-机器学习" class="header-anchor">#</a> 29. 机器学习</h2> <h3 id="_29-1-1-决策树"><a href="#_29-1-1-决策树" class="header-anchor">#</a> 29.1.1. 决策树</h3> <h3 id="_29-1-2-随机森林算法"><a href="#_29-1-2-随机森林算法" class="header-anchor">#</a> 29.1.2. 随机森林算法</h3> <h3 id="_29-1-3-逻辑回归"><a href="#_29-1-3-逻辑回归" class="header-anchor">#</a> 29.1.3. 逻辑回归</h3> <h3 id="_29-1-4-svm"><a href="#_29-1-4-svm" class="header-anchor">#</a> 29.1.4. SVM............................................................................................................................................</h3> <h3 id="_29-1-5-朴素贝叶斯"><a href="#_29-1-5-朴素贝叶斯" class="header-anchor">#</a> 29.1.5. 朴素贝叶斯</h3> <h3 id="_29-1-6-k-最近邻算法"><a href="#_29-1-6-k-最近邻算法" class="header-anchor">#</a> 29.1.6. K 最近邻算法</h3> <h3 id="_29-1-7-k-均值算法"><a href="#_29-1-7-k-均值算法" class="header-anchor">#</a> 29.1.7. K 均值算法</h3> <h3 id="_29-1-8-adaboost-算法"><a href="#_29-1-8-adaboost-算法" class="header-anchor">#</a> 29.1.8. Adaboost 算法</h3> <h3 id="_29-1-9-神经网络"><a href="#_29-1-9-神经网络" class="header-anchor">#</a> 29.1.9. 神经网络</h3> <h3 id="_29-1-10-马尔可夫"><a href="#_29-1-10-马尔可夫" class="header-anchor">#</a> 29.1.10. 马尔可夫</h3> <p>参考：http://www.cyzone.cn/a/20170422/310196.html</p> <h2 id="_30-云计算"><a href="#_30-云计算" class="header-anchor">#</a> 30. 云计算</h2> <h3 id="_30-1-1-saas"><a href="#_30-1-1-saas" class="header-anchor">#</a> 30.1.1. SaaS</h3> <p>SaaS是Software-as-a-Service（软件即服务）</p> <h3 id="_30-1-2-paas"><a href="#_30-1-2-paas" class="header-anchor">#</a> 30.1.2. PaaS</h3> <p>PaaS是Platform-as-a-Service的缩写，意思是平台即服务。 把服务器平台作为一种服务提供的
商业模式。通过网络进行程序提供的服务称之为SaaS(Software as a Service)，而云计算时代相
应的服务器平台或者开发环境作为服务进行提供就成为了PaaS(Platform as a Service)。</p> <h3 id="_30-1-3-iaas"><a href="#_30-1-3-iaas" class="header-anchor">#</a> 30.1.3. IaaS</h3> <p>IaaS（Infrastructure as a Service），即基础设施即服务。提供给消费者的服务是对所有设施的
利用，包括处理、存储、网络和其它基本的计算资源，用户能够部署和运行任意软件，包括操作
系统和应用程序。</p> <h3 id="_30-1-4-docker"><a href="#_30-1-4-docker" class="header-anchor">#</a> 30.1.4. Docker</h3> <h4 id="_30-1-4-1-概念"><a href="#_30-1-4-1-概念" class="header-anchor">#</a> 30.1.4.1. 概念</h4> <div class="language- extra-class"><pre class="language-text"><code>Docker 镜像
(Images)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 镜像是用于创建 Docker 容器的模板。
</code></pre></div><p>Docker 的出现一定是因为目前的后端在开发和运维阶段确实需要一种虚拟化技术解决开发环境和
生产环境环境一致的问题，通过 Docker 我们可以将程序运行的环境也纳入到版本控制中，排除因
为环境造成不同运行结果的可能。但是上述需求虽然推动了虚拟化技术的产生，但是如果没有合
适的底层技术支撑，那么我们仍然得不到一个完美的产品。本文剩下的内容会介绍几种 Docker 使
用的核心技术，如果我们了解它们的使用方法和原理，就能清楚 Docker 的实现原理。Docker 使
用客户端-服务器 (C/S) 架构模式，使用远程API来管理和创建Docker容器。Docker 容器通过
Docker 镜像来创建。</p> <h4 id="_30-1-4-2-namespaces"><a href="#_30-1-4-2-namespaces" class="header-anchor">#</a> 30.1.4.2. Namespaces</h4> <p>命名空间（namespaces）是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间
通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的
需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能
看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，
我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。</p> <div class="language- extra-class"><pre class="language-text"><code>Docker 容器
(Container)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>容器是独立运行的一个或一组应用。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 客户端
(Client)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 客户端通过命令行或者其他工具使用 Docker API与 Docker 的守护进程通信。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 主机
(Host)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 仓库
(Registry)
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。
Docker Hub 提供了庞大的镜像集合供使用。
Docker
Machine
</code></pre></div><div class="language- extra-class"><pre class="language-text"><code>Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相
应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。
</code></pre></div><p>Linux 的命名空间机制提供了以下七种不同的命名空间，包括 CLONE_NEWCGROUP、
CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、
CLONE_NEWUSER 和 CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程
应该在哪些资源上与宿主机器进行隔离。</p> <h4 id="_30-1-4-3-进程-clone-newpid-实现的进程隔离"><a href="#_30-1-4-3-进程-clone-newpid-实现的进程隔离" class="header-anchor">#</a> 30.1.4.3. 进程(CLONE_NEWPID 实现的进程隔离)......................................................................................</h4> <p>docker 创建新进程时传入 CLONE_NEWPID 实现的进程隔离，也就是使用 Linux 的命名空间实现
进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。当我们每次运行
docker run 或者 docker start 时，都会在创建一个用于设置进程间隔离的 Spec，同时会设置进
程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间，所有命名空间相关
的设置 Spec 最后都会作为 Create 函数的入参在创建新的容器时进行设置。</p> <h4 id="_30-1-4-4-libnetwork与网络隔离"><a href="#_30-1-4-4-libnetwork与网络隔离" class="header-anchor">#</a> 30.1.4.4. Libnetwork与网络隔离</h4> <p>如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却有没有办法通过宿
主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离
的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。</p> <p>Docker整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同
容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型。</p> <p>libnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、
Endpoint 和 Network。在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前
容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个
Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡
veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux
网桥或者 VLAN。</p> <p>每一个使用 docker run 启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同
的网络模式，Host、Container、None 和 Bridge 模式。</p> <p>在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网
络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上启动之后会创建
新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。在默认情况下，</p> <p>每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的
容器中，会加入到名为 docker0 网桥中。</p> <h4 id="_30-1-4-5-资源隔离与cgroups"><a href="#_30-1-4-5-资源隔离与cgroups" class="header-anchor">#</a> 30.1.4.5. 资源隔离与CGroups</h4> <p>Control Groups（简称 CGroups）能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网
络带宽。每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关
系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。</p> <h4 id="_30-1-4-6-镜像与unionfs"><a href="#_30-1-4-6-镜像与unionfs" class="header-anchor">#</a> 30.1.4.6. 镜像与UnionFS</h4> <p>Linux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统
的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需
要解决 - 也就是镜像。</p> <p>Docker 镜像其实本质就是一个压缩包，我们可以使用命令将一个 Docker 镜像中的文件导出，你
可以看到这个镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说
Docker 镜像就是一个文件。</p> <h4 id="_30-1-4-7-存储驱动"><a href="#_30-1-4-7-存储驱动" class="header-anchor">#</a> 30.1.4.7. 存储驱动</h4> <p>Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与
Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。</p> <p>当镜像被 docker run 命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对
于运行时容器的修改其实都是对这个容器读写层的修改。</p> <p>容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写
的层，也就是同一个镜像可以对应多个容器</p> <p>UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文
件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀
的性能和效率。</p> <p>AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，
包括 aufs、devicemapper、overlay2、zfs 和 vfs 等等，在最新的 Docker 中，overlay2 取代了
aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs 作为 Docker
的默认驱动。</p> <h2 id="_30-1-5-openstack"><a href="#_30-1-5-openstack" class="header-anchor">#</a> 30.1.5. Openstack</h2></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/MyReader/note/blog/blog_0001.html" class="prev">
          vuepress Github Actions
        </a></span> <span class="next"><a href="/MyReader/note/book/book_0002.html">
          《Java开发手册(黄山版)》
        </a></span></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-b57cc07c data-v-7dd95ae2><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_1-目录" class="sidebar-link reco-side-_1-目录" data-v-b57cc07c>1. 目录</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-jvm" class="sidebar-link reco-side-_2-jvm" data-v-b57cc07c>2. JVM</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-1-线程" class="sidebar-link reco-side-_2-1-线程" data-v-b57cc07c>2.1. 线程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-2-jvm内存区域" class="sidebar-link reco-side-_2-2-jvm内存区域" data-v-b57cc07c>2.2. JVM内存区域</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-3-jvm运行时内存" class="sidebar-link reco-side-_2-3-jvm运行时内存" data-v-b57cc07c>2.3. JVM运行时内存</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-4-垃圾回收与算法" class="sidebar-link reco-side-_2-4-垃圾回收与算法" data-v-b57cc07c>2.4. 垃圾回收与算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-5-java-四中引用类型" class="sidebar-link reco-side-_2-5-java-四中引用类型" data-v-b57cc07c>2.5. JAVA 四中引用类型</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-6-gc分代收集算法-vs-分区收集算法" class="sidebar-link reco-side-_2-6-gc分代收集算法-vs-分区收集算法" data-v-b57cc07c>2.6. GC分代收集算法 VS 分区收集算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-7-gc垃圾收集器" class="sidebar-link reco-side-_2-7-gc垃圾收集器" data-v-b57cc07c>2.7. GC垃圾收集器</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-8-java-io-nio" class="sidebar-link reco-side-_2-8-java-io-nio" data-v-b57cc07c>2.8. JAVA IO/NIO</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#" class="sidebar-link reco-side-" data-v-b57cc07c>}</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_2-9-jvm-类加载机制" class="sidebar-link reco-side-_2-9-jvm-类加载机制" data-v-b57cc07c>2.9. JVM 类加载机制</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-java-集合" class="sidebar-link reco-side-_3-java-集合" data-v-b57cc07c>3. JAVA 集合</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-1-接口继承关系和实现" class="sidebar-link reco-side-_3-1-接口继承关系和实现" data-v-b57cc07c>3.1. 接口继承关系和实现</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-2-list" class="sidebar-link reco-side-_3-2-list" data-v-b57cc07c>3.2. LIST</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-3-set" class="sidebar-link reco-side-_3-3-set" data-v-b57cc07c>3.3. SET</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-4-map" class="sidebar-link reco-side-_3-4-map" data-v-b57cc07c>3.4. MAP</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-4-3-hashtable-线程安全" class="sidebar-link reco-side-_3-4-3-hashtable-线程安全" data-v-b57cc07c>3.4.3. HashTable （线程安全）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-4-4-treemap-可排序" class="sidebar-link reco-side-_3-4-4-treemap-可排序" data-v-b57cc07c>3.4.4. TreeMap （可排序）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_3-4-5-linkhashmap-记录插入顺序" class="sidebar-link reco-side-_3-4-5-linkhashmap-记录插入顺序" data-v-b57cc07c>3.4.5. LinkHashMap （记录插入顺序）</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-java-多线程并发" class="sidebar-link reco-side-_4-java-多线程并发" data-v-b57cc07c>4. JAVA 多线程并发</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-1-java-并发知识库" class="sidebar-link reco-side-_4-1-1-java-并发知识库" data-v-b57cc07c>4.1.1. JAVA 并发知识库</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-2-java-线程实现-创建方式" class="sidebar-link reco-side-_4-1-2-java-线程实现-创建方式" data-v-b57cc07c>4.1.2. JAVA 线程实现 / 创建方式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-3-4-种线程池" class="sidebar-link reco-side-_4-1-3-4-种线程池" data-v-b57cc07c>4.1.3. 4 种线程池</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-4-线程生命周期-状态" class="sidebar-link reco-side-_4-1-4-线程生命周期-状态" data-v-b57cc07c>4.1.4. 线程生命周期 ( 状态 )</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-5-终止线程-4-种方式" class="sidebar-link reco-side-_4-1-5-终止线程-4-种方式" data-v-b57cc07c>4.1.5. 终止线程 4 种方式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-6-sleep-与-wait-区别" class="sidebar-link reco-side-_4-1-6-sleep-与-wait-区别" data-v-b57cc07c>4.1.6. sleep 与 wait 区别</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-7-start-与-run-区别" class="sidebar-link reco-side-_4-1-7-start-与-run-区别" data-v-b57cc07c>4.1.7. start 与 run 区别</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-8-java-后台线程" class="sidebar-link reco-side-_4-1-8-java-后台线程" data-v-b57cc07c>4.1.8. JAVA 后台线程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-java-锁" class="sidebar-link reco-side-_4-1-9-java-锁" data-v-b57cc07c>4.1.9. JAVA 锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-8-可重入锁-递归锁" class="sidebar-link reco-side-_4-1-9-8-可重入锁-递归锁" data-v-b57cc07c>4.1.9.8. 可重入锁（递归锁）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-9-公平锁与非公平锁" class="sidebar-link reco-side-_4-1-9-9-公平锁与非公平锁" data-v-b57cc07c>4.1.9.9. 公平锁与非公平锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-10-readwritelock读写锁" class="sidebar-link reco-side-_4-1-9-10-readwritelock读写锁" data-v-b57cc07c>4.1.9.10. ReadWriteLock读写锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-11-共享锁和独占锁" class="sidebar-link reco-side-_4-1-9-11-共享锁和独占锁" data-v-b57cc07c>4.1.9.11. 共享锁和独占锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-12-重量级锁-mutex-lock" class="sidebar-link reco-side-_4-1-9-12-重量级锁-mutex-lock" data-v-b57cc07c>4.1.9.12. 重量级锁（Mutex Lock）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-13-轻量级锁" class="sidebar-link reco-side-_4-1-9-13-轻量级锁" data-v-b57cc07c>4.1.9.13. 轻量级锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-14-偏向锁" class="sidebar-link reco-side-_4-1-9-14-偏向锁" data-v-b57cc07c>4.1.9.14. 偏向锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-15-分段锁" class="sidebar-link reco-side-_4-1-9-15-分段锁" data-v-b57cc07c>4.1.9.15. 分段锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-9-16-锁优化" class="sidebar-link reco-side-_4-1-9-16-锁优化" data-v-b57cc07c>4.1.9.16. 锁优化</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-线程基本方法" class="sidebar-link reco-side-_4-1-10-线程基本方法" data-v-b57cc07c>4.1.10. 线程基本方法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-1-线程等待-wait" class="sidebar-link reco-side-_4-1-10-1-线程等待-wait" data-v-b57cc07c>4.1.10.1. 线程等待（wait）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-2-线程睡眠-sleep" class="sidebar-link reco-side-_4-1-10-2-线程睡眠-sleep" data-v-b57cc07c>4.1.10.2. 线程睡眠（sleep）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-3-线程让步-yield" class="sidebar-link reco-side-_4-1-10-3-线程让步-yield" data-v-b57cc07c>4.1.10.3. 线程让步（yield）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-4-线程中断-interrupt" class="sidebar-link reco-side-_4-1-10-4-线程中断-interrupt" data-v-b57cc07c>4.1.10.4. 线程中断（interrupt）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-5-join等待其他线程终止" class="sidebar-link reco-side-_4-1-10-5-join等待其他线程终止" data-v-b57cc07c>4.1.10.5. Join等待其他线程终止</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-6-为什么要用join-方法" class="sidebar-link reco-side-_4-1-10-6-为什么要用join-方法" data-v-b57cc07c>4.1.10.6. 为什么要用join()方法？</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-7-线程唤醒-notify" class="sidebar-link reco-side-_4-1-10-7-线程唤醒-notify" data-v-b57cc07c>4.1.10.7. 线程唤醒（notify）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-10-8-其他方法" class="sidebar-link reco-side-_4-1-10-8-其他方法" data-v-b57cc07c>4.1.10.8. 其他方法：</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-线程上下文切换" class="sidebar-link reco-side-_4-1-11-线程上下文切换" data-v-b57cc07c>4.1.11. 线程上下文切换</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-1-进程" class="sidebar-link reco-side-_4-1-11-1-进程" data-v-b57cc07c>4.1.11.1. 进程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-2-上下文" class="sidebar-link reco-side-_4-1-11-2-上下文" data-v-b57cc07c>4.1.11.2. 上下文</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-3-寄存器" class="sidebar-link reco-side-_4-1-11-3-寄存器" data-v-b57cc07c>4.1.11.3. 寄存器</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-4-程序计数器" class="sidebar-link reco-side-_4-1-11-4-程序计数器" data-v-b57cc07c>4.1.11.4. 程序计数器</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-5-pcb-切换桢" class="sidebar-link reco-side-_4-1-11-5-pcb-切换桢" data-v-b57cc07c>4.1.11.5. PCB-“切换桢”</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-6-上下文切换的活动" class="sidebar-link reco-side-_4-1-11-6-上下文切换的活动" data-v-b57cc07c>4.1.11.6. 上下文切换的活动：</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-11-7-引起线程上下文切换的原因" class="sidebar-link reco-side-_4-1-11-7-引起线程上下文切换的原因" data-v-b57cc07c>4.1.11.7. 引起线程上下文切换的原因</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-12-同步锁与死锁" class="sidebar-link reco-side-_4-1-12-同步锁与死锁" data-v-b57cc07c>4.1.12. 同步锁与死锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-12-1-同步锁" class="sidebar-link reco-side-_4-1-12-1-同步锁" data-v-b57cc07c>4.1.12.1. 同步锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-12-2-死锁" class="sidebar-link reco-side-_4-1-12-2-死锁" data-v-b57cc07c>4.1.12.2. 死锁</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-13-线程池原理" class="sidebar-link reco-side-_4-1-13-线程池原理" data-v-b57cc07c>4.1.13. 线程池原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-13-1-线程复用" class="sidebar-link reco-side-_4-1-13-1-线程复用" data-v-b57cc07c>4.1.13.1. 线程复用</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-13-2-线程池的组成" class="sidebar-link reco-side-_4-1-13-2-线程池的组成" data-v-b57cc07c>4.1.13.2. 线程池的组成</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-13-3-拒绝策略" class="sidebar-link reco-side-_4-1-13-3-拒绝策略" data-v-b57cc07c>4.1.13.3. 拒绝策略</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-13-4-java线程池工作过程" class="sidebar-link reco-side-_4-1-13-4-java线程池工作过程" data-v-b57cc07c>4.1.13.4. Java线程池工作过程</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-java-阻塞队列原理" class="sidebar-link reco-side-_4-1-14-java-阻塞队列原理" data-v-b57cc07c>4.1.14. JAVA 阻塞队列原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-1-阻塞队列的主要方法" class="sidebar-link reco-side-_4-1-14-1-阻塞队列的主要方法" data-v-b57cc07c>4.1.14.1. 阻塞队列的主要方法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-2-java中的阻塞队列" class="sidebar-link reco-side-_4-1-14-2-java中的阻塞队列" data-v-b57cc07c>4.1.14.2. Java中的阻塞队列</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-3-arrayblockingqueue-公平、非公平" class="sidebar-link reco-side-_4-1-14-3-arrayblockingqueue-公平、非公平" data-v-b57cc07c>4.1.14.3. ArrayBlockingQueue（公平、非公平）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-4-linkedblockingqueue-两个独立锁提高并发" class="sidebar-link reco-side-_4-1-14-4-linkedblockingqueue-两个独立锁提高并发" data-v-b57cc07c>4.1.14.4. LinkedBlockingQueue（两个独立锁提高并发）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-5-priorityblockingqueue-compareto排序实现优先" class="sidebar-link reco-side-_4-1-14-5-priorityblockingqueue-compareto排序实现优先" data-v-b57cc07c>4.1.14.5. PriorityBlockingQueue（compareTo排序实现优先）..............................................................</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-6-delayqueue-缓存失效、定时任务" class="sidebar-link reco-side-_4-1-14-6-delayqueue-缓存失效、定时任务" data-v-b57cc07c>4 .1.14.6. DelayQueue（缓存失效、定时任务 ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-7-synchronousqueue-不存储数据、可用于传递数据" class="sidebar-link reco-side-_4-1-14-7-synchronousqueue-不存储数据、可用于传递数据" data-v-b57cc07c>4.1.14.7. SynchronousQueue（不存储数据、可用于传递数据）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-14-8-linkedtransferqueue" class="sidebar-link reco-side-_4-1-14-8-linkedtransferqueue" data-v-b57cc07c>4.1.14.8. LinkedTransferQueue......................................................................................................................</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-15-cyclicbarrier-、-countdownlatch-、-semaphore-的用法" class="sidebar-link reco-side-_4-1-15-cyclicbarrier-、-countdownlatch-、-semaphore-的用法" data-v-b57cc07c>4.1.15. CyclicBarrier 、 CountDownLatch 、 Semaphore 的用法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-16-volatile-关键字的作用-变量可见性、禁止重排序" class="sidebar-link reco-side-_4-1-16-volatile-关键字的作用-变量可见性、禁止重排序" data-v-b57cc07c>4.1.16. volatile 关键字的作用（变量可见性、禁止重排序）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#享-线程直接给这个变量赋值。" class="sidebar-link reco-side-享-线程直接给这个变量赋值。" data-v-b57cc07c>享，线程直接给这个变量赋值。</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-17-如何在两个线程之间共享数据" class="sidebar-link reco-side-_4-1-17-如何在两个线程之间共享数据" data-v-b57cc07c>4.1.17. 如何在两个线程之间共享数据</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-18-threadlocal-作用-线程本地存储" class="sidebar-link reco-side-_4-1-18-threadlocal-作用-线程本地存储" data-v-b57cc07c>4.1.18. ThreadLocal 作用（线程本地存储）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-19-synchronized-和-reentrantlock-的区别" class="sidebar-link reco-side-_4-1-19-synchronized-和-reentrantlock-的区别" data-v-b57cc07c>4.1.19. synchronized 和 ReentrantLock 的区别</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-20-concurrenthashmap-并发" class="sidebar-link reco-side-_4-1-20-concurrenthashmap-并发" data-v-b57cc07c>4.1.20. ConcurrentHashMap 并发</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-21-java-中用到的线程调度" class="sidebar-link reco-side-_4-1-21-java-中用到的线程调度" data-v-b57cc07c>4.1.21. Java 中用到的线程调度</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-22-进程调度算法" class="sidebar-link reco-side-_4-1-22-进程调度算法" data-v-b57cc07c>4.1.22. 进程调度算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-23-什么是-cas-比较并交换-乐观锁机制-锁自旋" class="sidebar-link reco-side-_4-1-23-什么是-cas-比较并交换-乐观锁机制-锁自旋" data-v-b57cc07c>4.1.23. 什么是 CAS （比较并交换-乐观锁机制-锁自旋）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_4-1-24-什么是-aqs-抽象的队列同步器" class="sidebar-link reco-side-_4-1-24-什么是-aqs-抽象的队列同步器" data-v-b57cc07c>4.1.24. 什么是 AQS （抽象的队列同步器）</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-java-基础" class="sidebar-link reco-side-_5-java-基础" data-v-b57cc07c>5. JAVA 基础</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-1-java-异常分类及处理" class="sidebar-link reco-side-_5-1-1-java-异常分类及处理" data-v-b57cc07c>5.1.1. JAVA 异常分类及处理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-2-java-反射" class="sidebar-link reco-side-_5-1-2-java-反射" data-v-b57cc07c>5.1.2. JAVA 反射</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-3-java-注解" class="sidebar-link reco-side-_5-1-3-java-注解" data-v-b57cc07c>5.1.3. JAVA 注解</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-4-java-内部类" class="sidebar-link reco-side-_5-1-4-java-内部类" data-v-b57cc07c>5.1.4. JAVA 内部类</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-5-java-泛型" class="sidebar-link reco-side-_5-1-5-java-泛型" data-v-b57cc07c>5.1.5. JAVA 泛型</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-6-java-序列化-创建可复用的-java-对象" class="sidebar-link reco-side-_5-1-6-java-序列化-创建可复用的-java-对象" data-v-b57cc07c>5.1.6. JAVA 序列化 ( 创建可复用的 Java 对象 )</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_5-1-7-java-复制" class="sidebar-link reco-side-_5-1-7-java-复制" data-v-b57cc07c>5 .1.7. JAVA 复制</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-spring-原理" class="sidebar-link reco-side-_6-spring-原理" data-v-b57cc07c>6. SPRING 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-1-spring-特点" class="sidebar-link reco-side-_6-1-1-spring-特点" data-v-b57cc07c>6.1.1. Spring 特点</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-1-2-控制反转" class="sidebar-link reco-side-_6-1-1-2-控制反转" data-v-b57cc07c>6.1.1.2. 控制反转</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-1-3-面向切面" class="sidebar-link reco-side-_6-1-1-3-面向切面" data-v-b57cc07c>6.1.1.3. 面向切面</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-1-4-容器" class="sidebar-link reco-side-_6-1-1-4-容器" data-v-b57cc07c>6.1.1.4. 容器</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-1-5-框架集合" class="sidebar-link reco-side-_6-1-1-5-框架集合" data-v-b57cc07c>6.1.1.5. 框架集合</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-2-spring-核心组件" class="sidebar-link reco-side-_6-1-2-spring-核心组件" data-v-b57cc07c>6.1.2. Spring 核心组件</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-3-spring-常用模块" class="sidebar-link reco-side-_6-1-3-spring-常用模块" data-v-b57cc07c>6.1.3. Spring 常用模块</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-4-spring-主要包" class="sidebar-link reco-side-_6-1-4-spring-主要包" data-v-b57cc07c>6.1.4. Spring 主要包</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-5-spring-常用注解" class="sidebar-link reco-side-_6-1-5-spring-常用注解" data-v-b57cc07c>6.1.5. Spring 常用注解</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-6-spring-第三方结合" class="sidebar-link reco-side-_6-1-6-spring-第三方结合" data-v-b57cc07c>6.1.6. Spring 第三方结合</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-spring-ioc-原理" class="sidebar-link reco-side-_6-1-7-spring-ioc-原理" data-v-b57cc07c>6.1.7. Spring IOC 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-1-概念" class="sidebar-link reco-side-_6-1-7-1-概念" data-v-b57cc07c>6.1.7.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-2-spring容器高层视图" class="sidebar-link reco-side-_6-1-7-2-spring容器高层视图" data-v-b57cc07c>6.1.7.2. Spring容器高层视图</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-3-ioc容器实现" class="sidebar-link reco-side-_6-1-7-3-ioc容器实现" data-v-b57cc07c>6.1.7.3. IOC容器实现</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-4-spring-bean-作用域" class="sidebar-link reco-side-_6-1-7-4-spring-bean-作用域" data-v-b57cc07c>6.1.7.4. Spring Bean 作用域</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-5-spring-bean-生命周期" class="sidebar-link reco-side-_6-1-7-5-spring-bean-生命周期" data-v-b57cc07c>6.1.7.5. Spring Bean 生命周期</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-6-spring-依赖注入四种方式" class="sidebar-link reco-side-_6-1-7-6-spring-依赖注入四种方式" data-v-b57cc07c>6.1.7.6. Spring 依赖注入四种方式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-7-7-5-种不同方式的自动装配" class="sidebar-link reco-side-_6-1-7-7-5-种不同方式的自动装配" data-v-b57cc07c>6.1.7.7. 5 种不同方式的自动装配</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-8-spring-apo-原理" class="sidebar-link reco-side-_6-1-8-spring-apo-原理" data-v-b57cc07c>6.1.8. Spring APO 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-8-1-概念" class="sidebar-link reco-side-_6-1-8-1-概念" data-v-b57cc07c>6.1.8.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-8-2-aop核心概念" class="sidebar-link reco-side-_6-1-8-2-aop核心概念" data-v-b57cc07c>6.1.8.2. AOP核心概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-8-1-aop两种代理方式" class="sidebar-link reco-side-_6-1-8-1-aop两种代理方式" data-v-b57cc07c>6.1.8.1. AOP两种代理方式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-8-2-实现原理" class="sidebar-link reco-side-_6-1-8-2-实现原理" data-v-b57cc07c>6.1.8.2. 实现原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#-2" class="sidebar-link reco-side--2" data-v-b57cc07c>}</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-9-spring-mvc-原理" class="sidebar-link reco-side-_6-1-9-spring-mvc-原理" data-v-b57cc07c>6.1.9. Spring MVC 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-9-1-mvc流程" class="sidebar-link reco-side-_6-1-9-1-mvc流程" data-v-b57cc07c>6.1.9.1. MVC流程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-10-spring-boot-原理" class="sidebar-link reco-side-_6-1-10-spring-boot-原理" data-v-b57cc07c>6.1.10. Spring Boot 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-11-jpa-原理" class="sidebar-link reco-side-_6-1-11-jpa-原理" data-v-b57cc07c>6.1.11. JPA 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-12-mybatis-缓存" class="sidebar-link reco-side-_6-1-12-mybatis-缓存" data-v-b57cc07c>6.1.12. Mybatis 缓存</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_6-1-13-tomcat-架构" class="sidebar-link reco-side-_6-1-13-tomcat-架构" data-v-b57cc07c>6.1.13. Tomcat 架构</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-微服务" class="sidebar-link reco-side-_7-微服务" data-v-b57cc07c>7. 微服务</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-1-服务注册发现" class="sidebar-link reco-side-_7-1-1-服务注册发现" data-v-b57cc07c>7.1.1. 服务注册发现</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-2-api-网关" class="sidebar-link reco-side-_7-1-2-api-网关" data-v-b57cc07c>7.1.2. API 网关</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#重点是支持soap-jms-rest间的协议转换。" class="sidebar-link reco-side-重点是支持soap-jms-rest间的协议转换。" data-v-b57cc07c>重点是支持SOAP，JMS，Rest间的协议转换。</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-3-配置中心" class="sidebar-link reco-side-_7-1-3-配置中心" data-v-b57cc07c>7.1.3. 配置中心</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-4-事件调度-kafka" class="sidebar-link reco-side-_7-1-4-事件调度-kafka" data-v-b57cc07c>7.1.4. 事件调度（ kafka ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-5-服务跟踪-starter-sleuth" class="sidebar-link reco-side-_7-1-5-服务跟踪-starter-sleuth" data-v-b57cc07c>7.1.5. 服务跟踪（starter-sleuth）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-6-服务熔断-hystrix" class="sidebar-link reco-side-_7-1-6-服务熔断-hystrix" data-v-b57cc07c>7.1.6. 服务熔断（ Hystrix ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_7-1-7-api-管理" class="sidebar-link reco-side-_7-1-7-api-管理" data-v-b57cc07c>7.1.7. API 管理</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-netty-与-rpc" class="sidebar-link reco-side-_8-netty-与-rpc" data-v-b57cc07c>8. NETTY 与 RPC</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-1-netty-原理" class="sidebar-link reco-side-_8-1-1-netty-原理" data-v-b57cc07c>8.1.1. Netty 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-2-netty-高性能" class="sidebar-link reco-side-_8-1-2-netty-高性能" data-v-b57cc07c>8.1.2. Netty 高性能</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-3-netty-rpc-实现" class="sidebar-link reco-side-_8-1-3-netty-rpc-实现" data-v-b57cc07c>8.1.3. Netty RPC 实现</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-4-rmi-实现方式" class="sidebar-link reco-side-_8-1-4-rmi-实现方式" data-v-b57cc07c>8.1.4. RMI 实现方式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-5-protoclol-buffer" class="sidebar-link reco-side-_8-1-5-protoclol-buffer" data-v-b57cc07c>8.1.5. Protoclol Buffer</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_8-1-6-thrift" class="sidebar-link reco-side-_8-1-6-thrift" data-v-b57cc07c>8.1.6. Thrift</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-网络" class="sidebar-link reco-side-_9-网络" data-v-b57cc07c>9. 网络</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-1-1-网络-7-层架构" class="sidebar-link reco-side-_9-1-1-网络-7-层架构" data-v-b57cc07c>9.1.1. 网络 7 层架构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-1-2-tcp-ip-原理" class="sidebar-link reco-side-_9-1-2-tcp-ip-原理" data-v-b57cc07c>9.1.2. TCP/IP 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-1-3-tcp-三次握手-四次挥手" class="sidebar-link reco-side-_9-1-3-tcp-三次握手-四次挥手" data-v-b57cc07c>9.1.3. TCP 三次握手 / 四次挥手</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-1-4-http-原理" class="sidebar-link reco-side-_9-1-4-http-原理" data-v-b57cc07c>9.1.4. HTTP 原理</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_9-1-5-cdn-原理" class="sidebar-link reco-side-_9-1-5-cdn-原理" data-v-b57cc07c>9.1.5. CDN 原理</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_10-日志" class="sidebar-link reco-side-_10-日志" data-v-b57cc07c>10. 日志</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_10-1-1-slf4j" class="sidebar-link reco-side-_10-1-1-slf4j" data-v-b57cc07c>10.1.1. Slf4j</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_10-1-2-log4j" class="sidebar-link reco-side-_10-1-2-log4j" data-v-b57cc07c>10.1.2. Log4j</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_10-1-3-logback" class="sidebar-link reco-side-_10-1-3-logback" data-v-b57cc07c>10.1.3. LogBack</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_10-1-4-elk" class="sidebar-link reco-side-_10-1-4-elk" data-v-b57cc07c>10.1.4. ELK</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_11-zookeeper" class="sidebar-link reco-side-_11-zookeeper" data-v-b57cc07c>11. ZOOKEEPER</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_11-1-1-zookeeper-概念" class="sidebar-link reco-side-_11-1-1-zookeeper-概念" data-v-b57cc07c>11.1.1. Zookeeper 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_11-1-1-zookeeper-角色" class="sidebar-link reco-side-_11-1-1-zookeeper-角色" data-v-b57cc07c>11.1.1. Zookeeper 角色</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_11-1-2-zookeeper-工作原理-原子广播" class="sidebar-link reco-side-_11-1-2-zookeeper-工作原理-原子广播" data-v-b57cc07c>11.1.2. Zookeeper 工作原理（原子广播）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_11-1-3-znode-有四种形式的目录节点" class="sidebar-link reco-side-_11-1-3-znode-有四种形式的目录节点" data-v-b57cc07c>11.1.3. Znode 有四种形式的目录节点</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_12-kafka" class="sidebar-link reco-side-_12-kafka" data-v-b57cc07c>12. KAFKA</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_12-1-1-kafka-概念" class="sidebar-link reco-side-_12-1-1-kafka-概念" data-v-b57cc07c>12.1.1. Kafka 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_12-1-2-kafka-数据存储设计" class="sidebar-link reco-side-_12-1-2-kafka-数据存储设计" data-v-b57cc07c>12.1.2. Kafka 数据存储设计</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_12-1-3-生产者设计" class="sidebar-link reco-side-_12-1-3-生产者设计" data-v-b57cc07c>12.1.3. 生产者设计</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_12-1-1-消费者设计" class="sidebar-link reco-side-_12-1-1-消费者设计" data-v-b57cc07c>12.1.1. 消费者设计</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_13-rabbitmq" class="sidebar-link reco-side-_13-rabbitmq" data-v-b57cc07c>13. RABBITMQ</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_13-1-1-概念" class="sidebar-link reco-side-_13-1-1-概念" data-v-b57cc07c>13.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_13-1-2-rabbitmq-架构" class="sidebar-link reco-side-_13-1-2-rabbitmq-架构" data-v-b57cc07c>13.1.2. RabbitMQ 架构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_13-1-3-exchange-类型" class="sidebar-link reco-side-_13-1-3-exchange-类型" data-v-b57cc07c>13.1.3. Exchange 类型</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-hbase" class="sidebar-link reco-side-_14-hbase" data-v-b57cc07c>14. HBASE</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-1-概念" class="sidebar-link reco-side-_14-1-1-概念" data-v-b57cc07c>14.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-2-列式存储" class="sidebar-link reco-side-_14-1-2-列式存储" data-v-b57cc07c>14.1.2. 列式存储</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-3-hbase-核心概念" class="sidebar-link reco-side-_14-1-3-hbase-核心概念" data-v-b57cc07c>14.1.3. Hbase 核心概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-4-hbase-核心架构" class="sidebar-link reco-side-_14-1-4-hbase-核心架构" data-v-b57cc07c>14.1.4. Hbase 核心架构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-5-hbase-的写逻辑" class="sidebar-link reco-side-_14-1-5-hbase-的写逻辑" data-v-b57cc07c>14.1.5. Hbase 的写逻辑</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_14-1-6-hbase-vs-cassandra" class="sidebar-link reco-side-_14-1-6-hbase-vs-cassandra" data-v-b57cc07c>14.1.6. HBase vs Cassandra</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_15-mongodb" class="sidebar-link reco-side-_15-mongodb" data-v-b57cc07c>15. MONGODB</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_15-1-1-概念" class="sidebar-link reco-side-_15-1-1-概念" data-v-b57cc07c>15.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_15-1-2-特点" class="sidebar-link reco-side-_15-1-2-特点" data-v-b57cc07c>15.1.2. 特点</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-cassandra" class="sidebar-link reco-side-_16-cassandra" data-v-b57cc07c>16. CASSANDRA</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-1-概念" class="sidebar-link reco-side-_16-1-1-概念" data-v-b57cc07c>16.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-2-数据模型" class="sidebar-link reco-side-_16-1-2-数据模型" data-v-b57cc07c>16.1.2. 数据模型</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-3-cassandra-一致-hash-和虚拟节点" class="sidebar-link reco-side-_16-1-3-cassandra-一致-hash-和虚拟节点" data-v-b57cc07c>16.1.3. Cassandra 一致 Hash 和虚拟节点</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-4-gossip-协议" class="sidebar-link reco-side-_16-1-4-gossip-协议" data-v-b57cc07c>16.1.4. Gossip 协议</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-5-数据复制" class="sidebar-link reco-side-_16-1-5-数据复制" data-v-b57cc07c>16.1.5. 数据复制</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-6-数据写请求和协调者" class="sidebar-link reco-side-_16-1-6-数据写请求和协调者" data-v-b57cc07c>16.1.6. 数据写请求和协调者</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-7-数据读请求和后台修复" class="sidebar-link reco-side-_16-1-7-数据读请求和后台修复" data-v-b57cc07c>16.1.7. 数据读请求和后台修复</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-8-数据存储-commitlog、memtable、sstable" class="sidebar-link reco-side-_16-1-8-数据存储-commitlog、memtable、sstable" data-v-b57cc07c>16.1.8. 数据存储（CommitLog、MemTable、SSTable）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-9-二级索引-对要索引的-value-摘要-生成-rowkey" class="sidebar-link reco-side-_16-1-9-二级索引-对要索引的-value-摘要-生成-rowkey" data-v-b57cc07c>16.1.9. 二级索引（对要索引的 value 摘要，生成 RowKey ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_16-1-10-数据读写" class="sidebar-link reco-side-_16-1-10-数据读写" data-v-b57cc07c>16.1.10. 数据读写</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-设计模式" class="sidebar-link reco-side-_17-设计模式" data-v-b57cc07c>17. 设计模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-1-设计原则" class="sidebar-link reco-side-_17-1-1-设计原则" data-v-b57cc07c>17.1.1. 设计原则</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-2-工厂方法模式" class="sidebar-link reco-side-_17-1-2-工厂方法模式" data-v-b57cc07c>17.1.2. 工厂方法模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-3-抽象工厂模式" class="sidebar-link reco-side-_17-1-3-抽象工厂模式" data-v-b57cc07c>17.1.3. 抽象工厂模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-4-单例模式" class="sidebar-link reco-side-_17-1-4-单例模式" data-v-b57cc07c>17.1.4. 单例模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-5-建造者模式" class="sidebar-link reco-side-_17-1-5-建造者模式" data-v-b57cc07c>17.1.5. 建造者模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-6-原型模式" class="sidebar-link reco-side-_17-1-6-原型模式" data-v-b57cc07c>17.1.6. 原型模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-7-适配器模式" class="sidebar-link reco-side-_17-1-7-适配器模式" data-v-b57cc07c>17.1.7. 适配器模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-8-装饰器模式" class="sidebar-link reco-side-_17-1-8-装饰器模式" data-v-b57cc07c>17.1.8. 装饰器模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-9-代理模式" class="sidebar-link reco-side-_17-1-9-代理模式" data-v-b57cc07c>17.1.9. 代理模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-10-外观模式" class="sidebar-link reco-side-_17-1-10-外观模式" data-v-b57cc07c>17.1.10. 外观模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-11-桥接模式" class="sidebar-link reco-side-_17-1-11-桥接模式" data-v-b57cc07c>17.1.11. 桥接模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-12-组合模式" class="sidebar-link reco-side-_17-1-12-组合模式" data-v-b57cc07c>17.1.12. 组合模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-13-享元模式" class="sidebar-link reco-side-_17-1-13-享元模式" data-v-b57cc07c>17.1.13. 享元模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-14-策略模式" class="sidebar-link reco-side-_17-1-14-策略模式" data-v-b57cc07c>17.1.14. 策略模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-15-模板方法模式" class="sidebar-link reco-side-_17-1-15-模板方法模式" data-v-b57cc07c>17.1.15. 模板方法模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-16-观察者模式" class="sidebar-link reco-side-_17-1-16-观察者模式" data-v-b57cc07c>17.1.16. 观察者模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-17-迭代子模式" class="sidebar-link reco-side-_17-1-17-迭代子模式" data-v-b57cc07c>17.1.17. 迭代子模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-18-责任链模式" class="sidebar-link reco-side-_17-1-18-责任链模式" data-v-b57cc07c>17.1.18. 责任链模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-19-命令模式" class="sidebar-link reco-side-_17-1-19-命令模式" data-v-b57cc07c>17.1.19. 命令模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_1-7-1-20-备忘录模式" class="sidebar-link reco-side-_1-7-1-20-备忘录模式" data-v-b57cc07c>1 7.1.20. 备忘录模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-21-状态模式" class="sidebar-link reco-side-_17-1-21-状态模式" data-v-b57cc07c>17.1.21. 状态模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-22-访问者模式" class="sidebar-link reco-side-_17-1-22-访问者模式" data-v-b57cc07c>17.1.22. 访问者模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-23-中介者模式" class="sidebar-link reco-side-_17-1-23-中介者模式" data-v-b57cc07c>17.1.23. 中介者模式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_17-1-24-解释器模式" class="sidebar-link reco-side-_17-1-24-解释器模式" data-v-b57cc07c>17.1.24. 解释器模式</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-负载均衡" class="sidebar-link reco-side-_18-负载均衡" data-v-b57cc07c>18. 负载均衡</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-1-四层负载均衡-vs-七层负载均衡" class="sidebar-link reco-side-_18-1-1-四层负载均衡-vs-七层负载均衡" data-v-b57cc07c>18.1.1. 四层负载均衡 vs 七层负载均衡</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-2-负载均衡算法-策略" class="sidebar-link reco-side-_18-1-2-负载均衡算法-策略" data-v-b57cc07c>18.1.2. 负载均衡算法 / 策略</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-3-lvs" class="sidebar-link reco-side-_18-1-3-lvs" data-v-b57cc07c>18.1.3. LVS</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-4-keepalive" class="sidebar-link reco-side-_18-1-4-keepalive" data-v-b57cc07c>18.1.4. Keepalive</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-5-nginx-反向代理负载均衡" class="sidebar-link reco-side-_18-1-5-nginx-反向代理负载均衡" data-v-b57cc07c>18.1.5. Nginx 反向代理负载均衡</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#-3" class="sidebar-link reco-side--3" data-v-b57cc07c>}</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_18-1-6-haproxy" class="sidebar-link reco-side-_18-1-6-haproxy" data-v-b57cc07c>18.1.6. HAProxy</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-数据库" class="sidebar-link reco-side-_19-数据库" data-v-b57cc07c>19. 数据库</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-1-存储引擎" class="sidebar-link reco-side-_19-1-1-存储引擎" data-v-b57cc07c>19.1.1. 存储引擎</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-2-索引" class="sidebar-link reco-side-_19-1-2-索引" data-v-b57cc07c>19.1.2. 索引</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-3-数据库三范式" class="sidebar-link reco-side-_19-1-3-数据库三范式" data-v-b57cc07c>19.1.3. 数据库三范式</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-4-数据库是事务" class="sidebar-link reco-side-_19-1-4-数据库是事务" data-v-b57cc07c>19.1.4. 数据库是事务</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-5-存储过程-特定功能的-sql-语句集" class="sidebar-link reco-side-_19-1-5-存储过程-特定功能的-sql-语句集" data-v-b57cc07c>19.1.5. 存储过程 ( 特定功能的 SQL 语句集 )</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-6-触发器-一段能自动执行的程序" class="sidebar-link reco-side-_19-1-6-触发器-一段能自动执行的程序" data-v-b57cc07c>19.1.6. 触发器 ( 一段能自动执行的程序 )</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-7-数据库并发策略" class="sidebar-link reco-side-_19-1-7-数据库并发策略" data-v-b57cc07c>19.1.7. 数据库并发策略</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-8-数据库锁" class="sidebar-link reco-side-_19-1-8-数据库锁" data-v-b57cc07c>19.1.8. 数据库锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-9-基于-redis-分布式锁" class="sidebar-link reco-side-_19-1-9-基于-redis-分布式锁" data-v-b57cc07c>19.1.9. 基于 Redis 分布式锁</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-10-分区分表" class="sidebar-link reco-side-_19-1-10-分区分表" data-v-b57cc07c>19.1.10. 分区分表</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-11-两阶段提交协议" class="sidebar-link reco-side-_19-1-11-两阶段提交协议" data-v-b57cc07c>19.1.11. 两阶段提交协议</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-12-三阶段提交协议" class="sidebar-link reco-side-_19-1-12-三阶段提交协议" data-v-b57cc07c>19.1.12. 三阶段提交协议</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-13-柔性事务" class="sidebar-link reco-side-_19-1-13-柔性事务" data-v-b57cc07c>19.1.13. 柔性事务</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_19-1-14-cap" class="sidebar-link reco-side-_19-1-14-cap" data-v-b57cc07c>19.1.14. CAP</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-一致性算法" class="sidebar-link reco-side-_20-一致性算法" data-v-b57cc07c>20. 一致性算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-1-paxos" class="sidebar-link reco-side-_20-1-1-paxos" data-v-b57cc07c>20.1.1. Paxos</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-2-zab" class="sidebar-link reco-side-_20-1-2-zab" data-v-b57cc07c>20.1.2. Zab</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-3-raft" class="sidebar-link reco-side-_20-1-3-raft" data-v-b57cc07c>20.1.3. Raft</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-4-nwr" class="sidebar-link reco-side-_20-1-4-nwr" data-v-b57cc07c>20.1.4. NWR</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-5-gossip" class="sidebar-link reco-side-_20-1-5-gossip" data-v-b57cc07c>20.1.5. Gossip</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_20-1-6-一致性-hash" class="sidebar-link reco-side-_20-1-6-一致性-hash" data-v-b57cc07c>20.1.6. 一致性 Hash</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-java-算法" class="sidebar-link reco-side-_21-java-算法" data-v-b57cc07c>21. JAVA 算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-1-二分查找" class="sidebar-link reco-side-_21-1-1-二分查找" data-v-b57cc07c>21.1.1. 二分查找</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-2-冒泡排序算法" class="sidebar-link reco-side-_21-1-2-冒泡排序算法" data-v-b57cc07c>21.1.2. 冒泡排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-3-插入排序算法" class="sidebar-link reco-side-_21-1-3-插入排序算法" data-v-b57cc07c>21.1.3. 插入排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-4-快速排序算法" class="sidebar-link reco-side-_21-1-4-快速排序算法" data-v-b57cc07c>21.1.4. 快速排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-1-希尔排序算法" class="sidebar-link reco-side-_21-1-1-希尔排序算法" data-v-b57cc07c>21.1.1. 希尔排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-2-归并排序算法" class="sidebar-link reco-side-_21-1-2-归并排序算法" data-v-b57cc07c>21.1.2. 归并排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-3-桶排序算法" class="sidebar-link reco-side-_21-1-3-桶排序算法" data-v-b57cc07c>21.1.3. 桶排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-4-基数排序算法" class="sidebar-link reco-side-_21-1-4-基数排序算法" data-v-b57cc07c>21.1.4. 基数排序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-5-剪枝算法" class="sidebar-link reco-side-_21-1-5-剪枝算法" data-v-b57cc07c>21.1.5. 剪枝算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-6-回溯算法" class="sidebar-link reco-side-_21-1-6-回溯算法" data-v-b57cc07c>21.1.6. 回溯算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-7-最短路径算法" class="sidebar-link reco-side-_21-1-7-最短路径算法" data-v-b57cc07c>21.1.7. 最短路径算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-8-最大子数组算法" class="sidebar-link reco-side-_21-1-8-最大子数组算法" data-v-b57cc07c>21.1.8. 最大子数组算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-9-最长公共子序算法" class="sidebar-link reco-side-_21-1-9-最长公共子序算法" data-v-b57cc07c>21.1.9. 最长公共子序算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_21-1-10-最小生成树算法" class="sidebar-link reco-side-_21-1-10-最小生成树算法" data-v-b57cc07c>21.1.10. 最小生成树算法</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-数据结构" class="sidebar-link reco-side-_22-数据结构" data-v-b57cc07c>22. 数据结构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-1-栈-stack" class="sidebar-link reco-side-_22-1-1-栈-stack" data-v-b57cc07c>22.1.1. 栈（ stack ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-2-队列-queue" class="sidebar-link reco-side-_22-1-2-队列-queue" data-v-b57cc07c>22.1.2. 队列（ queue ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-3-链表-link" class="sidebar-link reco-side-_22-1-3-链表-link" data-v-b57cc07c>22.1.3. 链表（ Link ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-4-散列表-hash-table" class="sidebar-link reco-side-_22-1-4-散列表-hash-table" data-v-b57cc07c>22.1.4. 散列表（ Hash Table ）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-5-排序二叉树" class="sidebar-link reco-side-_22-1-5-排序二叉树" data-v-b57cc07c>22.1.5. 排序二叉树</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-6-红黑树" class="sidebar-link reco-side-_22-1-6-红黑树" data-v-b57cc07c>22.1.6. 红黑树</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-7-b-tree" class="sidebar-link reco-side-_22-1-7-b-tree" data-v-b57cc07c>22.1.7. B-TREE</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_22-1-8-位图" class="sidebar-link reco-side-_22-1-8-位图" data-v-b57cc07c>22.1.8. 位图</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_23-加密算法" class="sidebar-link reco-side-_23-加密算法" data-v-b57cc07c>23. 加密算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_23-1-1-aes" class="sidebar-link reco-side-_23-1-1-aes" data-v-b57cc07c>23.1.1. AES</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_23-1-2-rsa" class="sidebar-link reco-side-_23-1-2-rsa" data-v-b57cc07c>23.1.2. RSA</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_23-1-3-crc" class="sidebar-link reco-side-_23-1-3-crc" data-v-b57cc07c>23.1.3. CRC............................................................................................................................................</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_23-1-4-md5" class="sidebar-link reco-side-_23-1-4-md5" data-v-b57cc07c>23.1.4. MD5</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-分布式缓存" class="sidebar-link reco-side-_24-分布式缓存" data-v-b57cc07c>24. 分布式缓存</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-1-1-缓存雪崩" class="sidebar-link reco-side-_24-1-1-缓存雪崩" data-v-b57cc07c>24.1.1. 缓存雪崩</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-1-2-缓存穿透" class="sidebar-link reco-side-_24-1-2-缓存穿透" data-v-b57cc07c>24.1.2. 缓存穿透</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-1-3-缓存预热" class="sidebar-link reco-side-_24-1-3-缓存预热" data-v-b57cc07c>24.1.3. 缓存预热</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-1-4-缓存更新" class="sidebar-link reco-side-_24-1-4-缓存更新" data-v-b57cc07c>24.1.4. 缓存更新</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_24-1-5-缓存降级" class="sidebar-link reco-side-_24-1-5-缓存降级" data-v-b57cc07c>24.1.5. 缓存降级</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_25-hadoop" class="sidebar-link reco-side-_25-hadoop" data-v-b57cc07c>25. HADOOP</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_25-1-1-概念" class="sidebar-link reco-side-_25-1-1-概念" data-v-b57cc07c>25.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_25-1-2-hdfs" class="sidebar-link reco-side-_25-1-2-hdfs" data-v-b57cc07c>25.1.2. HDFS</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_25-1-3-mapreduce" class="sidebar-link reco-side-_25-1-3-mapreduce" data-v-b57cc07c>25.1.3. MapReduce</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_25-1-4-hadoop-mapreduce-作业的生命周期" class="sidebar-link reco-side-_25-1-4-hadoop-mapreduce-作业的生命周期" data-v-b57cc07c>25.1.4. Hadoop MapReduce 作业的生命周期</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-spark" class="sidebar-link reco-side-_26-spark" data-v-b57cc07c>26. SPARK</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-1-概念" class="sidebar-link reco-side-_26-1-1-概念" data-v-b57cc07c>26.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-2-核心架构" class="sidebar-link reco-side-_26-1-2-核心架构" data-v-b57cc07c>26.1.2. 核心架构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-3-核心组件" class="sidebar-link reco-side-_26-1-3-核心组件" data-v-b57cc07c>26.1.3. 核心组件</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-4-spark-编程模型" class="sidebar-link reco-side-_26-1-4-spark-编程模型" data-v-b57cc07c>26.1.4. SPARK 编程模型</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-5-spark-计算模型" class="sidebar-link reco-side-_26-1-5-spark-计算模型" data-v-b57cc07c>26.1.5. SPARK 计算模型</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-6-spark-运行流程" class="sidebar-link reco-side-_26-1-6-spark-运行流程" data-v-b57cc07c>26.1.6. SPARK 运行流程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-7-spark-rdd-流程" class="sidebar-link reco-side-_26-1-7-spark-rdd-流程" data-v-b57cc07c>26.1.7. SPARK RDD 流程</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_26-1-8-spark-rdd" class="sidebar-link reco-side-_26-1-8-spark-rdd" data-v-b57cc07c>26.1.8. SPARK RDD</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-storm" class="sidebar-link reco-side-_27-storm" data-v-b57cc07c>27. STORM</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-1-1-概念" class="sidebar-link reco-side-_27-1-1-概念" data-v-b57cc07c>27.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-1-1-集群架构" class="sidebar-link reco-side-_27-1-1-集群架构" data-v-b57cc07c>27.1.1. 集群架构</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-1-2-编程模型-spout-tuple-bolt" class="sidebar-link reco-side-_27-1-2-编程模型-spout-tuple-bolt" data-v-b57cc07c>27.1.2. 编程模型（spout-\&gt;tuple-\&gt;bolt）</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-1-3-topology-运行" class="sidebar-link reco-side-_27-1-3-topology-运行" data-v-b57cc07c>27.1.3. Topology 运行</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_27-1-4-storm-streaming-grouping" class="sidebar-link reco-side-_27-1-4-storm-streaming-grouping" data-v-b57cc07c>27.1.4. Storm Streaming Grouping</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-yarn" class="sidebar-link reco-side-_28-yarn" data-v-b57cc07c>28. YARN</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-1-1-概念" class="sidebar-link reco-side-_28-1-1-概念" data-v-b57cc07c>28.1.1. 概念</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-1-2-resourcemanager" class="sidebar-link reco-side-_28-1-2-resourcemanager" data-v-b57cc07c>28.1.2. ResourceManager</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-1-3-nodemanager" class="sidebar-link reco-side-_28-1-3-nodemanager" data-v-b57cc07c>28.1.3. NodeManager</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-1-4-applicationmaster" class="sidebar-link reco-side-_28-1-4-applicationmaster" data-v-b57cc07c>28.1.4. ApplicationMaster</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_28-1-5-yarn运行流程" class="sidebar-link reco-side-_28-1-5-yarn运行流程" data-v-b57cc07c>28.1.5. YARN运行流程</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-机器学习" class="sidebar-link reco-side-_29-机器学习" data-v-b57cc07c>29. 机器学习</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-1-决策树" class="sidebar-link reco-side-_29-1-1-决策树" data-v-b57cc07c>29.1.1. 决策树</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-2-随机森林算法" class="sidebar-link reco-side-_29-1-2-随机森林算法" data-v-b57cc07c>29.1.2. 随机森林算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-3-逻辑回归" class="sidebar-link reco-side-_29-1-3-逻辑回归" data-v-b57cc07c>29.1.3. 逻辑回归</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-4-svm" class="sidebar-link reco-side-_29-1-4-svm" data-v-b57cc07c>29.1.4. SVM............................................................................................................................................</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-5-朴素贝叶斯" class="sidebar-link reco-side-_29-1-5-朴素贝叶斯" data-v-b57cc07c>29.1.5. 朴素贝叶斯</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-6-k-最近邻算法" class="sidebar-link reco-side-_29-1-6-k-最近邻算法" data-v-b57cc07c>29.1.6. K 最近邻算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-7-k-均值算法" class="sidebar-link reco-side-_29-1-7-k-均值算法" data-v-b57cc07c>29.1.7. K 均值算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-8-adaboost-算法" class="sidebar-link reco-side-_29-1-8-adaboost-算法" data-v-b57cc07c>29.1.8. Adaboost 算法</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-9-神经网络" class="sidebar-link reco-side-_29-1-9-神经网络" data-v-b57cc07c>29.1.9. 神经网络</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_29-1-10-马尔可夫" class="sidebar-link reco-side-_29-1-10-马尔可夫" data-v-b57cc07c>29.1.10. 马尔可夫</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-云计算" class="sidebar-link reco-side-_30-云计算" data-v-b57cc07c>30. 云计算</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-1-1-saas" class="sidebar-link reco-side-_30-1-1-saas" data-v-b57cc07c>30.1.1. SaaS</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-1-2-paas" class="sidebar-link reco-side-_30-1-2-paas" data-v-b57cc07c>30.1.2. PaaS</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-1-3-iaas" class="sidebar-link reco-side-_30-1-3-iaas" data-v-b57cc07c>30.1.3. IaaS</a></li><li class="level-3" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-1-4-docker" class="sidebar-link reco-side-_30-1-4-docker" data-v-b57cc07c>30.1.4. Docker</a></li><li class="level-2" data-v-b57cc07c><a href="/MyReader/note/book/book_0001.html#_30-1-5-openstack" class="sidebar-link reco-side-_30-1-5-openstack" data-v-b57cc07c>30.1.5. Openstack</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/MyReader/assets/js/app.5ccfdbdc.js" defer></script><script src="/MyReader/assets/js/3.ead5ad5d.js" defer></script><script src="/MyReader/assets/js/1.f20a062a.js" defer></script><script src="/MyReader/assets/js/12.69678de1.js" defer></script>
  </body>
</html>
